<!DOCTYPE html>
<!--[if lt IE 7]> <html class="ie6 ie"> <![endif]-->
<!--[if IE 7]>    <html class="ie7 ie"> <![endif]-->
<!--[if IE 8]>    <html class="ie8 ie"> <![endif]-->
<!--[if IE 9]>    <html class="ie9 ie"> <![endif]-->
<!--[if !IE]> --> <html> <!-- <![endif]-->

<!-- Mirrored from seop.illc.uva.nl/entries/science-theory-observation/ by HTTrack Website Copier/3.x [XR&CO'2014], Wed, 22 Jun 2022 19:55:08 GMT -->
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>
Theory and Observation in Science (Stanford Encyclopedia of Philosophy)
</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="robots" content="noarchive, noodp" />
<meta property="citation_title" content="Theory and Observation in Science" />
<meta property="citation_author" content="Boyd, Nora Mills" />
<meta property="citation_author" content="Bogen, James" />
<meta property="citation_publication_date" content="2009/01/06" />
<meta name="DC.title" content="Theory and Observation in Science" />
<meta name="DC.creator" content="Boyd, Nora Mills" />
<meta name="DC.creator" content="Bogen, James" />
<meta name="DCTERMS.issued" content="2009-01-06" />
<meta name="DCTERMS.modified" content="2021-06-14" />

<!-- NOTE: Import webfonts using this link: -->
<link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,300,600,200&amp;subset=latin,latin-ext" rel="stylesheet" type="text/css" />

<link rel="stylesheet" type="text/css" media="screen,handheld" href="../../css/bootstrap.min.css" />
<link rel="stylesheet" type="text/css" media="screen,handheld" href="../../css/bootstrap-responsive.min.css" />
<link rel="stylesheet" type="text/css" href="../../css/font-awesome.min.css" />
<!--[if IE 7]> <link rel="stylesheet" type="text/css" href="../../css/font-awesome-ie7.min.css"> <![endif]-->
<link rel="stylesheet" type="text/css" media="screen,handheld" href="../../css/style.css" />
<link rel="stylesheet" type="text/css" media="print" href="../../css/print.css" />
<link rel="stylesheet" type="text/css" href="../../css/entry.css" />
<!--[if IE]> <link rel="stylesheet" type="text/css" href="../../css/ie.css" /> <![endif]-->
<script type="text/javascript" src="../../js/jquery-1.9.1.min.js"></script>
<script type="text/javascript" src="../../js/bootstrap.min.js"></script>

<!-- NOTE: Javascript for sticky behavior needed on article and ToC pages -->
<script type="text/javascript" src="../../js/jquery-scrolltofixed-min.js"></script>
<script type="text/javascript" src="../../js/entry.js"></script>

<!-- SEP custom script -->
<script type="text/javascript" src="../../js/sep.js"></script>
</head>

<!-- NOTE: The nojs class is removed from the page if javascript is enabled. Otherwise, it drives the display when there is no javascript. -->
<body class="nojs article" id="pagetopright">
<div id="container">
<div id="header-wrapper">
  <div id="header">
    <div id="branding">
      <div id="site-logo"><a href="../../index.html"><img src="../../symbols/sep-man-red.png" alt="SEP logo" /></a></div>
      <div id="site-title"><a href="../../index.html">Stanford Encyclopedia of Philosophy</a></div>
    </div>
    <div id="navigation">
      <div class="navbar">
        <div class="navbar-inner">
          <div class="container">
            <button class="btn btn-navbar collapsed" data-target=".collapse-main-menu" data-toggle="collapse" type="button"> <i class="icon-reorder"></i> Menu </button>
            <div class="nav-collapse collapse-main-menu in collapse">
              <ul class="nav">
                <li class="dropdown open"><a id="drop1" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-book"></i> Browse</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop1">
                    <li><a href="../../contents.html">Table of Contents</a></li>
                    <li><a href="../../new.html">What's New</a></li>
                    <li><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/random">Random Entry</a></li>
                    <li><a href="../../published.html">Chronological</a></li>
                    <li><a href="../../archives/index.html">Archives</a></li>
                  </ul>
                </li>
                <li class="dropdown open"><a id="drop2" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-info-sign"></i> About</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop2">
                    <li><a href="../../info.html">Editorial Information</a></li>
                    <li><a href="../../about.html">About the SEP</a></li>
                    <li><a href="../../board.html">Editorial Board</a></li>
                    <li><a href="../../cite.html">How to Cite the SEP</a></li>
                    <li><a href="../../special-characters.html">Special Characters</a></li>
                    <li><a href="../../tools/index.html">Advanced Tools</a></li>
                    <li><a href="../../contact.html">Contact</a></li>
                  </ul>
                </li>
                <li class="dropdown open"><a id="drop3" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-leaf"></i> Support SEP</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop3">
                    <li><a href="../../support/index.html">Support the SEP</a></li>
                    <li><a href="../../support/friends.html">PDFs for SEP Friends</a></li>
                    <li><a href="../../support/donate.html">Make a Donation</a></li>
                    <li><a href="../../support/sepia.html">SEPIA for Libraries</a></li>
                  </ul>
                </li>
              </ul>
            </div>
          </div>
        </div>
      </div>
    </div>
    <!-- End navigation -->
    
    <div id="search">
      <form id="search-form" method="get" action="https://seop.illc.uva.nl/search/searcher.py">
        <input type="search" name="query" placeholder="Search SEP" />
        <div class="search-btn-wrapper"><button class="btn search-btn" type="submit"><i class="icon-search"></i></button></div>
      </form>
    </div>
    <!-- End search --> 
    
  </div>
  <!-- End header --> 
</div>
<!-- End header wrapper -->

<div id="content">

<!-- Begin article sidebar -->
<div id="article-sidebar" class="sticky">
  <div class="navbar">
    <div class="navbar-inner">
      <div class="container">
        <button class="btn btn-navbar" data-target=".collapse-sidebar" data-toggle="collapse" type="button"> <i class="icon-reorder"></i> Entry Navigation </button>
        <div id="article-nav" class="nav-collapse collapse-sidebar in collapse">
          <ul class="nav">
            <li><a href="#toc">Entry Contents</a></li>
            <li><a href="#Bib">Bibliography</a></li>
            <li><a href="#Aca">Academic Tools</a></li>
            <li><a href="https://leibniz.stanford.edu/friends/preview/science-theory-observation/">Friends PDF Preview <i class="icon-external-link"></i></a></li>
            <li><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=science-theory-observation">Author and Citation Info <i class="icon-external-link"></i></a> </li>
            <li><a href="#pagetopright" class="back-to-top">Back to Top <i class="icon-angle-up icon2x"></i></a></li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</div>
<!-- End article sidebar --> 

<!-- NOTE: Article content must have two wrapper divs: id="article" and id="article-content" -->
<div id="article">
<div id="article-content">

<!-- BEGIN ARTICLE HTML -->


<div id="aueditable"><!--DO NOT MODIFY THIS LINE AND ABOVE-->

<h1>Theory and Observation in Science</h1><div id="pubinfo"><em>First published Tue Jan 6, 2009; substantive revision Mon Jun 14, 2021</em></div>

<div id="preamble">

<p>
Scientists obtain a great deal of the evidence they use by collecting
and producing empirical results. Much of the standard philosophical
literature on this subject comes from 20<sup>th</sup> century logical
empiricists, their followers, and critics who embraced their issues
while objecting to some of their aims and assumptions. Discussions
about empirical evidence have tended to focus on epistemological
questions regarding its role in theory testing. This entry follows
that precedent, even though empirical evidence also plays important
and philosophically interesting roles in other areas including
scientific discovery, the development of experimental tools and
techniques, and the application of scientific theories to practical
problems.</p>

<p>
The logical empiricists and their followers devoted much of their
attention to the distinction between observables and unobservables,
the form and content of observation reports, and the epistemic bearing
of observational evidence on theories it is used to evaluate.
Philosophical work in this tradition was characterized by the aim of
conceptually separating theory and observation, so that observation
could serve as the pure basis of theory appraisal. More recently, the
focus of the philosophical literature has shifted away from these
issues, and their close association to the languages and logics of
science, to investigations of how empirical data are generated,
analyzed, and used in practice. With this shift, we also see
philosophers largely setting aside the aspiration of a pure
observational basis for scientific knowledge and instead embracing a
view of science in which the theoretical and empirical are usefully
intertwined. This entry discusses these topics under the following
headings:</p>
</div> 

<div id="toc"><!--Entry Contents-->
<ul>
	<li><a href="#Int">1. Introduction</a></li>
	<li><a href="#Observationanddata">2. Observation and data</a>
	<ul>
		<li><a href="#Traditionalempiricism">2.1 Traditional empiricism</a></li>
		<li><a href="#Irrelevanceofobservation">2.2 The irrelevance of observation per se</a></li>
		<li><a href="#Dataandphenomena">2.3 Data and phenomena</a></li>
	</ul>
	</li>
	<li><a href="#Theoryandvalueladenness">3. Theory and value ladenness</a>
	<ul>
		<li><a href="#Perception">3.1 Perception</a></li>
		<li><a href="#Assuming">3.2 Assuming the theory to be tested</a></li>
		<li><a href="#Semantics">3.3 Semantics</a></li>
		<li><a href="#Values">3.4 Values</a></li>
		<li><a href="#Reuse">3.5 Reuse</a></li>
	</ul>
	</li>
	<li><a href="#Epistemicvalue">4. The epistemic value of empirical evidence</a>
	<ul>
		<li><a href="#Confirmation">4.1 Confirmation</a></li>
		<li><a href="#Saving">4.2 Saving the phenomena</a></li>
		<li><a href="#Empirical">4.3 Empirical adequacy</a></li>
	</ul>
	</li>
	<li><a href="#Con">5. Conclusion</a></li>
	<li><a href="#Bib">Bibliography</a></li>
	<li><a href="#Aca">Academic Tools</a></li>
	<li><a href="#Oth">Other Internet Resources</a></li>
	<li><a href="#Rel">Related Entries</a></li>
</ul>
<!--Entry Contents-->

<hr /></div>

<div id="main-text">

<h2><a name="Int">1. Introduction</a></h2>

<p>
Philosophers of science have traditionally recognized a special role
for observations in the epistemology of science. Observations are the
conduit through which the &lsquo;tribunal of experience&rsquo;
delivers its verdicts on scientific hypotheses and theories. The
evidential value of an observation has been assumed to depend on how
sensitive it is to whatever it is used to study. But this in turn
depends on the adequacy of any theoretical claims its sensitivity may
depend on. For example, we can challenge the use of a particular
thermometer reading to support a prediction of a patient&rsquo;s
temperature by challenging theoretical claims having to do with
whether a reading from a thermometer like this one, applied in the
same way under similar conditions, should indicate the patient&rsquo;s
temperature well enough to count in favor of or against the
prediction. At least some of those theoretical claims will be such
that regardless of whether an investigator explicitly endorses, or is
even aware of them, her use of the thermometer reading would be
undermined by their falsity. All observations and uses of
observational evidence are theory laden in this sense (cf. Chang 2005,
Azzouni 2004). As the example of the thermometer illustrates,
analogues of Norwood Hanson&rsquo;s claim that seeing is a theory
laden undertaking apply just as well to equipment generated
observations (Hanson 1958, 19). But if all observations and empirical
data are theory laden, how can they provide reality-based, objective
epistemic constraints on scientific reasoning?</p>

<p>
Recent scholarship has turned this question on its head. Why think
that theory ladenness of empirical results would be problematic in the
first place? If the theoretical assumptions with which the results are
imbued are correct, what is the harm of it? After all, it is in virtue
of those assumptions that the fruits of empirical investigation can be
&lsquo;put in touch&rsquo; with theorizing at all. A number scribbled
in a lab notebook can do a scientist little epistemic good unless she
can recruit the relevant background assumptions to even recognize it
as a reading of the patient&rsquo;s temperature. But philosophers have
embraced an entangled picture of the theoretical and empirical that
goes much deeper than this. Lloyd (2012) advocates for what she calls
&ldquo;complex empiricism&rdquo; in which there is &ldquo;no pristine
separation of model and data&rdquo; (397). Bogen (2016) points out
that &ldquo;impure empirical evidence&rdquo; (i.e. evidence that
incorporates the judgements of scientists) &ldquo;often tells us more
about the world that it could have if it were pure&rdquo; (784).
Indeed, Longino (2020) has urged that &ldquo;[t]he na&iuml;ve fantasy
that data have an immediate relation to phenomena of the world, that
they are &lsquo;objective&rsquo; in some strong, ontological sense of
that term, that they are the facts of the world directly speaking to
us, should be finally laid to rest&rdquo; and that &ldquo;even the
primary, original, state of data is not free from researchers&rsquo;
value- and theory-laden selection and organization&rdquo; (391).</p>

<p>
There is not widespread agreement among philosophers of science about
how to characterize the nature of scientific theories. What is a
theory? According to the traditional syntactic view, theories are
considered to be collections of sentences couched in logical language,
which must then be supplemented with correspondence rules in order to
be interpreted. Construed in this way, theories include maximally
general explanatory and predictive laws (Coulomb&rsquo;s law of
electrical attraction and repulsion, and Maxwellian electromagnetism
equations for example), along with lesser generalizations that
describe more limited natural and experimental phenomena (e.g., the
ideal gas equations describing relations between temperatures and
pressures of enclosed gasses, and general descriptions of positional
astronomical regularities). In contrast, the semantic view casts
theories as the space of states possible according to the theory, or
the set of mathematical models permissible according to the theory
(see Suppe 1977). However, there are also significantly more
ecumenical interpretations of what it means to be a scientific theory,
which include elements of diverse kinds. To take just one illustrative
example, Borrelli (2012) characterizes the Standard Model of particle
physics as a theoretical framework involving what she calls
&ldquo;theoretical cores&rdquo; that are composed of mathematical
structures, verbal stories, and analogies with empirical references
mixed together (196). This entry aims to accommodate all of these
views about the nature of scientific theories.</p>

<p>
In this entry, we trace the contours of traditional philosophical
engagement with questions surrounding theory and observation in
science that attempted to segregate the theoretical from the
observational, and to cleanly delineate between the observable and the
unobservable. We also discuss the more recent scholarship that
supplants the primacy of observation by human sensory perception with
an instrument-inclusive conception of data production and that
embraces the intertwining of theoretical and empirical in the
production of useful scientific results. Although theory testing
dominates much of the standard philosophical literature on
observation, much of what this entry says about the role of
observation in theory testing applies also to its role in inventing,
and modifying theories, and applying them to tasks in engineering,
medicine, and other practical enterprises.</p>

<h2><a name="Observationanddata">2. Observation and data</a></h2>

<h3><a name="Traditionalempiricism">2.1 Traditional empiricism</a></h3>

<p>
Reasoning from observations has been important to scientific practice
at least since the time of Aristotle, who mentions a number of sources
of observational evidence including animal dissection (Aristotle(a),
763a/30&ndash;b/15; Aristotle(b), 511b/20&ndash;25).
Francis Bacon argued long ago that the best way to discover things
about nature is to use experiences (his term for observations as well
as experimental results) to develop and improve scientific theories
(Bacon 1620, 49ff). The role of observational evidence in scientific
discovery was an important topic for Whewell (1858) and Mill (1872)
among others in the 19th century. But philosophers didn&rsquo;t talk
about observation as extensively, in as much detail, or in the way we
have become accustomed to, until the 20<sup>th</sup> century when
logical empiricists transformed philosophical thinking about it.</p>

<p>
One important transformation, characteristic of the linguistic turn in
philosophy, was to concentrate on the logic of observation reports
rather than on objects or phenomena observed. This focus made sense on
the assumption that a scientific theory is a system of sentences or
sentence-like structures (propositions, statements, claims, and so on)
to be tested by comparison to observational evidence. It was assumed
that the comparisons must be understood in terms of inferential
relations. If inferential relations hold only between sentence-like
structures, it follows that theories must be tested, not against
observations or things observed, but against sentences, propositions,
etc. used to report observations (Hempel 1935,
50&ndash;51; Schlick 1935). Theory testing was treated as
a matter of comparing observation sentences describing observations
made in natural or laboratory settings to observation sentences that
should be true according to the theory to be tested. This was to be
accomplished by using laws or lawlike generalizations along with
descriptions of initial conditions, correspondence rules, and
auxiliary hypotheses to derive observation sentences describing the
sensory deliverances of interest. This makes it imperative to ask what
observation sentences report.</p>

<p>
According to what Hempel called the <em>phenomenalist account</em>,
observation reports describe the observer&rsquo;s subjective
perceptual experiences.</p>

<blockquote>
&hellip; Such experiential data might be conceived of as being
sensations, perceptions, and similar phenomena of immediate
experience. (Hempel 1952, 674)
</blockquote>

<p>
This view is motivated by the assumption that the epistemic value of
an observation report depends upon its truth or accuracy, and that
with regard to perception, the only thing observers can know with
certainty to be true or accurate is how things appear to them. This
means that we cannot be confident that observation reports are true or
accurate if they describe anything beyond the observer&rsquo;s own
perceptual experience. Presumably one&rsquo;s confidence in a
conclusion should not exceed one&rsquo;s confidence in one&rsquo;s
best reasons to believe it. For the phenomenalist, it follows that
reports of subjective experience can provide better reasons to believe
claims they support than reports of other kinds of evidence.</p>

<p>
However, given the expressive limitations of the language available
for reporting subjective experiences, we cannot expect phenomenalistic
reports to be precise and unambiguous enough to test theoretical
claims whose evaluation requires accurate, fine-grained perceptual
discriminations. Worse yet, if experiences are directly available only
to those who have them, there is room to doubt whether different
people can understand the same observation sentence in the same way.
Suppose you had to evaluate a claim on the basis of someone
else&rsquo;s subjective report of how a litmus solution looked to her
when she dripped a liquid of unknown acidity into it. How could you
decide whether her visual experience was the same as the one you would
use her words to report?</p>

<p>
Such considerations led Hempel to propose, contrary to the
phenomenalists, that observation sentences report &lsquo;directly
observable&rsquo;, &lsquo;intersubjectively ascertainable&rsquo; facts
about physical objects</p>

<blockquote>
&hellip; such as the coincidence of the pointer of an instrument with a
numbered mark on a dial; a change of color in a test substance or in
the skin of a patient; the clicking of an amplifier connected with a
Geiger counter; etc. (ibid.)
</blockquote>

<p>
That the facts expressed in observation reports be intersubjectively
ascertainable was critical for the aims of the logical empiricists.
They hoped to articulate and explain the authoritativeness widely
conceded to the best natural, social, and behavioral scientific
theories in contrast to propaganda and pseudoscience. Some
pronouncements from astrologers and medical quacks gain wide
acceptance, as do those of religious leaders who rest their cases on
faith or personal revelation, and leaders who use their political
power to secure assent. But such claims do not enjoy the kind of
credibility that scientific theories can attain. The logical
empiricists tried to account for the genuine credibility of scientific
theories by appeal to the objectivity and accessibility of observation
reports, and the logic of theory testing. Part of what they meant by
calling observational evidence objective was that cultural and ethnic
factors have no bearing on what can validly be inferred about the
merits of a theory from observation reports. So conceived, objectivity
was important to the logical empiricists&rsquo; criticism of the Nazi
idea that Jews and Aryans have fundamentally different thought
processes such that physical theories suitable for Einstein and his
kind should not be inflicted on German students. In response to this
rationale for ethnic and cultural purging of the German educational
system, the logical empiricists argued that because of its
objectivity, observational evidence (rather than ethnic and cultural
factors) should be used to evaluate scientific theories (Galison
1990). In this way of thinking, observational evidence and its
subsequent bearing on scientific theories are objective also in virtue
of being free of non-epistemic values.</p>

<p>
Ensuing generations of philosophers of science have found the logical
empiricist focus on expressing the content of observations in a
rarefied and basic observation language too narrow. Search for a
suitably universal language as required by the logical empiricist
program has come up empty-handed and most philosophers of science have
given up its pursuit. Moreover, as we will discuss in the following
section, the centrality of observation itself (and pointer readings)
to the aims of empiricism in philosophy of science has also come under
scrutiny. However, leaving the search for a universal pure observation
language behind does not automatically undercut the norm of
objectivity as it relates to the social, political, and cultural
contexts of scientific research. Pristine logical foundations aside,
the objectivity of &lsquo;neutral&rsquo; observations in the face of
noxious political propaganda was appealing because it could serve as
shared ground available for intersubjective appraisal. This appeal
remains alive and well today, particularly as pernicious
misinformation campaigns are again formidable in public discourse (see
O&rsquo;Connor and Weatherall 2019). If individuals can genuinely
appraise the significance of empirical evidence and come to
well-justified agreement about how the evidence bears on theorizing,
then they can protect their epistemic deliberations from the undue
influence of fascists and other nefarious manipulators. However, this
aspiration must face subtleties arising from the social epistemology
of science and from the nature of empirical results themselves. In
practice, the appraisal of scientific results can often require
expertise that is not readily accessible to members of the public
without the relevant specialized training. Additionally, precisely
because empirical results are not pure observation reports, their
appraisal across communities of inquirers operating with different
background assumptions can require significant epistemic work.</p>

<p>
The logical empiricists paid little attention to the distinction
between observing and experimenting and its epistemic implications.
For some philosophers, to experiment is to isolate, prepare, and
manipulate things in hopes of producing epistemically useful evidence.
It had been customary to think of observing as noticing and attending
to interesting details of things perceived under more or less natural
conditions, or by extension, things perceived during the course of an
experiment. To look at a berry on a vine and attend to its color and
shape would be to observe it. To extract its juice and apply reagents
to test for the presence of copper compounds would be to perform an
experiment. By now, many philosophers have argued that contrivance and
manipulation influence epistemically significant features of
observable experimental results to such an extent that epistemologists
ignore them at their peril. Robert Boyle (1661), John Herschell
(1830), Bruno Latour and Steve Woolgar (1979), Ian Hacking (1983),
Harry Collins (1985) Allan Franklin (1986), Peter Galison (1987), Jim
Bogen and Jim Woodward (1988), and Hans-J&ouml;rg Rheinberger (1997),
are some of the philosophers and philosophically-minded scientists,
historians, and sociologists of science who gave serious consideration
to the distinction between observing and experimenting. The logical
empiricists tended to ignore it. Interestingly, the contemporary
vantage point that attends to modeling, data processing, and empirical
results may suggest a re-unification of observation and intervention
under the same epistemological framework. When one no longer thinks of
scientific observation as pure or direct, and recognizes the power of
good modeling to account for confounds without physically intervening
on the target system, the purported epistemic distinction between
observation and intervention loses its bite.</p>

<h3><a name="Irrelevanceofobservation">2.2 The irrelevance of observation per se</a></h3>

<p>
Observers use magnifying glasses, microscopes, or telescopes to see
things that are too small or far away to be seen, or seen clearly
enough, without them. Similarly, amplification devices are used to
hear faint sounds. But if to observe something is to perceive it, not
every use of instruments to augment the senses qualifies as
observational.</p>

<p>
Philosophers generally agree that you can observe the moons of Jupiter
with a telescope, or a heartbeat with a stethoscope. The van Fraassen
of <em>The Scientific Image</em> is a notable exception, for whom to
be &lsquo;observable&rsquo; meant to be something that, were it
present to a creature like us, would be observed. Thus, for van
Fraassen, the moons of Jupiter are observable &ldquo;since astronauts
will no doubt be able to see them as well from close up&rdquo; (1980,
16). In contrast, microscopic entities are not observable on van
Fraassen&rsquo;s account because creatures like us cannot
strategically maneuver ourselves to see them, present before us, with
our unaided senses.</p>

<p>
Many philosophers have criticized van Fraassen&rsquo;s view as overly
restrictive. Nevertheless, philosophers differ in their willingness to
draw the line between what counts as observable and what does not
along the spectrum of increasingly complicated instrumentation. Many
philosophers who don&rsquo;t mind telescopes and microscopes still
find it unnatural to say that high energy physicists
&lsquo;observe&rsquo; particles or particle interactions when they
look at bubble chamber photographs&mdash;let alone digital
visualizations of energy depositions left in calorimeters that are not
themselves inspected. Their intuitions come from the plausible
assumption that one can observe only what one can see by looking, hear
by listening, feel by touching, and so on. Investigators can neither
look at (direct their gazes toward and attend to) nor visually
experience charged particles moving through a detector. Instead they
can look at and see tracks in the chamber, in bubble chamber
photographs, calorimeter data visualizations, etc.</p>

<p>
In more contentious examples, some philosophers have moved to speaking
of instrument-augmented empirical research as more like tool use than
sensing. Hacking (1981) argues that we do not see <em>through</em> a
microscope, but rather <em>with</em> it. Daston and Galison (2007)
highlight the inherent interactivity of a scanning tunneling
microscope, in which scientists image and manipulate atoms by
exchanging electrons between the sharp tip of the microscope and the
surface to be imaged (397). Others have opted to stretch the meaning
of observation to accommodate what we might otherwise be tempted to
call instrument-aided detections. For instance, Shapere (1982) argues
that while it may initially strike philosophers as counter-intuitive,
it makes perfect sense to call the detection of neutrinos from the
interior of the sun &ldquo;direct observation.&rdquo;</p>

<p>
The variety of views on the observable/unobservable distinction hint
that empiricists may have been barking up the wrong philosophical
tree. Many of the things scientists investigate do not interact with
human perceptual systems as required to produce perceptual experiences
of them. The methods investigators use to study such things argue
against the idea&mdash;however plausible it may once have
seemed&mdash;that scientists do or should rely exclusively on their
perceptual systems to obtain the evidence they need. Thus Feyerabend
proposed as a thought experiment that if measuring equipment was
rigged up to register the magnitude of a quantity of interest, a
theory could be tested just as well against its outputs as against
records of human perceptions (Feyerabend 1969, 132&ndash;137).
Feyerabend could have made his point with historical examples instead
of thought experiments. A century earlier Helmholtz estimated the
speed of excitatory impulses traveling through a motor nerve. To
initiate impulses whose speed could be estimated, he implanted an
electrode into one end of a nerve fiber and ran a current into it from
a coil. The other end was attached to a bit of muscle whose
contraction signaled the arrival of the impulse. To find out how long
it took the impulse to reach the muscle he had to know when the
stimulating current reached the nerve. But</p>

<blockquote>
[o]ur senses are not capable of directly perceiving an individual
moment of time with such small duration &hellip;
</blockquote>

<p>
and so Helmholtz had to resort to what he called &lsquo;artificial
methods of observation&rsquo; (Olesko and Holmes 1994, 84). This meant
arranging things so that current from the coil could deflect a
galvanometer needle. Assuming that the magnitude of the deflection is
proportional to the duration of current passing from the coil,
Helmholtz could use the deflection to estimate the duration he could
not see (ibid). This sense of &lsquo;artificial observation&rsquo; is
not to be confused e.g., with using magnifying glasses or telescopes
to see tiny or distant objects. Such devices enable the observer to
scrutinize visible objects. The minuscule duration of the current flow
is not a visible object. Helmholtz studied it by cleverly concocting
circumstances so that the deflection of the needle would meaningfully
convey the information he needed. Hooke (1705,
16&ndash;17) argued for and designed instruments to
execute the same kind of strategy in the 17<sup>th</sup> century.</p>

<p>
It is of interest that records of perceptual observation are not
always epistemically superior to data collected via experimental
equipment. Indeed, it is not unusual for investigators to use
non-perceptual evidence to evaluate perceptual data and correct for
its errors. For example, Rutherford and Pettersson conducted similar
experiments to find out if certain elements disintegrated to emit
charged particles under radioactive bombardment. To detect emissions,
observers watched a scintillation screen for faint flashes produced by
particle strikes. Pettersson&rsquo;s assistants reported seeing
flashes from silicon and certain other elements. Rutherford&rsquo;s
did not. Rutherford&rsquo;s colleague, James Chadwick, visited
Pettersson&rsquo;s laboratory to evaluate his data. Instead of watching
the screen and checking Pettersson&rsquo;s data against what he saw,
Chadwick arranged to have Pettersson&rsquo;s assistants watch the
screen while unbeknownst to them he manipulated the equipment,
alternating normal operating conditions with a condition in which
particles, if any, could not hit the screen. Pettersson&rsquo;s data
were discredited by the fact that his assistants reported flashes at
close to the same rate in both conditions (Stuewer 1985,
284&ndash;288).</p>

<p>
When the process of producing data is relatively convoluted, it is
even easier to see that human sense perception is not the ultimate
epistemic engine. Consider functional magnetic resonance images (fMRI)
of the brain decorated with colors to indicate magnitudes of
electrical activity in different regions during the performance of a
cognitive task. To produce these images, brief magnetic pulses are
applied to the subject&rsquo;s brain. The magnetic force coordinates
the precessions of protons in hemoglobin and other bodily stuffs to
make them emit radio signals strong enough for the equipment to
respond to. When the magnetic force is relaxed, the signals from
protons in highly oxygenated hemoglobin deteriorate at a detectably
different rate than signals from blood that carries less oxygen.
Elaborate algorithms are applied to radio signal records to estimate
blood oxygen levels at the places from which the signals are
calculated to have originated. There is good reason to believe that
blood flowing just downstream from spiking neurons carries appreciably
more oxygen than blood in the vicinity of resting neurons. Assumptions
about the relevant spatial and temporal relations are used to estimate
levels of electrical activity in small regions of the brain
corresponding to pixels in the finished image. The results of all of
these computations are used to assign the appropriate colors to pixels
in a computer generated image of the brain. In view of all of this,
functional brain imaging differs, e.g., from looking and seeing,
photographing, and measuring with a thermometer or a galvanometer in
ways that make it uninformative to call it observation. And similarly
for many other methods scientists use to produce non-perceptual
evidence.</p>

<p>
The role of the senses in fMRI data production is limited to such
things as monitoring the equipment and keeping an eye on the subject.
Their epistemic role is limited to discriminating the colors in the
finished image, reading tables of numbers the computer used to assign
them, and so on. While it is true that researchers typically use their
sense of sight to take in visualizations of processed fMRI
data&mdash;or numbers on a page or screen for that
matter&mdash;this is not the primary locus of epistemic
action. Researchers learn about brain processes through fMRI data, to
the extent that they do, primarily in virtue of the suitability of the
causal connection between the target processes and the data records,
and of the transformations those data undergo when they are processed
into the maps or other results that scientists want to use. The
interesting questions are not about observability, i.e. whether
neuronal activity, blood oxygen levels, proton precessions, radio
signals, and so on, are properly understood as observable by creatures
like us. The epistemic significance of the fMRI data depends on their
delivering us the right sort of access to the target, but observation
is neither necessary nor sufficient for that
access.</p>

<p>
Following Shapere (1982), one could respond by adopting an extremely
permissive view of what counts as an &lsquo;observation&rsquo; so as
to allow even highly processed data to count as observations. However,
it is hard to reconcile the idea that highly processed data like fMRI
images record observations with the traditional empiricist notion that
calculations involving theoretical assumptions and background beliefs
must not be allowed (on pain of loss of objectivity) to intrude into
the process of data production. Observation garnered its special
epistemic status in the first place because it seemed more direct,
more immediate, and therefore less distorted and muddled than (say)
detection or inference. The production of fMRI images requires
extensive statistical manipulation based on theories about the radio
signals, and a variety of factors having to do with their detection
along with beliefs about relations between blood oxygen levels and
neuronal activity, sources of systematic error, and more. Insofar as
the use of the term &lsquo;observation&rsquo; connotes this extra
baggage of traditional empiricism, it may be better to replace
observation-talk with terminology that is more obviously permissive,
such as that of &lsquo;empirical data&rsquo; and &lsquo;empirical
results.&rsquo;</p>

<h3><a name="Dataandphenomena">2.3 Data and phenomena</a></h3>

<p>
Deposing observation from its traditional perch in empiricist
epistemologies of science need not estrange philosophers from
scientific practice. Terms like &lsquo;observation&rsquo; and
&lsquo;observation reports&rsquo; do not occur nearly as much in
scientific as in philosophical writings. In their place, working
scientists tend to talk about <em>data</em>. Philosophers who adopt
this usage are free to think about standard examples of observation as
members of a large, diverse, and growing family of data production
methods. Instead of trying to decide which methods to classify as
observational and which things qualify as observables, philosophers
can then concentrate on the epistemic influence of the factors that
differentiate members of the family. In particular, they can focus
their attention on what questions data produced by a given method can
be used to answer, what must be done to use that data fruitfully, and
the credibility of the answers they afford (Bogen 2016).</p>

<p>
Satisfactorily answering such questions warrants further philosophical
work. As Bogen and Woodward (1988) have argued, there is often a long
road between obtaining a particular dataset replete with
idiosyncrasies born of unspecified causal nuances to any claim about
the phenomenon ultimately of interest to the researchers. Empirical
data are typically produced in ways that make it impossible to predict
them from the generalizations they are used to test, or to derive
instances of those generalizations from data and non ad hoc auxiliary
hypotheses. Indeed, it is unusual for many members of a set of
reasonably precise quantitative data to agree with one another, let
alone with a quantitative prediction. That is because precise,
publicly accessible data typically cannot be produced except through
processes whose results reflect the influence of causal factors that
are too numerous, too different in kind, and too irregular in behavior
for any single theory to account for them. When Bernard Katz recorded
electrical activity in nerve fiber preparations, the numerical values
of his data were influenced by factors peculiar to the operation of
his galvanometers and other pieces of equipment, variations among the
positions of the stimulating and recording electrodes that had to be
inserted into the nerve, the physiological effects of their insertion,
and changes in the condition of the nerve as it deteriorated during
the course of the experiment. There were variations in the
investigators&rsquo; handling of the equipment. Vibrations shook the
equipment in response to a variety of irregularly occurring causes
ranging from random error sources to the heavy tread of Katz&rsquo;s
teacher, A.V. Hill, walking up and down the stairs outside of the
laboratory. That&rsquo;s a short list. To make matters worse, many of
these factors influenced the data as parts of irregularly occurring,
transient, and shifting assemblies of causal influences.</p>

<p>
The effects of systematic and random sources of error are typically
such that considerable analysis and interpretation are required to
take investigators from data sets to conclusions that can be used to
evaluate theoretical claims. Interestingly, this applies as much to
clear cases of perceptual data as to machine produced records. When
19<sup>th</sup> and early 20<sup>th</sup> century astronomers looked
through telescopes and pushed buttons to record the time at which they
saw a star pass a crosshair, the values of their data points depended,
not only upon light from that star, but also upon features of
perceptual processes, reaction times, and other psychological factors
that varied from observer to observer. No astronomical theory has the
resources to take such things into account.</p>

<p>
Instead of testing theoretical claims by direct comparison to the data
initially collected, investigators use data to infer facts about
phenomena, i.e., events, regularities, processes, etc. whose instances
are uniform and uncomplicated enough to make them susceptible to
systematic prediction and explanation (Bogen and Woodward 1988, 317).
The fact that lead melts at temperatures at or close to 327.5 C is an
example of a phenomenon, as are widespread regularities among
electrical quantities involved in the action potential, the motions of
astronomical bodies, etc. Theories that cannot be expected to predict
or explain such things as individual temperature readings can
nevertheless be evaluated on the basis of how useful they are in
predicting or explaining phenomena. The same
holds for the action potential as opposed to the electrical data from
which its features are calculated, and the motions of astronomical
bodies in contrast to the data of observational astronomy. It is
reasonable to ask a genetic theory how probable it is (given similar
upbringings in similar environments) that the offspring of a parent or
parents diagnosed with alcohol use disorder will develop one or more
symptoms the DSM classifies as indicative of alcohol use disorder. But
it would be quite unreasonable to ask the genetic theory to predict or
explain one patient&rsquo;s numerical score on one trial of a
particular diagnostic test, or why a diagnostician wrote a particular
entry in her report of an interview with an offspring of one of such
parents (see Bogen and Woodward, 1988,
319&ndash;326).</p>

<p>
Leonelli has challenged Bogen and Woodward&rsquo;s (1988) claim that
data are, as she puts it, &ldquo;unavoidably embedded in one
experimental context&rdquo; (2009, 738). She argues that when data are
suitably packaged, they can travel to new epistemic contexts and
retain epistemic utility&mdash;it is not just claims about
the phenomena that can travel, data travel too. Preparing data for
safe travel involves work, and by tracing data &lsquo;journeys,&rsquo;
philosophers can learn about how the careful labor of researchers,
data archivists, and database curators can facilitate useful data
mobility. While Leonelli&rsquo;s own work has often focused on data in
biology, Leonelli and Tempini (2020) contains many diverse case
studies of data journeys from a variety of scientific disciplines that
will be of value to philosophers interested in the methodology and
epistemology of science in practice.</p>

<p>
The fact that theories typically predict and explain features of
phenomena rather than idiosyncratic data should not be interpreted as
a failing. For many purposes, this is the more useful and illuminating
capacity. Suppose you could choose between a theory that predicted or
explained the way in which neurotransmitter release relates to
neuronal spiking (e.g., the fact that on average, transmitters are
released roughly once for every 10 spikes) and a theory which
explained or predicted the numbers displayed on the relevant
experimental equipment in one, or a few single cases. For most
purposes, the former theory would be preferable to the latter at the
very least because it applies to so many more cases. And similarly for
theories that predict or explain something about the probability of
alcohol use disorder conditional on some genetic factor or a theory
that predicted or explained the probability of faulty diagnoses of
alcohol use disorder conditional on facts about the training that
psychiatrists receive. For most purposes, these would be preferable to
a theory that predicted specific descriptions in a single particular
case history.</p>

<p>
However, there are circumstances in which scientists do want to
explain data. In empirical research it is often crucial to getting a
useful signal that scientists deal with sources of background noise
and confounding signals. This is part of the long road from newly
collected data to useful empirical results. An important step on the
way to eliminating unwanted noise or confounds is to determine their
sources. Different sources of noise can have different characteristics
that can be derived from and explained by theory. Consider the
difference between &lsquo;shot noise&rsquo; and &lsquo;thermal
noise,&rsquo; two ubiquitous sources of noise in precision electronics
(Schottky 1918; Nyquist 1928; Horowitz and Hill 2015). &lsquo;Shot
noise&rsquo; arises in virtue of the discrete nature of a signal. For
instance, light collected by a detector does not arrive all at once or
in perfectly continuous fashion. Photons rain onto a detector shot by
shot on account of being quanta. Imagine building up an image one
photon at a time&mdash;at first the structure of the image
is barely recognizable, but after the arrival of many photons, the
image eventually fills in. In fact, the contribution of noise of this
type goes as the square root of the signal. By contrast, thermal noise
is due to non-zero temperature&mdash;thermal fluctuations
cause a small current to flow in any circuit. If you cool your
instrument (which very many precision experiments in physics do) then
you can decrease thermal noise. Cooling the detector is not going to
change the quantum nature of photons though. Simply collecting more
photons will improve the signal to noise ratio with respect to shot
noise. Thus, determining what kind of noise is affecting one&rsquo;s
data, i.e. explaining features of the data themselves that are
idiosyncratic to the particular instruments and conditions prevailing
during a specific instance of data collection, can be critical to
eventually generating a dataset that can be used to answer questions
about phenomena of interest. In using data that require statistical
analysis, it is particularly clear that &ldquo;empirical assumptions
about the factors influencing the measurement results may be used to
motivate the assumption of a particular error distribution&rdquo;,
which can be crucial for justifying the application of methods of
analysis (Woodward 2011, 173).</p>

<p>
There are also circumstances in which scientists want to provide a
substantive, detailed explanation for a particular idiosyncratic
datum, and even circumstances in which procuring such explanations is
epistemically imperative. Ignoring outliers without good epistemic
reasons is just cherry-picking data, one of the canonical
&lsquo;questionable research practices.&rsquo; Allan Franklin has described Robert
Millikan&rsquo;s convenient exclusion of data he collected from
observing the second oil drop in his experiments of April 16, 1912
(1986, 231). When Millikan initially recorded the data for this drop,
his notebooks indicate that he was satisfied his apparatus was working
properly and that the experiment was running well&mdash;he
wrote &ldquo;Publish&rdquo; next to the data in his lab notebook.
However, after he had later calculated the value for the fundamental
electric charge that these data yielded, and found it aberrant with
respect to the values he calculated using data collected from other
good observing sessions, he changed his mind, writing
&ldquo;Won&rsquo;t work&rdquo; next to the calculation (ibid., see
also Woodward 2010, 794). Millikan not only never published this
result, he never published why he failed to publish it. When data are
excluded from analysis, there ought to be some explanation justifying
their omission over and above lack of agreement with the
experimenters&rsquo; expectations. Precisely because they are
outliers, some data require specific, detailed, idiosyncratic causal
explanations. Indeed, it is often in virtue of those very explanations
that outliers can be responsibly rejected. Some explanation of data
rejected as &lsquo;spurious&rsquo; is required. Otherwise, scientists
risk biasing their own work.</p>

<p>
Thus, while in transforming data as collected into something useful
for learning about phenomena, scientists often account for features of
the data such as different types of noise contributions, and sometimes
even explain the odd outlying data point or artifact, they simply do
not explain every individual teensy tiny causal contribution to the
exact character of a data set or datum in full detail. This is because
scientists can neither discover such causal minutia nor would their
invocation be necessary for typical research questions. The fact that
it may sometimes be important for scientists to provide detailed
explanations of data, and not just claims about phenomena inferred
from data, should not be confused with the dubious claim that
scientists could &lsquo;in principle&rsquo; detail every causal quirk
that contributed to some data (Woodward 2010; 2011).</p>

<p>
In view of all of this, together with the fact that a great many
theoretical claims can only be tested directly against facts about
phenomena, it behooves epistemologists to think about how data are
used to answer questions about phenomena. Lacking space for a detailed
discussion, the most this entry can do is to mention two main kinds of
things investigators do in order to draw conclusions from data. The
first is causal analysis carried out with or without the use of
statistical techniques. The second is non-causal statistical
analysis.</p>

<p>
First, investigators must distinguish features of the data that are
indicative of facts about the phenomenon of interest from those which
can safely be ignored, and those which must be corrected for.
Sometimes background knowledge makes this easy. Under normal
circumstances investigators know that their thermometers are sensitive
to temperature, and their pressure gauges, to pressure. An astronomer
or a chemist who knows what spectrographic equipment does, and what
she has applied it to will know what her data indicate. Sometimes it
is less obvious. When Santiago Ram&oacute;n y Cajal looked through his
microscope at a thin slice of stained nerve tissue, he had to figure
out which, if any, of the fibers he could see at one focal length
connected to or extended from things he could see only at another
focal length, or in another slice. Analogous considerations apply to
quantitative data. It was easy for Katz to tell when his equipment was
responding more to Hill&rsquo;s footfalls on the stairs than to the
electrical quantities it was set up to measure. It can be harder to
tell whether an abrupt jump in the amplitude of a high frequency EEG
oscillation was due to a feature of the subjects brain activity or an
artifact of extraneous electrical activity in the laboratory or
operating room where the measurements were made. The answers to
questions about which features of numerical and non-numerical data are
indicative of a phenomenon of interest typically depend at least in
part on what is known about the causes that conspire to produce the
data.</p>

<p>
Statistical arguments are often used to deal with questions about the
influence of epistemically relevant causal factors. For example, when
it is known that similar data can be produced by factors that have
nothing to do with the phenomenon of interest, Monte Carlo
simulations, regression analyses of sample data, and a variety of
other statistical techniques sometimes provide investigators with
their best chance of deciding how seriously to take a putatively
illuminating feature of their data.</p>

<p>
But statistical techniques are also required for purposes other than
causal analysis. To calculate the magnitude of a quantity like the
melting point of lead from a scatter of numerical data, investigators
throw out outliers, calculate the mean and the standard deviation,
etc., and establish confidence and significance levels. Regression and
other techniques are applied to the results to estimate how far from
the mean the magnitude of interest can be expected to fall in the
population of interest (e.g., the range of temperatures at which pure
samples of lead can be expected to melt).</p>

<p>
The fact that little can be learned from data without causal,
statistical, and related argumentation has interesting consequences
for received ideas about how the use of observational evidence
distinguishes science from pseudoscience, religion, and other
non-scientific cognitive endeavors. First, scientists are not the only
ones who use observational evidence to support their claims;
astrologers and medical quacks use them too. To find epistemically
significant differences, one must carefully consider what sorts of
data they use, where it comes from, and how it is employed. The
virtues of scientific as opposed to non-scientific theory evaluations
depend not only on its reliance on empirical data, but also on how the
data are produced, analyzed and interpreted to draw conclusions
against which theories can be evaluated. Secondly, it does not take
many examples to refute the notion that adherence to a single,
universally applicable &lsquo;scientific method&rsquo; differentiates
the sciences from the non-sciences. Data are produced, and used in far
too many different ways to treat informatively as instances of any
single method. Thirdly, it is usually, if not always, impossible for
investigators to draw conclusions to test theories against
observational data without explicit or implicit reliance on
theoretical resources.</p>

<p>
Bokulich (2020) has helpfully outlined a taxonomy of various ways in
which data can be model-laden to increase their epistemic utility. She
focuses on seven categories: data conversion, data correction, data
interpolation, data scaling, data fusion, data assimilation, and
synthetic data. Of these categories, conversion and correction are
perhaps the most familiar. Bokulich reminds us that even in the case
of reading a temperature from an ordinary mercury thermometer, we are
&lsquo;converting&rsquo; the data as measured, which in this case is
the height of the column of mercury, to a temperature (ibid., 795). In
more complicated cases, such as processing the arrival times of
acoustic signals in seismic reflection measurements to yield values
for subsurface depth, data conversion may involve models (ibid.). In
this example, models of the composition and geometry of the subsurface
are needed in order to account for differences in the speed of sound
in different materials. Data &lsquo;correction&rsquo; involves common
practices we have already discussed like modeling and mathematically
subtracting background noise contributions from one&rsquo;s dataset
(ibid., 796). Bokulich rightly points out that involving models in
these ways routinely improves the epistemic uses to which data can be
put. Data interpolation, scaling, and &lsquo;fusion&rsquo; are also
relatively widespread practices that deserve further philosophical
analysis. Interpolation involves filling in missing data in a patchy
data set, under the guidance of models. Data are scaled when they have
been generated in a particular scale (temporal, spatial, energy) and
modeling assumptions are recruited to transform them to apply at
another scale. Data are &lsquo;fused,&rsquo; in Bokulich&rsquo;s
terminology, when data collected in diverse contexts, using diverse
methods are combined, or integrated together. For instance, when data
from ice cores, tree rings, and the historical logbooks of sea
captains are merged into a joint climate dataset. Scientists must take
care in combining data of diverse provenance, and model new
uncertainties arising from the very amalgamation of datasets (ibid.,
800).</p>

<p>
Bokulich contrasts &lsquo;synthetic data&rsquo; with what she calls
&lsquo;real data&rsquo; (ibid., 801&ndash;802). Synthetic data are virtual,
or simulated data, and are not produced by physical interaction with
worldly research targets. Bokulich emphasizes the role that simulated
data can usefully play in testing and troubleshooting aspects of data
processing that are to eventually be deployed on empirical data
(ibid., 802). It can be incredibly useful for developing and
stress-testing a data processing pipeline to have fake datasets whose
characteristics are already known in virtue of having been produced by
the researchers, and being available for their inspection at will.
When the characteristics of a dataset are known, or indeed can be
tailored according to need, the effects of new processing methods can
be more readily traced than without. In this way, researchers can
familiarize themselves with the effects of a data processing pipeline,
and make adjustments to that pipeline in light of what they learn by
feeding fake data through it, before attempting to use that pipeline
on actual science data. Such investigations can be critical to
eventually arguing for the credibility of the final empirical results
and their appropriate interpretation and use.</p>

<p>
Data assimilation is perhaps a less widely appreciated aspect of
model-based data processing among philosophers of science, excepting
Parker (2016; 2017). Bokulich characterizes this method as &ldquo;the
optimal integration of data with dynamical model estimates to provide
a more accurate &lsquo;assimilation estimate&rsquo; of the
quantity&rdquo; (2020, 800). Thus, data assimilation involves
balancing the contributions of empirical data and the output of models
in an integrated estimate, according to the uncertainties associated
with these contributions.</p>

<p>
Bokulich argues that the involvement of models in these various
aspects of data processing does not necessarily lead to better
epistemic outcomes. Done wrong, integrating models and data can
introduce artifacts and make the processed data unreliable for the
purpose at hand (ibid., 804). Indeed, she notes that &ldquo;[t]here is
much work for methodologically reflective scientists and philosophers
of science to do in string out cases in which model-data symbiosis may
be problematic or circular&rdquo; (ibid.)</p>

<h2><a name="Theoryandvalueladenness">3. Theory and value ladenness</a></h2>

<p>
Empirical results are laden with values and theoretical commitments.
Philosophers have raised and appraised several possible kinds of
epistemic problems that could be associated with theory and/or
value-laden empirical results. They have worried about the extent to
which human perception itself is distorted by our commitments. They
have worried that drawing upon theoretical resources from the very
theory to be appraised (or its competitors) in the generation of
empirical results yields vicious circularity (or inconsistency). They
have also worried that contingent conceptual and/or linguistic
frameworks trap bits of evidence like bees in amber so that they
cannot carry on their epistemic lives outside of the contexts of their
origination, and that normative values necessarily corrupt the
integrity of science. Do the theory and value-ladenness of empirical
results render them hopelessly parochial? That is, when scientists
leave theoretical commitments behind and adopt new ones, must they
also relinquish the fruits of the empirical research imbued with their
prior commitments too? In this section, we discuss these worries and
responses that philosophers have offered to assuage them.</p>

<h3><a name="Perception">3.1 Perception</a></h3>

<p>
If you believe that observation by human sense perception is the
objective basis of all scientific knowledge, then you ought to be
particularly worried about the potential for human perception to be
corrupted by theoretical assumptions, wishful thinking, framing
effects, and so on. Daston and Galison recount the striking example of
Arthur Worthington&rsquo;s symmetrical milk drops (2007, 11&ndash;16).
Working in 1875, Worthington investigated the hydrodynamics of falling
fluid droplets and their evolution upon impacting a hard surface. At
first, he had tried to carefully track the drop dynamics with a strobe
light to burn a sequence of images into his own retinas. The images he
drew to record what he saw were radially symmetric, with rays of the
drop splashes emanating evenly from the center of the impact. However,
when Worthington transitioned from using his eyes and capacity to draw
from memory to using photography in 1894, he was shocked to find that
the kind of splashes he had been observing were irregular splats
(ibid., 13). Even curiouser, when Worthington returned to his
drawings, he found that he had indeed recorded some unsymmetrical
splashes. He had evidently dismissed them as uninformative accidents
instead of regarding them as revelatory of the phenomenon he was
intent on studying (ibid.) In attempting to document the ideal form of
the splashes, a general and regular form, he had subconsciously
down-played the irregularity of individual splashes. If theoretical
commitments, like Worthington&rsquo;s initial commitment to the
perfect symmetry of the physics he was studying, pervasively and
incorrigibly dictated the results of empirical inquiry, then the
epistemic aims of science would be seriously undermined.</p>

<p>
Perceptual psychologists, Bruner and Postman, found that subjects who
were briefly shown anomalous playing cards, e.g., a black four of
hearts, reported having seen their normal counterparts e.g., a red
four of hearts. It took repeated exposures to get subjects to say the
anomalous cards didn&rsquo;t look right, and eventually, to describe
them correctly (Kuhn 1962, 63). Kuhn took such studies to indicate
that things don&rsquo;t look the same to observers with different
conceptual resources. (For a more up-to-date discussion of theory and
conceptual perceptual loading see Lupyan 2015.) If so, black hearts
didn&rsquo;t look like black hearts until repeated exposures somehow
allowed subjects to acquire the concept of a black heart. By analogy,
Kuhn supposed, when observers working in conflicting paradigms look at
the same thing, their conceptual limitations should keep them from
having the same visual experiences (Kuhn 1962, 111,
113&ndash;114, 115, 120&ndash;1). This would
mean, for example, that when Priestley and Lavoisier watched the same
experiment, Lavoisier should have seen what accorded with his theory
that combustion and respiration are oxidation processes, while
Priestley&rsquo;s visual experiences should have agreed with his
theory that burning and respiration are processes of phlogiston
release.</p>

<p>
The example of Pettersson&rsquo;s and Rutherford&rsquo;s scintillation
screen evidence (above) attests to the fact that observers working in
different laboratories sometimes report seeing different things under
similar conditions. It is plausible that their expectations influence
their reports. It is plausible that their expectations are shaped by
their training and by their supervisors&rsquo; and associates&rsquo;
theory driven behavior. But as happens in other cases as well, all
parties to the dispute agreed to reject Pettersson&rsquo;s data by
appealing to results that both laboratories could obtain and interpret
in the same way without compromising their theoretical commitments.
Indeed, it is possible for scientists to share empirical results, not
just across diverse laboratory cultures, but even across serious
differences in worldview. Much as they disagreed about the nature of
respiration and combustion, Priestley and Lavoisier gave
quantitatively similar reports of how long their mice stayed alive and
their candles kept burning in closed bell jars. Priestley taught
Lavoisier how to obtain what he took to be measurements of the
phlogiston content of an unknown gas. A sample of the gas to be tested
is run into a graduated tube filled with water and inverted over a
water bath. After noting the height of the water remaining in the
tube, the observer adds &ldquo;nitrous air&rdquo; (we call it nitric
oxide) and checks the water level again. Priestley, who thought there
was no such thing as oxygen, believed the change in water level
indicated how much phlogiston the gas contained. Lavoisier reported
observing the same water levels as Priestley even after he abandoned
phlogiston theory and became convinced that changes in water level
indicated free oxygen content (Conant 1957,
74&ndash;109).</p>

<p>
A related issue is that of salience. Kuhn claimed that if Galileo and
an Aristotelian physicist had watched the same pendulum experiment,
they would not have looked at or attended to the same things. The
Aristotelian&rsquo;s paradigm would have required the experimenter to
measure</p>

<blockquote>
&hellip; the weight of the stone, the vertical height to which it had
been raised, and the time required for it to achieve rest (Kuhn 1962,
123)
</blockquote>

<p>
and ignore radius, angular displacement, and time per swing (ibid.,
124). These last were salient to Galileo because he treated pendulum
swings as constrained circular motions. The Galilean quantities would
be of no interest to an Aristotelian who treats the stone as falling
under constraint toward the center of the earth (ibid., 123). Thus
Galileo and the Aristotelian would not have collected the same data.
(Absent records of Aristotelian pendulum experiments we can think of
this as a thought experiment.)</p>

<p>
Interests change, however. Scientists may eventually come to
appreciate the significance of data that had not originally been
salient to them in light of new presuppositions. The moral of these
examples is that although paradigms or theoretical commitments
sometimes have an epistemically significant influence on what
observers perceive or what they attend to, it can be relatively easy
to nullify or correct for their effects. When presuppositions cause
epistemic damage, investigators are often able to eventually make
corrections. Thus, paradigms and theoretical commitments actually do
influence saliency, but their influence is neither inevitable nor
irremediable.</p>

<h3><a name="Assuming">3.2 Assuming the theory to be tested</a></h3>

<p>
Thomas Kuhn (1962), Norwood Hanson (1958), Paul Feyerabend (1959) and
others cast suspicion on the objectivity of observational evidence in
another way by arguing that one cannot use empirical evidence to test
a theory without committing oneself to that very theory. This would be
a problem if it leads to dogmatism but assuming the theory to be
tested is often benign and even necessary.</p>

<p>
For instance, Laymon (1988) demonstrates the manner in which the very
theory that the Michelson-Morley experiments are considered to test is
assumed in the experimental design, but that this does not engender
deleterious epistemic effects (250). The Michelson-Morley apparatus
consists of two interferometer arms at right angles to one another,
which are rotated in the course of the experiment so that, on the
original construal, the path length traversed by light in the
apparatus would vary according to alignment with or against the
Earth&rsquo;s velocity (carrying the apparatus) with respect to the
stationary aether. This difference in path length would show up as
displacement in the interference fringes of light in the
interferometer. Although Michelson&rsquo;s intention had been to
measure the velocity of the Earth with respect to the all-pervading
aether, the experiments eventually came to be regarded as furnishing
tests of the Fresnel aether theory itself. In particular, the null
results of these experiments were taken as evidence against the
existence of the aether. Naively, one might suppose that whatever
assumptions were made in the calculation of the results of these
experiments, it should not be the case that the theory under the gun
was assumed nor that its negation was.</p>

<p>
Before Michelson&rsquo;s experiments, the Fresnel aether theory did
not predict any sort of length contraction. Although Michelson assumed
no contraction in the arms of the interferometer, Laymon argues that
he could have assumed contraction, with no practical impact on the
results of the experiments. The predicted fringe shift is calculated
from the anticipated difference in the distance traveled by light in
the two arms is the same, when higher order terms are neglected. Thus,
in practice, the experimenters could assume either that the
contraction thesis was true or that it was false when determining the
length of the arms. Either way, the results of the experiment would be
the same. After Michelson&rsquo;s experiments returned no evidence of
the anticipated aether effects, Lorentz-Fitzgerald contraction was
postulated precisely to cancel out the expected (but not found)
effects and save the aether theory. Morley and Miller then set out
specifically to test the contraction thesis, and still assumed no
contraction in determining the length of the arms of their
interferometer (ibid., 253). Thus Laymon argues that the
Michelson-Morley experiments speak against the tempting assumption
that &ldquo;appraisal of a theory is based on phenomena which can be
detected and measured without using assumptions drawn from the theory
under examination <em>or from competitors to that theory</em>&rdquo;
(ibid., 246).</p>

<p>
Epistemological hand-wringing about the use of the very theory to be
tested in the generation of the evidence to be used for testing, seems
to spring primarily from a concern about vicious circularity. How can
we have a genuine trial, if the theory in question has been presumed
innocent from the outset? While it is true that there would be a
serious epistemic problem in a case where the use of the theory to be
tested conspired to <em>guarantee</em> that the evidence would turn
out to be confirmatory, this is not always the case when theories are
invoked in their own testing. Woodward (2011) summarizes a tidy
case:</p>

<blockquote>
For example, in Millikan&rsquo;s oil drop experiment, the mere fact
that theoretical assumptions (e.g., that the charge of the electron is
quantized and that all electrons have the same charge) play a role in
motivating his measurements or a vocabulary for describing his results
does not by itself show that his design and data analysis were of such
a character as to guarantee that he would obtain results supporting
his theoretical assumptions. His experiment was such that he might
well have obtained results showing that the charge of the electron was
not quantized or that there was no single stable value for this
quantity. (178)
</blockquote>

<p>
For any given case, determining whether the theoretical assumptions
being made are benign or straight-jacketing the results that it will
be possible to obtain will require investigating the particular
relationships between the assumptions and results in that case. When
data production and analysis processes are complicated, this task can
get difficult. But the point is that merely noting the involvement of
the theory to be tested in the generation of empirical results does
not by itself imply that those results cannot be objectively useful
for deciding whether the theory to be tested should be accepted or
rejected.</p>

<h3><a name="Semantics">3.3 Semantics</a></h3>

<p>
Kuhn argued that theoretical commitments exert a strong influence on
observation descriptions, and what they are understood to mean (Kuhn
1962, 127ff; Longino 1979, 38&ndash;42). If so, proponents of a caloric
account of heat won&rsquo;t describe or understand descriptions of
observed results of heat experiments in the same way as investigators
who think of heat in terms of mean kinetic energy or radiation. They
might all use the same words (e.g., &lsquo;temperature&rsquo;) to
report an observation without understanding them in the same way. This
poses a potential problem for communicating effectively across
paradigms, and similarly, for attributing the appropriate significance
to empirical results generated outside of one&rsquo;s own linguistic
framework.</p>

<p>
It is important to bear in mind that observers do not always use
declarative sentences to report observational and experimental
results. Instead, they often draw, photograph, make audio recordings,
etc. or set up their experimental devices to generate graphs,
pictorial images, tables of numbers, and other non-sentential records.
Obviously investigators&rsquo; conceptual resources and theoretical
biases can exert epistemically significant influences on what they
record (or set their equipment to record), which details they include
or emphasize, and which forms of representation they choose (Daston
and Galison 2007, 115&ndash;190,
309&ndash;361). But disagreements about the epistemic
import of a graph, picture or other non-sentential bit of data often
turn on causal rather than semantical considerations. Anatomists may
have to decide whether a dark spot in a micrograph was caused by a
staining artifact or by light reflected from an anatomically
significant structure. Physicists may wonder whether a blip in a
Geiger counter record reflects the causal influence of the radiation
they wanted to monitor, or a surge in ambient radiation. Chemists may
worry about the purity of samples used to obtain data. Such questions
are not, and are not well represented as, semantic questions to which
semantic theory loading is relevant. Late 20<sup>th</sup> century
philosophers may have ignored such cases and exaggerated the influence
of semantic theory loading because they thought of theory testing in
terms of inferential relations between observation and theoretical
sentences.</p>

<p>
Nevertheless, some empirical results are reported as declarative
sentences. Looking at a patient with red spots and a fever, an
investigator might report having seen the spots, or measles symptoms,
or a patient with measles. Watching an unknown liquid dripping into a
litmus solution an observer might report seeing a change in color, a
liquid with a PH of less than 7, or an acid. The appropriateness of a
description of a test outcome depends on how the relevant concepts are
operationalized. What justifies an observer to report having observed
a case of measles according to one operationalization might require
her to say no more than that she had observed measles symptoms, or
just red spots according to another.</p>

<p>
In keeping with Percy Bridgman&rsquo;s view that</p>

<blockquote>
&hellip; in general, we mean by a concept nothing more than a set of
operations; the concept is synonymous with the corresponding sets of
operations (Bridgman 1927, 5)
</blockquote>

<p>
one might suppose that operationalizations are definitions or meaning
rules such that it is analytically true, e.g., that every liquid that
turns litmus red in a properly conducted test is acidic. But it is
more faithful to actual scientific practice to think of
operationalizations as defeasible rules for the application of a
concept such that both the rules and their applications are subject to
revision on the basis of new empirical or theoretical developments. So
understood, to operationalize is to adopt verbal and related practices
for the purpose of enabling scientists to do their work.
Operationalizations are thus sensitive and subject to change on the
basis of findings that influence their usefulness (Feest 2005).</p>

<p>
Definitional or not, investigators in different research traditions
may be trained to report their observations in conformity with
conflicting operationalizations. Thus instead of training observers to
describe what they see in a bubble chamber as a whitish streak or a
trail, one might train them to say they see a particle track or even a
particle. This may reflect what Kuhn meant by suggesting that some
observers might be justified or even required to describe themselves
as having seen oxygen, transparent and colorless though it is, or
atoms, invisible though they are (Kuhn 1962, 127ff). To the contrary,
one might object that what one sees should not be confused with what
one is trained to say when one sees it, and therefore that talking
about seeing a colorless gas or an invisible particle may be nothing
more than a picturesque way of talking about what certain
operationalizations entitle observers to say. Strictly speaking, the
objection concludes, the term &lsquo;observation report&rsquo; should
be reserved for descriptions that are neutral with respect to
conflicting operationalizations.</p>

<p>
If observational data are just those utterances that meet
Feyerabend&rsquo;s decidability and agreeability conditions, the
import of semantic theory loading depends upon how quickly, and for
which sentences reasonably sophisticated language users who stand in
different paradigms can non-inferentially reach the same decisions
about what to assert or deny. Some would expect enough agreement to
secure the objectivity of observational data. Others would not. Still
others would try to supply different standards for objectivity.</p>

<p>
With regard to sentential observation reports, the significance of
semantic theory loading is less ubiquitous than one might expect. The
interpretation of verbal reports often depends on ideas about causal
structure rather than the meanings of signs. Rather than worrying
about the meaning of words used to describe their observations,
scientists are more likely to wonder whether the observers made up or
withheld information, whether one or more details were artifacts of
observation conditions, whether the specimens were atypical, and so
on.</p>

<p>
Note that the worry about semantic theory loading extends beyond
observation reports of the sort that occupied the logical empiricists
and their close intellectual descendents. Combining results of diverse
methods for making proxy measurements of paleoclimate temperatures in
an epistemically responsible way requires careful attention to the
variety of operationalizations at play. Even if no &lsquo;observation
reports&rsquo; are involved, the sticky question about how to usefully
merge results obtained in different ways in order to satisfy
one&rsquo;s epistemic aims remains. Happily, the remedy for the worry
about semantic loading in this broader sense is likely to be the
same&mdash;investigating the provenance of those results
and comparing the variety of factors that have contributed to their
causal production.</p>

<p>
Kuhn placed too much emphasis on the discontinuity between evidence
generated in different paradigms. Even if we accept a broadly Kuhnian
picture, according to which paradigms are heterogeneous collections of
experimental practices, theoretical principles, problems selected for
investigation, approaches to their solution, etc., connections between
components are loose enough to allow investigators who disagree
profoundly over one or more theoretical claims to nevertheless agree
about how to design, execute, and record the results of their
experiments. That is why neuroscientists who disagreed about whether
nerve impulses consisted of electrical currents could measure the same
electrical quantities, and agree on the linguistic meaning and the
accuracy of observation reports including such terms as
&lsquo;potential&rsquo;, &lsquo;resistance&rsquo;,
&lsquo;voltage&rsquo; and &lsquo;current&rsquo;. As we discussed
above, the success that scientists have in repurposing results
generated by others for different purposes speaks against the
confinement of evidence to its native paradigm. Even when scientists
working with radically different core theoretical commitments cannot
make the same measurements themselves, with enough contextual
information about how each conducts research, it can be possible to
construct bridges that span the theoretical divides.</p>

<h3><a name="Values">3.4 Values</a></h3>

<p>
One could worry that the intertwining of the theoretical and empirical
would open the floodgates to bias in science. Human cognizing, both
historical and present day, is replete with disturbing commitments
including intolerance and narrow mindedness of many sorts. If such
commitments are integral to a theoretical framework, or endemic to the
reasoning of a scientist or scientific community, then they threaten
to corrupt the epistemic utility of empirical results generated using
their resources. The core impetus of the &lsquo;value-free
ideal&rsquo; is to maintain a safe distance between the appraisal of
scientific theories according to the evidence on one hand, and the
swarm of moral, political, social, and economic values on the other.
While proponents of the value-free ideal might admit that the
motivation to pursue a theory or the legal protection of human
subjects in permissible experimental methods involve non-epistemic
values, they would contend that such values ought not ought not enter
into the constitution of empirical results themselves, nor the
adjudication or justification of scientific theorizing in light of the
evidence (see Intemann 2021, 202).</p>

<p>
As a matter of fact, values do enter into science at a variety of
stages. Above we saw that &lsquo;theory-ladenness&rsquo; could refer
to the involvement of theory in perception, in semantics, and in a
kind of circularity that some have worried begets unfalsifiability and
thereby dogmatism. Like theory-ladenness, values can and sometimes do
affect judgments about the salience of certain evidence and the
conceptual framing of data. Indeed, on a permissive construal of the
nature of theories, values can simply be understood as part of a
theoretical framework. Intemann (2021) highlights a striking example
from medical research where key conceptual resources include notions
like &lsquo;harm,&rsquo; &lsquo;risk,&rsquo; &lsquo;health
benefit,&rsquo; and &lsquo;safety.&rsquo; She refers to research on
the comparative safety of giving birth at home and giving birth at a
hospital for low-risk parents in the United States. Studies reporting
that home births are less safe typically attend to infant and birthing
parent mortality rates&mdash;which are low for these
subjects whether at home or in hospital&mdash;but leave
out of consideration rates of c-section and episiotomy, which are both
relatively high in hospital settings. Thus, a value-laden decision
about whether a possible outcome counts as a harm worth considering
can influence the outcome of the study&mdash;in this case
tipping the balance towards the conclusion that hospital births are
more safe (ibid., 206).</p>

<p>
Note that the birth safety case differs from the sort of cases at
issue in the philosophical debate about risk and thresholds for
acceptance and rejection of hypotheses. In accepting an hypothesis, a
person makes a judgement that the risk of being mistaken is
sufficiently low (Rudner 1953). When the consequences of being wrong
are deemed grave, the threshold for acceptance may be correspondingly
high. Thus, in evaluating the epistemic status of an hypothesis in
light of the evidence, a person may have to make a value-based
judgement. However, in the birth safety case, the judgement comes into
play at an earlier stage, well before the decision to accept or reject
the hypothesis is to be made. The judgement occurs already in deciding
what is to count as a &lsquo;harm&rsquo; worth considering for the
purposes of this research.</p>

<p>
The fact that values do sometimes enter into scientific reasoning does
not by itself settle the question of whether it would be better if
they did not. In order to assess the normative proposal, philosophers
of science have attempted to disambiguate the various ways in which
values might be thought to enter into science, and the various
referents that get crammed under the single heading of
&lsquo;values.&rsquo; Anderson (2004) articulates eight stages of
scientific research where values (&lsquo;evaluative
presuppositions&rsquo;) might be employed in epistemically fruitful
ways. In paraphrase: 1) orientation in a field, 2) framing a research
question, 3) conceptualizing the target, 4) identifying relevant data,
5) data generation, 6) data analysis, 7) deciding when to cease data
analysis, and 8) drawing conclusions (Anderson 2004, 11). Similarly,
Intemann (2021) lays out five ways &ldquo;that values play a role in
scientific reasoning&rdquo; with which feminist philosophers of
science have engaged in particular:</p>

<blockquote>
(1) the framing [of] research problems, (2) observing phenomena and
describing data, (3) reasoning about value-laden concepts and
assessing risks, (4) adopting particular models, and (5) collecting
and interpreting evidence. (208)
</blockquote>

<p>
Ward (2021) presents a streamlined and general taxonomy of four
ways in which values relate to choices: as reasons motivating or
justifying choices, as causal effectors of choices, or as goods
affected by choices. By investigating the role of values in these
particular stages or aspects of research, philosophers of science can
offer higher resolution insights than just the observation that values
are involved in science at all and untangle crosstalk.</p>

<p>
Similarly, fine points can be made about the nature of values involved
in these various contexts. Such clarification is likely important for
determining whether the contribution of certain values in a given
context is deleterious or salutary, and in what sense. Douglas (2013)
argues that the &lsquo;value&rsquo; of internal consistency of a
theory and of the empirical adequacy of a theory with respect to the
available evidence are minimal criteria for any viable scientific
theory (799&ndash;800). She contrasts these with the sort of values that
Kuhn called &lsquo;virtues,&rsquo; i.e. scope, simplicity, and
explanatory power that are properties of theories themselves, and
unification, novel prediction and precision, which are properties a
theory has in relation to a body of evidence (800&ndash;801). These are the
sort of values that may be relevant to explaining and justifying
choices that scientists make to pursue/abandon or accept/reject
particular theories. Moreover, Douglas (2000) argues that what she
calls &ldquo;non-epistemic values&rdquo; (in particular, ethical value
judgements) also enter into decisions at various stages
&ldquo;internal&rdquo; to scientific reasoning, such as data
collection and interpretation (565). Consider a laboratory toxicology
study in which animals exposed to dioxins are compared to unexposed
controls. Douglas discusses researchers who want to determine the
threshold for safe exposure. Admitting false positives can be expected
to lead to overregulation of the chemical industry, while false
negatives yield underregulation and thus pose greater risk to public
health. The decision about where to set the unsafe exposure threshold,
that is, set the threshold for a statistically significant difference
between experimental and control animal populations, involves
balancing the acceptability of these two types of errors. According to
Douglas, this balancing act will depend on &ldquo;whether we are more
concerned about protecting public health from dioxin pollution or
whether we are more concerned about protecting industries that produce
dioxins from increased regulation&rdquo; (ibid., 568). That scientists
do as a matter of fact sometimes make such decisions is clear. They
judge, for instance, a specimen slide of a rat liver to be tumorous or
not, and whether borderline cases should count as benign or malignant
(ibid., 569&ndash;572). Moreover, in such cases, it is not clear that the
responsibility of making such decisions could be offloaded to
non-scientists.</p>

<p>
Many philosophers accept that values can contribute to the generation
of empirical results without spoiling their epistemic utility.
Anderson&rsquo;s (2004) diagnosis is as follows:</p>

<blockquote>
Deep down, what the objectors find worrisome about allowing value
judgments to guide scientific inquiry is not that they have evaluative
content, but that these judgments might be held dogmatically, so as to
preclude the recognition of evidence that might undermine them. We
need to ensure that value judgements do not operate to drive inquiry
to a predetermined conclusion. This is our fundamental criterion for
distinguishing legitimate from illegitimate uses of values in science.
(11)
</blockquote>

<p>
Data production (including experimental design and execution) is
heavily influenced by investigators&rsquo; background assumptions.
Sometimes these include theoretical commitments that lead
experimentalists to produce non-illuminating or misleading evidence.
In other cases they may lead experimentalists to ignore, or even fail
to produce useful evidence. For example, in order to obtain data on
orgasms in female stumptail macaques, one researcher wired up females
to produce radio records of orgasmic muscle contractions, heart rate
increases, etc. But as Elisabeth Lloyd reports, &ldquo;&hellip; the
researcher &hellip; wired up the heart rate of the male macaques as
the signal to start recording the female orgasms. When I pointed out
that the vast majority of female stumptail orgasms occurred during sex
among the females alone, he replied that yes he knew that, but he was
only interested in important orgasms&rdquo; (Lloyd 1993, 142).
Although female stumptail orgasms occurring during sex with males are
atypical, the experimental design was driven by the assumption that
what makes features of female sexuality worth studying is their
contribution to reproduction (ibid., 139). This assumption influenced
experimental design in such a way as to preclude learning about the
full range of female stumptail orgasms.</p>

<p>
Anderson (2004) presents an influential analysis of the role of values
in research on divorce. Researchers committed to an interpretive
framework rooted in &lsquo;traditional family values&rsquo; could
conduct research on the assumption that divorce is mostly bad for
spouses and any children that they have (ibid., 12). This background
assumption, which is rooted in a normative appraisal of a certain
model of good family life, could lead social science researchers to
restrict the questions with which they survey their research subjects
to ones about the negative impacts of divorce on their lives, thereby
curtailing the possibility of discovering ways that divorce may have
actually made the ex-spouses lives better (ibid., 13). This is an
example of the influence that values can have on the nature of the
results that research ultimately yields, which is epistemically
detrimental. In this case, the values in play biased the research
outcomes to preclude recognition of countervailing evidence. Anderson
argues that the problematic influence of values comes when research
&ldquo;is rigged in advance&rdquo; to confirm certain
hypotheses&mdash;when the influence of values amounts to incorrigible
dogmatism (ibid., 19). &ldquo;Dogmatism&rdquo; in her sense is
unfalsifiability in practice, &ldquo;their stubbornness in the face of
any conceivable evidence&rdquo;(ibid., 22).</p>

<p>
Fortunately, such dogmatism is not ubiquitous and when it occurs it
can often be corrected eventually. Above we noted that the mere
involvement of the theory to be tested in the generation of an
empirical result does not automatically yield vicious
circularity&mdash;it depends on how the theory is
involved. Furthermore, even if the assumptions initially made in the
generation of empirical results are incorrect, future scientists will
have opportunities to reassess those assumptions in light of new
information and techniques. Thus, as long as scientists continue their
work there need be no time at which the epistemic value of an
empirical result can be established once and for all. This should come
as no surprise to anyone who is aware that science is fallible, but it
is no grounds for skepticism. It can be perfectly reasonable to trust
the evidence available at present even though it is logically possible
for epistemic troubles to arise in the future. A similar point can be
made regarding values (although cf. Yap 2016).</p>

<p>
Moreover, while the inclusion of values in the generation of an
empirical result can sometimes be epistemically bad, values properly
deployed can also be harmless, or even epistemically helpful. As in
the cases of research on female stumptail macaque orgasms and the
effects of divorce, certain values can sometimes serve to illuminate
the way in which other epistemically problematic assumptions have
hindered potential scientific insight. By valuing knowledge about
female sexuality beyond its role in reproduction, scientists can
recognize the narrowness of an approach that only conceives of female
sexuality insofar as it relates to reproduction. By questioning the
absolute value of one traditional ideal for flourishing families,
researchers can garner evidence that might end up destabilizing the
empirical foundation supporting that ideal.</p>

<h3><a name="Reuse">3.5 Reuse</a></h3>

<p>
Empirical results are most obviously put to epistemic work in their
contexts of origin. Scientists conceive of empirical research, collect
and analyze the relevant data, and then bring the results to bear on
the theoretical issues that inspired the research in the first place.
However, philosophers have also discussed ways in which empirical
results are transferred out of their native contexts and applied in
diverse and sometimes unexpected ways (see Leonelli and Tempini 2020).
Cases of reuse, or repurposing of empirical results in different
epistemic contexts raise several interesting issues for philosophers
of science. For one, such cases challenge the assumption that theory
(and value) ladenness confines the epistemic utility of empirical
results to a particular conceptual framework. Ancient Babylonian
eclipse records inscribed on cuneiform tablets have been used to
generate constraints on contemporary geophysical theorizing about the
causes of the lengthening of the day on Earth (Stephenson, Morrison,
and Hohenkerk 2016). This is surprising since the ancient observations
were originally recorded for the purpose of making astrological
prognostications. Nevertheless, with enough background information,
the records as inscribed can be translated, the layers of assumptions
baked into their presentation peeled back, and the results repurposed
using resources of the contemporary epistemic context, the likes of
which the Babylonians could have hardly dreamed.</p>

<p>
Furthermore, the potential for reuse and repurposing feeds back on the
methodological norms of data production and handling. In light of the
difficulty of reusing or repurposing data without sufficient
background information about the original context, Goodman et al.
(2014) note that &ldquo;data reuse is most possible when: 1) data; 2)
metadata (information describing the data); and 3) information about
the process of generating those data, such as code, all all
provided&rdquo; (3). Indeed, they advocate for sharing data and code
in addition to results customarily published in science. As we have
seen, the loading of data with theory is usually necessary to putting
that data to any serious epistemic
use&mdash;theory-loading makes theory appraisal possible.
Philosophers have begun to appreciate that this epistemic boon does
not necessarily come at the cost of rendering data &ldquo;tragically
local&rdquo; (Wylie 2020, 285, quoting Latour 1999). But it is
important to note the useful travel of data between contexts is
significantly aided by foresight, curation, and management for that
aim.</p>

<p>
In light of the mediated nature of empirical results, Boyd (2018)
argues for an &ldquo;enriched view of evidence,&rdquo; in which the
evidence that serves as the &lsquo;tribunal of experience&rsquo; is
understood to be &ldquo;lines of evidence&rdquo; composed of the
products of data collection and all of the products of their
transformation on the way to the generation of empirical results that
are ultimately compared to theoretical predictions, considered
together with metadata associated with their provenance. Such metadata
includes information about theoretical assumptions that are made in
data collection, processing, and the presentation of empirical
results. Boyd argues that by appealing to metadata to
&lsquo;rewind&rsquo; the processing of assumption-imbued empirical
results and then by re-processing them using new resources, the
epistemic utility of empirical evidence can survive transitions to new
contexts. Thus, the enriched view of evidence supports the idea that
it is not despite the intertwining of the theoretical and empirical
that scientists accomplish key epistemic aims, but often in virtue of
it (ibid., 420). In addition, it makes the epistemic value of metadata
encoding the various assumptions that have been made throughout the
course of data collection and processing explicit.</p>

<p>
The desirability of explicitly furnishing empirical data and results
with auxiliary information that allow them to travel can be
appreciated in light of the &lsquo;objectivity&rsquo; norm, construed
as accessibility to interpersonal scrutiny. When data are repurposed
in novel contexts, they are not only shared between subjects, but can
in some cases be shared across radically different paradigms with
incompatible theoretical commitments.</p>

<h2><a name="Epistemicvalue">4. The epistemic value of empirical evidence</a></h2>

<p>
One of the important applications of empirical evidence is its use in
assessing the epistemic status of scientific theories. In this section
we briefly discuss philosophical work on the role of empirical
evidence in confirmation/falsification of scientific theories,
&lsquo;saving the phenomena,&rsquo; and in appraising the empirical
adequacy of theories. However, further philosophical work ought to
explore the variety of ways that empirical results bear on the
epistemic status of theories and theorizing in scientific practice
beyond these.</p>

<h3><a name="Confirmation">4.1 Confirmation</a></h3>

<p>
It is natural to think that computability, range of application, and
other things being equal, true theories are better than false ones,
good approximations are better than bad ones, and highly probable
theoretical claims are better than less probable ones. One way to
decide whether a theory or a theoretical claim is true, close to the
truth, or acceptably probable is to derive predictions from it and use
empirical data to evaluate them. Hypothetico-Deductive (HD)
confirmation theorists proposed that empirical evidence argues for
the truth of theories whose deductive consequences it verifies, and
against those whose consequences it falsifies (Popper 1959, 32&ndash;34).
But laws and theoretical generalization seldom if ever entail
observational predictions unless they are conjoined with one or more
auxiliary hypotheses taken from the theory they belong to. When the
prediction turns out to be false, HD has trouble explaining which of
the conjuncts is to blame. If a theory entails a true prediction, it
will continue to do so in conjunction with arbitrarily selected
irrelevant claims. HD has trouble explaining why the prediction does
not confirm the irrelevancies along with the theory of interest.</p>

<p>
Another approach to confirmation by empirical evidence is Inference to the Best Explanation (IBE). The idea is roughly that an explanation of the evidence that exhibits certain desirable characteristics with respect to a family of candidate explanations is likely to be the true on (Lipton 1991). On this approach, it is in virtue of their successful explanation of the empirical evidence that theoretical claims are supported. Naturally, IBE advocates face the challenges of defending a suitable characterization of what counts as the &lsquo;best&rsquo; and of justifying the limited pool of candidate explanations considered (Stanford 2006).</p>

<p>
Bayesian approaches to scientific confirmation have garnered significant attention and are now widespread in philosophy of science. Bayesians hold that the evidential bearing of empirical evidence on a theoretical claim is to be understood in terms of likelihood or conditional probability. For example, whether empirical evidence
argues for a theoretical claim might be thought to depend upon whether
it is more probable (and if so how much more probable) than its denial
conditional on a description of the evidence together with background
beliefs, including theoretical commitments. But by Bayes&rsquo;
Theorem, the posterior probability of the claim of interest (that is, its probability given the evidence) is proportional to that claim&rsquo;s prior probability. How to justify the choice of these prior probability assignments is one of the most notorious points of contention arising for Bayesians. If one makes the assignment of priors a subjective matter decided by epistemic agents, then it is not clear that they can be justified. Once again, one&rsquo;s use of evidence to evaluate a theory depends in part upon one&rsquo;s theoretical commitments (Earman 1992, 33&ndash;86; Roush 2005, 149&ndash;186). If one instead appeals to chains of successive updating using Bayes&rsquo; Theorem based on past evidence, one has to invoke assumptions that generally do not obtain in actual scientific reasoning. For instance, to &lsquo;wash out&rsquo; the influence of priors a limit theorem is invoked wherein we consider very many updating iterations, but much scientific reasoning of interest does not happen in the limit, and so in practice priors hold unjustified sway (Norton 2021, 33).</p>

<p>
Rather than attempting to cast all instances of confirmation based on empirical evidence as belonging to a universal schema, a better approach may be to &lsquo;go local&rsquo;. Norton&rsquo;s material theory of induction argues that inductive support arises from background knowledge, that is, from material facts that are domain specific. Norton argues that, for instance, the induction from &ldquo;Some samples of the element bismuth melt at 271&deg;C&rdquo; to &ldquo;all samples of the element bismuth melt at 271&deg;C&rdquo; is admissible not in virtue of some universal schema that carries us from &lsquo;some&rsquo; to &lsquo;all&rsquo; but matters of fact (Norton 2003). In this particular case, the fact that licenses the induction is a fact about elements: &ldquo;their samples are generally uniform in their physical properties&rdquo; (ibid., 650). This is a fact pertinent to chemical elements, but not to samples of material like wax (ibid.). Thus Norton repeatedly emphasizes that &ldquo;all induction is local&rdquo;.</p>

<p>    
Still, there are those who may be skeptical about the very possibility of confirmation or of successful induction. Insofar as the bearing of evidence on theory is never totally decisive, insofar there is no single trusty universal schema that captures empirical support, perhaps the relationship between empirical evidence and scientific theory is not really about support after all. Giving up on empirical support would not automatically mean abandoning any epistemic value for empirical evidence. Rather than confirm theory, the epistemic role of evidence could be to constrain, for example by furnishing phenomena for theory to systematize or to adequately model.
</p>

<h3><a name="Saving">4.2 Saving the phenomena</a></h3>

<p>
Theories are said to &lsquo;save&rsquo; observable phenomena if they
satisfactorily predict, describe, or systematize them. How well a
theory performs any of these tasks need not depend upon the truth or
accuracy of its basic principles. Thus according to Osiander&rsquo;s
preface to Copernicus&rsquo; <em>On the Revolutions</em>, a locus
classicus, astronomers &ldquo;&hellip; cannot in any way attain to true
causes&rdquo; of the regularities among observable astronomical
events, and must content themselves with saving the phenomena in the
sense of using</p>

<blockquote>
&hellip; whatever suppositions enable &hellip; [them] to be computed
correctly from the principles of geometry for the future as well as
the past &hellip; (Osiander 1543, XX)
</blockquote>

<p>
Theorists are to use those assumptions as calculating tools without
committing themselves to their truth. In particular, the assumption
that the planets revolve around the sun must be evaluated solely in
terms of how useful it is in calculating their observable relative
positions to a satisfactory approximation. Pierre Duhem&rsquo;s
<em>Aim and Structure of Physical Theory</em> articulates a related
conception. For Duhem a physical theory</p>

<blockquote>
&hellip; is a system of mathematical propositions, deduced from a small
number of principles, which aim to represent as simply and completely,
and exactly as possible, a set of experimental laws. (Duhem 1906, 19)
</blockquote>

<p>
&lsquo;Experimental laws&rsquo; are general, mathematical descriptions
of observable experimental results. Investigators produce them by
performing measuring and other experimental operations and assigning
symbols to perceptible results according to pre-established
operational definitions (Duhem 1906, 19). For Duhem, the main function
of a physical theory is to help us store and retrieve information
about observables we would not otherwise be able to keep track of. If
that is what a theory is supposed to accomplish, its main virtue
should be intellectual economy. Theorists are to replace reports of
individual observations with experimental laws and devise higher level
laws (the fewer, the better) from which experimental laws (the more,
the better) can be mathematically derived (Duhem 1906, 21ff).</p>

<p>
A theory&rsquo;s experimental laws can be tested for accuracy and
comprehensiveness by comparing them to observational data. Let EL be
one or more experimental laws that perform acceptably well on such
tests. Higher level laws can then be evaluated on the basis of how
well they integrate EL into the rest of the theory. Some data that
don&rsquo;t fit integrated experimental laws won&rsquo;t be
interesting enough to worry about. Other data may need to be
accommodated by replacing or modifying one or more experimental laws
or adding new ones. If the required additions, modifications or
replacements deliver experimental laws that are harder to integrate,
the data count against the theory. If the required changes are
conducive to improved systematization the data count in favor of it.
If the required changes make no difference, the data don&rsquo;t argue
for or against the theory.</p>

<h3><a name="Empirical">4.3 Empirical adequacy</a></h3>

<p>
On van Fraassen&rsquo;s (1980) semantic account, a theory is
empirically adequate when the empirical structure of at least one
model of that theory is isomorphic to what he calls the
&ldquo;appearances&rdquo; (45). In other words, when the theory
&ldquo;has at least one model that all the actual phenomena fit
inside&rdquo; (12). Thus, for van Fraassen, we continually check the
empirical adequacy of our theories by seeing if they have the
structural resources to accommodate new observations. We&rsquo;ll
never know that a given theory is totally empirically adequate, since
for van Fraassen, empirical adequacy obtains with respect to all that
is observable in principle to creatures like us, not all that has
already been observed (69).</p>

<p>
The primary appeal of dealing in empirical adequacy rather than
confirmation is its appropriate epistemic humility. Instead of
claiming that confirming evidence justifies belief (or boosted
confidence) that a theory is true, one is restricted to saying that
the theory continues to be consistent with the evidence as far as we
can tell so far. However, if the epistemic utility of empirical
results in appraising the status of theories is just to judge their
empirical adequacy, then it may be difficult to account for the
difference between adequate but unrealistic theories, and those
equally adequate theories that ought to be taken seriously as
representations. Appealing to extra-empirical virtues like parsimony
may be a way out, but one that will not appeal to philosophers
skeptical of the connection thereby supposed between such virtues and
representational fidelity.</p>

<h2><a name="Con">5. Conclusion</a></h2>

<p>
On an earlier way of thinking, observation was to serve as the
unmediated foundation of science&mdash;direct access to
the facts upon which the edifice of scientific knowledge could be
built. When conflict arose between factions with different ideological
commitments, observations could furnish the material for neutral
arbitration and settle the matter objectively, in virtue of being
independent of non-empirical commitments. According to this view,
scientists working in different paradigms could at least appeal to the
same observations, and propagandists could be held accountable to the
publicly accessible content of theory and value-free observations.
Despite their different theories, Priestley and Lavoisier could find
shared ground in the observations. Anti-Semites would be compelled to
admit the success of a theory authored by a Jewish physicist, in
virtue of the unassailable facts revealed by
observation.</p>

<p>
This version of empiricism with respect to science does not accord
well with the fact that observation per se plays a relatively small
role in many actual scientific methodologies, and the fact that even
the most &lsquo;raw&rsquo; data is often already theoretically imbued.
The strict contrast between theory and observation in science is more
fruitfully supplanted by inquiry into the relationship between
theorizing and empirical results.</p>

<p>
Contemporary philosophers of science tend to embrace the theory
ladenness of empirical results. Instead of seeing the integration of
the theoretical and the empirical as an impediment to furthering
scientific knowledge, they see it as necessary. A &lsquo;view from
nowhere&rsquo; would not bear on our particular theories. That is, it
is impossible to put empirical results to use without recruiting some
theoretical resources. In order to use an empirical result to
constrain or test a theory it has to be processed into a form that can
be compared to that theory. To get stellar spectrograms to bear on
Newtonian or relativistic cosmology, they need to be
processed&mdash;into galactic rotation curves, say. The spectrograms
by themselves are just artifacts, pieces of paper. Scientists need
theoretical resources in order to even identify that such artifacts
bear information relevant for their purposes, and certainly to put
them to any epistemic use in assessing theories.</p>

<p>
This outlook does not render contemporary philosophers of science all
constructivists, however. Theory mediates the connection between the
target of inquiry and the scientific worldview, it does not sever it.
Moreover, vigilance is still required to ensure that the particular
ways in which theory is &lsquo;involved&rsquo; in the production of
empirical results are not epistemically detrimental. Theory can be
deployed in experiment design, data processing, and presentation of
results in unproductive ways, for instance, in determining whether the
results will speak for or against a particular theory regardless of
what the world is like. Critical appraisal of the roles of theory is
thus important for genuine learning about nature through science.
Indeed, it seems that extra-empirical values can sometimes assist such
critical appraisal. Instead of viewing observation as the theory-free
and for that reason furnishing the content with which to appraise
theories, we might attend to the choices and mistakes that can be made
in collecting and generating empirical results with the help of
theoretical resources, and endeavor to make choices conducive to
learning and correct mistakes as we discover them.</p>

<p>
Recognizing the involvement of theory and values in the constitution
and generation of empirical results does not undermine the special
epistemic value of empirical science in contrast to propaganda and
pseudoscience. In cases where the influence of cultural, political,
and religious values hinder scientific inquiry, it is often the case
that they do so by limiting or determining the nature of the empirical
results. Yet, by working to make the assumptions that shape results
explicit we can examine their suitability for our purposes and attempt
to restructure inquiry as necessary. When disagreements arise,
scientists can attempt to settle them by appealing to the causal
connections between the research target and the empirical data. The
tribunal of experience speaks through empirical results, but it only
does so through via careful fashioning with theoretical resources.</p>
</div>

<div id="bibliography">

<h2><a name="Bib">Bibliography</a></h2>

<ul class="hanging">

<li>Anderson, E., 2004, &ldquo;Uses of Value Judgments in Science: A
General Argument, with Lessons from a Case Study of Feminist Research
on Divorce,&rdquo; <em>Hypatia</em>, 19(1): 1&ndash;24.</li>

<li>Aristotle(a), <em>Generation of Animals</em> in <em>Complete Works
of Aristotle</em> (Volume 1), J. Barnes (ed.), Princeton: Princeton
University Press, 1995, pp. 774&ndash;993</li>

<li>Aristotle(b), <em>History of Animals</em> in <em>Complete Works of
Aristotle</em> (Volume 1), J. Barnes (ed.), Princeton: Princeton
University Press, 1995, pp. 1111&ndash;1228.</li>

<li>Azzouni, J., 2004, &ldquo;Theory, Observation, and Scientific
Realism,&rdquo; <em>British Journal for the Philosophy of
Science</em>, 55(3): 371&ndash;92.</li>

<li>Bacon, Francis, 1620, <em>Novum Organum with other parts of the
Great Instauration</em>, P. Urbach and J. Gibson (eds. and trans.), La
Salle: Open Court, 1994.</li>

<li>Bogen, J., 2016, &ldquo;Empiricism and After,&rdquo;in P.
Humphreys (ed.), <em>Oxford Handbook of Philosophy of Science</em>,
Oxford: Oxford University Press, pp. 779&ndash;795.</li>

<li>Bogen, J, and Woodward, J., 1988, &ldquo;Saving the
Phenomena,&rdquo; <em>Philosophical Review</em>, XCVII (3):
303&ndash;352.</li>

<li>Bokulich, A., 2020, &ldquo;Towards a Taxonomy of the
Model-Ladenness of Data,&rdquo; <em>Philosophy of Science</em>, 87(5):
793&ndash;806.</li>

<li>Borrelli, A., 2012, &ldquo;The Case of the Composite Higgs: The
Model as a &lsquo;Rosetta Stone&rsquo; in Contemporary High-Energy
Physics,&rdquo; <em>Studies in History and Philosophy of Science</em> (Part
B: Studies in History and Philosophy of Modern Physics), 43(3):
195&ndash;214.</li>

<li>Boyd, N. M., 2018, &ldquo;Evidence Enriched,&rdquo; <em>Philosophy
of Science</em>, 85(3): 403&ndash;21.</li>

<li>Boyle, R., 1661, <em>The Sceptical Chymist</em>, Montana:
Kessinger (reprint of 1661 edition).</li>

<li>Bridgman, P., 1927, <em>The Logic of Modern Physics</em>, New
York: Macmillan.</li>

<li>Chang, H., 2005, &ldquo;A Case for Old-fashioned Observability,
and a Reconstructive Empiricism,&rdquo; <em>Philosophy of
Science</em>, 72(5): 876&ndash;887.</li>

<li>Collins, H. M., 1985 <em>Changing Order</em>, Chicago: University
of Chicago Press.</li>

<li>Conant, J.B., 1957, (ed.) &ldquo;The Overthrow of the Phlogiston
Theory: The Chemical Revolution of 1775&ndash;1789,&rdquo; in
J.B.Conant and L.K. Nash (eds.), <em>Harvard Studies in Experimental
Science</em>, Volume I, Cambridge: Harvard University Press, pp.
65&ndash;116).</li>

<li>Daston, L., and P. Galison, 2007, <em>Objectivity</em>, Brooklyn:
Zone Books.</li>

<li>Douglas, H., 2000, &ldquo;Inductive Risk and Values in
Science,&rdquo; <em>Philosophy of Science</em>, 67(4):
559&ndash;79.</li>

<li>&ndash;&ndash;&ndash;, 2013, &ldquo;The Value of Cognitive
Values,&rdquo; <em>Philosophy of Science</em>, 80(5):
796&ndash;806.</li>

<li>Duhem, P., 1906, <em>The Aim and Structure of Physical
Theory</em>, P. Wiener (tr.), Princeton: Princeton University Press,
1991.</li>

<li>Earman, J., 1992, <em>Bayes or Bust?</em>, Cambridge: MIT
Press.</li>

<li>Feest, U., 2005, &ldquo;Operationism in psychology: what the
debate is about, what the debate should be about,&rdquo; <em>Journal
of the History of the Behavioral Sciences</em>, 41(2):
131&ndash;149.</li>

<li>Feyerabend, P.K., 1969, &ldquo;Science Without Experience,&rdquo;
in P.K. Feyerabend, <em>Realism, Rationalism, and Scientific
Method</em> (Philosophical Papers I), Cambridge: Cambridge University
Press, 1985, pp. 132&ndash;136.</li>

<li>Franklin, A., 1986, <em>The Neglect of Experiment</em>, Cambridge:
Cambridge University Press.</li>

<li>Galison, P., 1987, <em>How Experiments End</em>, Chicago:
University of Chicago Press.</li>

<li>&ndash;&ndash;&ndash;, 1990, &ldquo;Aufbau/Bauhaus: logical positivism and
architectural modernism,&rdquo; <em>Critical Inquiry</em>, 16 (4):
709&ndash;753.</li>

<li>Goodman, A., et al., 2014, &ldquo;Ten Simple Rules for the Care and
Feeding of Scientific Data,&rdquo; <em>PLoS Computational
Biology</em>, 10(4): e1003542.</li>

<li>Hacking, I., 1981, &ldquo;Do We See Through a Microscope?,&rdquo;
<em>Pacific Philosophical Quarterly</em>, 62(4): 305&ndash;322.</li>

<li>&ndash;&ndash;&ndash;, 1983, <em>Representing and
Intervening</em>, Cambridge: Cambridge University Press.</li>

<li>Hanson, N.R., 1958, <em>Patterns of Discovery</em>, Cambridge,
Cambridge University Press.</li>

<li>Hempel, C.G., 1952, &ldquo;Fundamentals of Concept Formation in
Empirical Science,&rdquo; in <em>Foundations of the Unity of
Science</em>, Volume 2, O. Neurath, R. Carnap, C. Morris (eds.),
Chicago: University of Chicago Press, 1970, pp. 651&ndash;746.</li>

<li>Herschel, J. F. W., 1830, <em>Preliminary Discourse on the Study
of Natural Philosophy</em>, New York: Johnson Reprint Corp.,
1966.</li>

<li>Hooke, R., 1705, &ldquo;The Method of Improving Natural
Philosophy,&rdquo; in R. Waller (ed.), <em>The Posthumous Works of
Robert Hooke</em>, London: Frank Cass and Company, 1971.</li>

<li>Horowitz, P., and W. Hill, 2015, <em>The Art of Electronics</em>,
third edition, New York: Cambridge University Press.</li>

<li>Intemann, K., 2021, &ldquo;Feminist Perspectives on Values in
Science,&rdquo; in S. Crasnow and L. Intemann (eds.), <em>The
Routledge Handbook of Feminist Philosophy of Science</em>, New York:
Routledge, pp. 201&ndash;15.</li>

<li>Kuhn, T.S., <em>The Structure of Scientific Revolutions</em>,
1962, Chicago: University of Chicago Press, reprinted,1996.</li>

<li>Latour, B., 1999, &ldquo;Circulating Reference: Sampling the Soil
in the Amazon Forest,&rdquo; in <em>Pandora&rsquo;s Hope: Essays on the
Reality of Science Studies</em>, Cambridge, MA: Harvard University
Press, pp. 24&ndash;79.</li>

<li>Latour, B., and Woolgar, S., 1979, <em>Laboratory Life, The
Construction of Scientific Facts</em>, Princeton: Princeton University
Press, 1986.</li>

<li>Laymon, R., 1988, &ldquo;The Michelson-Morley Experiment and the
Appraisal of Theories,&rdquo; in A. Donovan, L. Laudan, and R. Laudan
(eds.), <em>Scrutinizing Science: Empirical Studies of Scientific
Change</em>, Baltimore: The Johns Hopkins University Press,
pp. 245&ndash;266.</li>

<li>Leonelli, S., 2009, &ldquo;On the Locality of Data and Claims
about Phenomena,&rdquo; <em>Philosophy of Science</em>, 76(5):
737&ndash;49.</li>

<li>Leonelli, S., and N. Tempini (eds.), 2020, <em>Data Journeys in
the Sciences</em>, Cham: Springer.</li>

<li>Lipton, P., 1991, <em>Inference to the Best Explanation</em>, London: Routledge.</li>

<li>Lloyd, E.A., 1993, &ldquo;Pre-theoretical Assumptions In
Evolutionary Explanations of Female Sexuality,&rdquo;
<em>Philosophical Studies</em>, 69: 139&ndash;153.</li>

<li>&ndash;&ndash;&ndash;, 2012, &ldquo;The Role of &lsquo;Complex&rsquo;
Empiricism in the Debates about Satellite Data and Climate
Models,&rdquo;, <em>Studies in History and Philosophy of Science</em> (Part
A), 43(2): 390&ndash;401.</li>

<li>Longino, H., 1979, &ldquo;Evidence and Hypothesis: An Analysis of
Evidential Relations,&rdquo; <em>Philosophy of Science</em>, 46(1):
35&ndash;56.</li>

<li>&ndash;&ndash;&ndash;, 2020, &ldquo;Afterward:Data in
Transit,&rdquo; in S.  Leonelli and N. Tempini (eds.), <em>Data
Journeys in the Sciences</em>, Cham: Springer, pp. 391&ndash;400.</li>

<li>Lupyan, G., 2015, &ldquo;Cognitive Penetrability of Perception in
the Age of Prediction &ndash; Predictive Systems are Penetrable
Systems,&rdquo; <em>Review of Philosophical Psychology</em>, 6(4):
547&ndash;569. doi:10.1007/s13164-015-0253-4</li>

<li>Mill, J. S., 1872, <em>System of Logic</em>, London: Longmans,
Green, Reader, and Dyer.</li>

<li>Norton, J., 2003, &ldquo;A Material Theory of Induction,&rdquo; <em>Philosophy of Science</em>, 70(4): 647&ndash;70.</li>

<li>&ndash;&ndash;&ndash;, 2021, <em>The Material Theory of Induction</em>, <a href="http://www.pitt.edu/~jdnorton/papers/material_theory/Material_Induction_March_14_2021.pdf">http://www.pitt.edu/~jdnorton/papers/material_theory/Material_Induction_March_14_2021.pdf</a>.</li>

<li>Nyquist, H., 1928, &ldquo;Thermal Agitation of Electric Charge in
Conductors,&rdquo; <em>Physical Review</em>, 32(1): 110&ndash;13.</li>

<li>O&rsquo;Connor, C. and J. O. Weatherall, 2019, <em>The
Misinformation Age: How False Beliefs Spread</em>, New Haven: Yale
University Press.</li>

<li>Olesko, K.M. and Holmes, F.L., 1994, &ldquo;Experiment,
Quantification and Discovery: Helmholtz&rsquo;s Early Physiological
Researches, 1843&ndash;50,&rdquo; in D. Cahan, (ed.), <em>Hermann
Helmholtz and the Foundations of Nineteenth Century Science</em>,
Berkeley: UC Press, pp. 50&ndash;108.</li>

<li>Osiander, A., 1543, &ldquo;To the Reader Concerning the Hypothesis
of this Work,&rdquo; in N. Copernicus <em>On the Revolutions</em>, E.
Rosen (tr., ed.), Baltimore: Johns Hopkins University Press, 1978, p.
XX.</li>

<li>Parker, W. S., 2016, &ldquo;Reanalysis and Observation:
What&rsquo;s the Difference?,&rdquo; <em>Bulletin of the
American Meteorological Society</em>, 97(9): 1565&ndash;72.</li>

<li>&ndash;&ndash;&ndash;, 2017, &ldquo;Computer Simulation,
Measurement, and Data Assimilation,&rdquo; <em>The British Journal for
the Philosophy of Science</em>, 68(1): 273&ndash;304.</li>

<li>Popper, K.R.,1959, <em>The Logic of Scientific Discovery</em>,
K.R. Popper (tr.), New York: Basic Books.</li>

<li>Rheinberger, H. J., 1997, <em>Towards a History of Epistemic
Things: Synthesizing Proteins in the Test Tube</em>, Stanford:
Stanford University Press.</li>

<li>Roush, S., 2005, <em>Tracking Truth</em>, Cambridge: Cambridge
University Press.</li>

<li>Rudner, R., 1953, &ldquo;The Scientist Qua Scientist Makes Value
Judgments,&rdquo; <em>Philosophy of Science</em>, 20(1):
1&ndash;6.</li>

<li>Schlick, M., 1935, &ldquo;Facts and Propositions,&rdquo; in
<em>Philosophy and Analysis</em>, M. Macdonald (ed.), New York:
Philosophical Library, 1954, pp. 232&ndash;236.</li>

<li>Schottky, W. H., 1918, &ldquo;&Uuml;ber spontane Stromschwankungen
in verschiedenen Elektrizit&auml;tsleitern,&rdquo; <em>Annalen der
Physik</em>, 362(23): 541&ndash;67.</li>

<li>Shapere, D., 1982, &ldquo;The Concept of Observation in Science
and Philosophy,&rdquo; <em>Philosophy of Science</em>, 49(4):
485&ndash;525.</li>

<li>Stanford, K., 1991, <em>Exceeding Our Grasp: Science, History, and the Problem of Unconceived Alternatives</em>, Oxford: Oxford University Press.</li>

<li>Stephenson, F. R., L. V. Morrison, and C. Y. Hohenkerk, 2016,
&ldquo;Measurement of the Earth&rsquo;s Rotation: 720 BC to AD
2015,&rdquo; <em>Proceedings of the Royal Society A: Mathematical,
Physical and Engineering Sciences</em>, 472: 20160404.</li>

<li>Stuewer, R.H., 1985, &ldquo;Artificial Disintegration and the
Cambridge-Vienna Controversy,&rdquo; in P. Achinstein and O. Hannaway
(eds.), <em>Observation, Experiment, and Hypothesis in Modern Physical
Science</em>, Cambridge, MA: MIT Press, pp. 239&ndash;307.</li>

<li>Suppe, F., 1977, in F. Suppe (ed.) <em>The Structure of Scientific
Theories</em>, Urbana: University of Illinois Press.</li>

<li>Van Fraassen, B.C, 1980, <em>The Scientific Image</em>, Oxford:
Clarendon Press.</li>

<li>Ward, Z. B., 2021, &ldquo;On Value-Laden Science,&rdquo;
<em>Studies in History and Philosophy of Science Part A</em>, 85: 54&ndash;62.</li>

<li>Whewell, W., 1858, <em>Novum Organon Renovatum</em>, Book II, in
<em>William Whewell Theory of Scientific Method</em>, R.E. Butts
(ed.), Indianapolis: Hackett Publishing Company, 1989, pp.
103&ndash;249.</li>

<li>Woodward, J. F., 2010, &ldquo;Data, Phenomena, Signal, and
Noise,&rdquo; <em>Philosophy of Science</em>, 77(5):
792&ndash;803.</li>

<li>&ndash;&ndash;&ndash;, 2011, &ldquo;Data and Phenomena: A Restatement
and Defense,&rdquo; <em>Synthese</em>, 182(1): 165&ndash;79.</li>

<li>Wylie, A., 2020, &ldquo;Radiocarbon Dating in Archaeology:
Triangulation and Traceability,&rdquo; in S. Leonelli and N. Tempini
(eds.), <em>Data Journeys in the Sciences</em>, Cham: Springer,
pp. 285&ndash;301.</li>

<li>Yap, A., 2016, &ldquo;Feminist Radical Empiricism, Values, and
Evidence,&rdquo; <em>Hypatia</em>, 31(1): 58&ndash;73.</li>

</ul>

</div> 

<div id="academic-tools">

<h2 id="Aca">Academic Tools</h2>

<blockquote>
<table class="vert-top">
<tr>
<td><img src="../../symbols/sepman-icon.jpg" alt="sep man icon" /></td>
<td><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=science-theory-observation" target="other">How to cite this entry</a>.</td>
</tr>

<tr>
<td><img src="../../symbols/sepman-icon.jpg" alt="sep man icon" /></td>
<td><a href="https://leibniz.stanford.edu/friends/preview/science-theory-observation/" target="other">Preview the PDF version of this entry</a> at the
 <a href="https://leibniz.stanford.edu/friends/" target="other">Friends of the SEP Society</a>.</td>
</tr>

<tr>
<td><img src="../../symbols/inpho.png" alt="inpho icon" /></td>
<td><a href="https://www.inphoproject.org/entity?sep=science-theory-observation&amp;redirect=True" target="other">Look up topics and thinkers related to this entry</a>
 at the Internet Philosophy Ontology Project (InPhO).</td>
</tr>

<tr>
<td><img src="../../symbols/pp.gif" alt="phil papers icon" /></td>
<td><a href="https://philpapers.org/sep/science-theory-observation/" target="other">Enhanced bibliography for this entry</a>
at <a href="https://philpapers.org/" target="other">PhilPapers</a>, with links to its database.</td>
</tr>

</table>
</blockquote>

</div>

<div id="other-internet-resources">

<h2><a name="Oth">Other Internet Resources</a></h2>

<ul>

 <li><a href="http://www.iep.utm.edu/c/conf-ind.htm" target="other">Confirmation</a>,
 by Franz Huber, in the <em>Internet Encyclopedia of
Philosophy</em>.</li>

 <li><a href="https://ncse.com/files/pub/legal/kitzmiller/highlights/2005-12-20_Kitzmiller_decision.pdf" target="other">Transcript of Katzmiller v. Dover Area School District</a>
 (on the teaching of intelligent design).</li>
</ul>
</div>

<div id="related-entries">

<h2><a name="Rel">Related Entries</a></h2>

<p>

 <a href="../francis-bacon/index.html">Bacon, Francis</a> |
 <a href="../bayes-theorem/index.html">Bayes&rsquo; Theorem</a> |
 <a href="../constructive-empiricism/index.html">constructive empiricism</a> |
 <a href="../duhem/index.html">Duhem, Pierre</a> |
 <a href="../logical-empiricism/index.html">empiricism: logical</a> |
 <a href="../epistemology-bayesian/index.html">epistemology: Bayesian</a> |
 <a href="../feminist-science/index.html">feminist philosophy, topics: perspectives on science</a> |
 <a href="../incommensurability/index.html">incommensurability: of scientific theories</a> |
 <a href="../locke/index.html">Locke, John</a> |
 <a href="../measurement-science/index.html">measurement: in science</a> |
 <a href="../models-science/index.html">models in science</a> |
 <a href="../physics-experiment/index.html">physics: experiment in</a> |
 <a href="../pseudo-science/index.html">science: and pseudo-science</a> |
 <a href="../scientific-objectivity/index.html">scientific objectivity</a> |
 <a href="../science-big-data/index.html">scientific research and big data</a> |
 <a href="../statistics/index.html">statistics, philosophy of</a>

</p>

</div> 

</div><!-- #aueditable --><!--DO NOT MODIFY THIS LINE AND BELOW-->

<!-- END ARTICLE HTML -->

</div> <!-- End article-content -->

  <div id="article-copyright">
    <p>
 <a href="../../info.html#c">Copyright &copy; 2021</a> by

<br />
<a href="https://facultyweb.siena.edu/~nboyd/" target="other">Nora Mills Boyd</a>
&lt;<a href="m&#97;ilto:nboyd&#37;40siena&#37;2eedu"><em>nboyd<abbr title=" at ">&#64;</abbr>siena<abbr title=" dot ">&#46;</abbr>edu</em></a>&gt;<br />
James Bogen

    </p>
  </div>

</div> <!-- End article -->

<!-- NOTE: article banner is outside of the id="article" div. -->
<div id="article-banner" class="scroll-block">
  <div id="article-banner-content">
    <a href="../../fundraising/index.html">
    Open access to the SEP is made possible by a world-wide funding initiative.<br />
    The Encyclopedia Now Needs Your Support<br />
    Please Read How You Can Help Keep the Encyclopedia Free</a>
  </div>
</div> <!-- End article-banner -->

    </div> <!-- End content -->

    <div id="footer">

      <div id="footer-menu">
        <div class="menu-block">
          <h4><i class="icon-book"></i> Browse</h4>
          <ul role="menu">
            <li><a href="../../contents.html">Table of Contents</a></li>
            <li><a href="../../new.html">What's New</a></li>
            <li><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/random">Random Entry</a></li>
            <li><a href="../../published.html">Chronological</a></li>
            <li><a href="../../archives/index.html">Archives</a></li>
          </ul>
        </div>
        <div class="menu-block">
          <h4><i class="icon-info-sign"></i> About</h4>
          <ul role="menu">
            <li><a href="../../info.html">Editorial Information</a></li>
            <li><a href="../../about.html">About the SEP</a></li>
            <li><a href="../../board.html">Editorial Board</a></li>
            <li><a href="../../cite.html">How to Cite the SEP</a></li>
            <li><a href="../../special-characters.html">Special Characters</a></li>
            <li><a href="../../tools/index.html">Advanced Tools</a></li>
            <li><a href="../../contact.html">Contact</a></li>
          </ul>
        </div>
        <div class="menu-block">
          <h4><i class="icon-leaf"></i> Support SEP</h4>
          <ul role="menu">
            <li><a href="../../support/index.html">Support the SEP</a></li>
            <li><a href="../../support/friends.html">PDFs for SEP Friends</a></li>
            <li><a href="../../support/donate.html">Make a Donation</a></li>
            <li><a href="../../support/sepia.html">SEPIA for Libraries</a></li>
          </ul>
        </div>
      </div> <!-- End footer menu -->

      <div id="mirrors">
        <div id="mirror-info">
          <h4><i class="icon-globe"></i> Mirror Sites</h4>
          <p>View this site from another server:</p>
        </div>
        <div class="btn-group open">
          <a class="btn dropdown-toggle" data-toggle="dropdown" href="https://plato.stanford.edu/">
            <span class="flag flag-usa"></span> USA (Main Site) <span class="caret"></span>
            <span class="mirror-source">Philosophy, Stanford University</span>
          </a>
          <ul class="dropdown-menu">
            <li><a href="../../mirrors.html">Info about mirror sites</a></li>
          </ul>
        </div>
      </div> <!-- End mirrors -->
      
      <div id="site-credits">
        <p>The Stanford Encyclopedia of Philosophy is <a href="../../info.html#c">copyright &copy; 2021</a> by <a href="http://mally.stanford.edu/">The Metaphysics Research Lab</a>, Department of Philosophy, Stanford University</p>
        <p>Library of Congress Catalog Data: ISSN 1095-5054</p>
      </div> <!-- End site credits -->

    </div> <!-- End footer -->

  </div> <!-- End container -->

   <!-- NOTE: Script required for drop-down button to work (mirrors). -->
  <script>
    $('.dropdown-toggle').dropdown();
  </script>

</body>

<!-- Mirrored from seop.illc.uva.nl/entries/science-theory-observation/ by HTTrack Website Copier/3.x [XR&CO'2014], Wed, 22 Jun 2022 19:55:08 GMT -->
</html>
