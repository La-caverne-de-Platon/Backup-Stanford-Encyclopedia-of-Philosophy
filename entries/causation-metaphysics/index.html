<!DOCTYPE html>
<!--[if lt IE 7]> <html class="ie6 ie"> <![endif]-->
<!--[if IE 7]>    <html class="ie7 ie"> <![endif]-->
<!--[if IE 8]>    <html class="ie8 ie"> <![endif]-->
<!--[if IE 9]>    <html class="ie9 ie"> <![endif]-->
<!--[if !IE]> --> <html> <!-- <![endif]-->

<!-- Mirrored from seop.illc.uva.nl/entries/causation-metaphysics/ by HTTrack Website Copier/3.x [XR&CO'2014], Wed, 22 Jun 2022 19:41:11 GMT -->
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>
The Metaphysics of Causation (Stanford Encyclopedia of Philosophy)
</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="robots" content="noarchive, noodp" />
<meta property="citation_title" content="The Metaphysics of Causation" />
<meta property="citation_author" content="Gallow, J. Dmitri" />
<meta property="citation_publication_date" content="2022/04/14" />
<meta name="DC.title" content="The Metaphysics of Causation" />
<meta name="DC.creator" content="Gallow, J. Dmitri" />
<meta name="DCTERMS.issued" content="2022-04-14" />
<meta name="DCTERMS.modified" content="2022-04-14" />

<!-- NOTE: Import webfonts using this link: -->
<link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,300,600,200&amp;subset=latin,latin-ext" rel="stylesheet" type="text/css" />

<link rel="stylesheet" type="text/css" media="screen,handheld" href="../../css/bootstrap.min.css" />
<link rel="stylesheet" type="text/css" media="screen,handheld" href="../../css/bootstrap-responsive.min.css" />
<link rel="stylesheet" type="text/css" href="../../css/font-awesome.min.css" />
<!--[if IE 7]> <link rel="stylesheet" type="text/css" href="../../css/font-awesome-ie7.min.css"> <![endif]-->
<link rel="stylesheet" type="text/css" media="screen,handheld" href="../../css/style.css" />
<link rel="stylesheet" type="text/css" media="print" href="../../css/print.css" />
<link rel="stylesheet" type="text/css" href="../../css/entry.css" />
<!--[if IE]> <link rel="stylesheet" type="text/css" href="../../css/ie.css" /> <![endif]-->
<script type="text/javascript" src="../../js/jquery-1.9.1.min.js"></script>
<script type="text/javascript" src="../../js/bootstrap.min.js"></script>

<!-- NOTE: Javascript for sticky behavior needed on article and ToC pages -->
<script type="text/javascript" src="../../js/jquery-scrolltofixed-min.js"></script>
<script type="text/javascript" src="../../js/entry.js"></script>

<!-- SEP custom script -->
<script type="text/javascript" src="../../js/sep.js"></script>
</head>

<!-- NOTE: The nojs class is removed from the page if javascript is enabled. Otherwise, it drives the display when there is no javascript. -->
<body class="nojs article" id="pagetopright">
<div id="container">
<div id="header-wrapper">
  <div id="header">
    <div id="branding">
      <div id="site-logo"><a href="../../index.html"><img src="../../symbols/sep-man-red.png" alt="SEP home page" /></a></div>
      <div id="site-title"><a href="../../index.html">Stanford Encyclopedia of Philosophy</a></div>
    </div>
    <div id="navigation">
      <div class="navbar">
        <div class="navbar-inner">
          <div class="container">
            <button class="btn btn-navbar collapsed" data-target=".collapse-main-menu" data-toggle="collapse" type="button"> <i class="icon-reorder"></i> Menu </button>
            <div class="nav-collapse collapse-main-menu in collapse">
              <ul class="nav">
                <li class="dropdown open"><a id="drop1" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-book"></i> Browse</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop1">
                    <li><a href="../../contents.html">Table of Contents</a></li>
                    <li><a href="../../new.html">What's New</a></li>
                    <li><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/random">Random Entry</a></li>
                    <li><a href="../../published.html">Chronological</a></li>
                    <li><a href="../../archives/index.html">Archives</a></li>
                  </ul>
                </li>
                <li class="dropdown open"><a id="drop2" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-info-sign"></i> About</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop2">
                    <li><a href="../../info.html">Editorial Information</a></li>
                    <li><a href="../../about.html">About the SEP</a></li>
                    <li><a href="../../board.html">Editorial Board</a></li>
                    <li><a href="../../cite.html">How to Cite the SEP</a></li>
                    <li><a href="../../special-characters.html">Special Characters</a></li>
                    <li><a href="../../tools/index.html">Advanced Tools</a></li>
                    <li><a href="../../contact.html">Contact</a></li>
                  </ul>
                </li>
                <li class="dropdown open"><a id="drop3" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-leaf"></i> Support SEP</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop3">
                    <li><a href="../../support/index.html">Support the SEP</a></li>
                    <li><a href="../../support/friends.html">PDFs for SEP Friends</a></li>
                    <li><a href="../../support/donate.html">Make a Donation</a></li>
                    <li><a href="../../support/sepia.html">SEPIA for Libraries</a></li>
                  </ul>
                </li>
              </ul>
            </div>
          </div>
        </div>
      </div>
    </div>
    <!-- End navigation -->
    
    <div id="search">
      <form id="search-form" method="get" action="https://seop.illc.uva.nl/search/searcher.py">
        <input type="search" name="query" placeholder="Search SEP" />
        <div class="search-btn-wrapper"><button class="btn search-btn" type="submit"><i class="icon-search"></i></button></div>
      </form>
    </div>
    <!-- End search --> 
    
  </div>
  <!-- End header --> 
</div>
<!-- End header wrapper -->

<div id="content">

<!-- Begin article sidebar -->
<div id="article-sidebar" class="sticky">
  <div class="navbar">
    <div class="navbar-inner">
      <div class="container">
        <button class="btn btn-navbar" data-target=".collapse-sidebar" data-toggle="collapse" type="button"> <i class="icon-reorder"></i> Entry Navigation </button>
        <div id="article-nav" class="nav-collapse collapse-sidebar in collapse">
          <ul class="nav">
            <li><a href="#toc">Entry Contents</a></li>
            <li><a href="#Bib">Bibliography</a></li>
            <li><a href="#Aca">Academic Tools</a></li>
            <li><a href="https://leibniz.stanford.edu/friends/preview/causation-metaphysics/">Friends PDF Preview <i class="icon-external-link"></i></a></li>
            <li><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=causation-metaphysics">Author and Citation Info <i class="icon-external-link"></i></a> </li>
            <li><a href="#pagetopright" class="back-to-top">Back to Top <i class="icon-angle-up icon2x"></i></a></li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</div>
<!-- End article sidebar --> 

<!-- NOTE: Article content must have two wrapper divs: id="article" and id="article-content" -->
<div id="article">
<div id="article-content">

<!-- BEGIN ARTICLE HTML -->


<div id="aueditable"><!--DO NOT MODIFY THIS LINE AND ABOVE-->

<h1>The Metaphysics of Causation</h1><div id="pubinfo"><em>First published Thu Apr 14, 2022</em></div>

<div id="preamble">

<!--pdf exclude begin-->
<p class="smaller">
[<em>Editor&rsquo;s Note: The following new entry by J. Dmitri Gallow replaces the
 <a href="https://plato.stanford.edu/archives/spr2022/entries/causation-metaphysics/">former entry</a>
on this topic by the previous author.</em>]
</p>
<!--pdf exclude end-->

<p>
Consider the following claims:</p>

<ol>

<li id="claim1">The drought caused the famine.</li>

<li id="claim2">Drowsy driving causes crashes.</li>

<li id="claim3">How much I water my plant influences how tall it
grows.</li>

<li id="claim4">How much novocaine a patient receives affects how much
pain they will feel during dental surgery.</li>
</ol>

<p>
The metaphysics of causation asks questions about what it takes for
claims like these to be true&mdash;what kind of relation the claims
are about, and in virtue of what these relations obtain.</p>

<p>
Although both 1 and 2 are broadly causal claims, some think that they
are not claims about the same <em>kind</em> of causal relation. These
causal relations may be differentiated by their relata. Claim 1
relates <em>tokens</em>. It talks about a <em>particular</em> drought
and famine, not droughts and famines <em>in general</em>. On the other
hand, claim 2 relates <em>types</em>&mdash;it is not talking about any
particular instance of drowsy driving, but rather drowsy driving
<em>in general</em>. A prominent view is that there are different
kinds of causal relation corresponding to these different kinds of
relata. (See, for instance, Sober 1985 and Eells 1991.)</p>

<p>
Contrast 1 and 2 with claims like 3 and 4. In claim 3, the causal verb
&ldquo;influences&rdquo; is not flanked by token happenings, nor types
of happenings. Instead, it is flanked by what we can call <em>variable
expressions</em>. Variable expressions are interrogative clauses like
&ldquo;how much I weigh&rdquo;, &ldquo;what the scale reads&rdquo;,
&ldquo;when the game ends&rdquo;, and &ldquo;whether I catch the
bus&rdquo;. We can call the denotation of variable expressions
<em>variables</em>. Just as we distinguish between token happenings
and types of happenings, we may distinguish between token variables
and type variables. For instance, <em>how much I weigh</em> is a token
variable whose value depends upon my weight. <em>How much Barack Obama
weighs</em> is a different token variable whose value depends upon
Obama&rsquo;s weight. We may say that how much I exercise affects how
much I weigh. And we may say that how much Obama exercises affects how
much Obama weighs. These are two different claims are about causal
relations between token variables. Alternatively, we could claim that
how much one exercises affects how much one weighs. On its face, this
is not a claim about any particular variable. Instead, it is talking
about how exercise affects weight <em>in general</em>. It asserts a
relationship between two <em>types</em> of variables. Likewise, 4
doesn&rsquo;t make a claim about the relationship between any
particular individual&rsquo;s novocaine and sensation. Instead, it
says something about how novocaine affects sensation <em>in
general</em>.</p>

<p>
We will be careful to distinguish these four different kinds of causal
claims. Unfortunately, there is no standard terminology to mark the
distinction between causal claims likes like 1 &amp; 2 and causal
claims like 3 &amp; 4. So let us introduce new conventions. To mark
their contrast with variables, call causal relata like droughts,
famines, and car crashes (whether type or token)
&ldquo;constants&rdquo;. Then, let us call the relation which holds
between constants <em>causation</em>. A causal claim that relates
token constants will be called a claim about <em>token causation</em>.
(This is sometimes called <em>singular causation</em>, or <em>actual
causation</em>.) A causal claim that relates types of constants will
be called a claim about <em>type causation</em>. (This is sometimes
called <em>general causation</em>.) On the other hand, the relation
which holds between variables (whether type or token) will be called
<em>influence</em>. A causal claim that relates token variables will
be called a claim about <em>token influence</em>. (Hitchcock 2007a,
uses <em>token causal structure</em> for a network of relations of
token influence.) A causal claim that relates types of variables will
be called a claim about <em>type influence</em>.</p>

<table class="cellpad-small-dense centered hrulesTH">
<thead>
<tr>
<th>&nbsp;</th>
<th><em>Tokens</em></th>
<th><em>Types</em></th> </tr> </thead>
<tbody>
<tr>
<th><em>Constants</em></th>
  <td>Token Causation</td>
  <td>Type Causation</td> </tr>
<tr>
<th><em>Variables</em></th>
  <td>Token Influence</td>
  <td>Type Influence</td> </tr> </tbody>
</table>

<p>
For each of these putative causal relations, we can raise metaphysical
questions: What are their relata? What is their arity? In virtue of
what do those relata stand in the relevant causal relation? And how
does this kind of causal relation relate to the others? Of course,
there is disagreement about whether each&mdash;or any&mdash;of these
relations exists. Russell (1912: 1) famously denied that there are any
causal relations at all, quipping that causation is &ldquo;a relic of
a bygone age, surviving, like the monarchy, only because it is
erroneously supposed to do no harm&rdquo; (see also Norton 2003).
Others may deny that there is a relation of general causation or
influence at all, contending that claims like 2 and 3 are simply
generalizations about token causal relations (see
 <a href="#RelaTokeCaus">&sect;2.1</a>
 below).</p>
</div> 

<div id="toc">

<!--Entry Contents-->
<ul>
<li><a href="#TokeCaus">1. Token Causation</a>

	<ul>
	<li><a href="#Rela">1.1 Relata</a>

		<ul>
		<li><a href="#Even">1.1.1 Events</a></li>
		<li><a href="#Fact">1.1.2 Facts</a></li>
		<li><a href="#VariValu">1.1.3 Variable Values</a></li>
		<li><a href="#FineGraiCausDiff">1.1.4 Fineness of Grain and Causal Differences</a></li>
		</ul>
		</li>
	<li><a href="#Rela_1">1.2 Relation</a>
		<ul>
		<li><a href="#Inst">1.2.1 Instances</a></li>
		<li><a href="#Arit">1.2.2 Arity</a></li>
		<li><a href="#Norm">1.2.3 Normality</a></li>
		</ul>
		</li>
	</ul>
	</li>
<li><a href="#TypeCaus">2. Type Causation</a>
	<ul>
	<li><a href="#RelaTokeCaus">2.1 Relationship to Token Causation</a></li>
	<li><a href="#NetCompEffe">2.2 Net and Component Effects</a></li>
	</ul>
	</li>
<li><a href="#Infl">3. Influence</a>
	<ul>
	<li><a href="#Rela_2">3.1 Relata</a></li>
	<li><a href="#Mode">3.2 Models</a></li>
	<li><a href="#RelaTokeCaus_1">3.3 Relationship to Token Causation</a></li>
	<li><a href="#MetaMode">3.4 The Metaphysics of the Models</a></li>
	</ul>
	</li>
<li><a href="#Bib">Bibliography</a></li>
<li><a href="#Aca">Academic Tools</a></li>
<li><a href="#Oth">Other Internet Resources</a></li>
<li><a href="#Rel">Related Entries</a></li>
</ul>
<!--Entry Contents-->
<hr />

</div>

<div id="main-text">

<h2 id="TokeCaus">1. Token Causation</h2>

<h3 id="Rela">1.1 Relata</h3>

<p>
Claims like 1 describe a relation which holds between <em>token</em>
causes and effects&mdash;but what are token causes and effects? What
are the relata of the token causal relations described by claims like
1? One popular view is that token causes and effects are
<em>events</em> (Davidson 1963, 1967; Kim 1973; Lewis 1986b&mdash;see
the entry on
 <a href="../events/index.html">events</a>).
 Others hold that token causes and effects are facts (Bennett 1988;
Mellor 1995&mdash;see the entry on
 <a href="../facts/index.html">facts</a>).
 Within the causal modeling approach (see the entry on
 <a href="../causal-models/index.html">causal models</a>),
 it is often assumed that causes and effects are the <em>values of
variables</em> (Hitchcock 2001a; Woodward 2003; Halpern &amp; Pearl
2005; Hall 2007; Halpern 2016a). One also finds support for other
relata like <em>conditions</em> (J. L. Mackie 1965), <em>event
allomorphs</em> (Dretske 1977), <em>tropes</em> (Campbell 1990),
<em>states of affairs</em> (Armstrong 1997; Dowe 2000: ch. 7),
<em>situations</em> (Menzies 1989a), and <em>aspects</em> (Paul 2000).
Allegiances are complicated by disagreements over what events, facts,
and these other creatures are. For instance, for both Bennett and
Mellor, facts are just states-of-affairs which obtain, bringing their
position in line with Armstrong&rsquo;s. And, amongst those who agree
that the causal relata are events, there is considerable disagreement
about what exactly events are.</p>

<h4 id="Even">1.1.1 Events</h4>

<p>
Let&rsquo;s begin with events. Some have proposed that events are just
regions of spacetime (Lemmon 1966; Quine 1985). That is: they propose
that events are individuated by the time and place of their
occurrence. This is a very coarse-grained view of events. According to
it, no two distinct events can occur at the same place and time. To
see why some think this individuates events <em>too</em> coarsely,
consider the example form Davidson (1969): A metal ball is spun on a
hotplate. As it rotates, the ball heats up. It heats up and rotates
within precisely the same region of spacetime. So, if we individuate
events in terms of the time and place of their occurrence, then we
must say that the ball&rsquo;s heating up and its rotation are one and
the same event. But it can seem that the ball&rsquo;s heating up and
its rotation differ causally. The ball&rsquo;s heating up caused the
surroundings to warm, but it does not appear that the ball&rsquo;s
rotation caused the surroundings to warm. Similarly, the ball&rsquo;s
being spun caused it to rotate, but didn&rsquo;t cause it to heat up.
And the hotplate caused the ball to heat up, but didn&rsquo;t cause it
to rotate. Moved by examples like these, Davidson (1969) suggests
individuating events by their causes and effects. That is, Davidson
proposes that <i>x</i> and <i>y</i> are the same event iff, for
every event <i>z</i>, both <i>z</i> caused <i>x</i> iff
<i>z</i> caused <i>y</i> and <i>x</i> caused <i>z</i> iff
<i>y</i> caused <i>z</i>. The left-to-right direction of this
biconditional follows from the Indiscernability of Identicals, so the
right-to-left is the substantive direction; it tells us that we should
not draw any more distinctions between events than are needed to
account for differences in causation. This imposes a constraint on how
a theory of events must relate to a theory of causation, but on its
own, it does not tell us what events are, nor how finely they are
individuated. After all, without some additional claims about which
events are causally related, Davidson&rsquo;s thesis is entirely
consistent with the claim that the ball&rsquo;s rotation and its
heating are identical.</p>

<p>
Kim (1976) provides a more detailed fine-grained theory of events.
According to him, events are individuated by the properties or
relations they involve, the objects which exemplify those properties
or relations, and the times during which they exemplify those
properties or relations. For instance, the event of the ball rotating
is the triple of the property of rotation, the object of the ball, and
the time interval during which the ball rotates: &lang;is rotating,
the ball, <i>t</i><sub>1</sub>&ndash;<i>t</i><sub>2</sub>&rang;.
And the event of the ball heating is the triple of the property of
heating, the object of the ball, and the time interval during which
the ball heats: &lang;is heating, the
ball, <i>t</i><sub>1</sub>&ndash;<i>t</i><sub>2</sub>&rang;. These
two triples involve different properties, so they are different
events.</p>

<p>
Lewis (1986b) gives a different fine-grained theory of events. On
Lewis&rsquo;s view, events are properties of a spacetime region. For
Lewis, properties are intensions, or classes of possible individuals.
So, on Lewis&rsquo;s view, events are classes of spacetime regions at
possible worlds. What it is for an event to occur at a world,
<i>w</i>, is for the event to contain a spacetime region from
<i>w</i>. Lewis is also able to distinguish the ball&rsquo;s
rotation from its heating; though these events occupy the same region
of spacetime at the actual world, they do not necessarily co-occur. It
is possible for the ball to heat without rotating, and it is possible
for the ball to rotate without heating. So the class of spacetime
regions in which the ball rotates is not the same as the class of
spacetime regions in which the ball heats, and if Lewis identifies the
former class with the event of the ball rotating, and the latter with
the event of the ball heating, then he may distinguish these two
events.</p>

<h4 id="Fact">1.1.2 Facts</h4>

<p>
One reason to be unhappy with the view that token causes and effects
are events is that it appears that <em>absences</em> or
<em>omissions</em> can be involved in causal relations. For instance,
Anna&rsquo;s failure to water her plant may cause it to die. Here, we
have an absence as a token cause. Likewise, Anna&rsquo;s vacation may
have caused her to not water the plant. Here, we have an absence as a
token effect. But it does not seem that absences or omissions are
events. They are <em>nothings</em>, non-occurrences, and are hence not
identical to any occurrent events. This motivates taking token causes
and effects to be <em>facts</em>, rather than events. Even if there is
no event which is Anna&rsquo;s failing to water her plant, it is
nonetheless a fact that Anna didn&rsquo;t water her plant.</p>

<p>
Some are not moved by this consideration because they deny that
absences can be token causes and effects. For instance, Armstrong
claims</p>

<blockquote>

<p>
Omissions and so forth are not part of the real driving force in
nature. Every causal situation develops as it does as a result of the
presence of positive factors alone. (1999: 17, see also Thomson 2003,
Beebee 2004a, and Moore 2009)</p>
</blockquote>

<p>
This position doesn&rsquo;t necessarily preclude one from admitting
that absences can stand in some cause-like relation; for instance,
Dowe (2000, 2001) develops an account of ersatz causation (causation*)
which relates absences, even though he denies that causation proper
ever relates absences. Others are unmoved because they think that
absences are events. For instance, a Kimian could take Anna&rsquo;s
failure to water her plant to be her exemplification of a negative
property (the property of not watering her plant) throughout some time
interval. Alternatively, Hart and Honor&eacute; propose that</p>

<blockquote>

<p>
negative statements like &ldquo;he did not pull the signal&rdquo; are
ways of describing the world, just as affirmative statements are, but
they describe it by <em>contrast</em> not by <em>comparison</em> as
affirmative statements do. (1959 [1985: 38])</p>
</blockquote>

<p>
For example, suppose that, instead of watering the plant, Anna took a
stroll. Then we could take &ldquo;Anna&rsquo;s failure to water her
plant&rdquo; to be a contrastive way of describing Anna&rsquo;s
stroll; we could then allow that the event of Anna&rsquo;s stroll
caused the plant to die.</p>

<h4 id="VariValu">1.1.3 Variable Values</h4>

<p>
In contrast to the extensive literature on events and facts, there has
been comparatively less discussion of the metaphysics of variables and
variable values. When the issue is discussed, many find it congenial
to reduce variable values in some way or other to one of the other
kinds of entities which have been proposed as token causal relata. In
many applications, binary variables (variables which take on two
potential values, usually 0 and 1) are used for <em>whether a certain
event occurs</em>. Then, questions about what it takes for the
variable to take on a value can be translated into questions about
what it takes for the relevant event to occur. Hitchcock (2012)
suggests that the values of variables be taken to be Lewsian <em>event
alterations</em>. (For Lewis [2000], an <em>alteration</em> of an
event, <i>e</i>, is a modally fragile event&mdash;an event
which would not occur, were it ever-so-slightly different&mdash;which
is not too different from <i>e</i> itself. Some alterations of
<i>e</i> will be ways for <i>e</i> to occur, and some will be ways
for <i>e</i> to fail to occur, but they are all alterations of
<i>e</i>.) An unabridged draft of Hall (2007, see reference for
link) proposes that a variable is a family of pairwise incompatible
propositions, where each proposition is</p>

<blockquote>

<p>
about the state of a particular physical system or region of space at
or during a particular time or time-interval.</p>
</blockquote>

<p>
On this understanding, a variable&rsquo;s actual value just
corresponds to the true proposition in the family. If we assume that
facts are just true propositions, we get a view on which the token
causal relata are just facts (of a particular kind).</p>

<p>
In general, it seems that we can take any pre-existing view about
token causes and effects and translate it into a view about variable
values. For instance, take a Kimian view of events, on which, for any
property <i>F</i>, any individual <i>a</i>, and any time or time
interval <i>t</i>, &lang;<i>F</i>, <i>a</i>, <i>t</i>&rang;
is an event. Then, we could have a view on which each value of a given
variable corresponds to one of these Kimian triples. What&rsquo;s
distinctive about variable values as causal relata, then, isn&rsquo;t
the individual values, but rather, how they are packaged together into
a single variable. For instance, taking the Kimian view as our point
of departure, we could have a variable, call it <em>who steals the
bike</em>, whose potential values include &lang;steals the bike,
Susan, <i>t</i>&rang; and &lang;steals the bike, Alex,
<i>t</i>&rang;. Or we could have a variable, call it <em>what Susan
steals</em>, whose potential values include &lang;steals the bike,
Susan, <i>t</i>&rang; and &lang;steals the canoe, Susan,
<i>t</i>&rang;. And there&rsquo;s a third variable, call it
<em>what Susan does to the bike</em>, whose potential values include
&lang;steals the bike, Susan, <i>t</i>&rang; and &lang;buys the
bike, Susan, <i>t</i>&rang;. Now, there&rsquo;s an additional
metaphysical question faced by those who think that the token causal
relata are variable values&mdash;a question not faced by
Kim&mdash;which is: are the variable values <em>who steals the bike
=</em> &lang;steals the bike, Susan, <i>t</i>&rang;, <em>what
Susan steals =</em> &lang;steals the bike, Susan, <i>t</i>&rang;,
and <em>what Susan does to the bike</em> = &lang;steals the bike,
Susan, <i>t</i>&rang; all the same causal relatum, or are they
different? (For more on these kinds of questions, see
 <a href="#Rela_2">&sect;3.1</a>  below.)</p>

<p>
Here is an argument (adapted from Dretske 1977) that the variable
values <em>what Susan steals =</em> &lang;steals the bike, Susan,
<i>t</i>&rang; and <em>what Susan does to the bike</em> =
&lang;steals the bike, Susan, <i>t</i>&rang; should be treated
differently. Suppose that the store has water-tight security, so that,
if Susan steals anything at all&mdash;be it the bike, the canoe, or
what-have-you&mdash;she will be arrested. Then, consider the sentences
5 and 6 (read them with additional stress on the emphasized
words):</p>

<ol start="5">

<li>Susan&rsquo;s stealing <em>the bike</em> caused her to be
arrested.</li>

<li>Susan&rsquo;s <em>stealing</em> the bike caused her to be
arrested.</li>
</ol>

<p>
As Dretske notes, while 5 sounds false, 6 sounds true. Dretske uses
this to argue for token causal relata which are more fine-grained than
events. He calls them <em>event allomorphs</em>. But, if we think that
the causal relata are the values of variables, then it&rsquo;s natural
to account for the apparent difference in truth-value between 5 and 6
by contending that, while 5 is talking about a variable like <em>what
Susan steals</em>, 6 is talking about a variable like <em>what Susan
does to the bike</em>. But then, in order to say that 5 is false while
6 is true, we must say that the variable value <em>what Susan steals
=</em> &lang;steals the bike, Susan, <i>t</i>&rang; is a different
causal relatum than <em>what Susan does to the bike</em> =
&lang;steals the bike, Susan, <i>t</i>&rang;. The former caused
Susan to be arrested, whereas the latter did not.</p>

<h4 id="FineGraiCausDiff">1.1.4 Fineness of Grain and Causal Differences</h4>

<p>
We&rsquo;ve now twice encountered arguments of the following form:
&ldquo;<i>c</i> caused <i>e</i>&rdquo; is true, but
&ldquo;<em>c*</em> caused <i>e</i>&rdquo; is false, so it must be
that &ldquo;<i>c</i>&rdquo; and &ldquo;<i>c</i>*&rdquo; denote two
different causal relata. In short: where there are differences in
causation, there must be differences in the causal relata. Call this
the <em>causal differences</em> argument. This argument was used to
show that token causes cannot just be regions of spacetime&mdash;for
then, the ball&rsquo;s rotation and its heating would be one and the
same event, but the ball&rsquo;s rotation differs causally from its
heating. It was again used to show that &ldquo;Susan&rsquo;s stealing
<em class="bold">the bike</em>&rdquo; must be a different token cause
than &ldquo;Susan&rsquo;s <em class="bold">stealing</em> the
bike&rdquo;. This second example shows us that the style of argument
can lead to a <em>very</em> fine-grained view of the causal relata. It
is, after all, necessary that Susan <em class="bold">steals</em> the
bike if and only if Susan steals <em class="bold">the bike</em>, so it
looks like this style of argument leads us to draw hyperintensional
distinctions between causal relata. Some may see hyperintensional
distinctions between causal relata as a <em>reductio</em>, and
conclude that something must be wrong with the causal differences
argument.</p>

<p>
We could resist the argument in at least three different ways.
Firstly, we could contend that causal claims like 5 and 6 are not in
fact <em>causal</em> claims. Strevens (2008) proposes that apparently
causal claims like 5 and 6 are in fact <em>causal-explanatory</em>
claims. As Strevens puts it:</p>

<blockquote>

<p>
claims of the form <em><i>c</i> was a cause of
<i>e</i></em>&hellip;do not assert the existence of a raw
metaphysical relation between two events <i>c</i> and <i>e</i>;
rather, they are causal-explanatory claims that assert that <i>c</i>
is a part of the causal explanation for <i>e</i>. (2008: 4)</p>
</blockquote>

<p>
(See also Davidson 1967, 1970; Strawson 1985.) On a view like this, we
can maintain that, while <em>causation</em> relates coarse-grained
entities like regions of spacetime, <em>causal explanation</em>
relates more fine-grained entities like propositions, or events
under-a-description.</p>

<p>
Secondly, we could claim that &ldquo;&hellip;causes&hellip;&rdquo; is
an <em>intensional</em> context, which does not allow the substitution
of co-referring terms without a change of truth-value (see Anscombe
1975; Achinstein 1975, 1983; and McDermott 1995). By way of
explanation: names of events are uncontroversially not
intersubstitutable within quotation marks. From
&ldquo;&lsquo;Caesar&rsquo;s crossing the Rubicon&rsquo; has four
words&rdquo; and &ldquo;Caesar&rsquo;s crossing the Rubicon = The
start of the Roman Civil War&rdquo;, we cannot conclude
&ldquo;&lsquo;The start of the Roman Civil War&rsquo; has four
words&rdquo;. If we think that flanking the verb &ldquo;to
cause&rdquo; is like appearing within quotation marks in this way,
then we can likewise reject the inference from &ldquo;Turning on the
hotplate caused the ball&rsquo;s heating&rdquo; and &ldquo;The
ball&rsquo;s heating = the ball&rsquo;s rotation&rdquo; to
&ldquo;Turning on the hotplate caused the ball&rsquo;s
rotation&rdquo;.</p>

<p>
Thirdly, we could appeal to a kind of contrastivism on which the
causal relation is four-place, rather than two-place (Schaffer 2005:
&sect;4). On this view, causal claims have the logical form
&ldquo;<i>c</i>, rather than <em>c*</em>, caused <i>e</i>, rather
than <em>e*</em>&rdquo; (where <em>c*</em> and <em>e*</em> are
contrast causes and effects, or perhaps sets thereof). Then, we could
suggest that claims like 5 and 6 suggest different contrasts, which
make a causal difference without requiring any difference in the first
or third argument places. In short: there are causal differences
without differences in causes or effects; some causal differences are
due to different <em>contrasts</em>. This kind of view would allow us
to retain even the very coarse theory of events from Quine (1985),
according to which an event is just a region of spacetime. The entry
discusses contrastivism further in
 <a href="#Arit">&sect;1.2.2</a>
 below.</p>

<h3 id="Rela_1">1.2 Relation</h3>

<h4 id="Inst">1.2.1 Instances</h4>

<p>
There are a wide variety of theories of the token causal
relation&mdash;theories of what it takes for one event, fact, or
what-have-you to be a token cause of another. This entry won&rsquo;t
attempt to survey the available options. The interested reader should
consult the entries on
 <a href="../causation-counterfactual/index.html">counterfactual theories of causation</a>,
 <a href="../causation-mani/index.html">causation and manipulability</a>,
 <a href="../causation-probabilistic/index.html">probabilistic causation</a>,
 and
 <a href="../causation-regularity/index.html">regularity theories of causation</a>,
 Process theories of causation are discussed in the entries on 
 <a href="../causation-physics/index.html#ConsQuanAccoCaus">causation in physics</a>
 and
 <a href="../wesley-salmon/index.html#CausProc">Wesley Salmon</a>
 (see also Dowe 1997 [2008]). Instead, this entry will survey some of
the most philosophically interesting and persistently troublesome
<em>instances</em> of token causation, and discuss what these
instances might teach us about the token causal relation.</p>

<p>
<strong>Preemption.</strong> Cases of what&rsquo;s been called
<em>preemption</em> share a common structure: there is a backup,
would-be cause of <i>e</i> (call it &ldquo;<i>b</i>&rdquo;, for
<i>b</i>ackup). Had <i>c</i> not happened, the backup <i>b</i>
would have been a cause of <i>e</i>, but <i>c</i> <em>preempted
<i>b</i></em>, causing <i>e</i> to happen, and simultaneously
making it so that <i>b</i> is not a cause of <i>e</i>. Here are
two vignettes with this structure:</p>

<ol type="1">

<li>Suzy has a grievance against her neighbor and wants to retaliate
by shattering his window. Billy is also aggrieved, and tells Suzy that
he will throw the rock. So Suzy stays at home to establish an alibi
while Billy leaves and throws a rock at the window. The rock hits and
the window shatters. Here, Suzy&rsquo;s grievance is a backup,
would-be cause of the window&rsquo;s shattering. Had Billy not been
aggrieved, Suzy would have caused the window to shatter. But she was
preempted by Billy.</li>

<li>Patricia is suffering from a terminal disease. To ease her pain,
the doctors give her a palliative dose of morphine. Due to a clerical
error, she is given too much morphine and dies from an overdose. Here,
the terminal disease is a backup, would-be cause of Patricia&rsquo;s
death. Had she not been given the morphine, the disease would have
killed her. But the disease was preempted by the overdose of
morphine.</li>
</ol>

<p>
In cases of preemption, the nearly universally shared judgment is that
the &ldquo;preempting&rdquo; <i>c</i> is a cause of <i>e</i>. For
instance, Billy&rsquo;s grievance is a cause of the window&rsquo;s
shattering, and the morphine is a cause of Patricia&rsquo;s death.
(There are dissenters to the consensus; Beckers and Vennekens (2017,
2018) insist that the &ldquo;preempting&rdquo; <i>c</i> is not a
cause of <i>e</i> in cases like these.)</p>

<p>
The first of these vignettes is a case of what&rsquo;s come to be
known as <em>early</em> preemption, whereas the second is a case of
what&rsquo;s come to be known as <em>late</em> preemption. Cases of
early preemption have roughly the same structure as the following
&ldquo;neuron diagram&rdquo;:</p>

<div class="figure avoid-break" id="fig1">

<img alt="neuron diagram: link to extended description below, 
 also see following paragraph" src="figure1.svg" 
style="width:200px" /> 



<p class="center">
<span class="figlabel">Figure 1:</span> Early preemption neuron
diagram 1. [An
 <a href="figdesc.html#fig1">extended description of figure 1</a>
 is in the supplement.]</p>
</div>

<p>
Here&rsquo;s how to read this diagram: every circle represents a
<em>neuron</em>. Associated with each neuron is a certain
time&mdash;here, the time written beneath that neuron. A neuron can
either fire or not fire at its designated time. If the circle is
colored grey, this indicates that the neuron fired. If it is colored
white, this indicates that the neuron did not fire. So, in the diagram
above, <i>b</i>, <i>c</i>, <i>d</i>, and <i>e</i> fired, and
<i>a</i> did not fire. Arrows represent <em>stimulatory</em>
connections between neurons. If the neuron at the base of an arrow
fires, then the neuron at its head will fire so long as that neuron is
not inhibited. The circle-headed lines represent <em>inhibitory</em>
connections between neurons. If the neuron at the base of one of these
connections fires, then the neuron at its head will <em>not</em> fire.
So, in the diagram above, <i>a</i> doesn&rsquo;t fire, even though
<i>b</i> did, because <i>c</i> inhibited <i>a</i>.</p>

<p>
Here, &ldquo;<i>c</i>&rdquo; stands both for the neuron <i>c</i>
and for the event of the neuron <i>c</i> firing (or the fact that
<i>c</i> fired, or whatever), and likewise for the other letters.
Then, this neuron diagram has the structure of <em>preemption:
<i>b</i></em> is a backup, would-be cause of <i>e</i>&rsquo;s
firing. Had <i>c</i> not fired, the neuron system would have looked
like this:</p>

<div class="figure avoid-break" id="fig2">

<img alt="neuron diagram: link to extended description below" src="figure2.svg" style="width:200px" />

<p class="center">
<span class="figlabel">Figure 2:</span> Early preemption neuron
diagram 2. [An
 <a href="figdesc.html#fig2">extended description of figure 2</a>
 is in the supplement.]</p>
</div>

<p>
Here, <i>b</i> is a cause of <i>e</i>. So, in the original neuron
system, <i>b</i> is a backup, would-be cause of <i>e</i>; had
<i>c</i> not fired, <i>b</i> would have been a cause of
<i>e</i>, but <i>c</i> preempts <i>b</i> and causes <i>e</i>
itself.</p>

<p>
As a brief aside, some authors use neuron diagrams like these as
representational tools for modelling the causal structure of cases
described by vignettes. So, they might say that the neuron <i>b</i>
represents whether Suzy is aggrieved, <i>a</i> represents whether
Suzy throws a rock at the neighbor&rsquo;s window, and <i>e</i>
represents whether the window shatters. Hitchcock (2007b) gives
reasons to worry about this use of neuron diagrams, and argues that we
should instead use causal models as a representational tool (see the
entry on
 <a href="../causal-models/index.html">causal models</a>,
 and
 <a href="#Mode">&sect;3.2</a>
 below). Whatever we think about using neuron diagrams to represent
the causal structure of scenarios described in vignettes, there should
be little objection to using them to model <em>systems of
neurons</em>, hooked up with stimulatory and inhibitory connections in
the ways indicated in the diagram (Hitchcock 2007b agrees).
That&rsquo;s how neuron diagrams will be understood here. So the
neuron diagram isn&rsquo;t being used to model Suzy and Billy&rsquo;s
situation. It is used to model a very simple system of five neurons,
and, arguably, the system of neurons has a similar causal structure to
the vignette involving Billy and Suzy.</p>

<p>
What makes cases of early preemption <em>early</em> is that there is
some time before <i>e</i> happens at which the backup causal
chain is cut. In our neuron diagram, at time <em>t2</em>, once
<i>a</i> fails to fire, the backup <i>b</i> no longer has any hope
of being a cause of <i>e</i>&rsquo;s firing. So, if <i>d</i> had
not fired (in violation of the neuron laws), <i>e</i> would not have
fired. In the case of Billy and Suzy, once Billy tells Suzy he&rsquo;s
going to throw a rock at the window, the potential causal chain
leading from Suzy&rsquo;s grievance to the window&rsquo;s shattering
is cut. Now that&rsquo;s she&rsquo;s at home establishing an alibi,
she has no hope of causing the window to shatter. Many counterfactual
theories of causation appeal to this feature of early preemption in
order to secure the verdict that <i>c</i> is a cause of <i>e</i>.
(See, for instance, Ramachandran (1997, 1998), Ganeri et al. (1996,
1998), Yablo (2002, 2004), Hitchcock (2001a), Halpern and Pearl
(2005), Woodward (2003), Halpern (2016a), Andreas and G&uuml;nther
(2020, 2021), and Weslake (ms.&mdash;see Other Internet
Resources).)</p>

<p>
Matters are different in cases of <em>late preemption</em>. What makes
cases of late preemption <em>late</em> is that the causal chain from
the potential backup is only cut short <em>after</em> the effect
<i>e</i> happens. There was no time prior to her death at which
Patricia&rsquo;s terminal disease stopped being deadly. So, at any
time prior to her death by overdose, were the morphine or any of its
effects to be taken away, Patricia would still have died from the
disease.</p>

<p>
Many cases of late preemption are cases in which the cause
<em>hastens</em> the effect. That is, had the cause been absent, the
effect&mdash;or, in any case, something very similar to the
effect&mdash;would have happened later than it actually did. But this
isn&rsquo;t an essential feature of the case. Consider the following:
Quentin is given chemotherapy to fight his cancer. The chemotherapy
compromises his immune system, and after catching a flu, Quentin dies
from pneumonia. It is easy to suppose that the chemotherapy prolonged
Quentin&rsquo;s life. Suppose that, had he not received chemo, the
cancer would have killed him in January. And suppose that the
pneumonia killed him in February. So the chemotherapy did not hasten
Quentin&rsquo;s death; it delayed it. Nonetheless, this could easily
be a case of late preemption. The chemotherapy prevented the cancer
from killing Quentin, but we may easily suppose that there is no time
prior to his death at which removing the chemotherapy, or the flu, or
the pneumonia, would have prevented him from dying. We may easily
suppose that the cancer remained deadly throughout. (For more on
causes, hasteners, and delayers, see Bennett 1987; Lombard 1990; P.
Mackie 1992; Paul 1998a; Sartorio 2006; Hitchcock 2012; and Touborg
2018.) The case of Quentin can easily be modified so that, had he not
received chemo, he would have died at exactly the same time that he
actually died. This version gives us a case of late preemption in
which, had the cause been absent, the effect&mdash;or, in any case,
something very similar to the effect&mdash;would have happened at the
very same time that it actually did.</p>

<p>
Cases of preemption show us that causes need not be <em>necessary</em>
for their effects. The effect <i>e</i> did not depend upon its cause
<i>c</i>. Had <i>c</i> been absent, <i>e</i> would still have
happened, due to the backup <i>b</i>. They moreover suggest that
there is something important about the process whereby causes and
effects are connected. Both <i>c</i> and the backup <i>b</i> were
sufficient for <i>e</i> to happen. What seems to make the difference
between them is that there is the right kind of connecting process
leading from <i>c</i> to <i>e</i>, and there is not the right kind
of connecting process leading from <i>b</i> to <i>e</i>. For this
reason, while counterfactual, probabilistic, agential, and regularity
theories often stumble on cases of preemption, they are more easily
treated by process theories.</p>

<p>
Schaffer (2000a) introduces cases of what he calls <em>trumping
preemption</em>. In these cases, there is preemption even though there
is no &ldquo;cutting&rdquo; of the backup causal process. That is:
there is no missing part of the process leading from the backup
<i>b</i> to <i>e</i>, but nonetheless, <i>b</i> does not count
as a cause of <i>e</i> because <i>c</i> &ldquo;trumps&rdquo;
<i>b</i>. Here are two cases like this:</p>

<ol type="1">

<li>The laws of magic say that the first spell cast on a given day
goes into effect at midnight; spells cast after the first are
ineffective. On Monday, there are only two spells cast. In the
morning, Merlin casts a spell to turn the prince into a frog. And in
the evening, Morgana casts a spell to turn the prince into a frog. At
midnight, the prince turns into a frog.</li>

<li>The Major outranks the Sergeant, who outranks the Corporal. The
Corporal will follow the orders of the highest-ranking officer. The
Major and the Sergeant both give the Corporal the order to advance,
and the Corporal advances.</li>
</ol>

<p>
In the first case, Schaffer contends that Merlin&rsquo;s spell caused
the prince to turn into a frog and that Morgana&rsquo;s spell did not.
Merlin&rsquo;s spell, after all, was the first spell of the day, and
that&rsquo;s what the laws of magic identify as the relevant feature.
And, in the second case, Schaffer contends that the Major caused the
Corporal to advance, and the Sergeant did not. After all, the Corporal
listens to the orders of the highest ranking officer, and in this
case, that&rsquo;s the Major. (For further discussion, see Lewis 2000;
Halpern &amp; Pearl 2005; Hitchcock 2007a; Halpern &amp; Hitchcock
2010: &sect;4.2; and Paul &amp; Hall 2013: &sect;4.3.4.)</p>

<p>
<strong>Prevention. </strong>Cases of preemption tend to be handled
easily by process theories of causation, whereas counterfactual,
manipulation, probabilistic, and regularity theories have more
difficulty saying both that the preempting <i>c</i> is a cause of
<i>e</i> and that the preempted backup <i>b</i> is not a cause of
<i>e</i>. For, in cases of preemption, we can easily trace out the
process whereby <i>c</i> leads to <i>e</i>, whereas the process
which would have led from <i>b</i> to <i>e</i> was interrupted by
<i>c</i>. On the other hand, process theories have more difficulty
with cases of <em>prevention</em>. Here&rsquo;s a case of prevention:
over the Atlantic ocean, James Bond shoots down a missile which is
heading for Blofield&rsquo;s compound, and Blofield survives
unscathed. Bond prevented Blofield from dying. If we understand
prevention as causation-not (<i>c</i> prevents <i>e</i> iff
<i>c</i> caused it to be the case that <i>e</i> didn&rsquo;t
happen), then Bond caused Blofield to not die. But there does not
appear to be any causal <em>process</em> leading from Bond to
Blofield&mdash;both Bond and the missile were thousands of miles
away.</p>

<p>
Some deny that cases of prevention are genuinely causal (see Aronson
1971; Dowe 2000; Beebee 2004a; and Hall 2004). This response could be
further justified with worries about absences being effects (recall
 <a href="#Fact">&sect;1.1.2</a>).
 However, there are additional worries about the cases which Hall
(2004) calls &ldquo;double prevention&rdquo;. In these cases,
<i>c</i> prevents <i>d</i>, and, if <i>d</i> had happened, then
<i>d</i> would have prevented <i>e</i>. So <i>c</i> prevents a
preventer of <i>e</i>. For instance: Blofield launches a cyber
attack on Europe&rsquo;s electrical grid, plunging the continent into
the dark. Had Bond not shot down the missile, it would have prevented
Blofield from carrying out the cyber attack. So Bond prevented a
potential preventer of the cyber attack. Here, there is an inclination
to say that Bond was an (inadvertent) cause of the cyber attack.
However, there is no connecting process leading from Bond to the cyber
attack&mdash;there is no relevant energy-momentum flow, mark
transmission, or persisting trope connecting them.</p>

<p>
Cases of double prevention have roughly the structure of this neuron
diagram:</p>

<div class="figure avoid-break" id="fig3">

<img alt="neuron diagram: link to extended description below" src="figure3.svg" style="width:200px" />

<p class="center">
<span class="figlabel">Figure 3:</span> Double prevention neuron
diagram. [An
 <a href="figdesc.html#fig3">extended description of figure 3</a>
 is in the supplement.]</p>
</div>

<p>
As Schaffer (2000c, 2012b) argues, many paradigm cases of causation
turn out, on closer inspection, to be instances of double prevention.
Pam uses a catapult to hurl a rock through the window. It seems clear
that Pam&rsquo;s actions caused the window to shatter. But suppose the
catapult works like this: a catch prevents the catapult from
launching, and Pam&rsquo;s releasing the catch prevents it from
preventing the launch. Thus, the relationship between Pam&rsquo;s
releasing the catch and the shattering of the window is one of double
prevention. Here, it is less comfortable to deny that Pam caused the
window to shatter, though not all agree. Aronson denies that there is
any causation in a similar case:</p>

<blockquote>

<p>
Consider a weight that is attached to a stretched spring. At a certain
time, the catch that holds the spring taut is released, and the weight
immediately begins to accelerate. One might be tempted to say that the
release of the catch was the cause of the weight&rsquo;s acceleration.
If so, then what did the release of the catch transfer to the weight?
Nothing, of course. (1971: 425)</p>
</blockquote>

<p>
Aronson contends that, while the release of the catch was an enabling
condition for the weight&rsquo;s acceleration, it was not strictly
speaking a <em>cause</em> of the weight&rsquo;s acceleration.</p>

<p>
<strong>Preemptive Prevention.</strong> There&rsquo;s another
interesting class of cases where one preventer <em>preempts</em>
another (see McDermott 1995 and Collins 2000). Here are two cases like
this:</p>

<ol type="1">

<li>Either Bond or M could shoot down the missile headed for
Blofield&rsquo;s compound. Bond tells M that he will do it, so M goes
home. Bond shoots down the missile, and Blofield survives.</li>

<li>Bond shoots down a missile headed for Blofield&rsquo;s compound.
However, Blofield&rsquo;s compound has its own perfectly reliable
anti-missile defense system. So, had Bond not shot the missile down,
the anti-missile defense system would have, and Blofield would have
survived unscathed.</li>
</ol>

<p>
By analogy with ordinary preemption, we can call the first case an
instance of <em>early preemptive prevention</em>. Once Bond tells M
that he will shoot down the missile, M is no longer a potential
preventer of the missile strike. If, at the last minute, Bond had
changed his mind, Blofield&rsquo;s compound would have been destroyed.
In contrast, we can call the second case an instance of <em>late
preemptive prevention</em>. At no point does the missile defense
system &ldquo;step down&rdquo;, and stop being a potential preventer
of the compound&rsquo;s destruction.</p>

<p>
The first case has a structure similar to this neuron system,</p>

<div class="figure avoid-break" id="fig4">
<img alt="neuron diagram: link to extended description below" src="figure4.svg" style="width:200px" />

<p class="center">
<span class="figlabel">Figure 4:</span> Early preemptive prevention
neuron diagram. [An
 <a href="figdesc.html#fig4">extended description of figure 4</a>
 is in the supplement.]</p>
</div>

<p>
Whereas the second case has a structure similar to this neuron
system,</p>

<div class="figure avoid-break" id="fig5">
<img alt="neuron diagram: link to extended description below" src="figure5.svg" style="width:200px" />

<p class="center">
<span class="figlabel">Figure 5:</span> Late preemptive prevention
neuron diagram. [An
 <a href="figdesc.html#fig5">extended description of figure 5</a>
 is in the supplement.]</p>
</div>

<p>
There seems to be more of an inclination to attribute causation in
cases of early preemptive prevention than in cases of late preemptive
prevention. As McDermott (1995) puts it: in case (2), many are
initially inclined to deny that Bond prevented the compound&rsquo;s
destruction; but, when they are asked &ldquo;Of Bond and the missile
defense system, which prevented the compound&rsquo;s
destruction?&rdquo;, it feels very natural to answer with
&ldquo;Bond&rdquo;. (As Collins 2000 notes, things begin to feel
different if we suppose that the anti-missile defense system is less
than perfectly reliable.)</p>

<p>
<strong>Switches.</strong> Suppose that a lamp has two bulbs: one on
the left, and one on the right. There is a switch which determines
whether power will flow to the bulb on the left or the one on the
right. If the power is on and the switch is set to the left, then the
left bulb will be on, and the room will be illuminated. If the power
is on and the switch is set to the right, then the right bulb will be
on, and the room will be illuminated. If the power is off, then
neither bulb will be on, and the room will be dark, no matter how the
switch is set. To start, the power is off and the switch is set to the
left. Filipa flips the switch to the right, and Phoebe turns on the
power. The right bulb turns on, and the room is illuminated.</p>

<p>
Cases like these are discussed by Hall (2000) and Sartorio (2005,
2013), among others. This particular example comes from Pearl (2000).
In these kinds of cases, there are five events (or facts, or
what-have-you): <i>f</i>, <i>p</i>, <i>l</i>, <i>r</i>, and
<i>e</i>, with the following features: if <i>p</i> happens, it
will cause either <i>l</i> or <i>r</i> to happen, depending upon
whether <i>f</i> happens. And if either <i>l</i> or <i>r</i>
happens, it will cause <i>e</i> to happen. For instance, in our
example, <i>f</i> is Filipa flipping the switch to the right,
<i>p</i> is Phoebe turning on the power, <i>l</i> and <i>r</i>
are the left and right bulbs turning on, respectively, and <i>e</i>
is the room being illuminated. In this case, it can seem that
there&rsquo;s an important difference between Filipa and Phoebe.
Whereas Filipa made a difference to <em>how</em> the room got
illuminated (whether by the left bulb or the right one), she did not
make a difference to <em>whether</em> the room got illuminated.
Phoebe, in contrast, did make a difference to <em>whether</em> the
room got illuminated. It seems natural to say that, while
Phoebe&rsquo;s turning on the power was a cause of the room being
illuminated, Filipa&rsquo;s flipping the switch was not.</p>

<p>
Switching cases have roughly the same structure as the following
neuron diagram:</p>

<div class="figure avoid-break" id="fig6">

<img alt="neuron diagram: link to extended description below" src="figure6.svg" style="width:299px" />

<p class="center">
<span class="figlabel">Figure 6:</span> Switch neuron diagram 1. [An
 <a href="figdesc.html#fig6">extended description of figure 6</a>
 is in the supplement.]</p>
</div>

<p>
Here, the neuron <i>s</i> (the switch) is special. It can either be
set to the left or to the right, indicated by the direction the arrow
is pointing. Likewise, the connection between <i>f</i> and
<i>s</i> is special. If <i>f</i> fires, then <i>s</i> will be
set to the right. If <i>f</i> does not fire, then <i>s</i> will be
set to the left. On the other hand, the connection between <i>p</i>
and <i>s</i> is normal. If <i>p</i> fires, then <i>s</i> will
fire. If <i>s</i> fires while set to the left, then <i>l</i> will
fire. If <i>s</i> fires while set to the right, then <i>r</i> will
fire. If either <i>l</i> or <i>r</i> fires, then <i>e</i> will
fire.</p>

<p>
If <i>f</i> hadn&rsquo;t fired, <i>s</i> would have fired while
set to the left, so <i>l</i> would have fired, and <i>e</i> would
have fired.</p>

<div class="figure avoid-break" id="fig7">

<img alt="neuron diagram: link to extended description below" src="figure7.svg" style="width:299px" />

<p class="center">
<span class="figlabel">Figure 7:</span> Switch neuron diagram 2. [An
 <a href="figdesc.html#fig7">extended description of figure 7</a>
 is in the supplement.]</p>
</div>

<p>
On the other hand, if <i>p</i> hadn&rsquo;t fired, <i>s</i> would
still have been set to the right, but it would not have fired, so
neither <i>r</i> nor <i>e</i> would have fired:</p>

<div class="figure avoid-break" id="fig8">

<img alt="neuron diagram: link to extended description below" src="figure8.svg" style="width:299px" />

<p class="center">
<span class="figlabel">Figure 8:</span> Switch neuron diagram 3. [An
 <a href="figdesc.html#fig8">extended description of figure 8</a>
 is in the supplement.]</p>
</div>

<p>
Reflection on switches can lead to the conclusion that token causation
cannot be merely a matter of the intrinsic nature of the process
leading from cause to effect. Consider the following variant: while
the right bulb is functional, the left bulb is not. If the power had
been turned on while the switch was set to the left, the left bulb
would not have turned on, and the room would have remained dark. Given
<em>this</em> setup, Filipa&rsquo;s flipping the switch to the right
<em>does</em> appear to be a cause of the room&rsquo;s being
illuminated. After all, with this setup, had Filipa not flipped the
switch, the room would have remained dark. But, if we just look at the
intrinsic features of the process leading from Filipa&rsquo;s flipping
the switch to the room&rsquo;s illumination, there will be no
difference. Or consider the following system of neurons:</p>

<div class="figure avoid-break" id="fig9">

<img alt="neuron diagram: link to extended description below" src="figure9.svg" style="width:299px" />

<p class="center">
<span class="figlabel">Figure 9:</span> Switch neuron diagram 4. [An
 <a href="figdesc.html#fig9">extended description of figure 9</a>
 is in the supplement.]</p>
</div>

<p>
Here, <i>f</i>&rsquo;s firing appears to be a cause of
<i>e</i>&rsquo;s firing (along with <i>p</i>). If <i>f</i>
hadn&rsquo;t fired, then the switch <i>s</i> would have been set to
the left, so <i>e</i> would not have fired. So <i>f</i>&rsquo;s
firing was needed for <i>e</i> to fire. However, there doesn&rsquo;t
seem to be any difference between the process leading from
<i>f</i>&rsquo;s firing to <i>e</i>&rsquo;s firing in
<em>this</em> system of neurons and the process leading from
<i>f</i>&rsquo;s firing to <i>e</i>&rsquo;s firing in the
<em>original</em> system of neurons.</p>

<p>
So switches suggest that whether one event (fact, or whatever),
<i>c</i>, is a cause of another, <i>e</i>, is not just a matter of
the intrinsic features of the process leading from <i>c</i> to
<i>e</i>. It looks like we may also have to consider counterfactual
information about what things would have been like in the absence of
<i>c</i>. (See the discussion in Paul and Hall, 2013.)</p>

<p>
Switches also pose a problem for the view that causation is
transitive&mdash;that is, the view that, if <i>c</i> causes
<i>d</i> and <i>d</i> causes <i>e</i>, then <i>c</i> causes
<i>e</i>. For, in the original version of the case, it seems that
Filipa&rsquo;s flipping the switch to the right caused the right bulb
to turn on. And it appears that the right bulb turning on caused the
room to be illuminated. But it does not appear that Filipa&rsquo;s
flipping the switch to the right caused the room to be illuminated.
(For further discussion of switches and the transitivity of causation,
see McDermott 1995; Hall 2000, 2007; Paul 2000; Hitchcock 2001a; Lewis
2000; Maslen 2004; Schaffer 2005; Halpern 2016b; Beckers &amp;
Vennekens 2017; and McDonnell 2018.)</p>

<h4 id="Arit">1.2.2 Arity</h4>

<p>
The standard view is that causation is a binary relation between two
relata: cause and effect. However, some suggest that causation may be
a ternary or a quaternary relation. Inspired by van Fraassen
(1980)&rsquo;s work on contrastive explanation, we could take
causation to be a ternary, or 3-place, relation between a cause, an
effect, and a contrast for the effect. On this view, the logical form
of the causal relation is: <i>c</i> is a cause of <i>e</i>, rather
than <em>e*</em>. For instance, it seems correct to say that
Adam&rsquo;s being hungry caused him to eat the apple, rather than
toss it aside. But it seems wrong to say that Adam&rsquo;s being
hungry caused him to eat the apple, rather than the pear. So changing
the contrast for the effect seems to makes a difference to causation.
Hitchcock (1993, 1995a, 1996) gives a contrastive probabilistic theory
of causation, according to which causation is a ternary relation
between a cause, a contrast for the cause, and an effect. On this
view, the logical form of the causal relation is: <i>c</i>, rather
than <em>c*</em>, is a cause of <i>e</i>. For instance, it can seem
that Paul&rsquo;s smoking a pack a day, rather than not at all, is a
cause of his lung cancer. But it seems wrong that Paul&rsquo;s smoking
a pack a day, rather than two packs a day, is a cause of his lung
cancer. Schaffer (2005) combines these two views, arguing that
causation is a quaternary relation between a cause, a contrast for the
cause, an effect, and a contrast for the effect. On this view, the
logical form of the causal relation is: <i>c</i>, rather than
<em>c*</em>, is a cause of <i>e</i>, rather than <em>e*</em>.</p>

<p>
If we think that the causal relation is ternary or quaternary, then
some of the arguments we considered earlier can look weaker. For
instance, consider what we called the <em>causal differences</em>
argument from
 <a href="#FineGraiCausDiff">&sect;1.1.4</a>.
 We argued that we must distinguish the cause &ldquo;Susan&rsquo;s
stealing <em>the bike</em>&rdquo; from &ldquo;Susan&rsquo;s
<em>stealing</em> the bike&rdquo;, since the latter, but not the
former, caused her to be arrested. If we are contrastivists about
causation, then we could insist that the differences in focal stress
serve to make salient different contrasts for one and the same event:
Susan&rsquo;s stealing of the bike. When we emphasize &ldquo;the
bike&rdquo;, we suggests a contrast event in which Susan steals
something else. And Susan&rsquo;s stealing the bike, rather than the
canoe, didn&rsquo;t cause her to be arrested. On the other hand, when
we emphasize &ldquo;stealing&rdquo;, we suggest a contrast event in
which Susan does something else to the bike&mdash;purchasing it,
let&rsquo;s say. And Susan&rsquo;s stealing the bike, rather than
purchasing it, <em>is</em> a cause of her arrest. Schaffer (2005) even
suggests that, if causation is 4-place, then we could take the
incredibly coarse-grained Quinean view of events.</p>

<p>
Schaffer (2005) additionally suggests that, if we say that causation
is quaternary, we can defend a version of transitivity. Of course,
transitivity is a property of a binary relation, but Schaffer proposes
that the quaternary relation satisfies the following constraint: if
<i>c</i>, rather than <em>c*</em>, is a cause of <i>d</i>, rather
than <em>d*</em>, and <i>d</i>, rather than <em>d*</em> is a cause
of <i>e</i>, rather than <em>e*</em>, then <i>c</i>, rather than
<em>c*</em> is a cause of <i>e</i>, rather than <em>e*</em>. Think
of it like this: corresponding to the 4-place causal relation is a
two-place relation between event-contrast <em>pairs</em>; and Schaffer
maintains that this two-place relation between pairs of events and
their contrasts is a transitive relation. It&rsquo;s not immediately
obvious how this helps with switches like the one we saw in
 <a href="#Inst">&sect;1.2.1</a>
 above. For it seems that Filipa&rsquo;s flipping the switch to the
right, rather than not flipping it, caused the right bulb to be on,
rather than off. And it seems that the right bulb being on, rather
than off, caused the room to be illuminated, rather than dark. But it
doesn&rsquo;t appear that Filipa&rsquo;s flipping the switch to the
right, rather than not flipping it, caused the room to be illuminated,
rather than dark. The trick is that Schaffer has a view of events on
which they are <em>world-bound</em>. So, in order to make the first
causal claim true, the contrast &ldquo;the right bulb&rsquo;s being
off&rdquo; must be an event which only occurs in the world in which
Filipa does not flip the switch to the right, and the left bulb is on.
Therefore, the second causal claim will turn out to be false; the
right bulb&rsquo;s being on, rather than off <em>in a world in which
the left bulb is on</em>, is not a cause of the room&rsquo;s being
illuminated, rather than dark.</p>

<h4 id="Norm">1.2.3 Normality</h4>

<p>
It is natural to distinguish between <em>causes</em> and
<em>background</em>, or <em>enabling</em>, conditions. For instance,
suppose that you strike a match and it lights. It&rsquo;s natural to
cite your striking the match as a cause of its lighting, but
it&rsquo;s far less natural to cite the presence of oxygen as a cause
of its lighting, even though, without the oxygen, the match
wouldn&rsquo;t have lit. There&rsquo;s some inclination to say that
the presence of oxygen merely <em>enabled</em> the strike to cause the
match to light, but did not cause it to light itself. Lewis (1973)
echoes a traditional, dismissive, attitude when he refers to the
distinction between causes and background conditions as
&ldquo;invidious discrimination&rdquo; (see also Mill 1843 and J. L.
Mackie 1974). On this view, the distinction is pragmatic,
unsystematic, and dependent upon our interests. Alien scientists from
Venus&mdash;where there is no oxygen in the atmosphere&mdash;might
find it incredibly natural to point to the presence of oxygen as a
cause of the fire. On the traditional view, neither we nor the
Venusian scientists are making any objective error; we each simply
have different expectations about the world, and so we find some
features of it more noteworthy than others. There are ever-so-many
causes out there, but we <em>select</em> some of them to call causes.
The others, the ones we do not select, are regarded as mere background
conditions.</p>

<p>
Hart and Honor&eacute; (1959 [1985]) suggest that conditions which are
<em>normal</em>, or <em>default</em>, are background conditions;
whereas those which are <em>abnormal</em>, or <em>deviant</em>, are
causes. This distinction between normal, default, or inertial
conditions and abnormal, deviant, or non-inertial causes has been
appearing with increasing regularity in the recent literature. For
instance, McGrath (2005) presents the following vignette: Abigail goes
on vacation and asks her neighbor, Byron, to water her plant. Byron
promises to water the plant, but doesn&rsquo;t, and the plant dies. It
sounds very natural to say that Byron&rsquo;s failure to water the
plant was a cause of its death; it sounds much worse to suggest that
Abigail&rsquo;s <em>other</em> neighbor, Chris, caused the plant to
die by not watering it. However, it seems that the only relevant
difference between Bryon and Chris is that Byron made a
<em>promise</em> to water the plant, and Chris did not. So
Byron&rsquo;s failure to water the plant was abnormal, whereas
Chris&rsquo;s failure to water the plant was normal. McGrath&rsquo;s
example involves absences or omissions, but this feature of the case
is incidental. Hitchcock and Knobe (2009) give the following case:
while administrators are allowed to take pens, professors are not.
Both Adriel the administrator and Piper the professor take pens. Later
in the day, there are no pens left, and the Dean is unable to sign an
important paper. Here, it seems much better to cite Piper than Adriel
as a cause of the problem. And it seems that the only relevant
difference is that Adriel was <em>permitted</em> to take the pen, but
Piper was not. (For more, see Kahneman &amp; Miller 1986; Thomson
2003; and Maudlin 2004.)</p>

<p>
Considering just these kinds of cases, it&rsquo;s not unnatural to see
the phenomenon as just more &ldquo;selection effects&rdquo;. Perhaps
both Byron and Chris caused the plant to die, but for pragmatic
reasons we find it more natural to cite the person who broke a promise
as a cause. Hall (2007) presents a more challenging argument for the
view that normality and defaults should figure in our theory of
causation. He asks us to consider the following pair of neuron
systems:</p>

<div class="figure" id="fig10">

<div class="avoid-break">

<img alt="neuron diagram: link to extended description below" src="figure10a.svg" style="width:200px" />

<p class="center">
(a)</p>
</div>

<div class="avoid-break">

<img alt="a diagram: link to extended description below" src="figure10b.svg" style="width:200px" />

<p class="center">
(b)</p>
</div>

<p class="center">
<span class="figlabel">Figure 10:</span> Pair of neuron diagrams. [An
 <a href="figdesc.html#fig10">extended description of figure 10</a>
 is in the supplement.]</p>
</div>

<p>
In figure 10(a), we have the case of <em>early preemption</em> from
 <a href="#Inst">&sect;1.2.1</a>.
 Here, <i>c</i>&rsquo;s firing is a cause of <i>e</i>&rsquo;s
firing. In figure 10(b), we have a case of what Hall calls a
&ldquo;short circuit&rdquo;. When <i>c</i> fires, it both initiates
a threat to <i>e</i>&rsquo;s dormancy (by making <i>a</i> fire)
and neutralizes that very threat (by making <i>d</i> fire).
Here&rsquo;s a vignette with a similar structure (see Hall 2004, and
Hitchcock 2001a): a boulder becomes dislodged and careens down the
hill towards Hiker. Seeing the boulder coming, Hiker jumps out of the
way, narrowly averting death. In this case, the boulder&rsquo;s fall
both initiates a threat to Hiker&rsquo;s life and neutralizes that
very threat (by alerting them to its presence). Hall contends that the
boulder&rsquo;s becoming dislodged did not cause Hiker to survive;
and, in the case of the short circuit, <i>c</i>&rsquo;s firing did
not cause <i>e</i> to not fire. Intuitively, <i>c</i> accomplished
nothing <em>vis-a-vis</em> <i>e</i>. But Hall notes that these two
neuron systems are isomorphic to each other. We can make the point
with systems of structural equations (see the entry on
 <a href="../causal-models/index.html">causal models</a>,
 and
 <a href="#Mode">&sect;3.2</a>
 below). Start with the case of early preemption, and use binary
variables, <i>A</i>, <i>B</i>, <i>C</i>, <i>D</i>, and
<i>E</i> for whether <i>a</i>, <i>b</i>, <i>c</i>, <i>d</i>,
and <i>e</i> fire, respectively. These variables takes on the value
1 if their paired neuron fires, and they take on the value 0 if they
do not. Then, we can represent the causal structure of early
preemption with this system of equations:</p> 

\[\begin{aligned} 
A &amp; \coloneqq B \wedge \neg C \\ 
D &amp; \coloneqq C\\ 
E &amp; \coloneqq A \vee D \\ 
\end{aligned}\]

<p>
Turning to the short circuit, notice that we can use <em>A*</em>,
<em>B*</em>, and <em>E*</em> as binary variables for whether the
neurons <i>a</i>, <i>b</i>, and <i>e</i> <em>do not</em> fire.
These variables take on the values 1 if their paired neuron
<em>doesn&rsquo;t</em> fire, and they take on the value 0 if it
<em>does</em>. And, again, we can use <i>C</i> and <i>D</i> as
variables for whether the neurons <i>c</i> and <i>d</i> fire;
these non-asterisked variables take on the value 1 if their paired
neuron <em>does</em> fire, and 0 if it <em>doesn&rsquo;t</em>. With
these conventions in place, we can then write down the following
<em>isomorphic</em> system of equations for the neuron system of short
circuit:</p> 

\[\begin{aligned} 
A^{*} &amp; \coloneqq B^{*} \wedge \neg C \\ 
D &amp; \coloneqq C \\ 
E^{*} &amp; \coloneqq A^{*} \vee D 
\end{aligned}\]

<p>
These equations are isomorphic to the ones we wrote down for the case
of early preemption. Moreover, the values of the variables are
precisely the same in each case. In the case of early preemption,
\(A=0\) and \(B = C = D = E = 1\); whereas, in the case of short
circuit, \(A^*=0\) and \(B^* = C = D = E^* = 1\) (similar cases are
discussed in Hiddleston 2005).</p>

<p>
Therefore, if we want to claim that <i>c</i> is a cause of
<i>e</i> in the case of early preemption, but deny that <i>c</i>
is a cause of <i>e</i> in the case of short circuit, we will have to
point to some information which is not contained in these equations
and the values of these variables. And several authors have reached
for the distinction between <em>default</em>, <em>normal</em> states
and <em>deviant, abnormal</em> events (see, for instance, Hall 2007;
Hitchcock 2007a; Halpern 2008, 2016a; Paul &amp; Hall 2013; Halpern
&amp; Hitchcock 2015; and Gallow 2021. For criticism, see Blanchard
&amp; Schaffer, 2017).</p>

<p>
On a traditional picture, there is a broad, indiscriminate notion of
causation which makes no appeal to normality; considerations of
normality are used, pragmatically, to &ldquo;select&rdquo; which of
the indiscriminate causes we call &ldquo;causes&rdquo; and which we
call &ldquo;background conditions&rdquo;. The isomorphism between
early preemption and short circuit challenges this picture, for two
reasons. Firstly, <i>c</i>&rsquo;s firing is presumably just as
deviant in early preemption as it is in short circuit, so it
can&rsquo;t just be the normality of the putative cause which makes
the difference. Secondly, those who want to deny that
<i>c</i>&rsquo;s firing is a cause of <i>e</i>&rsquo;s failure to
fire in short circuit do not want to claim that <i>c</i>&rsquo;s
firing was even a background condition for <i>e</i>&rsquo;s failure
to fire. The inclination is to say that <i>c</i>&rsquo;s firing had
<em>nothing at all</em> to do with <i>e</i>&rsquo;s failure to
fire.</p>

<h2 id="TypeCaus">2. Type Causation</h2>

<h3 id="RelaTokeCaus">2.1 Relationship to Token Causation</h3>

<p>
Type causal relations are described by generic claims like
&ldquo;Drowsy driving causes crashes&rdquo; or &ldquo;Smoking causes
cancer&rdquo;. One prominent question concerns the relationship
between type and token causal claims. One view has it that type causal
claims are just generalizations or generics about token causal claims
(see Lewis 1973; Hausman 1998: chapter 5; and Hausman 2005). For
instance, to say that smoking causes cancer is just to say that token
cancers are generally caused by token histories of smoking. And to say
that drowsy driving causes crashes is just to say that, in general,
token episodes of drowsy driving cause token crashes. Generic claims
like these shouldn&rsquo;t be understood as saying that <em>most</em>
or even <em>many</em> token episodes of drowsy driving are token
causes of car crashes. Compare: &ldquo;mosquitos carry the West Nile
virus&rdquo;, which is a true generic despite the fact that most
mosquitos do not carry the West Nile virus. (See the entry on
 <a href="../generics/index.html">generics</a>.)
 On this view, type causal claims are ultimately about token causal
relations.</p>

<p>
Another view has it that type causal relations are more fundamental
than token causal relations; what makes it the case that
<em>Chris&rsquo;s</em> smoking caused his cancer is, at least in part,
that smoking causes cancer, Chris smoked, and he got cancer. This kind
of view is defended by theorists like Hume (1739&ndash;40, 1748), Mill
(1843), J. L. Mackie (1965), Hempel (1965), and Davidson (1967). These
theorists begin by giving an analysis of causal relations between
types of events, facts, or what-have-you. For instance: Hume says that
what it is for the type <i>C</i> to cause the type <i>E</i> is for
things of type <i>C</i> to be constantly conjoined with things of
type <i>E</i>. This general regularity is then used to explain why
it is that any particular thing of type <i>C</i> is a token cause of
any particular thing of type <i>E</i>. Subsequent regularity and
&ldquo;covering law&rdquo; theories add additional bells and whistles;
but they retain the idea that a token causal relation between
<i>c</i> and <i>e</i> holds in virtue of some broader regularity
or law which subsumes the particular relationship between <i>c</i>
and <i>e</i>.</p>

<p>
One reason to doubt that token causal relations are just
instantiations of type causal relations is that there appear to be
token causal relations without any corresponding type causal relation,
and there appear to be token causal relations which go against the
corresponding type causal relations. Scriven (1962) gives the
following example: you reach for your cigarettes, accidentally
knocking over an ink bottle and staining the carpet. Your reaching for
your cigarettes caused the carpet to be stained, but it&rsquo;s not
the case that reaching for cigarettes causes carpet stains in general.
Suppes (1970) attributes this example to Deborah Rosen: at the golf
course, you hit the ball into a tree, the ball rebounds and,
fantastically enough, goes into the hole. In this case, hitting the
ball into the tree caused the hole-in-one, but hitting the ball into
trees does not cause holes-in-one in general.</p>

<p>
A third position, defended by Ellery Eells (1991), is that neither
token nor type causal relations are more fundamental than the other.
Eells gives two probabilistic analyses of causation: one for type
causation, and another for token causation. Eells thinks that type
causal claims cannot just be generalizations about token causal claims
because of examples like this: drinking a quart of plutonium causes
death, even though nobody has ever drank a quart of plutonium, and so
no particular persons&rsquo;s death has been caused by drinking a
quart of plutonium. So this type causal claim cannot be a
generalization over token causal claims. (See Hausman 1998: chapter 5,
for a response.)</p>

<p>
For more on the relationship between token and type causation,
particularly within a probabilistic approach to causation, see
Hitchcock (1995a).</p>

<h3 id="NetCompEffe">2.2 Net and Component Effects</h3>

<p>
Consider the following case, adopted from Hesslow (1976): suppose that
birth control pills (<i>B</i>) prevent pregnancy (<i>P</i>).
However, they can also have the unintended side-effect of thrombosis
(<i>T</i>). So we might be inclined to accept the type causal claim
&ldquo;birth control pills cause thrombosis&rdquo;. But wait:
<em>another</em> potential cause of thrombosis is pregnancy. And birth
control pills inhibit pregnancy. The general structure of the case is
as shown below.</p>

<div class="figure avoid-break" id="fig11">

<img alt="diagram but not neuron: link to extended description below" src="figure11.svg" style="width:250px" />

<p class="center">
<span class="figlabel">Figure 11:</span> Hesslow&rsquo;s birth control
case [An
 <a href="figdesc.html#fig11">extended description of figure 11</a>
 is in the supplement.]</p>
</div>

<p>
Birth control pills <em>directly</em> promote thrombosis, but at the
same time, they prevent pregnancy, which itself promotes thrombosis.
By adjusting the probabilities, we can make it so that, overall,
taking birth control makes no difference to the probability of
thrombosis. Then, we might be inclined to accept the type causal claim
&ldquo;birth control pills have no effect on
thrombosis&rdquo;&mdash;after all, your chances of getting thrombosis
are exactly the same, whether or not you take birth control. Hitchcock
(2001b) argues that cases like this require us to distinguish two
different kinds of effects which type causes can have: what he calls a
<em>net effect</em>, on the one hand, and what he calls <em>component
effect</em>, on the other. In Hesslow&rsquo;s case, birth control
pills have no <em>net</em> effect on thrombosis. This is the sense in
which it&rsquo;s true to say &ldquo;birth control pills have no effect
on thrombosis&rdquo;. At the same time, birth control pills have a
<em>component</em>&mdash;or <em>path-specific</em>&mdash;effect on
thrombosis. Along the path <i>B</i> &rarr; <i>T</i>, birth control
promotes thrombosis. This is the sense in which it&rsquo;s true to say
&ldquo;birth control pills cause thrombosis&rdquo;. For further
discussion, see Woodward (2003: &sect;2.3) and Weinberger (2019).</p>

<h2 id="Infl">3. Influence</h2>

<h3 id="Rela_2">3.1 Relata</h3>

<p>
As emphasized in
 <a href="#Rela">&sect;1.1</a>
 above, any theory of events or facts can easily be transposed into a
theory of the values of token variables. And, plausibly, token
variables are individuated by their values. So, when it comes to token
influence between variables, we will face many of the same questions
and debates about the causal relata: how fine- or coarse-grained are
they? When are two variables the same; when are they different? Can
variables include absences or omissions as values? There is, however,
an additional question to be a asked about the metaphysics of
variables: when can some collection of variable <em>values</em> be
grouped together into a single variable? All agree that the potential
values of a variable must <em>exclude</em> each other. That is: if \(v\)
and \(v^*\) are two values of the variable \(V\),
then it should be impossible that \(V=v \wedge
V=v^*\) (here, \(V=v\) is the proposition that the variable \(V\)
takes on the value \(v\), and likewise
\(V=v^*\) is the proposition that the variable \(V\)
takes on the value \(v^*\)).</p>

<p>
But there are additional questions to be asked about which values may
be grouped together into token variables. For instance: must the
values of a variable concern the same time? Or can a single variable
have multiple values which concern different times? Suppose Patricia
died on Monday from an overdose of morphine; had she not received the
morphine, she would have died on Tuesday. Then, there are several
different variables we might try to use when thinking about
Patricia&rsquo;s death. We could use a single variable for <em>whether
Patricia died</em>. This variable would take on one value if Patricia
died on Monday or Tuesday, and another value if she remained alive
throughout Monday and Tuesday. Or we could use a single variable for
<em>when Patricia died</em>. This variable would take on one value if
she died on Monday, and another value if she died on Tuesday.
Alternatively, we could use a collection of time-indexed variables,
<em>whether Patricia had died by time <i>t</i></em>, for some range
of times <i>t</i>. As Hitchcock (2012) puts it: the question is
whether Patricia&rsquo;s dying on Monday and Patricia&rsquo;s dying on
Tuesday</p>

<blockquote>

<p>
correspond to the <em>same value</em> of the <em>same variable</em>,
to <em>different values</em> of the <em>same variable</em>, or to
values of different <em>variables</em>. (2012: 90)</p>
</blockquote>

<p>
Of course, this question carries the presupposition that we must
choose between these options. You might instead think that
<em>all</em> of these variables exist, and each enter into different
relations of influence.</p>

<p>
When it comes to type variables, there are additional questions about
how token variables are to be type-individuated, over and above
questions about the individuation conditions of the token variables
themselves. This question is not much discussed, but it is natural to
think that the type individuation of variables is inherited from the
type-individuation of their values. That is: \(X_1\) and \(X_2\) are
of the same type if and only if \(X_1\) and \(X_2\) have the same
number of potential values, and each those values are of the same
type. For instance, the token variables <em>how much I weigh</em> and
<em>how much Obama weighs</em> are of the same type, as they both have
the same type of potential values (1 kg, 2 kg, etc); on the other
hand, <em>how much I weigh</em> and <em>how many pounds of arugula
Obama eats</em> are not of the same type, since their potential values
are not of the same type.</p>

<h3 id="Mode">3.2 Models</h3>

<p>
Relations of influence between variables are often encoded in formal
models. Just as the causal relations between tokens and types can be
either deterministic or probabilistic, so too can the relations of
influence between variables be either deterministic or probabilistic.
Deterministic relations between variables are represented with
structural equations models; whereas indeterministic relations between
variables can be represented with probabilistic models (sometimes with
structural equations models with random errors&mdash;see the entry on
 <a href="../causal-models/index.html#StruEquaModeRandErro">causal models</a>&mdash;or
 often with just a causal graph paired with a probability distribution
over the values of the variables appearing in that graph&mdash;see the
entry on
 <a href="../causation-probabilistic/index.html#CausMode">probabilistic causation</a>.)</p>
 
<p>
In the deterministic case, the relations of influence between
variables can be encoded in a system of structural equations. For
illustration, consider again the neuron system we used in
 <a href="#Inst">&sect;1.2.1</a>
 above to illustrate early preemption. As we saw in
 <a href="#Norm">&sect;1.2.3</a>,
 for each neuron in the system, we can introduce a variable for
whether that neuron fires at the relevant time. Once we&rsquo;ve done
so, the following system of structural equations describes the causal
relations between these variables.</p> 

\[\begin{aligned} 
A &amp; \coloneqq B \wedge \neg C \\ 
D &amp; \coloneqq C \\ 
E &amp; \coloneqq A \vee D 
\end{aligned}\]

<p>
Before getting to the metaphysical questions about what kinds of
relations these equations represent, and what it takes for a system of
equations like this to be correct, let us first focus on how these
equations are <em>used</em> in practice. It&rsquo;s important to
recognize that there is meant to be a difference between
<em>structural</em> equations and ordinary equations. The equation \(D
= C\) is symmetric. It could be re-written, equivalently, as \(C=D\).
In contrast, the <em>structural</em> equation \(D \coloneqq C\) is
<em>nonsymmetric</em>. It tells us that the variable \(D\)
is causally influenced by the variable \(C\).
And this form of causal influence is not symmetric.
To emphasize that these equations are not symmetric,
&ldquo;\(\coloneqq\)&rdquo; is used, rather than &ldquo;\(=\)&rdquo;.</p>

<p>
Some terminology: given a system of structural equations, the
variables which appear on the left-hand-side of some equation are
called the <em>endogenous</em> variables. The variables which only
ever appear on the right-hand-side of the equations are called
<em>exogenous</em>. The model does not tell us anything about how the
values of the exogenous variables are determined; but it does tell us
something about how the values of the endogenous variables are
causally determined by the values of the other variables in the
model.</p>

<p>
In this case, an assignment of values to the exogenous variables is
enough to tell us the value of every endogenous variable in the model.
That is: if you know that \(B=C=1\), you also know that \(A=0\) and
\(D=E=1\). That needn&rsquo;t be the case in general. For instance,
consider the following system of equations:</p> 

\[\begin{aligned} 
Y &amp;\coloneqq X + Z \\ 
X &amp;\coloneqq Y - Z 
\end{aligned}\]

<p>
In this system of structural equations, even after you know that the
exogenous variable \(Z = 10\), you are not able to solve for the
values of the two endogenous variables, \(X\) and \(Y\).
The reason for this is that, in this system of
equations, there is a <em>cycle</em> of influence: \(X\)
influences \(Y\), and \(Y\)
influences \(X\). When there are
cycles of influence like this, even a deterministic system of
equations, together with an assignment of values to the exogenous
variables, will not determine the values of all of the endogenous
variables. (See the entry on
 <a href="../causation-backwards/index.html">backwards causation</a>
 and the section on causal loops in the entry on
 <a href="../time-travel/index.html#CauLoo">time travel</a>.)
 However, if we rule out cycles of influence like this, then an
assignment of values to the exogenous variables will determine the
values of all of the variables in the model. Likewise, any probability
distribution over the exogenous variables will induce a probability
distribution over the endogenous variables, as well.</p>

<p>
It is often assumed that each of the structural equations in the
system is independently disruptable. For instance: there is, at least
in principle, some way of disrupting \(C\)&rsquo;s
causal influence on \(D\)&mdash;some way of making it
so that the structural equation \(D \coloneqq C\) no longer
holds&mdash;which leaves it so that both of the structural equations
\(A\coloneqq B \wedge \neg C\) and \(E\coloneqq A \vee D\) continue to
hold. Not every way of disrupting the causal relation between the
variables \(C\) and \(D\) will be like
this. For instance, suppose that we remove all of the connections
emanating <em>out</em> of the neuron <i>c</i>. This will disrupt the
causal connection between \(C\) and \(D\),
but it will also disrupt the causal connection
between \(C\) and \(A\); it will make it
so that the structural equation \(A\coloneqq B \wedge \neg C\) no
longer holds. (This equation tells us that, if \(C=1\), then \(A=0\);
but, with the connection between <i>c</i> and <i>a</i> severed,
this is no longer true.) This property of a system of structural
equations&mdash;that each of the equations may be disrupted without
affecting any of the other equations in the model&mdash;is known as
<em>modularity</em>. (For criticism of this requirement, see
Cartwright 2002; for a defense, see Hausman &amp; Woodward 1999, 2004.
For more on modularity, see Woodward 2003.)</p>

<p>
If the system of equations is modular, then it is at least in
principle possible to disrupt one of the equations without affecting
any of the others. Suppose that happens, and we disrupt the equation
\(A\coloneqq B \wedge \neg C\) without affecting any of the other
equations, for instance. Suppose further that we do this in such a way
as to determine the value of \(A\), or to determine a
probability distribution over the values of \(A\).
Then, we have performed <em>an intervention</em> on the variable \(A\).
Note that this notion of an intervention is relative
to a system of equations. Whether some way of disrupting an equation
and directly setting the value of the variable on its left-hand-side
counts as an intervention or not will vary from causal model to causal
model. In general, <em>an intervention</em> on an endogenous variable,
\(V\) (relative to some model) is some way of making it
so that \(V\)&rsquo;s structural equation (the equation
with \(V\) on the left-hand-side) no longer holds, even
though every other structural equation in the model continues to hold,
and directly setting the value of \(V\), or directly
determining a probability distribution over the values of \(V\).</p>

<p>
Given a deterministic causal model&mdash;a system of structural
equations&mdash;the way to formally represent an intervention on an
endogenous variable, \(V\), is straightforward: you
remove the structural equation which has that variable on its
left-hand-side, and leave all the other equations unchanged. You go on
to treat \(V\) as if it were an exogenous variable,
with the value or the probability distribution it was given through
the intervention. Assuming the system of equations is acyclic, you can
then work out the value of the other variables in the model, or the
probability distribution over the values of the other variables in the
model, as before.</p>

<p>
Interventions like these have been used by many to provide a semantics
for what will here be called <em>causal</em> counterfactual
conditionals. As the term is used here, what makes a counterfactual
<em>causal</em> is that it holds fixed factors which are causally
independent of its antecedent. It doesn&rsquo;t say anything about
what would have to <em>have been</em> different in order for the
antecedent to obtain. That is: it says nothing about the necessary
causal precursors of the antecedent. It holds fixed all factors which
are not causally downstream of the antecedent, and only allows to
swing free factors which are causally downstream of the antecedent.
Within a system of structural equations, this is accomplished by
modeling an <em>intervention</em> to bring about the truth of the
antecedent. (For more on this &ldquo;interventionist&rdquo; treatment
of counterfactuals, see Galles &amp; Pearl 1998; Briggs 2012; Huber
2013, and the entry on
 <a href="../counterfactuals/index.html">counterfactuals</a>.)</p>
 
<h3 id="RelaTokeCaus_1">3.3 Relationship to Token Causation</h3>

<p>
Several authors have provided theories of token causation which use
causal models like these. (See, for instance, Hitchcock 2001a, 2007a;
Woodward, 2003, Menzies 2004, 2006
 [<a href="#Oth">Other Internet Resources</a>];
 Halpern &amp; Pearl 2005; Hall 2007; Halpern 2008, 2016a, 2016b;
Beckers &amp; Vennekens 2017, 2018; Andreas &amp; G&uuml;nther 2020,
2021; Gallow 2021; Weslake ms.&mdash;see Other Internet Resources.)
The theories almost always understand the causal models as describing
relations of influence between <em>token</em> variables. Most of these
theories are roughly counterfactual. They attempt to use the
interventionist semantics for causal counterfactuals to provide an
account of when one variable value is a token cause of another. On
this approach, the networks of influence encoded in a causal model
provide the pathways along which token causation propagates. If one
variable value, \(C=c\), is going to be a token cause of another,
\(E=e\), then there must be some path of influence leading from the
variable <i>C</i> to the variable <i>E</i>,</p> 

\[C \to D_1 \to D_2 \to \dots \to D_N \to E.\]

<p>
The theories diverge in what additional conditions must be met for
\(C=c\) to be a token cause of \(E=e\). Many, though not all, agree
that counterfactual dependence between \(C=c\) and \(E=e\) is
sufficient for \(C=c\) being a token cause of \(E=e\). (For more, see
the entry on
 <a href="../causation-counterfactual/index.html#StrEquFra">counterfactual theories of causation</a>.)</p>
 
<h3 id="MetaMode">3.4 The Metaphysics of the Models</h3>

<p>
This section discusses what it takes for these models to be
accurate&mdash;what the world must be like to host the relations of
influence described by the model. However, it must be noted that not
every author in the literature would be happy with the way this
question is posed. Many prefer to talk about whether a model is
<em>appropriate</em> or <em>apt</em>. This is in part because they
recognize that many of the models written down and used in practice
misrepresent the world. For instance, the models portray systems as
deterministic, neglecting minute quantum mechanical chances. Thus,
Halpern writes that</p>

<blockquote>

<p>
I am not sure that there are any &ldquo;right&rdquo; models, but some
models may be more useful, or better representations of reality, than
others. (2016a: 108)</p>
</blockquote>

<p>
Of course, if we are going to say that a causal model
<em>mis</em>represents the world, we must have a prior understanding
of what the model represents. To misrepresent is to represent
inaccurately. This section is going to be focused on the question of
what it is for a causal model to represent accurately. There is of
course a further and subsequent question to be asked about when the
inaccuracies of the model are negligible enough that the model may be
<em>appropriate</em> or <em>apt</em> to use in a given context.</p>

<p>
In one sense, this question should be seen as stipulative; the models
come from humans, not gods. It is for us to say what they do and do
not represent. Nonetheless, we should take care that our stipulations
don&rsquo;t undermine the purposes for which the models were designed,
nor the use to which they are standardly put. Insofar as they are
meant to capture the notion of <em>influence</em> which appears in
causal claims like &ldquo;how much I water my plant influences how
tall it grows&rdquo;, and insofar as they are meant to forge
connections between influence and counterfactuals&mdash;or influence
and and token causation, or influence and control, or influence and
chance&mdash;not just any stipulations will serve our purposes.
Whether these connections are plausible or defensible will depend upon
how we understand the models; what we take them to be saying about the
world.</p>

<p>
The formalism of the models is much the same, whether we are
representing token influence or type influence. But when it comes to
explaining what it takes for these models to be accurate, it will
matter whether we are talking about token influence or type influence.
In the case of token influence, Hitchcock (2001a: 283&ndash;284)
suggests that what it takes for a causal model to be correct is for a
certain family of counterfactuals to be true:</p>

<blockquote>

<p>
A system of structural equations is an elegant means for representing
a whole family of counterfactuals&hellip;The correctness of a set of
structural equations&hellip;depends upon the truth of these
counterfactuals.</p>
</blockquote>

<p>
On this kind of view, what it takes for a system of structural
equations to correctly represent a network of token influence is for
some corresponding counterfactuals to be true. There is a weaker and a
stronger version of this requirement. On the stronger version, we
require that <em>all</em> of the (infinitely many) counterfactuals
which can be derived from the model (<em>via</em> the interventionist
procedure outlined in the previous subsection) are true. On the weaker
version, we require only the more limited class of counterfactuals
which say that, were any subset of the variables to have their values
set <em>via</em> an intervention, the equations for the non-intervened
upon variables would continue to be true. For illustration, take the
following system of equations,</p> 

\[\begin{aligned} 
Z &amp;\coloneqq X + Y \\ 
Y &amp;\coloneqq X 
\end{aligned}\]

<p>
The weak requirement is that, for any values \(x, y, z\), the
following counterfactuals hold:</p> 

\[\begin{align} \tag{1}
X = x &amp;{}\boxto ( Y=x \wedge Z= x + Y) \\ 
Y = y &amp;{}\boxto Z = X + y \\ 
Z = z &amp;{}\boxto Y = X \\ 
(X=x \wedge Y=y) &amp;{}\boxto Z= x + y \\ 
(X=x \wedge Z=z) &amp;{}\boxto Y = x 
\end{align}\]

<p>
One worry with the weak requirement is that the counterfactuals in (1)
fail to capture the modularity of the structural equations. Recall:
it&rsquo;s important to distinguish between the <em>structural</em>
equations \(Y \coloneqq X\) and \(Z \coloneqq X + Y\) and the
<em>equations</em> \(Y = X\) and \(Z=X+Y\). Modularity is not just the
claim that, if we were to intervene to set <i>X</i> equal to
<i>x</i>, the equations \(Y = X\) and \(Z=X+Y\) would continue to be
true. It is the claim that, if we were to intervene to set <i>X</i>
equal to <i>x</i>, the <em>structural</em> equations \(Y \coloneqq
X\) and \(Z \coloneqq X + Y\) would continue to <em>hold</em>. This
requires, at least, that the counterfactuals</p> 

\[\begin{aligned} 
X=x' &amp;{}\boxto Y=x' \\ 
(X=x' \wedge Y=y) &amp;{}\boxto Z = x' + y 
\end{aligned}\]

<p>
<em>would still</em> be true, for any values \(x'\) and \(y\),
were we to intervene to set <i>X</i> equal to
<i>x</i>. So it requires that the nested counterfactuals</p>

\[\begin{aligned}
X=x &amp; {}\boxto (X=x' \boxto Y=x') \\ 
X = x &amp;{}\boxto ((Y=y \wedge X=x') \boxto Z= x' + y) 
\end{aligned}\]

<p>
are actually true. (And, indeed, these nested counterfactuals follow
from the system of equations, on the causal modeling semantics.)
However, on many semantics for counterfactuals, this nested
counterfactual does not follow from the counterfactuals given in
(3.4.1) above. We might attempt to reduce nested counterfactuals like
these to counterfactuals with conjunctive antecedents by appeal to a
principle of exportation, according to which \(\phi \boxto (\psi
\boxto \chi)\) follows from \((\phi \wedge \psi) \boxto \chi\).
However, on the causal modeling semantics, exportation is not valid in
general. Take the causal model above. Assuming counterfactuals with
necessarily false antecedents are vacuously true,</p> 

\[(X=x \wedge X = x') \boxto Y = x \]

<p>
will be deemed true so long as \(x \neq x'\). But</p> 

\[X = x {}\boxto (X=x' \boxto Y = x) \]

<p>
will be deemed false. (See Briggs 2012, for related discussion, and
Gallow 2016, for an alternative approach.)</p>

<p>
Some think that more than a family of true counterfactuals is required
in order for a token causal model to be correct&mdash;or, at least, in
order for a causal model to provide us with a guide to token causation
(see
 <a href="#RelaTokeCaus_1">&sect;3.3</a>).
 Many, persuaded by the considerations from
 <a href="#Norm">&sect;1.2.3</a>
 above, include information about which variable values are more or
less normal than which others. And Handfield et al. (2008) suggest
that the models must only represent relations of influence which
correspond to &ldquo;connecting processes&rdquo;, in the sense of Fair
(1979), Salmon (1984, 1994), or Dowe (2000). The idea is this: if a
variable, <i>X</i>, shows up on the right-hand-side of
<i>Y</i>&rsquo;s structural equation, then there must be some
possible state of the system (some possible assignment of values to
the variables in the model) such that, in that state, there is a
connecting process leading from <i>X</i>&rsquo;s value to
<i>Y</i>&rsquo;s value.</p>

<p>
Woodward (2003) focuses on systems of <em>type</em> influence. He
proposes a series of non-reductive definitions which jointly
characterize what it is for one type of variable, <i>X</i>, to
directly influence another type of variable, <i>Y</i>, relative to a
set of variables types, \(\mathbf{V}\), which contains both <i>X</i>
and <i>Y</i>. First, we are told:</p>

<blockquote>

<p>
<i>X</i> directly influences <i>Y</i>, relative to a set of
variables \(\mathbf{V}\), iff there is a possible intervention on
<i>X</i> which will change <i>Y</i> when all other variables in
\(\mathbf{V}\) are held fixed at some value by interventions.</p>
</blockquote>

<p>
The definition makes reference to the notion of an
<em>intervention</em>. (Notice: though Woodward is explicating the
relation of <em>type</em> influence, any particular intervention will
be a <em>token</em> occurrence.) We saw how interventions are formally
modeled in the previous subsection; but Woodward gives the following
definition of an intervention in terms of an <em>intervention
variable</em>. We are told:</p>

<blockquote>

<p>
<i>I</i>&rsquo;s assuming some value <em>I=i</em> is an intervention
on <i>X</i> (with respect to <i>Y</i>) iff <i>I</i> is an
intervention variable for <i>X</i> (with respect to <i>Y</i>) and
<em>I=i</em> is a token cause of the value taken on by <i>X</i>.</p>
</blockquote>

<p>
This definition relies upon the notion of an <em>intervention
variable</em> (for <i>X</i> with respect to <i>Y</i>). We are
told:</p>

<blockquote>

<p>
<i>I</i> is an intervention variable for <i>X</i> with respect to
<i>Y</i>, relative to \(\mathbf{V}\), iff:</p>

<ol>

<li><i>I</i> influences <i>X</i>;</li>

<li>there are values of <i>I</i> such that, when <i>I</i> takes on
those values, <i>X</i>&rsquo;s value does not change when any of the
other variables in \(\mathbf{V}\) which influence <i>X</i> change
their values; instead, the value of <i>X</i> is determined by the
value of <i>I</i> alone;</li>

<li>every directed path of influence leading from <i>I</i> to
<i>Y</i> travels through <i>X</i>&mdash;that is, if there&rsquo;s
some collection of variables \(Z_1, Z_2, \dots, Z_N \in \mathbf{V}\)
such that \(I\) directly influences \(Z_1\), \(Z_1\)
directly influences \(Z_2\), \(\dots\), and \(Z_N \) directly
influences \(Y\), then \(X = Z_i\), for some \(i \in \{
1, 2, \dots, N \}\)</li>

<li><i>I</i> is statistically independent of any variable <i>Z</i>
which directly influences <i>Y</i> and which is on a directed path
of influence which does not go through <i>X</i>.</li>
</ol>
</blockquote>

<p>
This definition appeals to the notion of (type) influence; so it will
not allow us to gives a reductive analysis of influence. But notice
that it doesn&rsquo;t appeal to influence between <i>X</i> and
<i>Y</i>&mdash;and that is the relation which Woodward is attempting
to characterize. So while the series of definitions are not reductive,
they are not <em>viciously</em> circular. They tell us something about
how influence between <i>X</i> and <i>Y</i> relates to influence
between variables besides <i>X</i> and <i>Y</i>. (See the entry on
 <a href="../causation-mani/index.html#CircProb">causation and manipulability</a>
 for more.)</p>

</div> 


<div id="bibliography">

<h2 id="Bib">Bibliography</h2>

<ul class="hanging">

<li>Achinstein, Peter, 1975, &ldquo;Causation, Transparency, and
Emphasis&rdquo;, <em>Canadian Journal of Philosophy</em>, 5(1):
1&ndash;23. doi:10.1080/00455091.1975.10716094</li>

<li>&ndash;&ndash;&ndash;, 1983, <em>The Nature of Explanation</em>,
New York/London: Oxford University Press.</li>

<li>Albert, David, 2000, <em>Time and Chance</em>, Cambridge, MA:
Harvard University Press.</li>

<li>Andreas, Holger and Mario G&uuml;nther, 2020, &ldquo;Causation in
Terms of Production&rdquo;, <em>Philosophical Studies</em>, 177(6):
1565&ndash;1591. doi:10.1007/s11098-019-01275-3</li>

<li>&ndash;&ndash;&ndash;, 2021, &ldquo;A Ramsey Test Analysis of
Causation for Causal Models&rdquo;, <em>The British Journal for the
Philosophy of Science</em>, 72(2): 587&ndash;615.
doi:10.1093/bjps/axy074</li>

<li>Anscombe, G. E. M., 1975, &ldquo;Causality and
Determination&rdquo;, in Sosa 1975: 63&ndash;81.</li>

<li>Armstrong, D. M., 1997, <em>A World of States of Affairs</em>,
Cambridge: Cambridge University Press.</li>

<li>&ndash;&ndash;&ndash;, 1999, &ldquo;The Open Door: Counterfactual
Versus Singularist Theories of Causation&rdquo;, in Sankey 1999:
175&ndash;185. doi:10.1007/978-94-015-9229-1_16</li>

<li>&ndash;&ndash;&ndash;, 2004, &ldquo;Going through the Open Door
Again: Counterfactual versus Singularist Theories of Causation&rdquo;,
in Collins, Hall, and Paul 2004b: 445&ndash;457.</li>

<li>Aronson, Jerrold L., 1971, &ldquo;On the Grammar of
&lsquo;Cause&rsquo;&rdquo;, <em>Synthese</em>, 22(3&ndash;4):
414&ndash;430. doi:10.1007/BF00413436</li>

<li>Beauchamp, Tom and Alex Rosenberg, 1981, <em>Hume and the Problem
of Causation</em>, Oxford: Oxford University Press.</li>

<li>Beckers, Sander and Joost Vennekens, 2017, &ldquo;The Transitivity
and Asymmetry of Actual Causation&rdquo;, <em>Ergo</em>, 4: art. 1.
doi:10.3998/ergo.12405314.0004.001</li>

<li>&ndash;&ndash;&ndash;, 2018, &ldquo;A Principled Approach to
Defining Actual Causation&rdquo;, <em>Synthese</em>, 195(2):
835&ndash;862. doi:10.1007/s11229-016-1247-1</li>

<li>Beebee, Helen, 2004a, &ldquo;Causing and Nothingness&rdquo;, in
Collins, Hall, and Paul 2004b: 291&ndash;308.</li>

<li>&ndash;&ndash;&ndash;, 2004b, &ldquo;Chance-changing Causal
Processes&rdquo;, in Dowe and Noordhof 2004: 39&ndash;57.</li>

<li>Bennett, Jonathan, 1987, &ldquo;Event Causation: The
Counterfactual Analysis&rdquo;, in James E. Tomberlin (editor),
<em>Philosophical Perspectives I: Metaphysics</em>, Atascadero, CA:
Ridgeview Publishing Company: 367&ndash;386.</li>

<li>&ndash;&ndash;&ndash;, 1988, <em>Events and their Names</em>,
Indianapolis, IN: Hackett Publishers.</li>

<li>Black, Max, 1956, &ldquo;Why Cannot an Effect Precede Its
Cause?&rdquo;, <em>Analysis</em>, 16(3): 49&ndash;58.
doi:10.1093/analys/16.3.49</li>

<li>Blanchard, Thomas and Jonathan Schaffer, 2017, &ldquo;Cause
without Default&rdquo;, in <em>Making a Difference</em>, Helen Beebee,
Christopher Hitchcock, and Huw Price (eds.), Oxford: Oxford University
Press, ch. 10.</li>

<li>Brand, Myles, 1980, &ldquo;Simultaneous Causation&rdquo;, in van
Inwagen 1980: 137&ndash;153.</li>

<li>Briggs, Rachael, 2012, &ldquo;Interventionist
Counterfactuals&rdquo;, <em>Philosophical Studies</em>, 160(1):
139&ndash;166. doi:10.1007/s11098-012-9908-5</li>

<li>Campbell, Keith, 1990, <em>Abstract Particulars</em>, Oxford:
Basil Blackwell.</li>

<li>Carroll, John, 1994, <em>Laws of Nature</em>, Cambridge: Cambridge
University Press.</li>

<li>Cartwright, Nancy, 1983, <em>How the Laws of Physics Lie</em>,
Oxford: Clarendon Press.</li>

<li>&ndash;&ndash;&ndash;, 2002, &ldquo;Against Modularity, the Causal
Markov Condition, and Any Link Between the Two: Comments on Hausman
and Woodward&rdquo;, <em>The British Journal for the Philosophy of
Science</em>, 53(3): 411&ndash;453. doi:10.1093/bjps/53.3.411</li>

<li>Casta&ntilde;eda, Hector-Neri, 1984, &ldquo;Causes, Causity, and
Energy&rdquo;, <em>Midwest Studies in Philosophy</em>, 9: 17&ndash;27.
doi:10.1111/j.1475-4975.1984.tb00050.x</li>

<li>Coady, David, 2004, &ldquo;Preempting Preemption&rdquo;, in
Collins, Hall, and Paul 2004b: 325&ndash;340.</li>

<li>Collingwood, R. G., 1940, <em>An Essay on Metaphysics</em>,
Oxford: Clarendon Press.</li>

<li>Collins, John, 2000, &ldquo;Preemptive Prevention&rdquo;, <em>The
Journal of Philosophy</em>, 97(4): 223&ndash;234.
doi:10.2307/2678391</li>

<li>Collins, John, Ned Hall, and L. A. Paul, 2004a,
&ldquo;Counterfactuals and Causation: History, Problems, and
Prospects&rdquo;, in Collins, Hall, and Paul 2004b: 1&ndash;58.</li>

<li>&ndash;&ndash;&ndash; (eds.), 2004b, <em>Causation and
Counterfactuals</em>, (Representation and Mind), Cambridge, MA: MIT
Press.</li>

<li>Davidson, Donald, 1963 [1980], &ldquo;Actions, Reasons, and
Causes&rdquo;, <em>The Journal of Philosophy</em>, 60(23):
685&ndash;700. Reprinted in Davidson 1980: 3&ndash;19.
doi:10.2307/2023177</li>

<li>&ndash;&ndash;&ndash;, 1967 [1980], &ldquo;Causal
Relations&rdquo;, <em>The Journal of Philosophy</em>, 64(21):
691&ndash;703. Reprinted in Davidson 1980: 149&ndash;162.
doi:10.2307/2023853</li>

<li>&ndash;&ndash;&ndash;, 1969 [1980], &ldquo;The Individuation of
Events&rdquo;, in <em>Essays in Honor of Carl G. Hempel</em>, Nicholas
Rescher (ed.), Dordrecht: D. Reider. Reprinted in Davidson 1980:
163&ndash;80.</li>

<li>&ndash;&ndash;&ndash;, 1970 [1980], &ldquo;Mental Events&rdquo;,
in <em>Experience and Theory</em>, Lawrence Foster and J. W. Swanson
(eds), Amherst, MA: University of Massachusetts Press. Reprinted in
Davidson 1980: 207&ndash;227.</li>

<li>&ndash;&ndash;&ndash;, 1980, <em>Essays on Actions and
Events</em>, Oxford: Clarendon Press.</li>

<li>&ndash;&ndash;&ndash;, 1985, &ldquo;Reply to Quine on
Events&rdquo;, in LePore and McLaughlin 1985: 172&ndash;176.</li>

<li>&ndash;&ndash;&ndash;, 1993, &ldquo;Thinking Causes&rdquo;, in J.
Heil and A. Mele (eds.), <em>Mental Causation</em>, Oxford: Clarendon
Press, pp. 3&ndash;17.</li>

<li>Dowe, Phil, 1992, &ldquo;Wesley Salmon&rsquo;s Process Theory of
Causality and the Conserved Quantity Theory&rdquo;, <em>Philosophy of
Science</em>, 59(2): 195&ndash;216. doi:10.1086/289662</li>

<li>&ndash;&ndash;&ndash;, 1997 [2008], <em>Causal Processes</em>
(Fall 2008 edition), Edward N. Zalta (ed.), first version published
1997. URL=
 &lt;<a href="https://plato.stanford.edu/archives/fall2008/entries/causation-process/" target="other">https://plato.stanford.edu/archives/fall2008/entries/causation-process/</a>&gt;</li>
 
<li>&ndash;&ndash;&ndash;, 2000, <em>Physical Causation</em>,
Cambridge: Cambridge University Press.
doi:10.1017/CBO9780511570650</li>

<li>&ndash;&ndash;&ndash;, 2001, &ldquo;A Counterfactual Theory of
Prevention and &lsquo;Causation&rsquo; by Omission&rdquo;,
<em>Australasian Journal of Philosophy</em>, 79(2): 216&ndash;226.
doi:10.1080/713659223</li>

<li>Dowe, Phil and Paul Noordhof (eds.), 2004, <em>Cause and Chance:
Causation in an Indeterministic World</em>, London: Routledge.
doi:10.4324/9780203494660</li>

<li>Dretske, Fred I., 1977, &ldquo;Referring to Events&rdquo;,
<em>Midwest Studies in Philosophy</em>, 2: 90&ndash;99.
doi:10.1111/j.1475-4975.1977.tb00030.x</li>

<li>Ducasse, C. J., 1926, &ldquo;On the Nature and the Observability
of the Causal Relation&rdquo;, <em>The Journal of Philosophy</em>,
23(3): 57&ndash;68. doi:10.2307/2014377</li>

<li>Dummett, Michael, 1964, &ldquo;Bringing About the Past&rdquo;,
<em>Philosophical Review</em>, 73(3): 338&ndash;359.
doi:10.2307/2183661</li>

<li>Eells, Ellery, 1991, <em>Probabilistic Causality</em>, Cambridge:
Cambridge University Press.</li>

<li>Ehring, Douglas, 1986, &ldquo;The Transference Theory of
Causation&rdquo;, <em>Synthese</em>, 67(2): 249&ndash;258.
doi:10.1007/BF00540071</li>

<li>&ndash;&ndash;&ndash;, 1997, <em>Causation and Persistence</em>,
Oxford: Oxford University Press.</li>

<li>Ellis, Brian, 1999, &ldquo;Causal Powers and Laws of
Nature&rdquo;, in Sankey 1999: 19&ndash;34.
doi:10.1007/978-94-015-9229-1_2</li>

<li>Fair, David, 1979, &ldquo;Causation and the Flow of Energy&rdquo;,
<em>Erkenntnis</em>, 14(3): 219&ndash;250. doi:10.1007/BF00174894</li>

<li>Fales, Evan, 1990, <em>Causation and Universals</em>, London:
Routledge Press.</li>

<li>Galles, David and Judea Pearl, 1998, &ldquo;An Axiomatic
Characterization of Causal Counterfactuals&rdquo;, <em>Foundations of
Science</em>, 3(1): 151&ndash;182. doi:10.1023/A:1009602825894</li>

<li>Gallow, J. Dmitri, 2016, &ldquo;A Theory of Structural
Determination&rdquo;, <em>Philosophical Studies</em>, 173(1):
159&ndash;186. doi:10.1007/s11098-015-0474-5</li>

<li>&ndash;&ndash;&ndash;, 2021, &ldquo;A Model-Invariant Theory of
Causation&rdquo;, <em>The Philosophical Review</em>, 130(1):
45&ndash;96. doi:10.1215/00318108-8699682</li>

<li>Ganeri, Jonardon, Paul Noordhof, and Murali Ramachandran, 1996,
&ldquo;Counterfactuals and Preemptive Causation&rdquo;,
<em>Analysis</em>, 56(4): 219&ndash;225.
doi:10.1093/analys/56.4.219</li>

<li>&ndash;&ndash;&ndash;, 1998, &ldquo;For a (Revised)
PCA-analysis&rdquo;, <em>Analysis</em>, 58(1): 45&ndash;47.</li>

<li>Gasking, Douglas, 1955, &ldquo;Causation and Recipes&rdquo;,
<em>Mind</em>, 64(256): 479&ndash;487.
doi:10.1093/mind/LXIV.256.479</li>

<li>G&ouml;del, Kurt, 1949, &ldquo;A Remark about the Relationship
between Relativity Theory and Idealistic Philosophy&rdquo;, in P.
Schilpp (ed.), <em>Albert Einstein: Philosopher-Scientist</em>, La
Salle: Open Court, pp. 557&ndash;62.</li>

<li>Good, I. J., 1961a, &ldquo;A Causal Calculus (I)&rdquo;, <em>The
British Journal for the Philosophy of Science</em>, 11(44):
305&ndash;318. doi:10.1093/bjps/XI.44.305</li>

<li>&ndash;&ndash;&ndash;, 1961b, &ldquo;A Causal Calculus
(II)&rdquo;, <em>The British Journal for the Philosophy of
Science</em>, 12(45): 43&ndash;51. doi:10.1093/bjps/XII.45.43</li>

<li>Hall, Ned, 2000, &ldquo;Causation and the Price of
Transitivity&rdquo;, <em>The Journal of Philosophy</em>, 97(4):
198&ndash;222. doi:10.2307/2678390</li>

<li>&ndash;&ndash;&ndash;, 2004, &ldquo;Two Concepts of
Causation&rdquo; in Collins, Hall, and Paul 2004b: 181&ndash;204.</li>

<li>&ndash;&ndash;&ndash;, 2007, &ldquo;Structural Equations and
Causation&rdquo;, <em>Philosophical Studies</em>, 132(1):
109&ndash;136.
 [<a href="https://dash.harvard.edu/handle/1/3710361" target="other">Hall 2007 unabridged draft available online</a>]
 doi:10.1007/s11098-006-9057-9</li>

<li>Halpern, Joseph, 2008, &ldquo;Defaults and Normality in Causal
Structures&rdquo; in G. Brewka and J. Lang (eds.), <em>Principles of
Knowledge Representation and Reasoning</em>, Palo Alto: AAAI Press,
pp. 198&ndash;208.</li>

<li>&ndash;&ndash;&ndash;, 2016a, <em>Actual Causality</em>,
Cambridge, MA: MIT Press.</li>

<li>&ndash;&ndash;&ndash;, 2016b, &ldquo;Sufficient Conditions for
Causality to Be Transitive&rdquo;, <em>Philosophy of Science</em>,
83(2): 213&ndash;226. doi:10.1086/684915</li>

<li>Halpern, Joseph Y. and Christopher Hitchcock, 2010, &ldquo;Actual
Causation and the Art of Modeling&rdquo;, in <em>Causality,
Probability, and Heuristics: A Tribute to Judea Pearl</em>, London:
College Publications, pp. 383&ndash;406.</li>

<li>&ndash;&ndash;&ndash;, 2015, &ldquo;Graded Causation and
Defaults&rdquo;, <em>The British Journal for the Philosophy of
Science</em>, 66(2): 413&ndash;457. doi:10.1093/bjps/axt050</li>

<li>Halpern, Joseph Y. and Judea Pearl, 2005, &ldquo;Causes and
Explanations: A Structural-Model Approach. Part I: Causes&rdquo;,
<em>The British Journal for the Philosophy of Science</em>, 56(4):
843&ndash;887. doi:10.1093/bjps/axi147</li>

<li>Handfield, Toby, Charles R. Twardy, Kevin B. Korb, and Graham
Oppy, 2008, &ldquo;The Metaphysics of Causal Models: Where&rsquo;s the
Biff?&rdquo;, <em>Erkenntnis</em>, 68(2): 149&ndash;168.
doi:10.1007/s10670-007-9060-3</li>

<li>Hart, H. L. A. and A. M. Honor&eacute;, 1959 [1985], <em>Causation
in the Law</em>, Oxford: Clarendon Press. Second extended edition,
1985.</li>

<li>Hausman, Daniel M., 1998, <em>Causal Asymmetries</em>, Cambridge:
Cambridge University Press. doi:10.1017/CBO9780511663710</li>

<li>&ndash;&ndash;&ndash;, 2005, &ldquo;Causal Relata: Tokens, Types,
or Variables?&rdquo;, <em>Erkenntnis</em>, 63(1): 33&ndash;54.
doi:10.1007/s10670-005-0562-6</li>

<li>Hausman, Daniel M. and James Woodward, 1999, &ldquo;Independence,
Invariance and the Causal Markov Condition&rdquo;, <em>The British
Journal for the Philosophy of Science</em>, 50(4): 521&ndash;583.
doi:10.1093/bjps/50.4.521</li>

<li>&ndash;&ndash;&ndash;, 2004, &ldquo;Modularity and the Causal
Markov Condition: A Restatement&rdquo;, <em>The British Journal for
the Philosophy of Science</em>, 55(1): 147&ndash;161.
doi:10.1093/bjps/55.1.147</li>

<li>Hempel, Carl, 1965, <em>Aspects of Scientific Explanation</em>,
New York, NY: Free Press.</li>

<li>Hesslow, Germund, 1976, &ldquo;Two Notes on the Probabilistic
Approach to Causality&rdquo;, <em>Philosophy of Science</em>, 43(2):
290&ndash;292. doi:10.1086/288684</li>

<li>Hiddleston, Eric, 2005, &ldquo;Causal Powers&rdquo;, <em>The
British Journal for the Philosophy of Science</em>, 56(1):
27&ndash;59. doi:10.1093/phisci/axi102</li>

<li>Hitchcock, Christopher Read, 1993, &ldquo;A Generalized
Probabilistic Theory of Causal Relevance&rdquo;, <em>Synthese</em>,
97(3): 335&ndash;364. doi:10.1007/BF01064073</li>

<li>&ndash;&ndash;&ndash;, 1995a, &ldquo;The Mishap at Reichenbach
Fall: Singular vs. General Causation&rdquo;, <em>Philosophical
Studies</em>, 78(3): 257&ndash;291. doi:10.1007/BF00990114</li>

<li>&ndash;&ndash;&ndash;, 1995b, &ldquo;Salmon on Explanatory
Relevance&rdquo;, <em>Philosophy of Science</em>, 62(2):
304&ndash;320. doi:10.1086/289858</li>

<li>&ndash;&ndash;&ndash;, 1996, &ldquo;The Role of Contrast in Causal
and Explanatory Claims&rdquo;, <em>Synthese</em>, 107(3):
395&ndash;419. doi:10.1007/BF00413843</li>

<li>&ndash;&ndash;&ndash;, 2001a, &ldquo;The Intransitivity of
Causation Revealed in Equations and Graphs&rdquo;, <em>The Journal of
Philosophy</em>, 98(6): 273&ndash;299. doi:10.2307/2678432</li>

<li>&ndash;&ndash;&ndash;, 2001b, &ldquo;A Tale of Two Effects&rdquo;,
<em>Philosophical Review</em>, 110(3): 361&ndash;396.
doi:10.1215/00318108-110-3-361</li>

<li>&ndash;&ndash;&ndash;, 2004, &ldquo;Do All and Only Causes Raise
the Probabilities of Effects?&rdquo; in Collins, Hall, and Paul 2004b:
403&ndash;418.</li>

<li>&ndash;&ndash;&ndash;, 2007a, &ldquo;Prevention, Preemption, and
the Principle of Sufficient Reason&rdquo;, <em>Philosophical
Review</em>, 116(4): 495&ndash;532. doi:10.1215/00318108-2007-012</li>

<li>&ndash;&ndash;&ndash;, 2007b, &ldquo;What&rsquo;s Wrong with
Neuron Diagrams?&rdquo; in J. K. Campbell, M. O&rsquo;Rourke, and H.
S. Silverstein (eds.), <em>Causation and Explanation</em>, Cambridge,
MA: The MIT Press, pp. 69&ndash;92.</li>

<li>&ndash;&ndash;&ndash;, 2011, &ldquo;Trumping and Contrastive
Causation&rdquo;, <em>Synthese</em>, 181(2): 227&ndash;240.
doi:10.1007/s11229-010-9799-y</li>

<li>&ndash;&ndash;&ndash;, 2012, &ldquo;Events and Times: A Case Study
in Means-Ends Metaphysics&rdquo;, <em>Philosophical Studies</em>,
160(1): 79&ndash;96. doi:10.1007/s11098-012-9909-4</li>

<li>Hitchcock, Christopher and Joshua Knobe, 2009, &ldquo;Cause and
Norm&rdquo;:, <em>The Journal of Philosophy</em>, 106(11):
587&ndash;612. doi:10.5840/jphil20091061128</li>

<li>Horwich, Paul, 1987, <em>Asymmetries in Time</em>, Cambridge, MA:
The MIT Press.</li>

<li>Huber, Franz, 2013, &ldquo;Structural Equations and Beyond&rdquo;,
<em>The Review of Symbolic Logic</em>, 6(4): 709&ndash;732.
doi:10.1017/S175502031300018X</li>

<li>Hume, David, 1739&ndash;40, <em>A Treatise of Humean Nature</em>,
London: John Noon. New edition, L. A. Selby-Bigge and P. H. Nidditch
(eds), Oxford: Clarendon Press, 1975.</li>

<li>&ndash;&ndash;&ndash;, 1748, <em>An Enquiry Concerning Human
Understanding</em>, London. Included in <em>Enquiries concerning Human
Understanding and concerning the Principles of Morals</em>, L. A.
Selby-Bigge and P. H. Niddith (eds), third edition, Oxford: Clarendon
Press, 1975.</li>

<li>Kahneman, Daniel and Dale T. Miller, 1986, &ldquo;Norm Theory:
Comparing Reality to Its Alternatives.&rdquo;, <em>Psychological
Review</em>, 93(2): 136&ndash;153. doi:10.1037/0033-295X.93.2.136</li>

<li>Kant, Immanuel, 1781 [1965], <em>Critique of Pure Reason</em>,
trans. N. Kemp Smith. New York: Macmillan Press.</li>

<li>Kim, Jaegwon, 1973, &ldquo;Causation, Nomic Subsumption, and the
Concept of Event&rdquo;, <em>The Journal of Philosophy</em>, 70(8):
217&ndash;236. doi:10.2307/2025096</li>

<li>&ndash;&ndash;&ndash;, 1976, &ldquo;Events as Property
Exemplifications&rdquo;, in M. Brand and D. Walton (eds.), <em>Action
Theory</em>, Dordrecht: D. Reidel Publishing, pp. 159&ndash;77.</li>

<li>Kistler, Max, 1998, &ldquo;Reducing Causality to
Transmission&rdquo;, <em>Erkenntnis</em>, 48(1): 1&ndash;25.
doi:10.1023/A:1005374229251</li>

<li>Kutach, Douglas, 2007, &ldquo;The Physical Foundations of
Causation&rdquo;, in Price and Corry 2007: 327&ndash;50.</li>

<li>Kvart, Igal, 1986, <em>A Theory of Counterfactuals</em>,
Indianapolis, IN: Hackett Publishing.</li>

<li>&ndash;&ndash;&ndash;, 1997, &ldquo;Cause and Some Positive Causal
Impact&rdquo;, in J. Tomberlin (ed.), <em>Philosophical Perspectives
11: Mind, Causation, and World</em>, Oxford: Basil Blackwell, pp.
401&ndash;32.</li>

<li>&ndash;&ndash;&ndash;, 2004, &ldquo;Probabilistic Cause, Edge
Conditions, Late Preemption and Discrete Cases&rdquo;, in Dowe and
Noordhof 2004: 163&ndash;187.</li>

<li>Lemmon, E. J., 1966, &ldquo;Comments on &lsquo;The Logical Form of
Action Sentences&rsquo;&rdquo;, in N. Rescher (ed.), <em>The Logic of
Decision and Action</em>, Pittsburgh, PA: University of Pittsburgh
Press, pp. 96&ndash;103.</li>

<li>LePore, Ernest and Brian P. McLaughlin (eds.), 1985, <em>Actions
and Events: Perspectives on the Philosophy of Donald Davidson</em>,
Oxford/New York: B. Blackwell.</li>

<li>Lewis, David, 1973, &ldquo;Causation&rdquo;, <em>The Journal of
Philosophy</em>, 70(17): 556&ndash;567. doi:10.2307/2025310</li>

<li>&ndash;&ndash;&ndash;, 1979, &ldquo;Counterfactual Dependence and
Time&rsquo;s Arrow&rdquo;, <em>No&ucirc;s</em>, 13(4):
455&ndash;476.</li>

<li>&ndash;&ndash;&ndash;, 1986a, &ldquo;Postscript to
&lsquo;Causation&rsquo;&rdquo;, in <em>Philosophical Papers, Volume
2</em>, Oxford: Oxford University Press, 172&ndash;213.</li>

<li>&ndash;&ndash;&ndash;, 1986b, &ldquo;Events&rdquo;, in
<em>Philosophical Papers, Volume 2</em>, Oxford: Oxford University
Press, 241&ndash;69.</li>

<li>&ndash;&ndash;&ndash;, 2000, &ldquo;Causation as Influence&rdquo;,
<em>The Journal of Philosophy</em>, 97(4): 182&ndash;197.
doi:10.2307/2678389</li>

<li>&ndash;&ndash;&ndash;, 2004, &ldquo;Void and Object&rdquo;, in
Collins, Hall, and Paul 2004b: 277&ndash;290.</li>

<li>Loewer, Barry, 2007, &ldquo;Counterfactuals and the Second
Law&rdquo;, in Price and Corry 2007: 293&ndash;326.</li>

<li>Lombard, Lawrence Brian, 1990, &ldquo;Causes, Enablers, and the
Counterfactual Analysis&rdquo;, <em>Philosophical Studies</em>, 59(2):
195&ndash;211. doi:10.1007/BF00368206</li>

<li>Mackie, J. L., 1965, &ldquo;Causes and Conditions&rdquo;,
<em>American Philosophical Quarterly</em>, 2(4): 245&ndash;264.</li>

<li>&ndash;&ndash;&ndash;, 1974, <em>The Cement of the Universe</em>,
Oxford: Oxford University Press.</li>

<li>Mackie, Penelope, 1992, &ldquo;Causing, Delaying, and Hastening:
Do Rains Cause Fires?&rdquo;, <em>Mind</em>, 101(403): 483&ndash;500.
doi:10.1093/mind/101.403.483</li>

<li>Maslen, Cei, 2004, &ldquo;Causes, Contrasts, and the
Nontransitivity of Causation&rdquo;, in Collins, Hall, and Paul 2004b:
341&ndash;358.</li>

<li>Maudlin, Tim, 2004, &ldquo;Causation, Counterfactuals, and the
Third Factor&rdquo;, in Collins, Hall, and Paul 2004b:
419&ndash;443.</li>

<li>&ndash;&ndash;&ndash;, 2007, &ldquo;On the Passing of Time&rdquo;,
in his <em>The Metaphysics within Physics</em>, Oxford: Oxford
University Press, pp. 104&ndash;142.</li>

<li>McDermott, Michael, 1995, &ldquo;Redundant Causation&rdquo;,
<em>The British Journal for the Philosophy of Science</em>, 46(4):
523&ndash;544. doi:10.1093/bjps/46.4.523</li>

<li>&ndash;&ndash;&ndash;, 2002, &ldquo;Causation: Influence Versus
Sufficiency&rdquo;, <em>The Journal of Philosophy</em>, 99(2):
84&ndash;101. doi:10.5840/jphil200299219</li>

<li>McDonnell, Neil, 2018, &ldquo;Transitivity and Proportionality in
Causation&rdquo;, <em>Synthese</em>, 195(3): 1211&ndash;1229.
doi:10.1007/s11229-016-1263-1</li>

<li>McGrath, Sarah, 2005, &ldquo;Causation By Omission: A
Dilemma&rdquo;, <em>Philosophical Studies</em>, 123(1&ndash;2):
125&ndash;148. doi:10.1007/s11098-004-5216-z</li>

<li>Mellor, D. H., 1981, <em>Real Time</em>, Cambridge: Cambridge
University Press.</li>

<li>&ndash;&ndash;&ndash;, 1988, &ldquo;On Raising the Chances of
Effects&rdquo;, in J. Fetzer (ed.), <em>Probability and
Causality</em>, Dordrecht: D. Reidel Publishing, pp.
229&ndash;40.</li>

<li>&ndash;&ndash;&ndash;, 1995, <em>The Facts of Causation</em>,
London: Routledge Press.</li>

<li>Menzies, Peter, 1989a, &ldquo;A Unified Account of Causal
Relata&rdquo;, <em>Australasian Journal of Philosophy</em>, 67(1):
59&ndash;83. doi:10.1080/00048408912343681</li>

<li>&ndash;&ndash;&ndash;, 1989b, &ldquo;Probabilistic Causation and
Causal Processes: A Critique of Lewis&rdquo;, <em>Philosophy of
Science</em>, 56(4): 642&ndash;663. doi:10.1086/289518</li>

<li>&ndash;&ndash;&ndash;, 1996, &ldquo;Probabilistic Causation and
the Pre-Emption Problem&rdquo;, <em>Mind</em>, 105(417): 85&ndash;117.
doi:10.1093/mind/105.417.85</li>

<li>&ndash;&ndash;&ndash;, 2004, &ldquo;Difference-Making in
Context&rdquo;, in Collins, Hall, and Paul 2004b: 139&ndash;180.</li>

<li>&ndash;&ndash;&ndash;, 2007, &ldquo;Causation in Context&rdquo;,
in Price and Corry 2007: 191&ndash;223.</li>

<li>Menzies, Peter and Huw Price, 1993, &ldquo;Causation as a
Secondary Quality&rdquo;, <em>The British Journal for the Philosophy
of Science</em>, 44(2): 187&ndash;203. doi:10.1093/bjps/44.2.187</li>

<li>Mill, John Stuart, 1843, <em>A System of Logic, Ratiocinative and
Inductive: Being a Connected View of the Principles of Evidence, and
Methods of Scientific Investigation</em>, London: J.W. Parker.</li>

<li>Moore, Michael S., 2009, <em>Causation and Responsibility: An
Essay in Law, Morals, and Metaphysics</em>, Oxford: Oxford University
Press. doi:10.1093/acprof:oso/9780199256860.001.0001</li>

<li>Noordhof, Paul, 1999, &ldquo;Probabilistic Causation, Preemption
and Counterfactuals&rdquo;, <em>Mind</em>, 108(429): 95&ndash;125.
doi:10.1093/mind/108.429.95</li>

<li>Northcott, Robert, 2008, &ldquo;Causation and Contrast
Classes&rdquo;, <em>Philosophical Studies</em>, 139(1): 111&ndash;123.
doi:10.1007/s11098-007-9105-0</li>

<li>Norton, John D., 2003, &ldquo;Causation as Folk Science&rdquo;,
<em>Philosopher&rsquo;s Imprint</em>, 3: art. 4.
 [<a href="http://hdl.handle.net/2027/spo.3521354.0003.004" target="other">Norton 2003 available online</a>]</li>
 
<li>Papineau, David, 1993, &ldquo;Can We Reduce Causal Direction to
Probabilities?&rdquo;, in Hull, D. M. Forbes, and K. Okruhlik (eds.),
<em>PSA 1992</em> (Volume 2), East Lansing: Philosophy of Science
Association, pp. 238&ndash;52.</li>

<li>Paul, L. A., 1998a, &ldquo;Keeping Track of the Time: Emending the
Counterfactual Analysis of Causation&rdquo;, <em>Analysis</em>, 58(3):
191&ndash;198. doi:10.1093/analys/58.3.191</li>

<li>&ndash;&ndash;&ndash;, 1998b, &ldquo;Problems with Late
Preemption&rdquo;, <em>Analysis</em>, 58(1): 48&ndash;53.
doi:10.1093/analys/58.1.48</li>

<li>&ndash;&ndash;&ndash;, 2000, &ldquo;Aspect Causation&rdquo;,
<em>The Journal of Philosophy</em>, 97(4): 235&ndash;256.
doi:10.2307/2678392</li>

<li>Paul, L. A. and Ned Hall, 2013, <em>Causation: A User&rsquo;s
Guide</em>, Oxford: Oxford University Press.
doi:10.1093/acprof:oso/9780199673445.001.0001</li>

<li>Pearl, Judea, 2000, <em>Causality</em>, Cambridge: Cambridge
University Press.</li>

<li>Price, Huw, 1991, &ldquo;Agency and Probabilistic
Causality&rdquo;, <em>The British Journal for the Philosophy of
Science</em>, 42(2): 157&ndash;176. doi:10.1093/bjps/42.2.157</li>

<li>&ndash;&ndash;&ndash;, 1996, <em>Time&rsquo;s Arrow and
Archimedes&rsquo; Point</em>, Oxford: Oxford University Press.</li>

<li>&ndash;&ndash;&ndash;, 2007, &ldquo;Causal Perspectivalism&rdquo;,
in Price and Corry 2007: 250&ndash;92.</li>

<li>Price, Huw and Richard Corry (eds.), 2007, <em>Causation, Physics,
and the Constitution of Reality: Russell&rsquo;s Republic
Revisited</em>, Oxford: Clarendon Press.</li>

<li>Quine, W. V. O., 1966, <em>The Ways of Paradox</em>, New York:
Random House.</li>

<li>&ndash;&ndash;&ndash;, 1985, &ldquo;Events and Reification&rdquo;,
in LePore and McLaughlin 1985: 162&ndash;171.</li>

<li>Ramachandran, Murali, 1997, &ldquo;A Counterfactual Analysis of
Causation&rdquo;, <em>Mind</em>, 106(422): 263&ndash;277.
doi:10.1093/mind/106.422.263</li>

<li>&ndash;&ndash;&ndash;, 1998, &ldquo;The M-Set Analysis of
Causation: Objections and Responses&rdquo;, <em>Mind</em>, 107(426):
465&ndash;471. doi:10.1093/mind/107.426.465</li>

<li>Russell, Bertrand, 1912, &ldquo;On the Notion of Cause&rdquo;,
<em>Proceedings of the Aristotelian Society</em>, 13: 1&ndash;26.
doi:10.1093/aristotelian/13.1.1</li>

<li>&ndash;&ndash;&ndash;, 1948, <em>Human Knowledge: Its Scope and
Limits</em>, New York: Simon and Schuster.</li>

<li>Salmon, Wesley C., 1984, <em>Scientific Explanation and the Causal
Structure of the World</em>, Princeton, NJ: Princeton University
Press.</li>

<li>&ndash;&ndash;&ndash;, 1994, &ldquo;Causality without
Counterfactuals&rdquo;, <em>Philosophy of Science</em>, 61(2):
297&ndash;312. doi:10.1086/289801</li>

<li>&ndash;&ndash;&ndash;, 1997, &ldquo;Causality and Explanation: A
Reply to Two Critiques&rdquo;, <em>Philosophy of Science</em>, 64(3):
461&ndash;477. doi:10.1086/392561</li>

<li>&ndash;&ndash;&ndash;, 1998, <em>Causality and Explanation</em>,
Oxford: Oxford University Press.</li>

<li>Sankey, Howard (ed.), 1999, <em>Causation and Laws of Nature</em>,
Dordrecht: Kluwer. doi:10.1007/978-94-015-9229-1</li>

<li>Sartorio, Carolina, 2005, &ldquo;Causes As
Difference-Makers&rdquo;, <em>Philosophical Studies</em>,
123(1&ndash;2): 71&ndash;96. doi:10.1007/s11098-004-5217-y</li>

<li>&ndash;&ndash;&ndash;, 2006, &ldquo;On Causing Something to Happen
in a Certain Way Without Causing It to Happen&rdquo;,
<em>Philosophical Studies</em>, 129(1): 119&ndash;136.
doi:10.1007/s11098-005-3023-9</li>

<li>&ndash;&ndash;&ndash;, 2013, &ldquo;Making a Difference in a
Deterministic World&rdquo;, <em>Philosophical Review</em>, 122(2):
189&ndash;214. doi:10.1215/00318108-1963707</li>

<li>Sayre, Kenneth M., 1977, &ldquo;Statistical Models of Causal
Relations&rdquo;, <em>Philosophy of Science</em>, 44(2):
203&ndash;214. doi:10.1086/288738</li>

<li>Schaffer, Jonathan, 2000a, &ldquo;Trumping Preemption&rdquo;,
<em>The Journal of Philosophy</em>, 97(4): 165&ndash;181.
doi:10.2307/2678388</li>

<li>&ndash;&ndash;&ndash;, 2000b, &ldquo;Overlappings:
Probability-Raising without Causation&rdquo;, <em>Australasian Journal
of Philosophy</em>, 78(1): 40&ndash;46.
doi:10.1080/00048400012349331</li>

<li>&ndash;&ndash;&ndash;, 2000c, &ldquo;Causation by
Disconnection&rdquo;, <em>Philosophy of Science</em>, 67(2):
285&ndash;300. doi:10.1086/392776</li>

<li>&ndash;&ndash;&ndash;, 2001, &ldquo;Causes as Probability Raisers
of Processes&rdquo;, <em>The Journal of Philosophy</em>, 98(2):
75&ndash;92. doi:10.2307/2678483</li>

<li>&ndash;&ndash;&ndash;, 2005, &ldquo;Contrastive Causation&rdquo;,
<em>Philosophical Review</em>, 114(3): 327&ndash;358.
doi:10.1215/00318108-114-3-327</li>

<li>&ndash;&ndash;&ndash;, 2007, &ldquo;Review of <em>Cause and
Chance: Causation in an Indeterministic World</em>, by Phil Dowe and
Paul Noordhof&rdquo;, <em>The British Journal for the Philosophy of
Science</em>, 58(4): 869&ndash;874. doi:10.1093/bjps/axm040</li>

<li>&ndash;&ndash;&ndash;, 2012a, &ldquo;Causal Contextualisms&rdquo;,
in <em>Contrastivism in Philosophy</em>, Martijn Blaauw (ed.), London:
Routledge, pp. 35&ndash;63.</li>

<li>&ndash;&ndash;&ndash;, 2012b, &ldquo;Disconnection and
Responsibility&rdquo;, <em>Legal Theory</em>, 18(4): 399&ndash;435.
doi:10.1017/S1352325212000092</li>

<li>Scriven, Michael, 1962, &ldquo;Explanations, Predictions, and
Laws&rdquo;, <em>Minnesota Studies in the Philosophy of Science</em>,
3: 170&ndash;230.</li>

<li>Shoemaker, Sydney, 1980, &ldquo;Causality and Properties&rdquo;,
in van Inwagen 1980: 109&ndash;135.</li>

<li>&ndash;&ndash;&ndash;, 1998, &ldquo;Causal and Metaphysical
Necessity&rdquo;, <em>Pacific Philosophical Quarterly</em>, 79(1):
59&ndash;77. doi:10.1111/1468-0114.00050</li>

<li>Skyrms, Brian, 1984, &ldquo;EPR: Lessons for Metaphysics&rdquo;,
<em>Midwest Studies in Philosophy</em>, 9: 245&ndash;255.
doi:10.1111/j.1475-4975.1984.tb00062.x</li>

<li>Sober, Elliott, 1985, &ldquo;Two Concepts of Cause&rdquo;, in P.
Asquith and P. Kitcher (eds.), <em>PSA 1984</em> (Volume 2), East
Lansing: Philosophy of Science Association, pp. 405&ndash;24.</li>

<li>Sosa, Ernest (ed.), 1975, <em>Causation and Conditionals</em>,
(Oxford Readings in Philosophy), London: Oxford University Press.</li>

<li>Spirtes, Peter, Clark Glymour, and Richard Scheines, 1993,
<em>Causation, Prediction, and Search</em>, New York:
Springer-Verlaag.</li>

<li>Strawson, P. F., 1985, &ldquo;Causality and Explanation&rdquo;, in
B. Vermazen and M. Hintikka (eds.), <em>Essays on Davidson: Actions
and Events</em>, Oxford: Clarendon Press, pp. 115&ndash;36.</li>

<li>Steward, Helen, 1997, <em>The Ontology of Mind</em>, Oxford:
Clarendon Press.</li>

<li>Strevens, Michael, 2008, <em>Depth: An Account of Scientific
Explanation</em>, Cambridge, MA: Harvard University Press.</li>

<li>Suppes, Patrick, 1970, <em>A Probabilistic Theory of
Causality</em>, Amsterdam: North Holland Publishing.</li>

<li>Swain, Marshall, 1978, &ldquo;A Counterfactual Analysis of Event
Causation&rdquo;, <em>Philosophical Studies</em>, 34(1): 1&ndash;19.
doi:10.1007/BF00364685</li>

<li>Taylor, Richard, 1966, <em>Action and Purpose</em>, Upper Saddle
River, NJ: Prentice Hall.</li>

<li>Thomson, Judith Jarvis, 2003, &ldquo;Causation: Omissions&rdquo;,
<em>Philosophy and Phenomenological Research</em>, 66(1):
81&ndash;103. doi:10.1111/j.1933-1592.2003.tb00244.x</li>

<li>Tooley, Michael, 1987, <em>Causation: A Realist Approach</em>,
Oxford: Clarendon Press.</li>

<li>&ndash;&ndash;&ndash;, 2004, &ldquo;Probability and
causation&rdquo;, in Dowe and Noordhof 2004: 77&ndash;119.</li>

<li>Touborg, Caroline Torpe, 2018, &ldquo;Hasteners and Delayers: Why
Rains Don&rsquo;t Cause Fires&rdquo;, <em>Philosophical Studies</em>,
175(7): 1557&ndash;1576. doi:10.1007/s11098-017-0923-4</li>

<li>Van Fraassen, Bas, 1980, <em>The Scientific Image</em>, Oxford:
Oxford University Press.</li>

<li>Van Inwagen, Peter (ed.), 1980, <em>Time and Cause: Essays
Presented to Richard Taylor</em>, Dordrecht: D. Reidel
Publishing.</li>

<li>Vendler, Zeno, 1984, &ldquo;Agency and Causation&rdquo;,
<em>Midwest Studies in Philosophy</em>, 9: 371&ndash;384.
doi:10.1111/j.1475-4975.1984.tb00068.x</li>

<li>Von Wright, G. H., 1975, &ldquo;On the Logic and Epistemology of
the Causal Relation&rdquo;, in Sosa 1975: 95&ndash;113.</li>

<li>Weinberger, Naftali, 2019, &ldquo;Path-Specific Effects&rdquo;,
<em>The British Journal for the Philosophy of Science</em>, 70(1):
53&ndash;76. doi:10.1093/bjps/axx040</li>

<li>Woodward, James, 1984, &ldquo;A Theory of Singular Causal
Explanation&rdquo;, <em>Erkenntnis</em>, 21(3): 231&ndash;262.
doi:10.1007/BF00169275</li>

<li>&ndash;&ndash;&ndash;, 2003, <em>Making Things Happen: A Theory of
Causal Explanation</em>, Oxford; Oxford University Press.</li>

<li>Yablo, Stephen, 2002, &ldquo;De Facto Dependence&rdquo;, <em>The
Journal of Philosophy</em>, 99(3): 130&ndash;148.
doi:10.2307/3655640</li>

<li>&ndash;&ndash;&ndash;, 2004, &ldquo;Advertisement for a Sketch of
an Outline of a Prototheory of Causation&rdquo;, in Collins, Hall, and
Paul 2004b: 119&ndash;138 (ch. 5).</li>
</ul>
</div> 

<div id="academic-tools">
<h2 id="Aca">Academic Tools</h2>

<blockquote>
<table class="vert-top">
<tr>
<td><img src="../../symbols/sepman-icon.jpg" alt="sep man icon" /></td>
<td><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=causation-metaphysics" target="other">How to cite this entry</a>.</td>
</tr>

<tr>
<td><img src="../../symbols/sepman-icon.jpg" alt="sep man icon" /></td>
<td><a href="https://leibniz.stanford.edu/friends/preview/causation-metaphysics/" target="other">Preview the PDF version of this entry</a> at the
 <a href="https://leibniz.stanford.edu/friends/" target="other">Friends of the SEP Society</a>.</td>
</tr>

<tr>
<td><img src="../../symbols/inpho.png" alt="inpho icon" /></td>
<td><a href="https://www.inphoproject.org/entity?sep=causation-metaphysics&amp;redirect=True" target="other">Look up topics and thinkers related to this entry</a>
 at the Internet Philosophy Ontology Project (InPhO).</td>
</tr>

<tr>
<td><img src="../../symbols/pp.gif" alt="phil papers icon" /></td>
<td><a href="https://philpapers.org/sep/causation-metaphysics/" target="other">Enhanced bibliography for this entry</a>
at <a href="https://philpapers.org/" target="other">PhilPapers</a>, with links to its database.</td>
</tr>

</table>
</blockquote>

</div>

<div id="other-internet-resources">

<h2 id="Oth">Other Internet Resources</h2>

<ul>

<li>Menzies, Peter, 2006,
 &ldquo;<a href="http://philsci-archive.pitt.edu/2962" target="other">A Structural Equations Account of Negative Causation</a>&rdquo;,
 PhilSci-Archive, deposited 10 October 2006.</li>

<li>Weslake, Brad,
 <a href="http://bweslake.s3.amazonaws.com/research/papers/weslake_ac.pdf" target="other">unpublished manuscript</a>.</li>
 
 <li><a href="https://en.wikipedia.org/wiki/Causality" target="other">Causality</a>,
 entry in Wikipedia.</li>

 <li><a href="https://philpapers.org/browse/causation-laws-etc" target="other">Causation, Laws, etc.</a>,
 category at PhilPapers.</li>

<li>Schaffer, Jonathan, &ldquo;The Metaphysics of Causation&rdquo;, 
 <em>Stanford Encyclopedia of Philosophy</em> (Sprin 2022 Edition),
Edward N. Zalta (ed.), URL = 
 &lt;<a href="https://plato.stanford.edu/archives/spr2022/entries/causation-metaphysics/">https://plato.stanford.edu/archives/spr2022/entries/causation-metaphysics/</a>&gt;.
 [This was the previous entry on this topic in the <em>Stanford
Encyclopedia of Philosophy</em> &mdash; see the 
<a href="https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=causation-metaphysics" class="plain" target="other">version history</a>.]</li>

</ul>
</div>

<div id="related-entries">

<h2 id="Rel">Related Entries</h2>

<p>

 <a href="../causal-models/index.html">causal models</a> |
 <a href="../causation-mani/index.html">causation: and manipulability</a> |
 <a href="../causation-backwards/index.html">causation: backward</a> |
 <a href="../causation-counterfactual/index.html">causation: counterfactual theories of</a> |
 <a href="../causation-physics/index.html">causation: in physics</a> |
 <a href="../causation-law/index.html">causation: in the law</a> |
 <a href="../causation-probabilistic/index.html">causation: probabilistic</a> |
 <a href="../causation-regularity/index.html">causation: regularity and inferential theories of</a> |
 <a href="../counterfactuals/index.html">conditionals: counterfactual</a> |
 <a href="../decision-causal/index.html">decision theory: causal</a> |
 <a href="../determinism-causal/index.html">determinism: causal</a> |
 <a href="../events/index.html">events</a> |
 <a href="../hume/index.html">Hume, David</a> |
 <a href="../laws-of-nature/index.html">laws of nature</a> |
 <a href="../mental-causation/index.html">mental causation</a> |
 <a href="../metaphysics/index.html">metaphysics</a> |
 <a href="../wesley-salmon/index.html">Salmon, Wesley</a>

</p>

</div>

<div id="acknowledgments">

<h3>Acknowledgments</h3>

<p>
Thanks to Phillip Bricker, Christopher Read Hitchcock, Doug Kutach,
Laurie Paul, and Ignacio Silva.</p>
</div>
<script type="text/javascript" src="local.js"></script>
<script type="text/javascript" src="../../MathJax/MathJaxb198.js?config=TeX-MML-AM_CHTML"></script>

</div><!-- #aueditable --><!--DO NOT MODIFY THIS LINE AND BELOW-->

<!-- END ARTICLE HTML -->

</div> <!-- End article-content -->

  <div id="article-copyright">
    <p>
 <a href="../../info.html#c">Copyright &copy; 2022</a> by

<br />
<a href="http://jdmitrigallow.com/" target="other">J. Dmitri Gallow</a>
&lt;<a href="m&#97;ilto:dmitri&#37;2egallow&#37;40gmail&#37;2ecom"><em>dmitri<abbr title=" dot ">&#46;</abbr>gallow<abbr title=" at ">&#64;</abbr>gmail<abbr title=" dot ">&#46;</abbr>com</em></a>&gt;
    </p>
  </div>

</div> <!-- End article -->

<!-- NOTE: article banner is outside of the id="article" div. -->
<div id="article-banner" class="scroll-block">
  <div id="article-banner-content">
    <a href="../../fundraising/index.html">
    Open access to the SEP is made possible by a world-wide funding initiative.<br />
    The Encyclopedia Now Needs Your Support<br />
    Please Read How You Can Help Keep the Encyclopedia Free</a>
  </div>
</div> <!-- End article-banner -->

    </div> <!-- End content -->

    <div id="footer">

      <div id="footer-menu">
        <div class="menu-block">
          <h4><i class="icon-book"></i> Browse</h4>
          <ul role="menu">
            <li><a href="../../contents.html">Table of Contents</a></li>
            <li><a href="../../new.html">What's New</a></li>
            <li><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/random">Random Entry</a></li>
            <li><a href="../../published.html">Chronological</a></li>
            <li><a href="../../archives/index.html">Archives</a></li>
          </ul>
        </div>
        <div class="menu-block">
          <h4><i class="icon-info-sign"></i> About</h4>
          <ul role="menu">
            <li><a href="../../info.html">Editorial Information</a></li>
            <li><a href="../../about.html">About the SEP</a></li>
            <li><a href="../../board.html">Editorial Board</a></li>
            <li><a href="../../cite.html">How to Cite the SEP</a></li>
            <li><a href="../../special-characters.html">Special Characters</a></li>
            <li><a href="../../tools/index.html">Advanced Tools</a></li>
            <li><a href="../../contact.html">Contact</a></li>
          </ul>
        </div>
        <div class="menu-block">
          <h4><i class="icon-leaf"></i> Support SEP</h4>
          <ul role="menu">
            <li><a href="../../support/index.html">Support the SEP</a></li>
            <li><a href="../../support/friends.html">PDFs for SEP Friends</a></li>
            <li><a href="../../support/donate.html">Make a Donation</a></li>
            <li><a href="../../support/sepia.html">SEPIA for Libraries</a></li>
          </ul>
        </div>
      </div> <!-- End footer menu -->

      <div id="mirrors">
        <div id="mirror-info">
          <h4><i class="icon-globe"></i> Mirror Sites</h4>
          <p>View this site from another server:</p>
        </div>
        <div class="btn-group open">
          <a class="btn dropdown-toggle" data-toggle="dropdown" href="https://plato.stanford.edu/">
            <span class="flag flag-usa"></span> USA (Main Site) <span class="caret"></span>
            <span class="mirror-source">Philosophy, Stanford University</span>
          </a>
          <ul class="dropdown-menu">
            <li><a href="../../mirrors.html">Info about mirror sites</a></li>
          </ul>
        </div>
      </div> <!-- End mirrors -->
      
      <div id="site-credits">
        <p>The Stanford Encyclopedia of Philosophy is <a href="../../info.html#c">copyright &copy; 2022</a> by <a href="http://mally.stanford.edu/">The Metaphysics Research Lab</a>, Department of Philosophy, Stanford University</p>
        <p>Library of Congress Catalog Data: ISSN 1095-5054</p>
      </div> <!-- End site credits -->

    </div> <!-- End footer -->

  </div> <!-- End container -->

   <!-- NOTE: Script required for drop-down button to work (mirrors). -->
  <script>
    $('.dropdown-toggle').dropdown();
  </script>

</body>

<!-- Mirrored from seop.illc.uva.nl/entries/causation-metaphysics/ by HTTrack Website Copier/3.x [XR&CO'2014], Wed, 22 Jun 2022 19:41:15 GMT -->
</html>
