<!DOCTYPE html>
<!--[if lt IE 7]> <html class="ie6 ie"> <![endif]-->
<!--[if IE 7]>    <html class="ie7 ie"> <![endif]-->
<!--[if IE 8]>    <html class="ie8 ie"> <![endif]-->
<!--[if IE 9]>    <html class="ie9 ie"> <![endif]-->
<!--[if !IE]> --> <html> <!-- <![endif]-->

<!-- Mirrored from seop.illc.uva.nl/entries/evidence/ by HTTrack Website Copier/3.x [XR&CO'2014], Wed, 22 Jun 2022 19:47:01 GMT -->
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>
Evidence (Stanford Encyclopedia of Philosophy)
</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="robots" content="noarchive, noodp" />
<meta property="citation_title" content="Evidence" />
<meta property="citation_author" content="Kelly, Thomas" />
<meta property="citation_publication_date" content="2006/08/11" />
<meta name="DC.title" content="Evidence" />
<meta name="DC.creator" content="Kelly, Thomas" />
<meta name="DCTERMS.issued" content="2006-08-11" />
<meta name="DCTERMS.modified" content="2014-07-28" />

<!-- NOTE: Import webfonts using this link: -->
<link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,300,600,200&amp;subset=latin,latin-ext" rel="stylesheet" type="text/css" />

<link rel="stylesheet" type="text/css" media="screen,handheld" href="../../css/bootstrap.min.css" />
<link rel="stylesheet" type="text/css" media="screen,handheld" href="../../css/bootstrap-responsive.min.css" />
<link rel="stylesheet" type="text/css" href="../../css/font-awesome.min.css" />
<!--[if IE 7]> <link rel="stylesheet" type="text/css" href="../../css/font-awesome-ie7.min.css"> <![endif]-->
<link rel="stylesheet" type="text/css" media="screen,handheld" href="../../css/style.css" />
<link rel="stylesheet" type="text/css" media="print" href="../../css/print.css" />
<link rel="stylesheet" type="text/css" href="../../css/entry.css" />
<!--[if IE]> <link rel="stylesheet" type="text/css" href="../../css/ie.css" /> <![endif]-->
<script type="text/javascript" src="../../js/jquery-1.9.1.min.js"></script>
<script type="text/javascript" src="../../js/bootstrap.min.js"></script>

<!-- NOTE: Javascript for sticky behavior needed on article and ToC pages -->
<script type="text/javascript" src="../../js/jquery-scrolltofixed-min.js"></script>
<script type="text/javascript" src="../../js/entry.js"></script>

<!-- SEP custom script -->
<script type="text/javascript" src="../../js/sep.js"></script>
</head>

<!-- NOTE: The nojs class is removed from the page if javascript is enabled. Otherwise, it drives the display when there is no javascript. -->
<body class="nojs article" id="pagetopright">
<div id="container">
<div id="header-wrapper">
  <div id="header">
    <div id="branding">
      <div id="site-logo"><a href="../../index.html"><img src="../../symbols/sep-man-red.png" alt="SEP logo" /></a></div>
      <div id="site-title"><a href="../../index.html">Stanford Encyclopedia of Philosophy</a></div>
    </div>
    <div id="navigation">
      <div class="navbar">
        <div class="navbar-inner">
          <div class="container">
            <button class="btn btn-navbar collapsed" data-target=".collapse-main-menu" data-toggle="collapse" type="button"> <i class="icon-reorder"></i> Menu </button>
            <div class="nav-collapse collapse-main-menu in collapse">
              <ul class="nav">
                <li class="dropdown open"><a id="drop1" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-book"></i> Browse</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop1">
                    <li><a href="../../contents.html">Table of Contents</a></li>
                    <li><a href="../../new.html">What's New</a></li>
                    <li><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/random">Random Entry</a></li>
                    <li><a href="../../published.html">Chronological</a></li>
                    <li><a href="../../archives/index.html">Archives</a></li>
                  </ul>
                </li>
                <li class="dropdown open"><a id="drop2" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-info-sign"></i> About</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop2">
                    <li><a href="../../info.html">Editorial Information</a></li>
                    <li><a href="../../about.html">About the SEP</a></li>
                    <li><a href="../../board.html">Editorial Board</a></li>
                    <li><a href="../../cite.html">How to Cite the SEP</a></li>
                    <li><a href="../../special-characters.html">Special Characters</a></li>
                    <li><a href="../../tools/index.html">Advanced Tools</a></li>
                    <li><a href="../../contact.html">Contact</a></li>
                  </ul>
                </li>
                <li class="dropdown open"><a id="drop3" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-leaf"></i> Support SEP</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop3">
                    <li><a href="../../support/index.html">Support the SEP</a></li>
                    <li><a href="../../support/friends.html">PDFs for SEP Friends</a></li>
                    <li><a href="../../support/donate.html">Make a Donation</a></li>
                    <li><a href="../../support/sepia.html">SEPIA for Libraries</a></li>
                  </ul>
                </li>
              </ul>
            </div>
          </div>
        </div>
      </div>
    </div>
    <!-- End navigation -->
    
    <div id="search">
      <form id="search-form" method="get" action="https://seop.illc.uva.nl/search/searcher.py">
        <input type="search" name="query" placeholder="Search SEP" />
        <div class="search-btn-wrapper"><button class="btn search-btn" type="submit"><i class="icon-search"></i></button></div>
      </form>
    </div>
    <!-- End search --> 
    
  </div>
  <!-- End header --> 
</div>
<!-- End header wrapper -->

<div id="content">

<!-- Begin article sidebar -->
<div id="article-sidebar" class="sticky">
  <div class="navbar">
    <div class="navbar-inner">
      <div class="container">
        <button class="btn btn-navbar" data-target=".collapse-sidebar" data-toggle="collapse" type="button"> <i class="icon-reorder"></i> Entry Navigation </button>
        <div id="article-nav" class="nav-collapse collapse-sidebar in collapse">
          <ul class="nav">
            <li><a href="#toc">Entry Contents</a></li>
            <li><a href="#Bib">Bibliography</a></li>
            <li><a href="#Aca">Academic Tools</a></li>
            <li><a href="https://leibniz.stanford.edu/friends/preview/evidence/">Friends PDF Preview <i class="icon-external-link"></i></a></li>
            <li><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=evidence">Author and Citation Info <i class="icon-external-link"></i></a> </li>
            <li><a href="#pagetopright" class="back-to-top">Back to Top <i class="icon-angle-up icon2x"></i></a></li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</div>
<!-- End article sidebar --> 

<!-- NOTE: Article content must have two wrapper divs: id="article" and id="article-content" -->
<div id="article">
<div id="article-content">

<!-- BEGIN ARTICLE HTML -->


<div id="aueditable"><!--DO NOT MODIFY THIS LINE AND ABOVE-->

<h1>Evidence</h1><div id="pubinfo"><em>First published Fri Aug 11, 2006; substantive revision Mon Jul 28, 2014</em></div>

<div id="preamble">

<blockquote>
For my own part, I think that if one were looking for a single
phrase to capture the stage to which philosophy has progressed,
&lsquo;the study of evidence&rsquo; would be a better choice than
&lsquo;the study of language&rsquo;.<br />
&nbsp;&nbsp;&nbsp;&mdash;A.J. Ayer, <em>Philosophy in the Twentieth
Century</em>
</blockquote>

<blockquote>
And when we try to define &lsquo;evidence&rsquo; &hellip; we find it
very difficult.<br />
&nbsp;&nbsp;&nbsp;&mdash;R.G. Collingwood, <em>The Idea of
History</em>
</blockquote>

<p>The concept of evidence is central to both epistemology and the
philosophy of science. Of course, &lsquo;evidence&rsquo; is hardly a
philosopher's term of art: it is not only, or even primarily,
philosophers who routinely speak of evidence, but also lawyers and
judges, historians and scientists, investigative journalists and
reporters, as well as the members of numerous other professions and
ordinary folk in the course of everyday life. The concept of evidence
would thus seem to be on firmer pre-theoretical ground than various
other concepts which enjoy similarly central standing within
philosophy. (Contrast, for example, the epistemologist's
quasi-technical term &lsquo;epistemic justification&rsquo;.)</p>

<p>When one compares philosophical accounts of evidence with the way
the concept is often employed in non-philosophical contexts, however,
a tension soon emerges. Consider first the kinds of things which
non-philosophers are apt to count as evidence. For the forensics
expert, evidence might consist of fingerprints on a gun, a bloodied
knife, or a semen-stained dress: evidence is, paradigmatically, the
kind of thing which one might place in a plastic bag and label
&lsquo;Exhibit A&rsquo;. Thus, a criminal defense attorney might float
the hypothesis that the evidence which seems to incriminate his client
was planted by a corrupt law enforcement official or hope for it to be
misplaced by a careless clerk. For an archaeologist, evidence is the
sort of thing which one might dig up from the ground and carefully
send back to one's laboratory for further analysis. Similarly, for the
historian, evidence might consist of hitherto overlooked documents
recently discovered in an archive or in an individual's personal
 library.<sup>[<a href="notes.html#1" name="note-1">1</a>]</sup>
 Reflection on examples such as these naturally suggests that evidence
consists paradigmatically of physical objects, or perhaps, physical
objects arranged in certain ways. For presumably, physical objects are
the sort of thing which one might place in a plastic bag, dig up from
the ground, send to a laboratory, or discover among the belongings of
an individual of historical interest. </p>

<p>
 However natural such a picture might be, it is at least somewhat
difficult to reconcile with historically prominent philosophical
accounts of the nature of evidence. Russell, the greatest empiricist
of the first half of the twentieth century, tended to think of
evidence as <em>sense data</em>, mental items of one's present
consciousness with which one is immediately acquainted. In this, he
stood squarely within the tradition of classical empiricism. Quine,
the greatest empiricist of the second half of the century, maintained
throughout his career that evidence consisted of the stimulation of
one's sensory
 receptors.<sup>[<a href="notes.html#2" name="note-2">2</a>]</sup>
 The logical positivists held that whatever evidence there is for a
given scientific theory is afforded by <em>observation statements</em>
or &lsquo;protocol sentence&rsquo;, linguistic entities with
suitably-restricted contents; the precise nature of the restrictions
became a vigorously contested matter within the tradition
 itself.<sup>[<a href="notes.html#3" name="note-3">3</a>]</sup>
 According to one recent and influential study, one's evidence consists
of the totality of propositions that one knows (Williamson 2000).
According to another, one's evidence consists exclusively of one's current mental states (Conee and Feldman 2004). Within
contemporary confirmation theory, a prominent version of Bayesianism is
naturally understood as identifying one's evidence with those beliefs
of which one is psychologically certain. Of course, the suggestion that
one might place sense data, sensory receptor stimulations, known
propositions, or one's current mental states in a plastic bag (or dig them
up from the ground, or send them to a laboratory, or &hellip;) is of dubious
intelligibility. From the perspective of much ordinary thought and talk
about evidence, much philosophical theorizing about evidence would seem
to embody a particularly grotesque category mistake. </p>

<p>
 Moreover, it is not simply that the accounts of evidence that have
been advanced by philosophers stand in at least some <em>prima
facie</em> tension with much that is said and thought about evidence
outside of philosophy. As even the cursory survey offered above makes
clear, philosophers themselves have offered quite divergent theories
of what sorts of things are eligible to serve as evidence. What might
account for such discrepancies?</p>

<p>
 One possibility is the following.  Both in and outside of philosophy,
the concept of evidence has often been called upon to fill a number of
distinct roles. Although some of these roles are complementary, others
stand in at least some measure of tension with one another. Indeed, as
we will see below, it is far from obvious that any one thing could
play all of the diverse roles that evidence has at various times been
expected to play. Different theories about the nature of evidence
might thus naturally emerge from different emphases on the competing
demands that have been placed on the concept.  In what follows, I
survey some of the theoretical roles that the concept of evidence has
been asked to play and explore some of the relations among them.</p>

</div>

<div id="toc">
<!--Entry Contents-->
<ul>
<li><a href="#EviWhiJusBel">1. Evidence as That Which Justifies Belief</a></li>
<li><a href="#RatThiResTheEvi">2. Rational Thinkers Respect Their Evidence </a></li>
<li><a href="#EviGuiTruEviSigSymMar">3. Evidence as a Guide to Truth: Evidence as Sign, Symptom, or Mark</a></li>
<li><a href="#ObjPubIntEviNeuArb">4. Objectivity, Publicity, and Intersubjectivity: Evidence as Neutral Arbiter</a></li>
<li><a href="#Bib">Bibliography</a></li>
<li><a href="#Aca">Academic Tools</a></li>
<li><a href="#Oth">Other Internet Resources</a></li>
<li><a href="#Rel">Related Entries</a></li>
</ul>
<!--Entry Contents-->

<hr />

</div>

<div id="main-text">

<h2><a name="EviWhiJusBel">1. Evidence as That Which Justifies Belief</a></h2>

<blockquote>
In any event, the concept of evidence is inseparable from that of
justification. When we talk of &lsquo;evidence&rsquo; in an
epistemological sense we are talking about justification: one thing is
&lsquo;evidence&rsquo; for another just in case the first tends to
enhance the reasonableness or justification of the second.&hellip; A
strictly nonnormative concept of evidence is not our concept of
evidence; it is something that we do not understand.<br />
&nbsp;&nbsp;&nbsp;&mdash;Jaegwon Kim, &lsquo;What is
&ldquo;Naturalized Epistemology&rdquo;?&rsquo;
</blockquote>

<p>
 Evidence, whatever else it is, is the kind of thing which can make a
difference to what one is <em>justified</em> in believing or (what is
often, but not always, taken to be the same thing) what it is
<em>reasonable</em> for one to believe. Some philosophers hold that
what one is justified in believing is entirely determined by one's
evidence. This view&mdash;which sometimes travels under the banner of
&lsquo;Evidentialism&rsquo;&mdash;can be formulated as a supervenience
thesis, according to which normative facts about what one is justified
in believing supervene on facts about one's evidence (See especially
Conee and Feldman 2004). Thus, according to the Evidentialist, any two
individuals who possessed exactly the same evidence would be exactly
alike with respect to what they are justified in believing about any
given question.</p>

<p>
 Given Evidentialism, various traditional debates within the theory of
knowledge are naturally cast as debates about the status of various
underdetermination theses. Thus, the <em>skeptic about our knowledge
of the external world</em> maintains that one's evidence (understood,
perhaps, as the totality of one's present experiences) does not favor
one's ordinary, commonsense views about one's surroundings over
various skeptical alternatives (e.g., the hypothesis that one is
hallucinating in an undetectable way). Similarly, one longstanding
controversy that divides realists and antirealists in the philosophy
of science can be understood as a debate about whether the kind of
evidence which is available to scientists is ever sufficient to
justify belief in theories that quantify over entities that are in
principle unobservable, such as electrons or quarks.</p>

<p>
 Inasmuch as evidence is the sort of thing which confers
justification, the concept of evidence is closely related to other
fundamental normative concepts such as the concept of <em>a
reason</em>. Indeed, it is natural to think that &lsquo;reason to
believe&rsquo; and &lsquo;evidence&rsquo; are more or less synonymous,
being distinguished chiefly by the fact that the former functions
grammatically as a count noun while the latter functions as a mass
 term.<sup>[<a href="notes.html#4" name="note-4">4</a>]</sup> </p>

<p>
 To the extent that what one is justified in believing depends upon
one's evidence, what is relevant is the bearing of one's
<em>total</em> evidence. Even if evidence <em>E</em> is sufficient to
justify believing hypothesis <em>H</em> when considered in isolation,
it does not follow that one who possesses evidence <em>E</em> is
justified in believing <em>H</em> on its basis. For one might possess
some additional evidence <em>E</em>&prime;, such that one is not
justified in believing <em>H</em> given <em>E</em> and
<em>E</em>&prime;. In these circumstances, evidence <em>E</em>&prime;
<em>defeats</em> the justification for believing <em>H</em> that would
be afforded by <em>E</em> in its absence. Thus, even if I am initially
justified in believing that <em>your name is Fritz</em> on the basis
of your testimony to that effect, the subsequent acquisition of
evidence which suggests that you are a pathological liar tends to
render this same belief unjustified. A given piece of evidence is
<em>defeasible</em> evidence just in case it is in principle
susceptible to being undermined by further evidence in this way;
evidence which is not susceptible to such undermining would be
<em>indefeasible</em> evidence. It is controversial whether any
evidence is indefeasible in this
 sense.<sup>[<a href="notes.html#5" name="note-5">5</a>]</sup></p>

<p>
 Following Pollock (1986), we can distinguish between
<em>undercutting</em> and <em>rebutting</em> defeaters. Intuitively,
where <em>E</em> is evidence for <em>H</em>, an undercutting defeater
is evidence which undermines the evidential connection between
<em>E</em> and <em>H</em>. Thus, evidence which suggests that you are
a pathological liar constitutes an undercutting defeater for your
testimony: although your testimony would ordinarily afford excellent
reason for me to believe that <em>your name is Fritz</em>, evidence
that you are a pathological liar tends to sever the evidential
connection between your testimony and that to which you testify. In
contrast, a rebutting defeater is evidence which prevents <em>E</em>
from justifying belief in <em>H</em> by supporting not-<em>H</em> in a
more direct way. Thus, credible testimony from another source that
your name is not Fritz but rather Leopold constitutes a rebutting
defeater for your original testimony. It is something of an open
question how deeply the distinction between &lsquo;undermining&rsquo;
and &lsquo;rebutting&rsquo; defeaters cuts.</p>

<p>
 Significantly, defeating evidence can itself be defeated by yet
further evidence: at a still later point in time, I might acquire
evidence <em>E</em>&Prime; which suggests that you are not a
pathological liar after all, the evidence to that effect having been
an artifice of your sworn enemy. In these circumstances, my initial
justification for believing that your name is Fritz afforded by the
original evidence <em>E</em> is restored. In principle, there is no
limit to the complexity of the relations of defeat that might obtain
between the members of a given body of evidence. Such complexity is
one source of our fallibility in responding to evidence in the
appropriate way. </p>

<p>
 In order to be justified in believing some proposition then, it is
not enough that that proposition be well-supported by some proper
subset of one's total evidence; rather, what is relevant is how
well-supported the proposition is by one's total evidence. In
insisting that facts about what one is justified in believing
supervene on facts about one's evidence, the Evidentialist should be
understood as holding that it is one's total evidence that is
relevant. Of course, this leaves open questions about what relation
one must bear to a piece of evidence <em>E</em> in order for
<em>E</em> to count as part of one's total evidence, as well as the
related question of what sorts of things are eligible for inclusion
among one's total
 evidence.<sup>[<a href="notes.html#6" name="note-6">6</a>]</sup></p>

<p>
 Given the thesis that evidence is that which justifies belief, one's
intuitions about the evidence that is available to an individual in a
hypothetical scenario will shape one's views about what the individual
would be justified in believing in that scenario. Of course, one can
also theorize in the opposite direction as well: to the extent that
one has independent intuitions about what an individual would be
justified in believing in a given scenario, such intuitions will shape
one's views about what evidence must be available to an individual so
situated&mdash;and therefore, one's views about the more general
theoretical issue about what evidence is, or what sorts of things can
and cannot qualify as evidence. Thus, if one is firmly convinced that
an individual in circumstances <em>C</em> might be justified in
believing that <em>p</em> is the case, it follows immediately that
being in circumstances of kind <em>C</em> is consistent with having
evidence sufficient to justify the belief that <em>p</em>. As we will
see below (Section 2), reasoning of this general form has often
encouraged a picture according to which one's total evidence is
exhausted by one's present experiences.</p>

<p>
 Here is an example of the way in which intuitions about justification
can drive one's account of evidence, given a commitment to the
Evidentialist thesis that changes in what an individual is justified
in believing always reflect changes in her total evidence. It is
sometimes suggested that how confident a scientist is justified in
being that a given hypothesis is true depends, not only on the
character of relevant data to which she has been exposed, but also on
the space of alternative hypotheses of which she is aware. According
to this line of thought, how strongly a given collection of data
supports a hypothesis is not wholly determined by the content of the
data and the hypothesis. (Nor is it wholly determined by their content
together with the scientist's background theory of how the world
works.) Rather, it also depends upon whether there are other plausible
competing hypotheses in the field. It is because of this that the mere
articulation of a plausible alternative hypothesis can dramatically
reduce how likely the original hypothesis is on the available
 data.<sup>[<a href="notes.html#7" name="note-7">7</a>]</sup> </p>

<p>
 Consider an historical example that is often thought to illustrate
this phenomenon. Many organisms manifest special characteristics that
enable them to flourish in their typical environments. According to
the <em>Design Hypothesis</em>, this is due to the fact that such
organisms were designed by an Intelligent Creator (i.e., God). The
Design Hypothesis is a potential explanation of the relevant facts: if
true, it would account for the facts in question. How much support do
the relevant facts lend to the Design Hypothesis? Plausibly, the
introduction of the Darwinian Hypothesis as a competitor in the
nineteenth century significantly diminished the support enjoyed by the
Design Hypothesis. That is, even if there were no reason to
<em>prefer</em> the Darwinian Hypothesis to the Design Hypothesis, the
mere fact that the Design Hypothesis was no longer the only potential
explanation in the field tends to erode (to some extent at least) how
much credence the Design Hypothesis merits on the basis of the
relevant considerations.</p>

<p>
 Assume for the sake of illustration that what one is justified in
believing does in fact depend upon the space of alternative hypotheses
of which one is aware: as new hypotheses are introduced, one's
justification for believing already proposed hypotheses changes. Given
the Evidentialist thesis that differences in justification are always
underwritten by differences in evidence, it follows that a complete
specification of one's evidence at any given time will make reference
to the set of hypotheses which one is aware of at that time. This is
an example of the way in which intuitive judgments about what
individuals are justified in believing in certain circumstances, when
coupled with a commitment to Evidentialism, can drive one's theory of
evidence (i.e., make a difference to which items one classifies as
&lsquo;evidence&rsquo; in one's theorizing).</p>

<p>
 The justifying or rationalizing role of evidence is also central to
other prominent epistemological views, including views which are
strictly speaking incompatible with Evidentialism as formulated
above. Consider, for example, Bayesianism. (See the entry on
 <a href="../epistemology-bayesian/index.html">Bayesian epistemology</a>.)
 The Bayesian holds that what it is reasonable for one to believe
depends both on the evidence to which one is exposed as well as on
one's prior probability distribution. According to the Bayesian then,
two individuals who share exactly the same total evidence might differ
in what it is reasonable for them to believe about some question in
virtue of having started with different prior probability
distributions. Still, inasmuch as Bayesians often focus upon rational
belief <em>change</em>, or on what is involved in rationally revising
one's beliefs over time, the justificatory role of evidence retains a
certain pride of place within the Bayesian scheme. For Bayesians
typically maintain that that which distinguishes those changes in
one's beliefs that are reasonable from those that are not is that the
former, unlike the latter, involve responding to newly-acquired
evidence in an appropriate
 way.<sup>[<a href="notes.html#8" name="note-8">8</a>]</sup>
 Thus, for the Bayesian no less than for the Evidentialist, it is
evidence which justifies that which stands in need of justification. </p>

<p>
 Notably, even views which tend to marginalize the role of a subject's
evidence in determining facts about what he or she is justified in
believing typically do not take facts about the subject's evidence to
be wholly irrelevant. Consider, for example, <em>reliabilist</em>
theories of epistemic justification (Goldman 1979, 1986). In its
purest and most straightforward form, reliabilism holds that the
status of a token belief as justified or unjustified depends upon
whether or not the psychological process which gives rise to the
belief is a reliable one, i.e., one that is truth-conducive. When
formulated in this way, the concept of evidence plays no role in the
reliabilist account of justification: in particular, the status of a
given belief as justified or unjustified depends upon whether the
relevant belief-forming process is <em>in fact</em> reliable, and not on
any evidence which the believer might possess which bears on the
question of its reliability (or even, for that matter, on any evidence
which the believer might possess which bears more directly on the
truth of the belief itself). Thus, someone who was in fact a reliable
clairvoyant would be justified in holding beliefs that she forms on
the basis of clairvoyance, even if her total evidence strongly
suggested both that (i) she does not possess the faculty of
clairvoyance, and that (ii) the relevant beliefs are false (BonJour
1985, Chapter 3). However, in response to such examples, reliabilists
typically seek to accommodate the intuition that such a subject is not
justified in maintaining her reliably-arrived-at beliefs in the face
of her evidence, and they seek to modify the simple reliabilist
account to allow for this (See, e.g., Goldman 1986: 109&ndash;112). The felt
need to modify the original, more straightforward account is, perhaps,
a testament to the resilience of the idea that one's evidence can make
a difference to what one is justified in believing&mdash;even if
other factors are <em>also</em> taken to be relevant.</p>
	

<h2><a name="RatThiResTheEvi">2. Rational Thinkers Respect Their Evidence </a></h2>

<blockquote>
A rational man is one who makes a proper use of reason: and this
implies, among other things, that he correctly estimates the strength
of evidence.<br />
&nbsp;&nbsp;&nbsp;&mdash;Ayer, <em>Probability and Evidence</em>
</blockquote>

<blockquote>
Insofar as we are rational in our beliefs, the intensity of belief
will tend to correspond to the firmness of the available
evidence. Insofar as we are rational, we will drop a belief when we
have tried in vain to find evidence for it.<br />
&nbsp;&nbsp;&nbsp;&mdash;Quine and Ullian, <em>The Web of Belief</em>
</blockquote>

<blockquote>
A wise man proportions his belief to the evidence.<br />
&nbsp;&nbsp;&nbsp;&mdash;David Hume, <em>An Enquiry Concerning Human
Understanding</em>
</blockquote>

<p>
 It is characteristic of rational thinkers to respect their evidence.
Insofar as one is rational, one is disposed to respond appropriately
to one's evidence: at any given time, one's views accurately reflect
the character of one's evidence at that time, and one's views manifest
a characteristic sensitivity or responsiveness to changes in one's
evidence through time. Of course, rationality is no guarantee of
correctness. Indeed, in a given case one might be led astray by
following one's evidence, as when one's evidence is
<em>misleading</em>.  But being mistaken is not the same as being
unreasonable. To the extent that one respects one's evidence, one is
not unreasonable even when one is
 wrong.<sup>[<a href="notes.html#9" name="note-9">9</a>]</sup> </p>

<p>
 The foregoing remarks, although bordering on the platitudinous,
naturally suggest a substantive model of the norms which govern our
practice of belief attribution. According to the model in question, in
attributing beliefs to you, I should, all else being equal, attribute
to you the belief that <em>p</em> just in case it would be reasonable
for you to believe that <em>p</em> given your total evidence. This is
the core idea behind one popular version of the Principle of
Charity. According to this line of thought, I am justified in drawing
inferences about what you believe on the basis of my knowledge of your
epistemic situation. Thus, if I know that your evidence strongly
suggests that <em>it will rain today</em>, then (all else being equal)
I should attribute to you the belief that it will rain today. On the
other hand, if I know that your evidence strongly suggests that it
will <em>not</em> rain today, then I should likewise attribute to you
a belief to that effect. Although on a given occasion a thinker who is
generally reasonable might fail to believe in accordance with her
evidence, such cases are exceptional. In the absence of any reason to
think that a given case is exceptional in this way, one is licensed to
draw inferences about the contents of another's beliefs on the basis
of information about the character of her evidence. The default
assumption is that a person's beliefs are those that it is appropriate
for her to hold given the evidence to which she has been exposed.</p>

<p>
 Above, we noted that in a given case one might be led astray by
following one's evidence: even if <em>p</em> is true, one's evidence
might misleadingly suggest that <em>p</em> is not true. When one's
evidence is misleading, one typically arrives at a false belief by
believing in accordance with it. We ordinarily assume that such cases
are exceptional. Are there possible worlds in which such cases are the
norm? Consider a careful and judicious thinker who consistently and
scrupulously attends to his evidence in arriving at his beliefs. In
our world, these habits lead to cognitive prosperity&mdash;the
individual holds a relatively large number of true beliefs and
relatively few false beliefs. (Or at least, he fares significantly
better with respect to truth and falsity than those who fail to attend
to their evidence and instead form their beliefs in a hasty or
haphazard manner.)  Consider next how the same individual fares in a
world that is subject to the machinations of a Cartesian evil demon, a
being bent on deceiving the world's inhabitants as to its true
character. Although the true character of the world in question
differs radically from our own, it is, from the point of view of its
inhabitants, utterly indistinguishable, for the Demon takes care to
ensure that the courses of experiences that the inhabitants undergo
are qualitatively identical to the courses of experiences that they
undergo in our non-delusory world. In the world run by the Cartesian
Demon, our thinker is no less judicious and no less scrupulous in
attending to (what he blamelessly takes to be) relevant considerations
than he is in our world. Because of his unfortunate circumstances,
however, his beliefs embody a radically false picture of his
environment. Granted that the thinker's beliefs about his environment
are false, are they any less justified than in our world? Is the
thinker himself any less rational? Many philosophers maintain that the
thinker's beliefs are equally well-justified and that the thinker
himself is equally rational in the two worlds (See e.g., Cohen 1984
and Pryor 2001). Apparently, there is strong intuitive resistance to
the idea that a thinker whose underlying dispositions and habits of
thought remain unchanged might become <em>less rational</em> simply in
virtue of being located in less fortuitous circumstances. As
Williamson (2000) has forcefully emphasized, however, embracing the
judgement that the thinker is equally rational in &lsquo;the good
case&rsquo; and &lsquo;the bad case&rsquo; tends to push one
inexorably towards a conception of evidence according to which one's
evidence is exhausted by one's subjective, non-factive mental
states. For if rationality is a matter of responding correctly to
one's evidence, then the judgement that the thinker is equally
rational in the good case and the bad case would seem to require that
the thinker has the same evidence for his beliefs in both cases. But
<em>ex hypothesi</em>, the only thing common to the good case and the
bad case that is a plausible candidate for being the thinker's
evidence are his non-factive mental states. Thus, the judgement that
the thinker is equally rational in both cases, when conjoined with the
view that rationality is a matter of responding to one's evidence in
the appropriate way, seems to force the conclusion that the thinker's
evidence is limited to his non-factive mental states <em>even in the
good case</em>. In this way, the requirement that the thinker has the
same evidence in the good case and the bad case seems to encourage
what Williamson calls &lsquo;the Phenomenal Conception of
 Evidence&rsquo;.<sup>[<a href="notes.html#10" name="note-10">10</a>]</sup></p>

<p>
 Consider also how the aforementioned Principle of Charity encourages
such a picture of evidence when it is applied to the world run by the
Demon. In attributing beliefs to an individual in the bad case, one
attributes exactly those beliefs that one would attribute if the same
individual were in the good case. For if the Demon's illusions are
truly undetectable, failure to detect them hardly seems to constitute
a failure of <em>rationality</em>. In attributing commonsense beliefs
to the individual in the bad case, one proceeds according to the
Principle of Charity: after all, it seems that these are exactly the
beliefs that even a perfectly rational (though not infallible) being
would have in the circumstances. But if the commonsense beliefs are no
less reasonable when held in the bad case, then the individual's
evidence for those beliefs must be just as strong in the bad case as
in the good case. Indeed, it is natural to describe the bad case as a
world in which the thinker's evidence is <em>systematically
misleading</em>. The trick to being a <em>good</em> Evil Demon (one
might think) is to be effective at planting misleading
evidence. Intuitively, the Demon misleads his victims by
<em>exploiting</em> their rationality, inasmuch as he trades on the
sensitivity of their beliefs to misleading evidence. (Indeed, those
who dogmatically cling to favored theories in the face of apparently
disconfirming evidence would seem to be relatively less vulnerable to
being manipulated by the Demon.) But the Demon misleads by providing
his victims with misleading experiences. Hence the temptation to
simply identify one's evidence with one's experiences: once again, the
phenomenal conception of evidence looms. </p>

<p>
 As Williamson emphasizes, the insistence that one's evidence is
identical in the good case and the bad case effectively rules out many
otherwise-attractive accounts of evidence:</p>

<blockquote>
 That one has the same evidence in the good and bad cases is a severe
constraint on the nature of evidence. It is inconsistent with the view
that evidence consists of true propositions like those standardly
offered as evidence for scientific theories.&hellip; For similar
reasons [it] does not permit my evidence to include perceptual states
individuated in part by relations to the environment. No matter how
favorable my epistemic circumstances, I am counted as having only as
much evidence as I have in the corresponding skeptical scenarios, no
matter how distant and bizarre. Retinal stimulations and brain states
fare no better as evidence, for in some skeptical scenarios they are
unknowably different too (2000:173).
 </blockquote>
	
<p>
 In view of its apparent consequences for the theory of evidence, the
idea that one's evidence is the same in the good case and the bad case
warrants further scrutiny. Again, it is uncontroversial that there is
a robust distinction between nonculpable error on the one hand and
irrationality or unreasonableness on the other. Nonculpable error does
not in general make for irrationality, even when such error is
relatively widespread and pervasive. Still, it's worth asking just how
much weight the distinction in question can bear. Is any amount of
nonculpable error about the environment in which one is embedded
compatible with perfect rationality? Or rather, at some point, does a
sufficient amount of error about one's environment tend to compromise
one's ability to form rational beliefs about that environment?</p>

<p>
 Here is one line of thought for the conclusion that a sufficient
level of nonculpable error about one's environment <em>does</em> tend
to compromise one's ability to arrive at rational beliefs about that
environment. It's plausible to suppose that much if not all of the
value that we place on believing rationally depends on a connection
between believing rationally and believing what is true (although the
precise nature of this connection is no doubt a particularly vexing
topic). One might worry that a view according to which even ideal,
perfect rationality can coexist harmoniously with a more or less
completely mistaken view of one's situation threatens to attenuate the
connection between believing rationally and believing truly too far,
and to render obscure why the former would be valuable relative to the
latter. To put the same point in terms of evidence: plausibly, much if
not all of the value of respecting one's evidence consists in the
putative link between doing so and believing the truth. Given this,
one might worry that a view according to which perfectly following
one's evidence is compatible with a more or less completely mistaken
view of one's situation threatens to render obscure why following
one's evidence would be a good thing to do relative to the goal of
having true rather than false beliefs.</p>

<p>
 This line of thought is not decisive, however. In general, the value
of <em>x</em> might consist in its serving as a means to <em>y</em>,
even if there are conditions in which relying on <em>x</em> utterly
fails to bring about (or even frustrates the achievement of)
<em>y</em>. Thus, it might be that the value of a given drug consists
in its being the miracle cure for some disease, even though in certain
conditions the drug would have the effect of aggravating the disease.
Similarly, it might be that we value following our evidence as a means
to believing what is true, even though we recognize that there are
circumstances such that, were we unfortunate enough to be in them,
doing so would hinder or frustrate that goal.</p>

<p>
 A different tack is pursued by Williamson, who argues at length that
we should not accept the idea that one has the same evidence in the
good case and the bad case. Central to his argument is the contention
that, even if one were to adopt the phenomenal conception of evidence,
this would not allow one to vindicate the underlying intuitions that
seemed to make its adoption attractive in the first place; hence, the
phenomenal conception of evidence is ultimately not well-motivated. As
we have seen, it is the desire to preserve the intuition that a
sufficiently scrupulous thinker in the bad case can be reasonable in
his beliefs (indeed, no less reasonable than a similarly scrupulous
thinker in the good case) which seems to rule out any conception of
evidence according to which one's evidence might consist of (say) true
propositions or facts about the external world. For a thinker in the
bad case is not in a position to recognize facts about the external
world; he is, however, in a position to recognize facts about his own
experiences. The view that one's evidence is limited to one's
experiences thus seems to be motivated by the idea that one's
evidence, no matter what else is true of it, must be the sort of thing
that one is always in a position to correctly take into account, at
least in principle. But (it is claimed) one's experiences are the
things that one is always in a position to correctly take into
account. Williamson argues that this last thought is a mistake: in
fact, one is not always in a position to correctly take into account
one's experiences, even in principle. Indeed, Williamson argues that
there is <em>no</em> non-trivial condition which is such that one is
always in a position to know that it obtains.  Thus, the thought that
evidence might be such that one is always in a position to know what
one's evidence is is a chimerical one. To insist that in order for <em>x</em>
to be among one's evidence, <em>x</em> must be such that one is always in a
position to know whether one's evidence includes <em>x</em> is thus to impose a
misguided and unrealizable <em>desideratum</em> on the theory of
evidence. In short: &lsquo;<em>Whatever</em> evidence is, one is not
always in a position to know what one has of it&rsquo; (2000: 178,
emphasis added).</p>

<p>
 Having
rejected the phenomenal conception, Williamson proposes that we take a
subject's evidence to consist of all and only those propositions that
the subject
 knows.<sup>[<a href="notes.html#11" name="note-11">11</a>]</sup>
 Williamson elaborates this simple and straightforward idea with great
sophistication; here we focus exclusively on the way in which the
resulting theory interacts with the theme that rational thinkers
respect their evidence. Of course, one immediate consequence of the
view that a subject's evidence consists of his knowledge is that a
thinker in the good case and a thinker in the bad case will
differ&mdash;indeed, differ significantly&mdash;in the evidence which
they possess.  When a thinker in the good case comes to know that
<em>there is blood on the knife</em> in virtue of having a visual
experience as of blood on the knife, the relevant proposition becomes
part of his total evidence. In contrast, when a thinker in the bad
case is caused by the Demon to undergo the same experience (or at
least, an experience that is qualitatively indistinguishable) and
arrives at the same belief, the relevant proposition is not part of
his total evidence, for the relevant proposition is not true and hence
not known. Inasmuch as the scrupulous thinker in the good case will
know far more than the scrupulous thinker in the bad case, the former
will have far more evidence for his beliefs than the latter. Given
that the two thinkers have the same beliefs, it seems that the thinker
in the good case will be significantly more reasonable in holding
those
 beliefs.<sup>[<a href="notes.html#12" name="note-12">12</a>]</sup> </p>

<p>
 How much of a cost is this? We should distinguish between two
different intuitions one might have about a thinker in the bad
case. The first intuition is that a thinker in the bad case has
<em>exactly</em> the same evidence as a thinker in the good
case. Perhaps abandoning this intuition is not much of a cost (if it
is any cost at all). A different intuition is the following: when a
thinker in the bad case takes his experiences at face value and forms
beliefs about the external world in the usual manner, those beliefs
are not simply unreasonable, in the way that they would be if, for
example, the thinker adopted those same beliefs on a whim, or in the
absence of any reason to do so at all.  Abandoning this intuition
would seem to be a much heavier price to pay.  However, it is
contentious whether this intuition can be preserved on a view
according to which one's evidence consists of one's knowledge.
Consider, once again, a thinker in the bad case who is caused by the
Demon to have a visual experience as of being in the presence of a
bloodied knife. Possessing no reason to doubt that the experience is
veridical, the thinker forms the belief that <em>there is blood on the
knife</em> in the usual manner. Intuitively, this belief is at the
very least better justified than it would be in the absence of the
relevant visual experience. On the supposition that one's evidence
consists of those propositions that one knows, we can ask: what known
proposition or propositions justify this belief, to the extent that it
is justified?  The proposition that there is blood on the knife is
false and therefore not known. Perhaps the thinker's evidence for his
belief that there is blood on the knife is the true proposition that
(i) <em>it appears that there is blood on the knife</em> or the true
proposition that (ii) <em>my experience is as of there being blood on
the
 knife</em>.<sup>[<a href="notes.html#13" name="note-13">13</a>]</sup>
 However, some philosophers maintain that in typical cases of
perception, one does not form beliefs about how things appear to one,
or about how one's perceptual experience presents things as being:
rather, in response to one's experiences, one simply forms beliefs
about the external world
 itself.<sup>[<a href="notes.html#14" name="note-14">14</a>]</sup>
 If this is correct, then, given that knowledge requires belief,
propositions like (i) and (ii) are not known because they are not
believed. Hence, if this model is correct, then, on the view that
one's evidence consists only of known propositions, the thinker's
belief that there is blood on the knife seems to lack any
 justification.<sup>[<a href="notes.html#15" name="note-15">15</a>]</sup></p>

<p>
 According to the phenomenal conception of evidence, <em>only</em>
one's experiences can serve as evidence. According to Williamson's
conception of evidence as knowledge, one's experiences are excluded
from counting as evidence&mdash;at best, one's evidence includes
whatever propositions about one's experiences that one knows. Even if
one abandons the phenomenal conception of evidence, however, one might
hold on to the idea that one's evidence <em>includes</em> one's
experiences, inasmuch as one's experiences can and often do make some
difference to what one is justified in believing, regardless of
whether one forms beliefs about those experiences themselves. A view
of evidence that is more liberal than either Williamson's or the
phenomenal conception might thus take one's evidence to include both
one's experiences and one's knowledge, on the grounds that the beliefs
of a rational thinker will exhibit direct sensitivity both to what he
knows and to the experiences that he undergoes. The question of
whether one's experiences&mdash;as opposed to one's beliefs about
one's experiences, or one's knowledge of one's
experiences&mdash;can play a direct role in justifying beliefs
about the external world is a much contested one in the philosophy of
perception; it will not be pursued further here.</p>

<p>
An issue that has recently come to the fore concerns the distinction
between <em>first-order evidence</em> and <em>higher-order
evidence</em> (Christensen 2010, Feldman 2005, Kelly 2005, 2010,
Lasonen-Aarnio 2014). Intuitively, first-order evidence <i>E</i> is
evidence that bears directly on some target proposition or hypothesis
<i>H</i>. Higher-order evidence is evidence about the character
of <i>E</i> itself, or about subjects' capacities and dispositions for
responding rationally to <i>E</i>. Suppose that a trained
meteorologist carefully surveys the available meteorological data and
concludes that <em>it will rain tomorrow</em>. Here, the
meteorological data (<i>E</i>) is first-order evidence that bears on
the hypothesis (<i>H</i>), that <em>it will rain tomorrow</em>.  Now
consider the fact that <em>the meteorologist arrived at the view that
it will rain tomorrow on the basis of E</em>. This fact is
higher-order evidence, inasmuch as it is evidence about the content
and import of the original meteorological data <i>E</i>. In
particular, given that the meteorologist is generally competent when
it comes to assessing the relevant kind of evidence, the fact that she
arrived at the view that H on the basis of <i>E</i> is evidence for
the epistemic propositions that <em>E supports H</em>. Moreover, at
least in many contexts, the fact that the meteorologist arrived at the
view that <i>H</i> on the basis of <i>E</i> will count as evidence,
not only for the epistemic proposition that <em>E supports H</em>, but
also for the hypothesis itself, i.e., <em>it will rain
tomorrow</em>. This seems especially clear in cases in which a third
party lacks access to the original meteorological evidence <i>E</i>
(or is incompetent to assess that evidence) but does know that the
meteorologist arrived at the verdict that <em>it will rain
tomorrow</em> on its basis. In these circumstances, it makes sense for
the third party to increase his credence in rain tomorrow, once he
learns what the meteorologist has concluded. In effect, in these
circumstances, one treats the fact that the meteorologist arrived at
the belief that it will rain tomorrow as a kind of <em>proxy</em> for
the meteorological evidence to which one lacks access, or which one is
incompetent to assess (Kelly 2005). Here <em>evidence of evidence</em>
(for <i>H</i>) is itself evidence for <i>H</i> (Feldman 2005). The
general lesson is that higher-order evidence sometimes serves as
evidence that should make a difference not only to what one believes
about the first-order evidence, but also to one's beliefs about the
world itself.</p>

<p>
Other cases, however, are less clear-cut. For example, suppose that a
second trained meteorologist evaluates the available meteorological
data <i>E</i> and arrives at her own view about the possibility that
it will rain tomorrow. She then learns that the first meteorologist
arrived at the view that it will rain tomorrow on the basis of
evidence <i>E</i>. Should the second meteorologist count her
colleague's opinion as <em>additional</em> evidence for the hypothesis
that it will rain tomorrow? Or would doing so be in effect to engage
in a kind of illegitimate double counting of the original evidence
(Kelly 2005, Matheson 2009)? More generally, in what circumstances,
exactly, is evidence of evidence (for some proposition) evidence for
that proposition (Fitelson 2012, Feldman 2014)? Questions about the
nature and bearing of higher-order evidence are topics of active
research.</p>
   

<h2><a name="EviGuiTruEviSigSymMar">3. Evidence as a Guide to Truth: Evidence as Sign, Symptom, or Mark</a></h2>

<blockquote>
The situation in which I would properly be said to have
<em>evidence</em> for the statement that some animal is a pig is that,
for example, in which the beast itself is not actually on view, but I
can see plenty of pig-like marks on the ground outside its retreat. If
I find a few buckets of pig-food, that's a bit more evidence, and the
noises and the smell may provide better evidence still. But if the
animal then emerges and stands there plainly in view, there is no
longer any question of collecting evidence; its coming into view
doesn't provide me with more <em>evidence</em> that it's a pig, I can
now just <em>see</em> that it is.<br />
&nbsp;&nbsp;&nbsp;&mdash;J.L. Austin, <em>Sense and Sensibilia</em>
</blockquote>

<blockquote>
&lsquo;Not enough evidence God! Not enough evidence!&rsquo;<br />
&nbsp;&nbsp;&nbsp;&mdash;Bertrand Russell, upon being asked what he
would reply if, after dying, he were brought into the presence of God
and asked why he had not been a believer
</blockquote>

<p>
 If <em>E</em> is evidence for some hypothesis <em>H</em>, then
<em>E</em> makes it more likely that <em>H</em> is true: in such
circumstances, <em>E</em> <em>confirms</em> <em>H</em>. On the other
hand, if <em>E</em> is evidence against <em>H</em>, then <em>E</em>
makes it less likely that <em>H</em> is true: <em>E</em>
<em>disconfirms</em> <em>H</em>. <em>Verification</em> is the limiting
case of confirmation: a piece of evidence verifies a hypothesis in
this sense just in case it conclusively establishes that hypothesis as
true. At the other end of the spectrum, <em>falsification</em> is the
limiting case of disconfirmation: a piece of evidence falsifies a
hypothesis just in case it conclusively establishes that the
hypothesis is false. It is at least somewhat controversial whether
full-fledged verification or falsification in this sense ever
 occurs.<sup>[<a href="notes.html#16" name="note-16">16</a>]</sup></p>

<p>
 Plausibly, there are some propositions whose truth or falsity we
grasp in an utterly direct, unmediated way. Consider, for example,
simple arithmetical truths such as the proposition that
2+2=4. Traditionally, such truths have been held to be
&lsquo;self-evident&rsquo;; allegedly, they need only to be understood
in order to be known. If the truth value of every proposition were
transparent in this way, perhaps we would have little or no need for
evidence. In contrast, a central function of evidence is to make
evident that which would not be so in its absence.</p>

<p>
 In general, we rely on evidence in cases in which our access to truth
would otherwise be problematic. One's recognition that <em>the earth
is roughly spherical in shape</em> seems to depend on one's evidence
in a way that one's recognition that 2+2=4 does not. Of course, it can
be a contested matter whether one's access to truth in some domain is
problematic&mdash;and thus, whether one is dependent upon evidence for
grasping truths about that domain. Common sense holds that we often
have unproblematic access to facts about our immediate physical
environment <em>via</em> sense perception; perhaps in part for this
reason, common sense regards it as at the very least odd, if not
simply wrong, to say that one who finds himself face-to-face with what
is clearly a pig thereby has strong <em>evidence</em> that the animal
is a pig. (Although it would no doubt also be odd to assert that one
<em>lacks</em> evidence that the animal is a pig in such
circumstances.) In contrast, much traditional epistemology holds that
one's access to such truths is always deeply problematic; what is
unproblematic, rather, is one's recognition that one's experiences
represent the world as being a certain way. Hence, much traditional
epistemology construes the relationship between one's experiences and
one's beliefs about the physical world on the model of the
relationship between evidence and hypothesis. On this model, the
fallibility of sense perception is assimilated to the fallibility of
non-deductive inference. (The above quotation from Austin is, of
course, a protest against the model in question.)</p>

<p>
 As a general matter, evidence seems to play a <em>mediating</em>
role vis-a-vis our efforts to arrive at an accurate picture of the
world: we seek to believe what is true by means of holding beliefs that
are well-supported by the evidence, and we seek to avoid believing what
is false by means of not holding beliefs that are not well-supported by
the evidence. The picture is well summarized by Blanshard:</p>

<blockquote>
 &lsquo;Surely the only possible rule&rsquo;, one may say, &lsquo;is
to believe what is true and disbelieve what is false.&rsquo; And of
course that would be the rule if we were in a position to know what
was true and what false. But the whole difficulty arises from the fact
that we do not and often cannot. What is to guide us then?&hellip; The
ideal is believe no more, but also no less, than what the evidence
warrants (1974: 410&ndash;411).
 </blockquote>

<p>
 Indeed, it is plausible to suppose that both the capacity of evidence
to justify belief (Section 1) and the fact that rational thinkers
respect their evidence (Section 2) depends upon the connection between
evidence and truth.</p>

<p>
 Why should attending to evidence constitute a
promising way of pursuing an accurate view of the world? This question
is more readily answered on some conceptions of evidence than on
others. Thus, consider a theory according to which evidence consists of
<em>facts</em>. Given that no true proposition is inconsistent with any
fact, one has an immediate rationale for not believing any proposition
that is inconsistent with one's evidence, for only propositions that
are consistent with one's evidence are even candidates for being true.
The same holds for Williamson's conception of evidence as knowledge:
inasmuch as any known proposition is true, inconsistency with one's
evidence entails inconsistency with some truth. Put the other way
around: if evidence consists of facts or known propositions, then no
body of evidence rules out any truth. Notice that the same is not true
for conceptions of evidence according to which one's evidence consists
of one's beliefs, or one's experiences, or propositions of which one is
psychologically certain: that a proposition is inconsistent with one of
my beliefs, or with the content of one of my experiences, or with a
proposition of which I am psychologically certain, does not guarantee
that it is false.</p>

<p>
 Perhaps the root notion of evidence is that of something which serves
as a reliable sign, symptom, or mark of that which it is evidence
<em>of</em>. In Ian Hacking's phrase, this is &lsquo;the evidence of
one thing that points beyond itself&rsquo; (1975: 37). Thus, smoke is
evidence of fire, Koplik spots evidence of measles, a certain
distinctive and off-putting smell evidence of rotten egg. Here, the
paradigm would seem to be that of straightforward correlation: the
reason why smoke counts as evidence of fire, but not of impending
rain, is that smoke is a reliable indicator or symptom of the former
but not of the latter. Taken at face value, the idea of evidence as
reliable indicator tends to encourage an inclusive picture of what
sorts of things are eligible to count as evidence, according to which
either mental or non-mental objects, events and states of affairs can
qualify as such. For such entities would seem to be perfectly capable
of standing in the relevant relation to other objects, events and
states of affairs.</p>

<p>
 Consider the claim that</p>

<blockquote>
 (1) Koplik spots are evidence of measles.
</blockquote>

<p>
 On what is perhaps its most natural reading, the truth of this claim
was an empirical discovery of medical science. At a certain point in
time, it was discovered that Koplik spots are a reliable indication of
measles&mdash;something which was true, presumably, long before
the discovery in question. Here, the evidence relation is understood
as a relation that either obtains or fails to obtain independently of
what anyone knows or believes about its
 obtaining.<sup>[<a href="notes.html#17" name="note-17">17</a>]</sup>
 To the extent that one is concerned to arrive at an accurate picture
of the world, knowledge of instances of this relation&mdash;roughly,
knowledge of what bits of the world tend to accompany what other bits
of the world&mdash;would seem to be exactly the sort of thing which
one is seeking.  When the evidence relation is construed in this way,
investigating it is of a piece with investigating the world
itself.</p>

<p>
 Similarly </p>

<blockquote>
 (2) Smoke is evidence of fire
</blockquote>

<p> 
 would seem to have the same empirical status as (1), differing
chiefly in that it is much more widely known. </p>

<p>
 When evidence is understood in this way, it is no mystery why
attending to evidence is a good strategy for one who is concerned to
arrive at an accurate picture of the world: given that Koplik spots
are in fact a reliable indicator of measles, it obviously behooves
those who are concerned to have true beliefs about which individuals
are suffering from measles to pay attention to facts about which
individuals have Koplik spots. Similarly, given that smoke is in fact
a reliable indicator of fire, those who are concerned to have true
beliefs about the presence or absence of fire do well to pay attention
to the presence or absence of smoke. Thus, when we understand
&lsquo;<em>E</em> is evidence for <em>H</em>&rsquo; as more or less
synonymous with &lsquo;<em>E</em> is a reliable indicator of
<em>H</em>&rsquo;, the connection between evidence and truth seems
easily secured and relatively straightforward. </p>

<p>
 Of course, although the presence of Koplik spots is in fact a
reliable guide to the presence of measles, one who is ignorant of this
fact is not in a position to conclude that a given patient has
measles, even if he or she is aware that the patient has Koplik
spots. Someone who knows that Koplik spots are evidence of measles is
in a position to diagnose patients in a way that someone who is
ignorant of that fact is not. In general, the extent to which one is
in a position to gain new information on the basis of particular
pieces of evidence typically depends upon one's background
knowledge. This fact is a commonplace among philosophers of science
and has also been emphasized by philosophically-sophisticated
 historians.<sup>[<a href="notes.html#18" name="note-18">18</a>]</sup></p>

<p>
 Suppose that one knows that a particular patient has Koplik spots but
is ignorant of the connection between Koplik spots and
measles. Moreover, suppose that one's ignorance is not itself the
result of any prior irrationality or unreasonableness on one's part:
rather, one has simply never had the opportunity to learn about the
connection between Koplik spots and measles. In these circumstances,
does one have evidence that the patient has measles? Taken in one
sense, this question should be answered affirmatively: one does have
evidence that the patient has measles, although one is not in a
position to recognize that one does.  However, the idea that one has
evidence in such circumstances seems to sit somewhat awkwardly with
the themes that evidence tends to justify belief, and that rational
thinkers are sensitive to their evidence. For consider the moment when
one first learns that the patient has Koplik spots. Given one's
ignorance of the connection between Koplik spots and measles, one is
not in any way unreasonable if one fails to become more confident that
the patient has measles. Indeed, given one's ignorance, it seems that
one would be unreasonable if one <em>did</em> become more confident
that the patient has measles upon learning that she has Koplik spots,
and that a belief that the patient has measles held on this basis
would be unjustified.</p>

<p>
 This suggests that the notion of evidence in play in statements such
as &lsquo;evidence tends to justify belief&rsquo; and &lsquo;rational
thinkers respect their evidence&rsquo; cannot simply be identified
with evidence in the sense of reliable indicator.  Let's call evidence
in the former sense <em>normative</em> evidence, and evidence in the
latter sense <em>indicator</em> evidence.  Although the normative
notion of evidence cannot simply be identified with the indicator
notion, we would expect the two to be closely linked, inasmuch as
one's possession of normative evidence frequently depends upon one's
awareness that one thing is indicator evidence of something else.</p>

<p>
 Reflection on the role that considerations of background theory play
in determining how it is reasonable for one to respond to new
information have convinced some that the normative notion of evidence
is better understood in terms of a three place-relation rather than a
two-place relation. According to this view, judgements of the form
&lsquo;<em>E</em> is evidence for <em>H</em>&rsquo;&mdash;when this is
understood as more or less synonymous with &lsquo;<em>E</em> tends to
make it more reasonable to believe <em>H</em>&rsquo;&mdash; are
typically elliptical for judgements of the form &lsquo;<em>E</em> is
evidence for <em>H</em> relative to background theory
<em>T</em>&rsquo;. Thus, given that your background theory includes
the claim that Koplik spots are a reliable indication of measles, the
fact that a particular patient has Koplik spots constitutes normative
evidence for you (gives you a reason to believe that) the patient has
measles. On the other hand, given that my background theory does
<em>not</em> include the claim that Koplik spots are a reliable
indication of measles, the fact that the same patient has Koplik spots
does <em>not</em> constitute normative evidence for me (give me a
reason to believe that) the patient has measles.</p>

<p>
 The view that the status of <em>E</em> as normative evidence for
<em>H</em> can depend upon considerations of background theory
immediately raises questions about the status of the background theory
itself. Given that one's background theory consists of some set of
propositions, which set is it? Is it the set of propositions that one
knows? Or rather, the set of propositions that one believes? Or
perhaps, the set of propositions that one <em>justifiably</em>
believes? It seems that <em>E</em> might count as evidence for
<em>H</em> relative to the set of propositions that one believes but
not relative to the set of propositions that one knows (or vice
versa)&mdash;which of these, if either, determines whether <em>E</em>
is evidence for <em>H</em>, in the sense that one's possession of
<em>E</em> tends to justify one in believing that <em>H</em> is true?
The issues that arise here are subtle and delicate; Christensen (1997)
is a careful and illuminating discussion.</p>

<p>
 <em>A note about confirmation theory</em>.  Although philosophy had
in some sense long been concerned with questions about when evidence
makes a theory more likely to be true, the investigation of this
relationship reached new levels of systematicity and rigor during the
positivist era. The positivists thought of philosophy as &lsquo;the
logic of science&rsquo;; they thus took it to be a central task of
philosophy to furnish detailed analyses and explications of
fundamental scientific concepts such as explanation and
confirmation.</p>

<p>
 Hempel (1945) and Carnap (1950) each distinguished two different
&lsquo;concepts&rsquo; of confirmation: the
&lsquo;classificatory&rsquo; or &lsquo;qualitative&rsquo; concept on
the one hand and the &lsquo;quantitative&rsquo; concept on the
other. Roughly, the classificatory concept is employed in the making
of yes-or-no judgements about whether a given piece of evidence does
or does not support a given hypothesis.  Thus, it is the
classificatory concept which is in play when one is concerned with
judgements of the following form: &lsquo;Hypothesis <em>H</em> is
confirmed by evidence <em>E</em>&rsquo;. On the other hand, the
quantitative concept is employed in making numerical judgements about
<em>how much</em> support a hypothesis derives from a given piece of
evidence (e.g,. &lsquo;Hypothesis <em>H</em> is confirmed by evidence
<em>E</em> to degree
 <em>R</em>&rsquo;).<sup>[<a href="notes.html#19" name="note-19">19</a>]</sup>
 Formal theories attempting to explicate each of these notions were
developed. Hempel (1945) took the lead in attempting to explicate the
qualitative concept while Carnap (1950, 1952) concentrated on the
quantitative concept. During this period, the philosophical study of
the relationship between evidence and theory took on, perhaps for the
first time, the characteristics of something like normal science, and
became a discipline replete with technical problems, puzzles, and
paradoxes, the anticipated solutions to which were viewed as items on
the agenda for future
 research.<sup>[<a href="notes.html#20" name="note-20">20</a>]</sup>
 Here lie the origins of present-day confirmation theory, as
represented by Bayesianism in its protean forms (See, e.g., Jeffrey
1965, 1992, 2004, Horwich 1983, Howson and Urbach 1993) and its rivals
(e.g., Glymour's (1980) &lsquo;bootstrapping&rsquo; model of
confirmation).</p>

<p>
 Although Carnap's own vision for confirmation theory was ultimately
 abandoned,<sup>[<a href="notes.html#21" name="note-21">21</a>]</sup>
 the quantitative approach that he championed proved influential to
the subsequent development of the subject. In particular, the emphasis
on attempting to understand confirmation in quantitative terms paved
the way for the increased use of mathematics&mdash;and
specifically, the probability calculus&mdash;in the philosophical
study of evidence. The idea that the probability calculus provides the
key to understanding the relation of confirmation is central to
Bayesianism, the dominant view within contemporary confirmation
theory. An examination of Bayesianism will not be undertaken
 here.<sup>[<a href="notes.html#22" name="note-22">22</a>]</sup>
 Instead, we will simply take note of the explication of the concept
of evidence which the Bayesian offers. At the outset of the present
section, we noted that evidence confirms a theory just in case that
evidence makes the theory more likely to be true; evidence disconfirms
a theory just in case the evidence renders the theory less likely to
be true. The Bayesian takes these platitudes at face value and offers
the following probabilistic explication of what it is for <em>E</em>
to be evidence for <em>H</em>: </p>

<blockquote>
 <em>E</em> is evidence for <em>H</em> if and only if
Prob(<em>H</em>/<em>E</em>) &gt; 
 Prob(<em>H</em>).<sup>[<a href="notes.html#23" name="note-23">23 </a>]</sup>
 </blockquote>

<p>
 That is, <em>E</em> is evidence for <em>H</em> just in case the
conditional probability of <em>H</em> on <em>E</em> is greater than
the unconditional probability of <em>H</em>. Thus, the fact that
<em>the suspect's blood is on the knife</em> is evidence for the
hypothesis that <em>the suspect committed the murder</em> if and only
if the probability that the suspect committed the murder is greater
given that his blood is on the knife than it would be otherwise.</p>

<p>
 Similarly </p>

<blockquote>
 <em>E</em> is evidence against <em>H</em> if and only if
Prob(<em>H</em>/<em>E</em>) &lt; Prob(<em>H</em>).
 </blockquote>

<p>
 That is, <em>E</em> is evidence against <em>H</em> just in case the
conditional probability of <em>H</em> on <em>E</em> is less than the
unconditional probability of <em>H</em>. Thus, the fact that <em>the
suspect's fingerprints are not on the knife</em> is evidence against
the hypothesis that <em>the suspect committed the murder</em> if and
only if the probability that the suspect committed the murder is lower
given the absence of his fingerprints on the knife than it would be
otherwise. Within this probabilistic model, verification (in the sense
of conclusive confirmation) would involve bestowing probability 1 on
an hypothesis while falsification would involve bestowing probability
0 on it.</p>

<p>
 This straightforward probabilistic model of evidence and confirmation
is an attractive and natural one. Indeed, hints of it are found in
Anglo-American
 law.<sup>[<a href="notes.html#24" name="note-24">24</a>]</sup>
 The model is not without its critics, however. Achinstein (1983)
contends that something can increase the probability of a claim
without providing evidence for that claim. For example, the
information that seven-time Olympic swimming champion Mark Spitz went
swimming increases the probability that Mark Spitz has just drowned;
nevertheless, according to Achinstein, the former hardly constitutes
evidence that the latter is
 true.<sup>[<a href="notes.html#25" name="note-25">25</a>]</sup>
 According to a line of thought in Goodman (1955), the notion of
confirmation that is crucial for science is not to be understood in
terms of straightforward increase-in-probability. Thus, consider the
generalization that <em>All of the change in my pocket consists of
nickels</em>.  Examining one of the coins in my pocket and finding
that it is a nickel undoubtedly increases the probability that the
generalization is true, inasmuch as it now has one less potential
falsifier. But Goodman contends the relevant observation does not
confirm the generalization, inasmuch as the observation should not
make one more confident that any of the other, as-yet-unexamined coins
in my pocket is itself a nickel.  (According to Goodman, although
&lsquo;accidental generalizations&rsquo; such as &lsquo;All the coins
in my pockets are nickels&rsquo; can have their probabilities raised
by observations, they cannot be confirmed by them, in the way that
&lsquo;law-like generalizations&rsquo; can be.)</p>

<p>
 In general, the idea
that the probability calculus provides the key to understanding the
concept of evidence has found greater favor among philosophers of
science than among traditional epistemologists. In the next and final
section, we turn to a cluster of themes that have also been much
emphasized by philosophers of science, themes which came to the fore as
a result of philosophical reflection upon the role that evidence plays
within scientific practice itself.</p>

<h2><a name="ObjPubIntEviNeuArb">4. Objectivity, Publicity, and Intersubjectivity: Evidence as Neutral Arbiter</a></h2>

<blockquote>
What is creditable &hellip; is not the mere belief in this or that,
but the having arrived at it by a process which, had the evidence been
different, would have carried one with equal readiness to a contrary
belief.<br />
&nbsp;&nbsp;&nbsp;&mdash;Blanshard, <em>Reason and Belief</em>
</blockquote>

<p>
 It is natural to suppose that the concept of evidence is intimately
related to the cognitive desideratum of <em>objectivity</em>.
According to this line of thought, individuals and institutions are
objective to the extent that they allow their views about what is the
case or what ought to be done to be guided by the evidence, as opposed
to (say) the typically distorting influences of ideological dogma,
prejudice in favor of one's kin, or texts whose claim to authority is
exhausted by their being venerated by tradition. To the extent that
individuals and institutions are objective in this sense, we should
expect their views to increasingly converge over time: as shared
evidence accumulates, consensus tends to emerge with respect to
formerly disputed questions. Objective inquiry is evidence-driven
inquiry, which makes for intersubjective agreement among
 inquirers.<sup>[<a href="notes.html#26" name="note-26">26</a>]</sup>
 Thus, it is widely thought that the reason why the natural sciences
exhibit a degree of consensus that is conspicuously absent from many
others fields is that the former are evidence-driven&mdash;and therefore,
objective&mdash;in ways that the latter are not. </p>

<p>
 According to this picture, a central function of evidence is to serve
as a <em>neutral arbiter</em> among rival theories and their
adherents. Whatever disagreements might exist at the level of theory,
if those who disagree are objective, then the persistence of their
disagreement is an inherently fragile matter, for it is always hostage
to the emergence of evidence which decisively resolves the dispute in
one direction or the other. Our ability to arrive at consensus in such
circumstances is thus constrained only by our resourcefulness and
ingenuity in generating such evidence (e.g., by designing and
executing crucial experiments) and by the generosity of the world in
offering it up.</p>

<p>
 The slogan &lsquo;the priority of evidence to theory&rsquo; has
sometimes been employed in an attempt to capture this general
theme. However, this slogan has itself been used in a number of
importantly different ways that it is worth pausing to
distinguish. </p>

<p>
 First, the claim that &lsquo;evidence is prior to theory&rsquo; might
suggest a simple model of scientific method that is often associated
(whether fairly or unfairly) with Francis Bacon. According to the
model in question, the collection of evidence is <em>temporally
prior</em> to the formulation of any theory or theories of the
relevant domain. That is, the first stage in any properly-conducted
scientific inquiry consists in gathering and classifying a large
amount of data; crucially, this process is in no way guided or aided
by considerations of theory. Only after a large amount of data has
been gathered and classified does the scientist first attempt to
formulate some theory or theories of the domain in question. On this
model, then, evidence is prior to theory within the <em>context of
discovery</em>. This model&mdash;which Hempel (1966) dubbed &lsquo;the
narrow inductivist account of scientific inquiry&rsquo;&mdash;is now
universally rejected by philosophers. For it is now appreciated that,
at any given time, which theories are accepted&mdash;or more weakly,
which theories are taken to be plausible hypotheses&mdash;typically
plays a crucial role in guiding the subsequent search for evidence
which bears on those theories. Thus, a crucial experiment might be
performed to decide between two rival theories <em>T</em><sub>1</sub>
and <em>T</em><sub>2</sub>; once performed, the outcome of that
experiment constitutes an expansion in the total evidence which is
subsequently available to the relevant scientific community. If,
however, the two leading contenders had been theories
<em>T</em><sub>1</sub> and <em>T</em><sub>3</sub>, a different crucial
experiment would have been performed, which would have (typically)
resulted in a different expansion in the total evidence. The point
that the formulation of hypotheses is often temporally prior to the
collection of evidence which bears on their truth (and that this
priority is no accident) is perhaps most immediately apparent on
Popper's falsificationist model of science (1959), according to which
exemplary scientific practice consists in repeatedly attempting to
falsify whichever theory is presently most favored by the relevant
scientific community. But it is no less true on other, less radical
models of science, which (unlike Popper's) allow a role for confirming
evidence as well as disconfirming evidence. As Hempel puts the
point,</p>

<blockquote>
 In sum, the maxim that data should be gathered without guidance by
antecedent hypotheses about the connections among the facts under
study is self-defeating, and it is certainly not followed in
scientific inquiry.  On the contrary, tentative hypotheses are needed
to give direction to a scientific investigation. Such hypotheses
determine, among other things, what data should be collected at a
given point in a scientific investigation (1966,
 p. 13).<sup>[<a href="notes.html#27" name="note-27">27</a>]</sup>
 </blockquote>
	
<p>
 A second, quite different, sense of &lsquo;priority&rsquo; in which
evidence has sometimes been held to be prior to theory is that of
<em>semantic</em> priority. According to this view, the meanings of
hypotheses that involve &lsquo;theoretical terms&rsquo; (e.g.,
&lsquo;electron&rsquo;) depend upon the connections between such
hypotheses and that which would count as evidence for their
truth&mdash;typically on such accounts, the observations that would
confirm them. The view that (observational) evidence is semantically
prior to theories was central to the logical positivist conception of
science. On this picture, meaning flows upward from the level of
observation; a given theory is imbued with whatever meaning it has in
virtue of standing in certain relations to the observational level,
which constitutes the original locus of meaning. The picture was
gradually abandoned, however, in the face of repeated failures to
carry through the kind of theoretical reductions that the picture
seemed to demand, as well as appreciation of the point, forcefully
emphasized by
 Putnam<sup>[<a href="notes.html#28" name="note-28">28</a>]</sup>
 and others, that the meanings of
theoretical terms do not seem to change as our views about what counts
as confirming evidence for hypotheses in which they occur evolve.</p>

<p>
 A third and final sense of &lsquo;priority&rsquo; in which evidence
has often been thought to be prior to theory is that of
<em>epistemic</em> priority. On this view, it is not that the task of
evidence gathering either is or ought to be performed earlier in time
than the task of formulating theories; nor is semantic priority at
issue. Rather, the thought is that theories depend for their
justification on standing in certain relations to evidence (understood
here, once again, as that which is observed), but that observations do
not themselves depend upon theories for their own justification. That
is: (observational) evidence is prior to theory within the <em>context
of justification</em>. This, perhaps, is the interpretation of
&lsquo;evidence is prior to theory&rsquo; on which the slogan enjoys
its greatest plausibility. For it seems that our justification for
believing any presently-accepted theory of natural or social science
typically does depend upon suitable observations having been made, but
that, on the other hand, one can be justified in taking oneself to
have observed that <em>such-and-such is the case</em> even if there is
at present no available theory as to <em>why</em> such-and-such is the
case (and indeed, even if such-and-such's being the case is unexpected
or unlikely given the theories that one presently accepts). To the
extent that such a justificational asymmetry exists, there would seem
to be some truth to the idea that evidence is epistemically prior to
 theory.<sup>[<a href="notes.html#29" name="note-29">29</a>]</sup>
 And this sort of priority might seem to be exactly what is required
if evidence is to play the role of neutral arbiter among those who
come to the table with different theoretical commitments.</p>

<p>
 The idea of evidence as a kind of ultimate court of appeal, uniquely
qualified to generate agreement among those who hold rival theories,
is a highly plausible one. Nevertheless, complications with this
simple picture&mdash;some more serious than
others&mdash;abound. Above, we took note of the widely-held view
according to which the bearing of a given piece of evidence on a given
hypothesis depends on considerations of background theory. Thus, two
individuals who hold different background theories might disagree
about how strongly a particular piece of evidence confirms a given
theory, or indeed, about whether the evidence confirms the theory at
all. Of course, if the question of who has the superior background
theory is itself susceptible to rational adjudication, then this
possibility need pose no deep threat to objectivity. Often enough,
this will be the case. Suppose, for example, that you treat the fact
that </p>

<blockquote>
(i) the patient has Koplik spots on her skin
 </blockquote>

<p>as evidence that</p>

<blockquote>
 (ii) the patient has measles
 </blockquote>

<p>
 while I do not, simply because you know that Koplik spots are
typically an effect of measles while I am ignorant of this fact. Here,
that you treat (i) as evidence for (ii) while I do not is attributable
to the straightforward superiority of your background theory to mine:
you possess a crucial piece of medical knowledge that I
lack. Presumably, if I were to acquire the relevant bit of medical
knowledge, then I too would treat (i) as confirming evidence for
(ii). The possibility that those who are relatively ill-informed might
differ from those who are better informed in the way that they respond
to evidence does not itself cast doubt on the capacity of evidence to
play the role of neutral arbiter among theories; clearly, what is
needed in such cases is for the worse informed party to become privy
to those facts of which they are presently ignorant. </p>

<p>
 However, a recurrent motif in twentieth century philosophy of science
is that the bearing of evidence on theory is mediated by factors that
might vary between individuals in ways that do not admit of such
rational adjudication. Imagine two eminent scientists, both of whom
are thoroughly acquainted with <em>all</em> of the available evidence
which bears on some theory. One believes the theory, the other
believes some different, incompatible theory instead.  Must one of the
two scientists be making a mistake about what their shared evidence
supports? Perhaps the most natural answer to this question, at least
at first blush, is &lsquo;Yes&rsquo;. A fair amount of twentieth
century philosophy of science shied away from this natural answer,
however, at least in part because of a growing awareness of just how
often eminent, fully-informed and <em>seemingly</em> rational
scientists have disagreed in the history of
 science.<sup>[<a href="notes.html#30" name="note-30">30</a>]</sup>
 Thus, Thomas Kuhn (1962) would maintain that both scientists might be
perfectly rational in holding incompatible theories, inasmuch as
rationality is relative to a paradigm, and the two scientists might be
operating within different paradigms. Similarly, Carnap (1952) would
maintain that both scientists might be rational because rationality is
relative to an inductive method or confirmation function, and the two
scientists might be employing different inductive methods or
confirmation functions. As we have noted, for the contemporary
Bayesian, how it is reasonable to respond to a given body of evidence
depends upon one's prior probability distribution: the two scientists
might thus both be rational in virtue of possessing different prior
probability distributions. There are, of course, important differences
among these accounts of rationality. But notice that they each possess
the same structure: what it is reasonable for one to believe depends
not only on one's total evidence but also on some further feature
<em>F</em> (one's prior probability distribution, paradigm, inductive
method.).  Because this further feature <em>F</em> can vary between
different individuals, even quite different responses to a given body
of evidence might be equally reasonable. On such views, the bearing of
a given body of evidence on a given theory becomes a highly
relativized matter. For this reason, the capacity of evidence to
generate agreement among even impeccably rational individuals is in
principle subject to significant limitations. </p>

<p>
 Why is relativity to a prior probability
distribution (paradigm, inductive method) any more threatening to the
idea of evidence as neutral arbiter than the previously mentioned
relativity to background theory? The difference is this: when I fail to
treat Koplik spots as evidence of measles, there is a clear and
straightforward sense in which my background theory is inferior to
yours. By contrast, proponents of the views presently under
consideration typically insist that a relatively wide range of prior
probability distributions (confirmation functions, inductive methods,
paradigms) might be <em>equally good</em>. For this reason, such views
are often criticized on the grounds that they turn the relationship
between evidence and theory into an overly subjective affair.</p>

<p>
 Proponents of such views are not wholly without resources for
attempting to alleviate this concern. In particular, many subjective
Bayesians place great weight on a phenomenon known as the
&lsquo;swamping&rsquo; or &lsquo;washing out&rsquo; of the
priors. Here, the idea is that even individuals who begin with quite
different prior probabilities will tend to converge in their views
given subsequent exposure to a sufficiently extensive body of common
evidence. However, the significance of the relevant convergence
results is highly
 controversial.<sup>[<a href="notes.html#31" name="note-31">31</a>]</sup> </p>

<p>
 According to the accounts briefly canvassed here, two individuals of
impeccable rationality might radically disagree about the bearing of a
particular piece of evidence <em>E</em> on a given hypothesis
<em>H</em>. Even in such cases, the disputants are not wholly without
common ground. For they at least agree about the characterization of
the evidence <em>E</em>: their disagreement concerns rather the
probative force of <em>E</em> with respect to <em>H</em>. An even more
radical challenge to the capacity of evidence to serve as neutral
arbiter among rival theories concerns the alleged <em>theory-ladenness
of observation</em>.  According to proponents of the doctrine of
theory-ladenness, in cases of fundamental theoretical dispute, there
will typically be no theoretically-neutral characterization of the
evidence available.  Rather, adherents of rival theories will
irremediably differ as to the appropriate description of the
 data itself.<sup>[<a href="notes.html#32" name="note-32">32</a>]</sup> </p>

<p>
 The doctrine of theory-ladenness is perhaps best appreciated when it
is viewed against the background of the positivist tradition to which
it was in large part a reaction. For the positivists, evidence was
both epistemically and semantically prior to theory. Moreover, central
to the positivist conception of science as a paradigm of rationality
and objectivity is the idea that its disputes admitted of rational
adjudication by appeal to evidence that could be appreciated by both
sides. For these reasons, the positivists often insisted that the
fundamental units of evidential significance&mdash;observation
statements or &lsquo;protocol sentences&rsquo;&mdash;should employ
only vocabulary that is within the idiolect of any minimally competent
speaker of the relevant language.  Ideally then, observation
statements should be comprehensible to and verifiable by individuals
who possess no specialized knowledge or terminological
sophistication. Thus, Carnap recommended &lsquo;blue&rsquo; and
&lsquo;hard&rsquo; as exemplary predicates for observation
 sentences.<sup>[<a href="notes.html#33" name="note-33">33</a>]</sup>
 As against this, Hanson insisted that</p>

<blockquote>
 &hellip; the layman simply cannot see what the physicist sees
&hellip; when the physicist looks at an X-ray tube, he sees the
instrument in terms of electrical circuit theory, thermodynamic
theory, the theories of metal and glass structure, thermionic
emission, optical transmission, refraction, diffraction, atomic
theory, quantum theory and special relativity (1961:19).
 </blockquote>
	
<p>
 But what holds for the physicist and the layman holds also for two
physicists with sufficiently different theoretical
commitments. Thus</p>

<blockquote>
 To say that Tycho and Kepler, Simplicius and Galileo, Hooke and
Newton, Priestly and Lavoisier, Soddy and Einstein, De Broglie and
Born, Heisenberg and Bohm all make the same observations but use them
differently is too easy. This parallels the too-easy epistemological
doctrine that all normal observers see the same things in <em>x</em>, but
interpret them differently. It does not explain controversy in
research science (1961:13).
 </blockquote>

<p>
 The extent to which observation is theory-laden remains a contested
 matter.<sup>[<a href="notes.html#34" name="note-34">34</a>]</sup>
 To the extent that evidence which bears on a theory does not admit of
a neutral characterization among those with sufficiently different
theoretical commitments, this threatens to limit the ability of such
evidence to successfully discharge the role of neutral arbiter in such
cases. Still, whatever concessions to the proponents of
theory-ladenness might be in order, the significance of the doctrine
that they defend should not be overstated. For in any case, it seems
undeniable that theories sometimes are discredited by the emergence of
evidence which is taken to undermine them&mdash;even in the eyes
of their former
 proponents.<sup>[<a href="notes.html#35" name="note-35">35</a>]</sup>
 Let's assume then that evidence sometimes does successfully discharge
the function of neutral arbiter among theories and is that which
secures intersubjective agreement among inquirers. What must evidence
be like, in order for it to play this role? That is, given that
evidence sometimes underwrites intersubjective agreement, what
constraints does this place on answers to the question: what sorts of
things are eligible to count as evidence?</p>

<p>
 Above, we noted that the traditional epistemological demand that
one's evidence consist of that to which one has immediate and
unproblematic access&mdash;and indeed, that one's evidence must be
such that one can appreciate it (at least it in principle) even when
one is in the most dire of epistemic predicaments&mdash;has often
encouraged a phenomenal conception of evidence, according to which
one's evidence is limited to one's experiences or sense data. On this
picture, evidence consists of essentially private mental states,
accessible only to the relevant subject. This picture of evidence
stands in no small measure of tension with the idea that a central
function of evidence is to serve as a neutral arbiter among competing
views. For it is natural to think that the ability of evidence to play
this latter role depends crucially on its having an
essentially <em>public</em> character, i.e., that it is the sort of
thing which can be grasped and appreciated by multiple
individuals. Here, the most natural contenders would seem to be
physical objects and the states of affairs and events in which they
participate, since it is such entities that are characteristically
accessible to multiple observers. (I ask what evidence there is for
your diagnosis that the patient suffers from measles; in response, you
might simply <em>point to</em> or <em>demonstrate</em> the lesions on
her skin.) On the other hand, to the extent that one's evidence
consists of essentially private states there would seem to be no
possibility of sharing one's evidence with others. But it is precisely
the possibility of sharing relevant evidence which is naturally
thought to secure the objectivity of science. Indeed, it has often
been held that inasmuch as the objectivity of science is underwritten
by the fact that science is evidence driven, it is the public
character of scientific evidence which is crucial. On this view, it is
a central methodological norm of science to eschew as inadmissible
(e.g.) any alleged episodes of incommunicable insight in considering
whether to accept or reject a claim. The theme of the essentially
public character of scientific evidence has been prominent from the
earliest days of modern science&mdash;it was championed, for example,
by Robert Boyle, founder of the Royal Society, who insisted that the
&lsquo;witnessing&rsquo; of experiments was to be a collective
 act<sup>[<a href="notes.html#36" name="note-36">36</a>]</sup>&mdash;and
 has remained so up until the present day. Unsurprisingly, the theme
was taken up by philosophers of science with gusto. Thus, Hempel
required that &lsquo;all statements of empirical science be capable of
test by reference to evidence which is public, i.e., evidence which
can be secured by different observers and does not depend essentially
on the observer&rsquo; (1952: 22). The idea was echoed by other
leading positivists (see, e.g., Feigl 1953) as well as by Popper
(1959). More recently, in the course of reviewing &lsquo;some of the
things objectivity, and specifically scientific objectivity, has been
thought to involve&rsquo;, Peter Railton singles out the idea that
</p>

<blockquote>
 &hellip; objective inquiry uses procedures that are intersubjective
and independent of particular individuals and circumstances&mdash;for
example &hellip; it makes no essential use of introspective or
subjectively privileged evidence in theory assessment (1985: 764).
 </blockquote>

<p>
 In short, it is not simply that the conception of evidence gleaned
from exemplary scientific practice differs from the conception of
evidence that traditional epistemology seemed to demand (as would be
the case if, for example, one was somewhat more inclusive than the
other). Rather, what seemed to be one of the characteristic features
of scientific evidence, viz. its potential publicity, is the exact
<em>contrary</em> of one of the characteristic features of evidence as
construed by much traditional epistemology, viz. its privacy. Such a
tension was bound to generate a certain amount of dissonance. One
historically noteworthy manifestation of this dissonance was the
protracted debate within the positivist tradition over the nature of
&lsquo;protocol sentences&rsquo;. Here, Carnap's odyssey is perhaps
the most illuminating. Early in his philosophical career, Carnap,
under the influence of Russell and Ernst Mach (and through them, the
tradition of classical empiricism) took sense data as the ultimate
evidence for all of our empirical knowledge.  (Indeed, his early work
<em>Der Logischer Aufbau der Welt</em> (1928) is largely devoted to
the Russellian project of &lsquo;constructing&rsquo; the external
world out of sense data.) During this period, Carnap maintained that
the protocol sentences that serve as the &lsquo;confirmation
basis&rsquo; for scientific theories refer to sense data or (to be
more precise) &lsquo;the sensing of sense data&rsquo;. However, under
the influence of both Popper and Otto Neurath, Carnap ultimately
abandoned this view of protocol sentences in favor of one on which
such sentences refer not to private mental events but rather to public
objects and states of affairs. As recounted in his philosophical
autobiography, the primary motivation for this change of heart was the
growing conviction that the conception of evidence as private mental
states rendered it inadequate to ground the intersubjectivity and
objectivity of
 science.<sup>[<a href="notes.html#37" name="note-37">37</a>]</sup>
 In this area as in others, the evolution of Carnap's own views was
crucial to the evolution of the views of the Vienna Circle as a whole.
The episode was well-recounted years later by Ayer: </p>

<blockquote>
 At the outset &hellip; the prevailing view was that these
[observation] statements referred to the subject's introspectible or
sensory experiences &hellip; [I]t was held, following Russell and
ultimately Berkeley, that perceiving physical objects was to be
analyzed in terms of having sensations, or as Russell put it, of
sensing sense data. Though physical objects might be publicly
accessible, sense data were taken to be private. There could be no
question of our literally sharing one another's sense data, any more
than we can literally share one another's thoughts or images or
feelings &hellip; [T]his conception of elementary statements was exposed
to attack on various grounds.&hellip; [T]he most serious difficulty lay
in the privacy of the objects to which the elementary statements were
supposed to refer.&hellip; Because of such difficulties, Neurath, and
subsequently Carnap, rejected the whole conception of elementary
statements. They argued that if elementary statements were to serve as
the basis for the intersubjective statements of science, they must
themselves be intersubjective. They must refer, not to private
incommunicable experiences, but to public physical events (1959:
17&ndash;20).
 </blockquote>

<p>
 Inasmuch as it is the distinctive function of protocol sentences to
report one's evidence, a view about what sorts of contents a protocol
sentence might have is in effect a view about what sorts of things can
count as evidence. To abandon a view according to which the subject
matter of any protocol sentence concerns the &lsquo;private
incommunicable experiences&rsquo; of some particular individual is in
effect to abandon a version of the phenomenal conception of
evidence. To adopt in its place a view according to which the subject
matter of any protocol sentence concerns &lsquo;public physical
events&rsquo; is thus a particularly radical shift, inasmuch as this
latter view seems to entail that <em>only</em> public physical events
can count as evidence&mdash;and in particular, that experiences,
formerly taken to exhaust the category of evidence, are ineligible to
count as
 such.<sup>[<a href="notes.html#38" name="note-38">38</a>]</sup> </p>

<p>
 Underneath the positivists' changing views about the nature of
protocol sentences, however, lay a fundamental assumption that they
never questioned. The assumption in question is the following: that
there is some general restriction on the subject matter of a sentence
if that sentence is a potential statement of one's evidence. This
assumption was explicitly rejected by Austin: </p>

<blockquote>
 It is not the case that the formulation of evidence is the function
of any special sort of sentence.&hellip; In general, <em>any</em> kind
of statement could state evidence for <em>any</em> other kind, if the
circumstances were appropriate.&hellip; (1962: 116; emphases his).
 </blockquote>
	
<p>
 According to the alternative picture sketched by Austin, there are,
indeed, circumstances in which one's having knowledge that things
<em>are</em> a certain way depends upon one's having
&lsquo;phenomenal&rsquo; evidence provided by the fact that is how
things <em>look</em>, <em>seem</em>, or <em>appear</em>.  Traditional
epistemology errs, however, in thinking that this is the general
case. Indeed, there are circumstances in which the fact that things
are a certain way constitutes one's evidence for judgements about how
they look, seem or
 appear.<sup>[<a href="notes.html#39" name="note-39">39</a>]</sup> </p>

<p>
 Inasmuch as he denies that there are any general restrictions on the
subject matter of an evidence statement, Austin's way of thinking
about evidence is considerably more liberal or inclusive than that of
much of the tradition. In this respect, his account of evidence
resembles Williamson's (2000) later theory. As we have seen,
Williamson holds that one's evidence consists of everything that one
knows. In particular, one's evidence is not limited to one's knowledge
of one's experiences, nor is it limited to one's observational
knowledge&mdash;one's evidence also includes any theoretical
knowledge that one might possess (p. 190). </p>

<p>
 On such liberalized views, although one's evidence is not limited to
one's introspectively arrived at knowledge of one's experiences, it
<em>includes</em> everything that one knows about one's experiences on
the basis of introspection. In this respect, such views are
incompatible not only with the phenomenal conception of evidence but
also with views that would rule out the objects of introspection as
evidence on the grounds that the objects of introspection lack the
objectivity and publicity that is characteristic of genuine
evidence. However, it is dubious that any view on which evidence plays
a role in justifying belief can consistently observe a constraint
which would preclude the objects of introspection from counting as
genuine evidence. Goldman (1997) argues that any such constraint is
inconsistent with the introspectionist methodology employed in various
areas of contemporary cognitive science and that this undercuts
&lsquo;the traditional view &hellip; that scientific evidence can be
produced only by intersubjective methods that can be used by different
investigators and will produce agreement&rsquo; (p. 95).</p>

<p>
 Reflection on examples drawn from more homely contexts also casts
doubt on the idea that all genuine evidence is in principle accessible
to multiple individuals. When one has a headache, one is typically
justified in believing that one has a headache. While others might
have evidence that one has a headache&mdash;evidence afforded,
perhaps, by one's testimony, or by one's non-linguistic
behavior&mdash;it is implausible that whatever evidence others
possess is identical with that which justifies one's own belief that
one has a headache. Indeed, it seems dubious that others could have
one's evidence, given that others cannot literally share one's
headache. </p>

<p>
 Here then we see another context in which theoretical demands are
placed on the concept of evidence that seem to pull in different
directions. On the one hand, it is thought central to the concept of
evidence that evidence is by its very nature the kind of thing that
can generate rational convergence of opinion in virtue of being shared
by multiple individuals. This encourages the idea that any genuine
piece of evidence can in principle be grasped by multiple individuals;
anything which cannot be so grasped is either not genuine evidence or
is at best a degenerate species thereof. On the other hand, evidence
is taken to be that which justifies belief. And it seems that many of
the beliefs which individuals hold about their own mental lives on the
basis of introspection are justified by factors with respect to which
they enjoy privileged access. Notably, the positivists' embrace of the
idea that protocol sentences refer exclusively to publicly-observable
physical objects and events was accompanied by an embrace of
behaviorism in
 psychology.<sup>[<a href="notes.html#40" name="note-40">40</a>]</sup>
 It is characteristic of behaviorism to denigrate the idea that the
deliverances of introspection can constitute genuine evidence; on this
combination of views then, the thesis that all evidence consists of
that which can be shared by multiple observers is upheld. For those who
reject behaviorism, however, the idea that at least some evidence does
not meet this condition is a more difficult one to resist.</p>

</div>

<div id="bibliography">

<h2><a name="Bib">Bibliography</a></h2>

<ul class="hanging">

<li>Achinstein, Peter, 1983. &lsquo;Concepts of Evidence,&rsquo; in
Achinstein (ed.) <em>The Concept of Evidence</em>, Oxford: Oxford
University Press: 145&ndash;174.</li>

<li>&ndash;&ndash;&ndash;, 1992. &lsquo;The Evidence Against
Kronz,&rsquo; <em>Philosophical Studies</em>, 67: 169&ndash;175.</li>

<li>&ndash;&ndash;&ndash;, 2001. <em>The Book of Evidence</em>, Oxford:
Oxford University Press.</li>

<li>Austin, J.L., 1962. <em>Sense and Sensibilia</em>, Oxford: Oxford
University Press.</li>

<li>Ayer, A.J., 1936. <em>Language, Truth, and Logic</em>, New York:
Dover.</li>

<li>&ndash;&ndash;&ndash;, 1946. <em>Language, Truth, and Logic</em>, Second
edition. New York: Dover.</li>

<li>&ndash;&ndash;&ndash;, ed., 1959. <em>Logical Positivism</em>,
MacMillan: New York.</li>

<li>&ndash;&ndash;&ndash;, 1982. <em>Philosophy in the Twentieth
Century</em>, New York: Random House.</li>

<li>&ndash;&ndash;&ndash;, 1972. <em>Probability and Evidence</em>,
New York: Columbia University Press.</li>

<li>Ballantyne, Nathan and Coffman, E.J., 2011. &lsquo;Uniqueness,
Evidence, and Rationality,&rsquo; <em>Philosophers' Imprint</em>, 11
(18).</li>

<li>Bell, Swenson-Wright, and Tybjerg, eds., 2008. <em>Evidence</em>,
Cambridge: Cambridge University Press.</li>

<li>Blanshard, Brand, 1974. <em>Reason and Belief</em>, London: Allen
and Unwin.</li>

<li>BonJour, Laurence, 1985. <em>The Structure of Empirical
Knowledge</em>, Cambridge, MA: Harvard University Press.</li>

<li>Bovens, Luc and Hartmann, Stephan, 2003. <em>Bayesian
Epistemology</em>, Oxford: Oxford University Press.</li>

<li>Carnap, Rudolf, 1928. <em>Der Logische Aufbau der Welt</em>,
Berlin: Schlachtensee.</li>

<li>&ndash;&ndash;&ndash;, 1932/33. &lsquo;Psychology in Physical
Language,&rsquo; Originally published in <em>Erkenntnis</em>,
vol. III. Reprinted in Ayer (1959): 165&ndash;198.</li>

<li>&ndash;&ndash;&ndash;, 1937. <em>The Logical Syntax of
Language</em> (New York: Harcourt, Brace and Co.).</li>

<li>&ndash;&ndash;&ndash;, 1950. <em>Logical Foundations of Probability</em>
(Chicago: University of Chicago Press).</li>

<li>&ndash;&ndash;&ndash;, 1952. <em>The Continuum of Inductive Methods</em>,
Chicago: University of Chicago Press.</li>

<li>&ndash;&ndash;&ndash;, 1963. <em>The Philosophy of Rudolph Carnap</em>
(Library of Living Philosophers, Vol. 11), Paul A. Schilpp (ed.), Open
Court: IL.</li>

<li>&ndash;&ndash;&ndash;, 1966. <em>An Introduction to the Philosophy of
Science</em>, Edited by Martin Gardner. New York: Dover.</li>

<li>Chihara, Charles, 1987. &lsquo;Some Problems for Bayesian
Confirmation Theory,&rsquo; <em>British Journal for the Philosophy of
Science</em>, 38: 551&ndash;560.</li>

<li>Christensen, David, 1997. &lsquo;What is Relative
Confirmation?&rsquo; <em>Nous</em>, 31(3): 370&ndash;384.</li>

<li>&ndash;&ndash;&ndash;, 2010.  &ldquo;Higher-Order
Evidence&rdquo;. <em>Philosophy and Phenomenological Research</em>,
81(1): 185&ndash;215.</li>

<li>Churchland, Paul, 1979. <em>Scientific Realism and the Plasticity
of Mind</em>, Cambridge: Cambridge University Press.</li>

<li>&ndash;&ndash;&ndash;, 1988. &lsquo;Perceptual Plasticity and
Theoretical Neutrality,&rsquo; <em>Philosophy of Science</em>, 55:2:
167&ndash;187.</li>

<li>Cohen, Stewart, 1984. &lsquo;Justification and Truth,&rsquo;
<em>Philosophical Studies</em>, 46: 279&ndash;295.</li>

<li>Collingwood, R.G., 1956. <em>The Idea of History</em>, Oxford:
Oxford University Press.</li>

<li>Conee, Earl, 2013. &lsquo;Seeming Evidence,&rsquo; in Tucker
(ed.) <em>Seemings and Justification: New Essays on Dogmatism and
Phenomenal Conservatism</em>, Oxford: Oxford University Press:
52&ndash;70. </li>

<li>Conee, Earl and Feldman, Richard, 2004. <em>Evidentialism</em>,
Oxford: Oxford University Press.</li>

<li>Dougherty, Trent, 2011. <em>Evidentialism and Its
Discontents</em>, Oxford: Oxford University Press.</li>

<li>Earman, John, 1992. <em>Bayes or Bust?</em>, Cambridge, MA: MIT
Press.</li>

<li>Feigl, Herbert, 1953. &lsquo;The Scientific Outlook: Naturalism
and Humanism&rsquo; in H. Feigl and M. Brodbeck (eds.) <em>Readings in
the Philosophy of Science</em>, New York: Appleton-Century-Croft.</li>

<li>Feldman, Richard, 1988. &lsquo;Having Evidence&rsquo; in David
Austin (ed.)  <em>Philosophical Analysis</em>, Dordrecht: Kluwer
Academic Publishers: 83&ndash;104. Reprinted in Conee and Feldman
(2004).</li>

<li>&ndash;&ndash;&ndash;, 2005. &lsquo;Respecting the Evidence&rsquo; in
<em>Philosophical Perspectives</em>, Volume 19, Oxford: Blackwell:
95&ndash;119.</li>

<li>&ndash;&ndash;&ndash;, 2014.  &lsquo;Evidence of Evidence is
Evidence,&rsquo; in Matheson and Vitz (eds.) <em>The Ethics of
Belief</em>, Oxford: Oxford University Press.</li>

<li>Fisher, R.A., 1930. &lsquo;Inverse Probability,&rsquo;
<em>Proceedings of the Cambridge Philosophical Society</em>, 26(4):
528&ndash;535.</li>

<li>Fitelson, Branden, 2012. &lsquo;Evidence of Evidence is not
(necessarily) evidence,&rsquo; <em>Analysis</em>, 72(1): 85&ndash;88.</li>

<li>Fodor, Jerry, 1984. &lsquo;Observation Reconsidered&rsquo; in
<em>Philosophy of Science</em>, 51: 23&ndash;43. Reprinted in Fodor (1992);
page numbers are to the reprint.</li>

<li>&ndash;&ndash;&ndash;, 1988. &lsquo;A Reply to Churchland's Perceptual
Plasticity and Theoretical Neutrality,&rsquo; in <em>Philosophy of
Science</em>, 55: 188&ndash;198. Reprinted in Fodor (1992).</li>

<li>&ndash;&ndash;&ndash;, 1992. <em>A Theory of Content and Other Essays</em>,
Cambridge, MA: The MIT Press.</li>

<li>Glymour, Clark, 1980. <em>Theory and Evidence</em>, Princeton, NJ:
Princeton University Press.</li>

<li>Goldman, Alvin, 1979. &lsquo;What Is Justified Belief?&rsquo; in
George Pappas (ed.). <em>Justification and Knowledge</em>, Dordrecht:
Reidel Publishing Company: 1&ndash;23.</li>

<li>&ndash;&ndash;&ndash;, 1986. <em>Epistemology and Cognition</em>,
Cambridge, MA: Harvard University Press.</li>

<li>&ndash;&ndash;&ndash;, 1997. &lsquo;Science, Publicity and
Consciousness,&rsquo; <em>Philosophy of Science</em>, 64:
525&ndash;545. Reprinted in Goldman (2002). References are to the reprinted
version.</li>

<li>&ndash;&ndash;&ndash;, 2002. <em>Pathways to Knowledge: Private and
Public</em>, Oxford: Oxford University Press.</li>

<li>&ndash;&ndash;&ndash;, 2011. &lsquo;Toward a Synthesis of
Reliabilism and Evidentialism,&rsquo; in Dougherty (ed.),
123&ndash;150.</li>

<li>Goodman, Nelson, 1955. <em>Fact, Fiction, and Forecast</em>,
Cambridge, MA: Harvard University Press.</li>

<li>Hacking, Ian, 1975. <em>The Emergence of Probability</em>,
Cambridge: Cambridge University Press.</li>

<li>Hanson, Norwood Russell, 1961. <em>Patterns of Discovery</em>,
Cambridge: Cambridge University Press.</li>

<li>Hempel, Carl, 1945. &lsquo;Studies in the Logic of
Confirmation,&rsquo; <em>Mind</em>, 54: 1&ndash;26, 97&ndash;121. Reprinted in
Hempel (1965).</li>

<li>&ndash;&ndash;&ndash;, 1952. <em>Fundamentals of Concept Formation in
Empirical Science</em>, Chicago, IL: University of Chicago Press.</li>

<li>&ndash;&ndash;&ndash;, 1960. &lsquo;Inductive Inconsistencies,&rsquo;
<em>Synthese</em>, 12: 439&ndash;469. Reprinted in Hempel (1965): 53&ndash;79.</li>

<li>&ndash;&ndash;&ndash;, 1965. <em>Aspects of Scientific Explanation and
Other Essays in the Philosophy of Science</em>, New York: The Free
Press.</li>

<li>&ndash;&ndash;&ndash;, 1966. <em>Philosophy of Natural Science</em>, Upper
Saddle River, NJ: Prentice-Hall.</li>

<li>Horwich, Paul, 1982. <em>Probability and Evidence</em>, Cambridge:
Cambridge University Press.</li>

<li>Howson, Colin and Urbach, Peter, 1993. <em>Scientific Reasoning:
The Bayesian Approach</em>, 2nd edition. Chicago: Open Court.</li>

<li>Jeffrey, Richard, 1965. <em>The Logic of Decision</em>, Chicago:
University of Chicago Press.</li>

<li>&ndash;&ndash;&ndash;, 1992. <em>Probability and the Art of
Judgement</em>, Cambridge: Cambridge University Press.</li>

<li>&ndash;&ndash;&ndash;, 2004. <em>Subjective Probability</em>
(Cambridge: Cambridge University Press).</li>

<li>Joyce, James, 1999. <em>The Foundations of Causal Decision
Theory</em>, Cambridge: Cambridge University Press.</li>

<li>&ndash;&ndash;&ndash;, 2005. &lsquo;How Probabilities Reflect
Evidence,&rsquo; <em>Philosophical Perspectives</em>, Volume 19,
Oxford: Blackwell: 153&ndash;178. </li>

<li>Kaplan, Mark, 1996. <em>Decision Theory as Philosophy</em>,
Cambridge: Cambridge University Press.</li>

<li>Kelly, Thomas, 2005. &lsquo;The Epistemic Significance of
Disagreement,&rsquo; <em>Oxford Studies in Epistemology</em>, 1:
167&ndash;196.</li>

<li>&ndash;&ndash;&ndash;, 2008. &lsquo;Evidence: Fundamental Concepts and the
Phenomenal Conception,&rsquo; <em>Philosophy Compass</em>, 3(5):
933&ndash;955.</li>

<li>&ndash;&ndash;&ndash;, 2010. &lsquo;Peer Disagreement and Higher Order
Evidence,&rsquo; in Feldman and Warfield (eds.) <em>Disagreement</em>,
Oxford: Oxford University Press: 111&ndash;174.</li>

<li>&ndash;&ndash;&ndash;, 2014. &lsquo;Evidence Can Be Permissive,&rsquo; in
Steup, Turri, and Sosa (eds.) <em>Contemporary Debates in
Epistemology</em>, 2nd edition. Oxford: Blackwell Publishers:
298&ndash;313.</li>

<li>Kim, Jaegwon, 1988. &lsquo;What is Naturalized
Epistemology?&rsquo; in James Tomberlin (ed.) <em>Philosophical
Perspectives 2, Epistemology</em>, Atascadero, CA: Ridgeview
Publishing Co: 381&ndash;405.</li>

<li>Kronz, Frederick, 1992. &lsquo;Carnap and Achinstein on
Evidence,&rsquo; <em>Philosophical Studies</em>, 67: 151&ndash;167.</li>

<li>Kuhn, Thomas, 1962. <em>The Structure of Scientific
Revolutions</em>, Chicago: University of Chicago Press.</li>

<li>&ndash;&ndash;&ndash;, 1977. <em>The Essential Tension: Selected Studies in
Scientific Tradition and Change</em>, Chicago: University of Chicago
Press.</li>

<li>Lasonen-Aarnio, Maria, 2014. &lsquo;Higher-Order Evidence and the
Limits of Defeat,&rsquo; <em>Philosophy and Phenomenological
Research</em>, 88(2): 314&ndash;345.</li>

<li>Levi, Isaac, 1980. <em>The Enterprise of Knowledge</em>
(Cambridge: Cambridge University Press).</li>

<li>&ndash;&ndash;&ndash;, 1991. <em>The Fixation of Belief and Its
Undoing</em>, Cambridge: Cambridge University Press.</li>

<li>Lipton, Peter, ed., 1995. <em>Theory, Evidence, and
Explanation</em>, Brookfield, VT: Dartmouth Publishing Group.</li>

<li>Maher, Patrick, 1993. <em>Betting on Theories</em>, Cambridge:
Cambridge University Press.</li>

<li>&ndash;&ndash;&ndash;, 1996. &lsquo;Subjective and Objective
Confirmation,&rsquo; <em>Philosophy of Science</em>, 63: 149&ndash;174.</li>
 
<li>Matheson, Jonathan, 2009.&lsquo;Conciliatory Views of Disagreement
and Higher-Order Evidence,&rsquo; <em>Episteme</em>, 6(3):
269&ndash;279.</li>

<li>Neta, Ram, 2008. &lsquo;What Evidence Do You
Have?&rsquo; <em>British Journal for the Philosophy of Science</em>,
59(1): 89&ndash;119.</li>

<li>Neyman, J., 1952. <em>Lectures and Conferences on Mathematical
Statistics and Probability</em>, 2nd edition. Washington, DC: US
Department of Agriculture.</li>

<li>Pollock, John, 1986. <em>Contemporary Theories of Knowledge</em>,
Towota, NJ: Rowman And Littlefield Publishers. 1st edition.</li>

<li>Pollock, John and Cruz, Joseph, 1999. <em>Contemporary Theories of
Knowledge</em>, Towota, NJ: Rowman and Littlefield Publishers. 2nd
edition.</li>

<li>Popper, Karl, 1959. <em>The Logic of Scientific Discovery</em>,
London: Hutchinson.</li>

<li>Putnam, Hilary, 1975. <em>Mind, Language, and Reality</em>,
Cambridge: Cambridge University Press.</li>

<li>Pryor, James, 2001. &lsquo;Highlights of Recent
Epistemology&rsquo; in the <em>British Journal for the Philosophy of
Science</em>, 52: 95&ndash;124.</li>

<li>Quine, W.V., 1951. &lsquo;Two Dogmas of Empiricism,&rsquo; in the
<em>Philosophical Review</em>, 60: 20&ndash;43.</li>

<li>&ndash;&ndash;&ndash;, 1968. &lsquo;Epistemology Naturalized&rsquo; in his
<em>Ontological Relativity and Other Essays</em>, New York: Columbia
University Press: 69&ndash;90.</li>

<li>Railton, Peter, 1985. &lsquo;Marx and the Objectivity of
Science,&rsquo; in P. Asquith and P. Kitcher, (eds.) <em>PSA</em>
1984, vol. II. East Lansing, MI: Philosophy of Science Association.
Reprinted in Richard Boyd, Philip Gasper, and J.D. Trout (eds.),
<em>The Philosophy of Science</em>, Cambridge, MA: The MIT Press,
1991: 763&ndash;773. References are to the reprinted version.</li>

<li>Rosenkrantz, R., 1981. <em>Foundations and Applications of
Inductive Probability</em>, Atascadero, CA: Ridgeview Publishing.</li>

<li>Rysiew, Patrick, 2011.  &lsquo;Making It Evident: Evidence and
Evidentness, Justification, and Belief,&rsquo; in Dougherty
(ed.) <em>Evidentialism and Its Discontents</em>, Oxford: Oxford
University Press: 207&ndash;225.</li>

<li>Shafer, G., 1976. <em>A Mathematical Theory of Evidence</em>
(Princeton: Princeton University Press).</li>

<li>Shapin, Steven, 1994. <em>A Social History of Truth</em>, Chicago:
The University of Chicago Press.</li>

<li>Silins, Nico, 2005. &lsquo;Deception and Evidence,&rsquo; in
<em>Philosophical Perspective</em> (Volume 19: Epistemology), Malden,
MA: Blackwell Publishers.</li>

<li>Skyrms, Brian, 1990. <em>The Dynamics of Rational
Deliberation</em>, Cambridge, MA: Harvard University Press.</li>

<li>Swinburne, Richard, 2011.  &ldquo;Evidence&rdquo;.  In Trent Dougherty
(ed.) <em>Evidentialism and Its Discontents</em>, Oxford University
Press: 195&ndash;206.</li>

<li>Talbott, William, 2001. &lsquo;Bayesian epistemology,&rsquo;
 <em>The Stanford Encylopedia of Philosophy</em> (Fall 2001 Edition),
Edward N. Zalta (ed.), URL = 
 &lt;<a href="https://plato.stanford.edu/archives/fall2001/entries/epistemology-bayesian/">https://plato.stanford.edu/archives/fall2001/entries/epistemology-bayesian/</a>&gt;.</li>

<li>White, Roger, 2005. &lsquo;Epistemic
Permissiveness,&rsquo; <em>Philosophical Perspectives</em>, 19(1):
445&ndash;459.</li>

<li>&ndash;&ndash;&ndash;, 2014. &lsquo;Evidence Cannot Be
Permissive,&rsquo; in Steup, Turri, and Sosa (eds.) <em>Contemporary
Debates in Epistemology</em>, 2nd edition. Oxford: Blackwell
Publishers: 312&ndash;323.</li>

<li>Williamson, Timothy, 2000. <em>Knowledge and Its Limits</em>,
Oxford: Oxford University Press.</li>

</ul>

</div>

<div id="academic-tools">

<h2><a id="Aca">Academic Tools</a></h2>

<blockquote>
<table>
<tr><td valign="top"><img src="../../symbols/sepman-icon.jpg" alt="sep man icon" /></td>
<td><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=evidence" target="other">How to cite this entry</a>.</td>
</tr>
<tr><td valign="top"><img src="../../symbols/sepman-icon.jpg" alt="sep man icon" /></td>
<td><a href="https://leibniz.stanford.edu/friends/preview/evidence/" target="other">Preview the PDF version of this entry</a> at the <a href="https://leibniz.stanford.edu/friends/" target="other">Friends of the SEP Society</a>.</td>
</tr>
<tr><td valign="top"><img src="../../symbols/inpho.png" alt="inpho icon" /></td>
<td><a href="https://www.inphoproject.org/entity?sep=evidence&amp;redirect=True" target="other">Look up topics and thinkers related to this entry</a>
 at the Internet Philosophy Ontology Project (InPhO).</td>
</tr>
<tr><td valign="top"><img src="../../symbols/pp.gif" alt="phil papers icon" /></td>
<td><a href="http://philpapers.org/sep/evidence/" target="other">Enhanced bibliography for this entry</a> at <a href="http://philpapers.org/" target="other">PhilPapers</a>, with links to its database.</td>
</tr>
</table>
</blockquote>

</div>

<div id="other-internet-resources">

<h2><a name="Oth">Other Internet Resources</a></h2>

<p>

[Please contact the author with suggestions.] </p>

</div>

<div id="related-entries">

<h2><a name="Rel">Related Entries</a></h2>

<p>

 <a href="../confirmation/index.html">confirmation</a> |
 <a href="../epistemology-bayesian/index.html">epistemology: Bayesian</a>

</p>

</div>

<div id="acknowledgments">

<h3>Acknowledgments</h3>

<p>
 For help in the preparation of this entry, I am grateful to Richard
 Feldman, Gilbert Harman, Nico Silins, Timothy Williamson, and
 especially, Sarah McGrath.</p>

</div>

</div><!-- #aueditable --><!--DO NOT MODIFY THIS LINE AND BELOW-->

<!-- END ARTICLE HTML -->

</div> <!-- End article-content -->

  <div id="article-copyright">
    <p>
 <a href="../../info.html#c">Copyright &copy; 2014</a> by

<br />
<a href="http://www.princeton.edu/~tkelly/" target="other">Thomas Kelly</a>
&lt;<a href="m&#97;ilto:tkelly&#37;40princeton&#37;2eedu"><em>tkelly<abbr title=" at ">&#64;</abbr>princeton<abbr title=" dot ">&#46;</abbr>edu</em></a>&gt;
    </p>
  </div>

</div> <!-- End article -->

<!-- NOTE: article banner is outside of the id="article" div. -->
<div id="article-banner" class="scroll-block">
  <div id="article-banner-content">
    <a href="../../fundraising/index.html">
    Open access to the SEP is made possible by a world-wide funding initiative.<br />
    The Encyclopedia Now Needs Your Support<br />
    Please Read How You Can Help Keep the Encyclopedia Free</a>
  </div>
</div> <!-- End article-banner -->

    </div> <!-- End content -->

    <div id="footer">

      <div id="footer-menu">
        <div class="menu-block">
          <h4><i class="icon-book"></i> Browse</h4>
          <ul role="menu">
            <li><a href="../../contents.html">Table of Contents</a></li>
            <li><a href="../../new.html">What's New</a></li>
            <li><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/random">Random Entry</a></li>
            <li><a href="../../published.html">Chronological</a></li>
            <li><a href="../../archives/index.html">Archives</a></li>
          </ul>
        </div>
        <div class="menu-block">
          <h4><i class="icon-info-sign"></i> About</h4>
          <ul role="menu">
            <li><a href="../../info.html">Editorial Information</a></li>
            <li><a href="../../about.html">About the SEP</a></li>
            <li><a href="../../board.html">Editorial Board</a></li>
            <li><a href="../../cite.html">How to Cite the SEP</a></li>
            <li><a href="../../special-characters.html">Special Characters</a></li>
            <li><a href="../../tools/index.html">Advanced Tools</a></li>
            <li><a href="../../contact.html">Contact</a></li>
          </ul>
        </div>
        <div class="menu-block">
          <h4><i class="icon-leaf"></i> Support SEP</h4>
          <ul role="menu">
            <li><a href="../../support/index.html">Support the SEP</a></li>
            <li><a href="../../support/friends.html">PDFs for SEP Friends</a></li>
            <li><a href="../../support/donate.html">Make a Donation</a></li>
            <li><a href="../../support/sepia.html">SEPIA for Libraries</a></li>
          </ul>
        </div>
      </div> <!-- End footer menu -->

      <div id="mirrors">
        <div id="mirror-info">
          <h4><i class="icon-globe"></i> Mirror Sites</h4>
          <p>View this site from another server:</p>
        </div>
        <div class="btn-group open">
          <a class="btn dropdown-toggle" data-toggle="dropdown" href="https://plato.stanford.edu/">
            <span class="flag flag-usa"></span> USA (Main Site) <span class="caret"></span>
            <span class="mirror-source">Philosophy, Stanford University</span>
          </a>
          <ul class="dropdown-menu">
            <li><a href="../../mirrors.html">Info about mirror sites</a></li>
          </ul>
        </div>
      </div> <!-- End mirrors -->
      
      <div id="site-credits">
        <p>The Stanford Encyclopedia of Philosophy is <a href="../../info.html#c">copyright &copy; 2021</a> by <a href="http://mally.stanford.edu/">The Metaphysics Research Lab</a>, Department of Philosophy, Stanford University</p>
        <p>Library of Congress Catalog Data: ISSN 1095-5054</p>
      </div> <!-- End site credits -->

    </div> <!-- End footer -->

  </div> <!-- End container -->

   <!-- NOTE: Script required for drop-down button to work (mirrors). -->
  <script>
    $('.dropdown-toggle').dropdown();
  </script>

</body>

<!-- Mirrored from seop.illc.uva.nl/entries/evidence/ by HTTrack Website Copier/3.x [XR&CO'2014], Wed, 22 Jun 2022 19:47:02 GMT -->
</html>
