<!DOCTYPE html>
<!--[if lt IE 7]> <html class="ie6 ie"> <![endif]-->
<!--[if IE 7]>    <html class="ie7 ie"> <![endif]-->
<!--[if IE 8]>    <html class="ie8 ie"> <![endif]-->
<!--[if IE 9]>    <html class="ie9 ie"> <![endif]-->
<!--[if !IE]> --> <html> <!-- <![endif]-->

<!-- Mirrored from seop.illc.uva.nl/entries/technology/ by HTTrack Website Copier/3.x [XR&CO'2014], Wed, 22 Jun 2022 19:55:52 GMT -->
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>
Philosophy of Technology (Stanford Encyclopedia of Philosophy)
</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="robots" content="noarchive, noodp" />
<meta property="citation_title" content="Philosophy of Technology" />
<meta property="citation_author" content="Franssen, Maarten" />
<meta property="citation_author" content="Lokhorst, Gert-Jan" />
<meta property="citation_author" content="van de Poel, Ibo" />
<meta property="citation_publication_date" content="2009/02/20" />
<meta name="DC.title" content="Philosophy of Technology" />
<meta name="DC.creator" content="Franssen, Maarten" />
<meta name="DC.creator" content="Lokhorst, Gert-Jan" />
<meta name="DC.creator" content="van de Poel, Ibo" />
<meta name="DCTERMS.issued" content="2009-02-20" />
<meta name="DCTERMS.modified" content="2018-09-06" />

<!-- NOTE: Import webfonts using this link: -->
<link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,300,600,200&amp;subset=latin,latin-ext" rel="stylesheet" type="text/css" />

<link rel="stylesheet" type="text/css" media="screen,handheld" href="../../css/bootstrap.min.css" />
<link rel="stylesheet" type="text/css" media="screen,handheld" href="../../css/bootstrap-responsive.min.css" />
<link rel="stylesheet" type="text/css" href="../../css/font-awesome.min.css" />
<!--[if IE 7]> <link rel="stylesheet" type="text/css" href="../../css/font-awesome-ie7.min.css"> <![endif]-->
<link rel="stylesheet" type="text/css" media="screen,handheld" href="../../css/style.css" />
<link rel="stylesheet" type="text/css" media="print" href="../../css/print.css" />
<link rel="stylesheet" type="text/css" href="../../css/entry.css" />
<!--[if IE]> <link rel="stylesheet" type="text/css" href="../../css/ie.css" /> <![endif]-->
<script type="text/javascript" src="../../js/jquery-1.9.1.min.js"></script>
<script type="text/javascript" src="../../js/bootstrap.min.js"></script>

<!-- NOTE: Javascript for sticky behavior needed on article and ToC pages -->
<script type="text/javascript" src="../../js/jquery-scrolltofixed-min.js"></script>
<script type="text/javascript" src="../../js/entry.js"></script>

<!-- SEP custom script -->
<script type="text/javascript" src="../../js/sep.js"></script>
</head>

<!-- NOTE: The nojs class is removed from the page if javascript is enabled. Otherwise, it drives the display when there is no javascript. -->
<body class="nojs article" id="pagetopright">
<div id="container">
<div id="header-wrapper">
  <div id="header">
    <div id="branding">
      <div id="site-logo"><a href="../../index.html"><img src="../../symbols/sep-man-red.png" alt="SEP home page" /></a></div>
      <div id="site-title"><a href="../../index.html">Stanford Encyclopedia of Philosophy</a></div>
    </div>
    <div id="navigation">
      <div class="navbar">
        <div class="navbar-inner">
          <div class="container">
            <button class="btn btn-navbar collapsed" data-target=".collapse-main-menu" data-toggle="collapse" type="button"> <i class="icon-reorder"></i> Menu </button>
            <div class="nav-collapse collapse-main-menu in collapse">
              <ul class="nav">
                <li class="dropdown open"><a id="drop1" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-book"></i> Browse</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop1">
                    <li><a href="../../contents.html">Table of Contents</a></li>
                    <li><a href="../../new.html">What's New</a></li>
                    <li><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/random">Random Entry</a></li>
                    <li><a href="../../published.html">Chronological</a></li>
                    <li><a href="../../archives/index.html">Archives</a></li>
                  </ul>
                </li>
                <li class="dropdown open"><a id="drop2" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-info-sign"></i> About</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop2">
                    <li><a href="../../info.html">Editorial Information</a></li>
                    <li><a href="../../about.html">About the SEP</a></li>
                    <li><a href="../../board.html">Editorial Board</a></li>
                    <li><a href="../../cite.html">How to Cite the SEP</a></li>
                    <li><a href="../../special-characters.html">Special Characters</a></li>
                    <li><a href="../../tools/index.html">Advanced Tools</a></li>
                    <li><a href="../../contact.html">Contact</a></li>
                  </ul>
                </li>
                <li class="dropdown open"><a id="drop3" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-leaf"></i> Support SEP</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop3">
                    <li><a href="../../support/index.html">Support the SEP</a></li>
                    <li><a href="../../support/friends.html">PDFs for SEP Friends</a></li>
                    <li><a href="../../support/donate.html">Make a Donation</a></li>
                    <li><a href="../../support/sepia.html">SEPIA for Libraries</a></li>
                  </ul>
                </li>
              </ul>
            </div>
          </div>
        </div>
      </div>
    </div>
    <!-- End navigation -->
    
    <div id="search">
      <form id="search-form" method="get" action="https://seop.illc.uva.nl/search/searcher.py">
        <input type="search" name="query" placeholder="Search SEP" />
        <div class="search-btn-wrapper"><button class="btn search-btn" type="submit"><i class="icon-search"></i></button></div>
      </form>
    </div>
    <!-- End search --> 
    
  </div>
  <!-- End header --> 
</div>
<!-- End header wrapper -->

<div id="content">

<!-- Begin article sidebar -->
<div id="article-sidebar" class="sticky">
  <div class="navbar">
    <div class="navbar-inner">
      <div class="container">
        <button class="btn btn-navbar" data-target=".collapse-sidebar" data-toggle="collapse" type="button"> <i class="icon-reorder"></i> Entry Navigation </button>
        <div id="article-nav" class="nav-collapse collapse-sidebar in collapse">
          <ul class="nav">
            <li><a href="#toc">Entry Contents</a></li>
            <li><a href="#Bib">Bibliography</a></li>
            <li><a href="#Aca">Academic Tools</a></li>
            <li><a href="https://leibniz.stanford.edu/friends/preview/technology/">Friends PDF Preview <i class="icon-external-link"></i></a></li>
            <li><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=technology">Author and Citation Info <i class="icon-external-link"></i></a> </li>
            <li><a href="#pagetopright" class="back-to-top">Back to Top <i class="icon-angle-up icon2x"></i></a></li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</div>
<!-- End article sidebar --> 

<!-- NOTE: Article content must have two wrapper divs: id="article" and id="article-content" -->
<div id="article">
<div id="article-content">

<!-- BEGIN ARTICLE HTML -->


<div id="aueditable"><!--DO NOT MODIFY THIS LINE AND ABOVE-->

<h1>Philosophy of Technology</h1><div id="pubinfo"><em>First published Fri Feb 20, 2009; substantive revision Thu Sep 6, 2018</em></div>

<div id="preamble">

<p>
If philosophy is the attempt &ldquo;to understand how things in the
broadest possible sense of the term hang together in the broadest
possible sense of the term&rdquo;, as Sellars (1962) put it,
philosophy should not ignore technology. It is largely by technology
that contemporary society hangs together. It is hugely important not
only as an economic force but also as a cultural force. Indeed during
the last two centuries, when it gradually emerged as a discipline,
philosophy of technology has mostly been concerned with the meaning of
technology for, and its impact on, society and culture, rather than
with technology itself. Mitcham (1994) calls this type of philosophy
of technology &ldquo;humanities philosophy of technology&rdquo;
because it accepts &ldquo;the primacy of the humanities over
technologies&rdquo; and is continuous with the overall perspective of
the humanities (and some of the social sciences). Only recently a
branch of the philosophy of technology has developed that is concerned
with technology itself and that aims to understand both the practice
of designing and creating artifacts (in a wide sense, including
artificial processes and systems) and the nature of the things so
created. This latter branch of the philosophy of technology seeks
continuity with the philosophy of science and with several other
fields in the analytic tradition in modern philosophy, such as the
philosophy of action and decision-making, rather than with the
humanities and social science.</p>

<p>
The entry starts with a brief historical overview, then continues with
a presentation of the themes on which modern analytic philosophy of
technology focuses. This is followed by a discussion of the societal
and ethical aspects of technology, in which some of the concerns of
humanities philosophy of technology are addressed. This twofold
presentation takes into consideration the development of technology as
the outcome of a process originating within and guided by the practice
of engineering, by standards on which only limited societal control is
exercised, as well as the consequences for society of the
implementation of the technology so created, which result from
processes upon which only limited control can be exercised.</p>






</div>

<div id="toc">
<!--Entry Contents-->
<ul>

 <li><a href="#HistDeve">1. Historical Developments</a>
 
<ul>

 <li><a href="#Gree">1.1 The Greeks</a></li>
 
 <li><a href="#LateDeveHumaPhilTech">1.2 Later Developments; Humanities Philosophy of Technology</a></li>
 
 <li><a href="#BasiAmbiMeanTech">1.3 A Basic Ambiguity in the Meaning of Technology</a></li>
 </ul></li>

 <li><a href="#AnalPhilTech">2. Analytic Philosophy of Technology</a>
 
<ul>

 <li><a href="#IntrPhilTechPhilSciePhilPrac">2.1 Introduction: Philosophy of Technology and Philosophy of Science as Philosophies of Practices</a></li>
 
 <li><a href="#RelaBetwTechScie">2.2 The Relationship Between Technology and Science</a></li>
 
 <li><a href="#CentDesiTech">2.3 The Centrality of Design to Technology</a></li>
 
 <li><a href="#MethIssuDesiDeciMaki">2.4 Methodological Issues: Design as Decision Making</a></li>
 
 <li><a href="#MetaIssuStatCharArti">2.5 Metaphysical Issues: The Status and Characteristics of Artifacts</a></li>
 
 <li><a href="#OtheTopi">2.6 Other Topics</a></li>
 </ul></li>

 <li><a href="#EthiSociAspeTech">3. Ethical and Social Aspects of Technology</a>
 
<ul>

 <li><a href="#DeveEthiTech">3.1 The Development of the Ethics of Technology</a></li>
 
 <li><a href="#ApprEthiTech">3.2 Approaches in the Ethics of Technology</a>
 
<ul>

 <li><a href="#CultPoliAppr">3.2.1 Cultural and political approaches</a></li>
 
 <li><a href="#EngiEthi">3.2.2 Engineering ethics</a></li>
 
 <li><a href="#EthiSpecTech">3.2.3 Ethics of specific technologies</a></li>
 </ul></li>

 <li><a href="#SomeRecuThemEthiTech">3.3 Some Recurrent Themes in the Ethics of Technology</a>
 
<ul>

 <li><a href="#NeutVersMoraAgen">3.3.1 Neutrality versus moral agency</a></li>
 
 <li><a href="#Resp">3.3.2 Responsibility</a></li>
 
 <li><a href="#Desi">3.3.3 Design</a></li>
 
 <li><a href="#TechRisk">3.3.4 Technological risks</a></li>
 </ul></li>
</ul></li>

 <li><a href="#Bib">Bibliography</a>
 
<ul>

 <li><a href="#Jour">Journals</a></li>
 
 <li><a href="#Ency">Encyclopedias</a></li>
 </ul></li>

 <li><a href="#Aca">Academic Tools</a></li>
 
 <li><a href="#Oth">Other Internet Resources</a></li>
 
 <li><a href="#Rel">Related Entries</a></li>
 </ul>
<!--Entry Contents-->






<hr />

</div>

<div id="main-text">



<h2 id="HistDeve">1. Historical Developments</h2>

<h3 id="Gree">1.1 The Greeks</h3>

<p>
Philosophical reflection on technology is about as old as philosophy
itself. Our oldest testimony is from ancient Greece. There are four
prominent themes. One early theme is the thesis that technology learns
from or imitates nature (Plato, <em>Laws</em> X 899a ff.). According
to Democritus, for example, house-building and weaving were first
invented by imitating swallows and spiders building their nests and
nets, respectively (Diels 1903 and Freeman 1948: 154).  Perhaps the
oldest extant source for the exemplary role of nature is Heraclitus
(Diels 1903 and Freeman 1948: 112).  Aristotle referred to this
tradition by repeating Democritus&rsquo; examples, but he did not
maintain that technology can only imitate nature: &ldquo;generally
<em>techn&egrave;</em> in some cases completes what nature cannot
bring to a finish, and in others imitates nature&rdquo;
(<em>Physics</em> II.8, 199a15; see also <em>Physics</em> II.2, and
see Schummer 2001 and this encyclopedia&rsquo;s entry on
 <a href="../episteme-techne/index.html"><em>episteme</em> and <em>techne</em></a>
 for discussion).</p>

<p>
A second theme is the thesis that there is a fundamental ontological
distinction between natural things and artifacts. According to
Aristotle (<em>Physics</em> II.1), the former have their principles of
generation and motion inside, whereas the latter, insofar as they are
artifacts, are generated only by outward causes, namely human aims and
forms in the human soul. Natural products (animals and their parts,
plants, and the four elements) move, grow, change, and reproduce
themselves by inner final causes; they are driven by purposes of
nature. Artifacts, on the other hand, cannot reproduce themselves.
Without human care and intervention, they vanish after some time by
losing their artificial forms and decomposing into (natural)
materials. For instance, if a wooden bed is buried, it decomposes to
earth or changes back into its botanical nature by putting forth a
shoot.</p>

<p>
The thesis that there is a fundamental difference between man-made
products and natural substances has had a long-lasting influence. In
the Middle Ages, Avicenna criticized alchemy on the ground that it can
never produce &lsquo;genuine&rsquo; substances
(Briffault 1930: 147). Even today, some still
maintain that there is a difference between, for example, natural and
synthetic vitamin C. The modern discussion of this theme is taken up
in
 <a href="#MetaIssuStatCharArti">Section 2.5</a>.</p>
 
<p>
Aristotle&rsquo;s doctrine of the four causes&mdash;material, formal,
efficient and final&mdash;can be regarded as a third early
contribution to the philosophy of technology. Aristotle explained this
doctrine by referring to technical artifacts such as houses and
statues (<em>Physics</em> II.3). The four causes are still very much
present in modern discussions related to the metaphysics of artifacts.
Discussions of the notion of function, for example, focus on its
inherent teleological or &lsquo;final&rsquo; character and the
difficulties this presents to its use in biology. And the notorious
case of the ship of Theseus&mdash;see this encyclopedia&rsquo;s
entries on
 <a href="../material-constitution/index.html">material constitution</a>,
 <a href="../identity-time/index.html">identity over time</a>,
 <a href="../identity-relative/index.html">relative identity</a>,
 and
 <a href="../sortals/index.html">sortals</a>&mdash;was
 introduced in modern philosophy by Hobbes as showing a conflict
between unity of matter and unity of form as principles of
individuation. This conflict is seen by many as characteristic of
artifacts. David Wiggins (1980: 89) takes it even to be the defining
characteristic of artifacts.</p>

<p>
A fourth point that deserves mentioning is the extensive employment of
technological images by Plato and Aristotle. In his <em>Timaeus</em>,
Plato described the world as the work of an Artisan, the Demiurge. His
account of the details of creation is full of images drawn from
carpentry, weaving, ceramics, metallurgy, and agricultural technology.
Aristotle used comparisons drawn from the arts and crafts to
illustrate how final causes are at work in natural processes. Despite
their negative appreciation of the life led by artisans, who they
considered too much occupied by the concerns of their profession and
the need to earn a living to qualify as free individuals, both Plato
and Aristotle found technological imagery indispensable for expressing
their belief in the rational design of the universe (Lloyd 1973:
61).</p>

<h3 id="LateDeveHumaPhilTech">1.2 Later Developments; Humanities Philosophy of Technology</h3>

<p>
Although there was much technological progress in the Roman empire and
during the Middle Ages, philosophical reflection on technology did not
grow at a corresponding rate. Comprehensive works such as
Vitruvius&rsquo; <em>De architectura</em> (first century BC) and
Agricola&rsquo;s <em>De re metallica</em> (1556) paid much attention
to practical aspects of technology but little to philosophy.</p>

<p>
In the realm of scholastic philosophy, there was an emergent
appreciation for the mechanical arts. They were generally considered
to be born of&mdash;and limited to&mdash;the mimicry of nature. This
view was challenged when alchemy was introduced in the Latin West
around the mid-twelfth century. Some alchemical writers such as Roger
Bacon were willing to argue that human art, even if learned by
imitating natural processes, could successfully reproduce natural
products or even surpass them (Newman 2004). The result was a philosophy of technology in which
human art was raised to a level of appreciation not found in other
writings until the Renaissance. However, the last three decades of the
thirteenth century witnessed an increasingly hostile attitude by
religious authorities toward alchemy that culminated eventually in the
denunciation <em>Contra alchymistas</em>, written by the inquisitor
Nicholas Eymeric in 1396 (Newman 2004).</p>

<p>
The Renaissance led to a greater appreciation of human beings and
their creative efforts, including technology. As a result,
philosophical reflection on technology and its impact on society
increased. Francis Bacon is generally regarded as the first modern
author to put forward such reflection. His view, expressed in his
fantasy <em>New Atlantis</em> (1627), was overwhelmingly positive.
This positive attitude lasted well into the nineteenth century,
incorporating the first half-century of the industrial revolution.</p>

<p>
For example, Karl Marx did not condemn the steam engine or the
spinning mill for the vices of the bourgeois mode of production; he
believed that ongoing technological innovation were necessary steps
toward the more blissful stages of socialism and communism of the
future (see Bimber 1990 for a discussion of different views on the
role of technology in Marx&rsquo;s theory of historical development,
and see Van der Pot 1985 [1994/2004] for an extensive historical
overview of appreciations of the development of technology).</p>

<p>
A turning point in the appreciation of technology as a socio-cultural
phenomenon is marked by Samuel Butler&rsquo;s <em>Erewhon</em> (1872),
written under the influence of the Industrial Revolution, and
Darwin&rsquo;s <em>On the Origin of Species</em> (1859). Butler&rsquo;s book gave an
account of a fictional country where all machines are banned and the
possession of a machine or the attempt to build one is a capital
crime. The people of this country had become convinced by an argument
that ongoing technical improvements are likely to lead to a
&lsquo;race&rsquo; of machines that will replace mankind as the
dominant species on earth.</p>

<p>
During the last quarter of the nineteenth century and most of the
twentieth century a critical attitude predominated in philosophical
reflection on technology. The representatives of this attitude were,
overwhelmingly, schooled in the humanities or the social sciences and
had virtually no first-hand knowledge of engineering practice. Whereas
Bacon wrote extensively on the method of science and conducted
physical experiments himself, Butler, being a clergyman, lacked such
first-hand knowledge. Ernst Kapp, who was the first to use the term
&lsquo;philosophy of technology&rsquo; in his book <em>Eine
Philosophie der Technik</em> (1877 [2018]), was a philologist and
historian.  Most of the authors who wrote critically about technology
and its socio-cultural role during the twentieth century were
philosophers of a general outlook, such as Martin Heidegger (1954
[1977]), Hans Jonas (1979 [1984]), Arnold Gehlen (1957 [1980]),
G&uuml;nther Anders (1956), and Andrew Feenberg (1999). Others had a
background in one of the other humanities or in social science, such
as literary criticism and social research in the case of Lewis Mumford
(1934), law in the case of Jacques Ellul (1954 [1964]), political
science in the case of Langdon Winner (1977, 1980, 1983) and literary
studies in the case of Albert Borgmann (1984). The form of philosophy
of technology constituted by the writings of these and others has been
called by Carl Mitcham (1994) &ldquo;humanities philosophy of
technology&rdquo;, because it takes its point of departure from the
social sciences and the humanities rather than from the practice of
technology, and it approaches technology accepting &ldquo;the primacy
of the humanities over technologies&rdquo; (1994: 39), since
technology originates from the goals and values of humans.
</p>

<p>
Humanities philosophers of technology tend to take the phenomenon of
technology itself largely for granted; they treat it as a &lsquo;black
box&rsquo;, a given, a unitary, monolithic, inescapable phenomenon.
Their interest is not so much to analyze and understand this
phenomenon itself but to grasp its relations to morality (Jonas,
Gehlen), politics (Winner), the structure of society (Mumford), human
culture (Ellul), the human condition (Hannah Arendt), or metaphysics
(Heidegger). In this, these philosophers are almost all openly
critical of technology: all things considered, they tend to have a
negative judgment of the way technology has affected human society and
culture, or at least they single out for consideration the negative
effects of technology on human society and culture. This does not
necessarily mean that technology itself is pointed out as the
principal cause of these negative developments. In the case of
Heidegger, in particular, the paramount position of technology in
modern society is rather a symptom of something more fundamental,
namely a wrongheaded attitude towards Being which has been on the rise
for almost 25 centuries. It is therefore questionable whether
Heidegger should be considered as a philosopher of technology,
although within the traditional view he is considered to be among the
most important ones. Much the same could be said about Arendt, in
particular her discussion of technology in <em>The Human
Condition</em> (1958), although her position in the canon of
humanities philosophy of technology is not as prominent.</p>

<p>
To be sure, the work of these founding figures of humanities
philosophy of technology has been taken further by a second and third
generation of scholars&mdash;in particular the work of Heidegger
remains an important source of inspiration&mdash;but who in doing so
have adopted a more neutral rather than overall negative view of
technology and its meaning for human life and culture. Notable
examples are Ihde (1979, 1993) and Verbeek (2000 [2005]).</p>

<p>
In its development, humanities philosophy of technology continues to
be influenced not so much by developments in philosophy (e.g.,
philosophy of science, philosophy of action, philosophy of mind) but
by developments in the social sciences and humanities. Although, for
example, Ihde and those who take their point of departure with him,
position their work as phenomenologist or postphenomenologist, there
does not seem to be much interest in either the past or the present of
this diffuse notion in philosophy, and in particular not much interest
in the far from easy question to what extent Heidegger can be
considered a phenomenologist. Of particular significance has been the
emergence of &lsquo;Science and Technology Studies&rsquo; (STS) in the
1980s, which studies from a broad social-scientific perspective how
social, political, and cultural values affect scientific research and
technological innovation, and how these in turn affect society,
politics, and culture. We discuss authors from humanities philosophy
of technology in
 <a href="#EthiSociAspeTech">Section 3</a>
on &lsquo;Ethical and Social Aspects of Technology&rsquo;, but do not
present separately and in detail the wide variety of views existing in
this field. For a detailed treatment Mitcham&rsquo;s 1994 book
provides an excellent overview. Olsen, Selinger and Riis (2008) offer
a collection of more recent contributions; Scharff and Dusek (2003
[2014]) and Kaplan (2004 [2009]) present comprehensive anthologies of
texts from this tradition.</p>

<h3 id="BasiAmbiMeanTech">1.3 A Basic Ambiguity in the Meaning of Technology</h3>

<p>
Mitcham contrasts &lsquo;humanities philosophy of technology&rsquo; to
&lsquo;engineering philosophy of technology&rsquo;, where the latter
refers to philosophical views developed by engineers or technologists
as &ldquo;attempts &hellip; to elaborate a technological
philosophy&rdquo; (1994: 17). Mitcham discusses only a handful of
people as engineering philosophers of technology, however: Ernst Kapp,
Peter Engelmeier, Friedrich Dessauer, and much more briefly Jacques
Lafitte, Gilbert Simondon, Hendrik van Riessen, Juan David
Garc&iacute;a Bacca, R. Buckminster Fuller and Mario Bunge. The label
raises serious questions, however: several of them hardly classify as
&lsquo;engineers or technologists&rsquo; and it is also not very clear
how the notion of &lsquo;a technological philosophy&rsquo; should be
understood. As philosophers these authors seem all to be rather
isolated figures, whose work shows little overlap and who seem to be
sharing mainly the absence of a &lsquo;working relation&rsquo; with
established philosophical disciplines. It is not so clear what sort of
questions and concerns underlie the notion of &lsquo;engineering
philosophy of technology&rsquo;. A larger role for systematic
philosophy could bring it quite close to some examples of humanities
philosophy of technology, for instance the work of Jacques Ellul,
where the analyses would be rather similar and the remaining
differences would be ones of attitude or appreciation.</p>

<p>
In the next section we discuss in more detail a form of philosophy of
technology that we consider to occupy, currently, the position of
alternative to the humanities philosophy of technology. It emerged in
the 1960s and gained momentum in the past fifteen to twenty years.
This form of the philosophy of technology, which may be called
&lsquo;analytic&rsquo;, is not primarily concerned with the relations
between technology and society but with technology itself. It
expressly does not look upon technology as a &lsquo;black box&rsquo;
but as a phenomenon that should be studied in detail. It regards
technology perhaps not in its entirety as a practice but as something
grounded in a practice, basically the practice of engineering. It
analyses this practice, its goals, its concepts and its methods, and
it relates its findings to various themes from philosophy.</p>

<p>
In focusing on technology as a practice sustained by engineers,
similar to the way philosophy of science focuses on the practice of
science as sustained by scientists, analytic philosophy of technology
could be thought to amount to the philosophy of engineering. Indeed
many of the issues related to design, discussed below in Sections
 <a href="#CentDesiTech">2.3</a>
 and
 <a href="#MethIssuDesiDeciMaki">2.4</a>,
 could be singled out as forming the subject matter of the philosophy
of engineering. The metaphysical issues discussed in Section
 <a href="#MetaIssuStatCharArti">2.5</a>
 could not, however, and analytic philosophy of technology is
therefore significantly broader than philosophy of engineering. The
very title of <em>Philosophy of Technology and Engineering
Sciences</em> (Meijers 2009), an extensive up-to-date overview, which
contains contributions to all of the topics treated in the next
section, expresses the view that technology and engineering do not
coincide. Which is not to say, however, that the book offers a clear
conception of what makes technology different from engineering, or
more than engineering. In fact, the existence of humanities philosophy
of technology and analytic philosophy of technology next to each other
reflects a basic ambiguity in the notion of technology that the
philosophical work that has been going on has not succeeded in
clarifying.</p>

<p>
Technology can be said to have two &lsquo;cores&rsquo; or
&lsquo;dimensions&rsquo;, which can be referred to as
<em>instrumentality</em> and <em>productivity</em>. Instrumentality
covers the totality of human endeavours to control their lives and
their environments by interfering with the world in an instrumental
way, by using things in a purposeful and clever way. Productivity
covers the totality of human endeavours to brings new things into
existence that can do certain things in a controlled and clever way.
For the study of instrumentality, however, it is in principle
irrelevant whether or not the things that are made use of in
controlling our lives and environments have been made by us first; if
we somehow could rely on natural objects to always be available to
serve our purposes, the analysis of instrumentality and its
consequences for how we live our lives would not necessarily be
affected. Likewise, for the analysis of what is involved in the making
of artifacts, and how the notion of artifact and of something new
being brought into existence are to be understood, it is to a large
extent irrelevant how human life, culture and society are changed as a
result of the artifacts that are in fact produced. Clearly, humanities
philosophy of technology has until now been more attracted by the
instrumentality core whereas analytic philosophy of technology has
mainly gone for the productivity core. But technology as one of the
basic phenomena of modern society, if not the most basic one, clearly
is constituted by the processes centering on and involving both cores.
It has proved difficult, however, to come to an overarching approach
in which the interaction between these two dimensions of technology
are adequately dealt with&mdash;no doubt partly due to the great
differences in philosophical orientation and methodology associated
with the two traditions and their separate foci. To improve this
situation is arguably the most urgent challenge that the field of
philosophy of technology as a whole is facing, since the continuation
of the two orientations leading their separate lives threatens its
unity and coherence as a discipline in the first place.
Notwithstanding its centrality and urgency, the ambiguity noted here
seems hardly to be confronted directly in the literature. It is
addressed by Lawson (2008, 2017) and by Franssen and Koller
(2016).</p>

<p>
After presenting the major issues of philosophical relevance in
technology and engineering that are studied by analytic philosophers
of technology in the next section, we discuss the problems and
challenges that technology poses for the society in which it is
practiced in the third and final section.</p>

<h2 id="AnalPhilTech">2. Analytic Philosophy of Technology</h2>

<h3 id="IntrPhilTechPhilSciePhilPrac">2.1 Introduction: Philosophy of Technology and Philosophy of Science as Philosophies of Practices</h3>

<p>
It may come as a surprise to those new to the topic that the fields of
philosophy of science and philosophy of technology show such great
differences, given that few practices in our society are as closely
related as science and technology. Experimental science is nowadays
crucially dependent on technology for the realization of its research
set-ups and for gathering and analyzing data. The phenomena that
modern science seeks to study could never be discovered without
producing them through technology.</p>

<p>
Theoretical research within technology has come to be often
indistinguishable from theoretical research in science, making
engineering science largely continuous with &lsquo;ordinary&rsquo; or
&lsquo;pure&rsquo; science. This is a relatively recent development,
which started around the middle of the nineteenth century, and is
responsible for great differences between modern technology and
traditional, craft-like techniques. The educational training that
aspiring scientists and engineers receive starts off being largely
identical and only gradually diverges into a science or an engineering
curriculum. Ever since the scientific revolution of the seventeenth
century, characterized by its two major innovations, the experimental
method and the mathematical articulation of scientific theories,
philosophical reflection on science has focused on the method by which
scientific knowledge is generated, on the reasons for thinking
scientific theories to be true, or approximately true, and on the
nature of evidence and the reasons for accepting one theory and
rejecting another. Hardly ever have philosophers of science posed
questions that did not have the community of scientists, their
concerns, their aims, their intuitions, their arguments and choices,
as a major target. In contrast it is only recently that the philosophy
of technology has discovered the community of engineers.</p>

<p>
It might be claimed that it is up to the philosophy of technology, and
not the philosophy of science, to target first of all the impact of
technology&mdash;and with it science&mdash;on society and culture,
because science affects society only through technology. This,
however, will not do. Right from the start of the scientific
revolution, science affected human culture and thought fundamentally
and directly, not with a detour through technology, and the same is
true for later developments such as relativity, atomic physics and
quantum mechanics, the theory of evolution, genetics, biochemistry,
and the increasingly dominating scientific world view overall.
Philosophers of science overwhelmingly give the impression that they
leave questions addressing the normative, social and cultural aspects
of science gladly to other philosophical disciplines, or to historical
studies. There are exceptions, however, and things may be changing;
Philip Kitcher, to name but one prominent philosopher of science, has
since 2000 written books on the relation of science to politics,
ethics and religion (Kitcher 2001, 2011).</p>

<p>
There is a major difference between the historical development of
modern technology as compared to modern science which may at least
partly explain this situation, which is that science emerged in the
seventeenth century from philosophy itself. The answers that Galileo,
Huygens, Newton, and others gave, by which they initiated the alliance
of empiricism and mathematical description that is so characteristic
of modern science, were answers to questions that had belonged to the
core business of philosophy since antiquity. Science, therefore, kept
the attention of philosophers. Philosophy of science is a
transformation of epistemology in the light of the emergence of
science. The foundational issues&mdash;the reality of atoms, the
status of causality and probability, questions of space and time, the
nature of the quantum world&mdash;that were so lively discussed during
the end of the nineteenth and the beginning of the twentieth century
are an illustration of this close relationship between scientists and
philosophers. No such intimacy has ever existed between those same
philosophers and technologists; their worlds still barely touch. To be
sure, a case can be made that, compared to the continuity existing
between natural philosophy and science, a similar continuity exists
between central questions in philosophy having to do with human action
and practical rationality and the way technology approaches and
systematizes the solution of practical problems. To investigate this
connection may indeed be considered a major theme for philosophy of
technology, and more is said on it in Sections
 <a href="#CentDesiTech">2.3</a>
 and
 <a href="#MethIssuDesiDeciMaki">2.4</a>.
 This continuity appears only by hindsight, however, and dimly, as the
historical development is at most a slow convening of various strands
of philosophical thinking on action and rationality, not a development
into variety from a single origin. Significantly it is only the
academic outsider Ellul who has, in his idiosyncratic way, recognized
in technology the emergent single dominant way of answering all
questions concerning human action, comparable to science as the single
dominant way of answering all questions concerning human knowledge
(Ellul 1954 [1964]). But Ellul was not so much interested in
investigating this relationship as in emphasizing and denouncing the
social and cultural consequences as he saw them. It is all the more
important to point out that humanities philosophy of technology cannot
be differentiated from analytic philosophy of technology by claiming
that only the former is interested in the social environment of
technology. There are studies which are rooted in analytic philosophy
of science but address specifically the relation of technology to
society and culture, and equally the relevance of social relations to
practices of technology, without taking an evaluative stand with
respect to technology; an example is B. Preston 2012.</p>

<h3 id="RelaBetwTechScie">2.2 The Relationship Between Technology and Science</h3>

<p>
The close relationship between the practices of science and technology
may easily keep the important differences between the two from view.
The predominant position of science in the philosophical field of
vision made it difficult for philosophers to recognize that technology
merits special attention for involving issues that do not emerge in
science. This view resulting from this lack of recognition is often
presented, perhaps somewhat dramatically, as coming down to a claim
that technology is &lsquo;merely&rsquo; applied science.</p>

<p>
A questioning of the relation between science and technology was the
central issue in one of the earliest discussions among analytic
philosophers of technology. In 1966, in a special issue of the journal
<em>Technology and Culture</em>, Henryk Skolimowski argued that
technology is something quite different from science (Skolimowski
1966). As he phrased it, science concerns itself with what is, whereas
technology concerns itself with what is to be. A few years later, in
his well-known book <em>The Sciences of the Artificial</em> (1969),
Herbert Simon emphasized this important distinction in almost the same
words, stating that the scientist is concerned with how things are but
the engineer with how things ought to be. Although it is difficult to
imagine that earlier philosophers were blind to this difference in
orientation, their inclination, in particular in the tradition of
logical empiricism, to view knowledge as a system of statements may
have led to a conviction that in technology no knowledge claims play a
role that cannot also be found in science. The study of technology,
therefore, was not expected to pose new challenges nor hold surprises
regarding the interests of analytic philosophy.</p>

<p>
In contrast, Mario Bunge (1966) defended the view that technology
<em>is</em> applied science, but in a subtle way that does justice to
the differences between science and technology. Bunge acknowledges
that technology is about action, but an action heavily underpinned by
theory&mdash;that is what distinguishes technology from the arts and
crafts and puts it on a par with science. According to Bunge, theories
in technology come in two types: substantive theories, which provide
knowledge about the object of action, and operative theories, which
are concerned with action itself. The substantive theories of
technology are indeed largely applications of scientific theories. The
operative theories, in contrast, are not preceded by scientific
theories but are born in applied research itself. Still, as Bunge
claims, operative theories show a dependence on science in that in
such theories the <em>method</em> of science is employed. This
includes such features as modeling and idealization, the use of
theoretical concepts and abstractions, and the modification of
theories by the absorption of empirical data through prediction and
retrodiction.</p>

<p>
In response to this discussion, Ian Jarvie (1966) proposed as
important questions for a philosophy of technology what the
epistemological status of technological statements is and how
technological statements are to be demarcated from scientific
statements. This suggests a thorough investigation of the various
forms of knowledge occurring in either practice, in particular, since
scientific knowledge has already been so extensively studied, of the
forms of knowledge that are characteristic of technology and are
lacking, or of much less prominence, in science. A distinction between
&lsquo;knowing that&rsquo;&mdash;traditional propositional
knowledge&mdash;and &lsquo;knowing how&rsquo;&mdash;non-articulated
and even impossible-to-articulate knowledge&mdash;had been introduced
by Gilbert Ryle (1949) in a different context. The notion of
&lsquo;knowing how&rsquo; was taken up by Michael Polanyi under the
name of tacit knowledge and made a central characteristic of
technology (Polanyi 1958); the current state of the philosophical
discussion is presented in this encyclopedia&rsquo;s entry on
 <a href="../knowledge-how/index.html">knowledge how</a>.
 However, emphasizing too much the role of unarticulated knowledge, of
&lsquo;rules of thumb&rsquo; as they are often called, easily
underplays the importance of rational methods in technology. An
emphasis on tacit knowledge may also be ill-fit for distinguishing the
practices of science and technology because the role of tacit
knowledge in science may well be more important than current
philosophy of science acknowledges, for example in concluding causal
relationships on the basis of empirical evidence. This was also an
important theme in the writings of Thomas Kuhn on theory change in
science (Kuhn 1962).</p>

<h3 id="CentDesiTech">2.3 The Centrality of Design to Technology</h3>

<p>
To claim, with Skolimowski and Simon, that technology is about what is
to be or what ought to be rather than what is may serve to distinguish
it from science but will hardly make it understandable why so much
philosophical reflection on technology has taken the form of
socio-cultural critique. Technology is an ongoing attempt to bring the
world closer to the way one wishes it to be. Whereas science aims to
understand the world as it is, technology aims to change the world.
These are abstractions, of course. For one, whose wishes concerning
what the world should be like are realized in technology? Unlike
scientists, who are often personally motivated in their attempts at
describing and understanding the world, engineers are seen, not in the
least by engineers themselves, as undertaking their attempts to change
the world as a service to the public. The ideas on what is to be or
what ought to be are seen as originating outside of technology itself;
engineers then take it upon themselves to realize these ideas. This
view is a major source for the widely spread picture of technology as
being <em>instrumental</em>, as delivering instruments ordered from
&lsquo;elsewhere&rsquo;, as means to ends specified outside of
engineering, a picture that has served further to support the claim
that technology is <em>neutral</em> with respect to values, discussed
in
 <a href="#NeutVersMoraAgen">Section 3.3.1</a>.
 This view involves a considerable distortion of reality, however.
Many engineers are intrinsically motivated to change the world; in
delivering ideas for improvement they are, so to speak, their own best
customers. The same is true for most industrial companies,
particularly in a market economy, where the prospect of great profits
is another powerful motivator. As a result, much technological
development is &lsquo;technology-driven&rsquo;.</p>

<p>
To understand where technology &lsquo;comes from&rsquo;, what drives
the innovation process, is of importance not only to those who are
curious to understand the phenomenon of technology itself but also to
those who are concerned about its role in society. Technology or
engineering as a practice is concerned with the creation of artifacts
and, of increasing importance, artifact-based services. The <em>design
process</em>, the structured process leading toward that goal, forms
the core of the practice of technology. In the engineering literature,
the design process is commonly represented as consisting of a series
of translational steps; see for this, e.g., Suh 2001. At the start are
the customer&rsquo;s needs or wishes. In the first step these are
translated into a list of <em>functional requirements</em>, which then
define the design task an engineer, or a team of engineers, has to
accomplish. The functional requirements specify as precisely as
possible what the device to be designed must be able to do. This step
is required because customers usually focus on just one or two
features and are unable to articulate the requirements that are
necessary to support the functionality they desire. In the second
step, the functional requirements are translated into <em>design
specifications</em>, which the exact physical parameters of crucial
components by which the functional requirements are going to be met.
The design parameters chosen to satisfy these requirements are
combined and made more precise such that a <em>blueprint</em> of the
device results. The blueprint contains all the details that must be
known such that the final step to the process of manufacturing the
device can take place. It is tempting to consider the blueprint as the
end result of a design process, instead of a finished copy being this
result. However, actual copies of a device are crucial for the purpose
of prototyping and testing. Prototyping and testing presuppose that
the sequence of steps making up the design process can and will often
contain iterations, leading to revisions of the design parameters
and/or the functional requirements. Even though, certainly for
mass-produced items, the manufacture of a product for delivery to its
customers or to the market comes after the closure of the design
phase, the manufacturing process is often reflected in the functional
requirements of a device, for example in putting restrictions on the
number of different components of which the device consists. The
complexity of a device will affect how difficult it will be to
maintain or repair it, and ease of maintenance or low repair costs are
often functional requirements. An important modern development is that
the complete life cycle of an artifact is now considered to be the
designing engineer&rsquo;s concern, up till the final stages of the
recycling and disposal of its components and materials, and the
functional requirements of any device should reflect this. From this
point of view, neither a blueprint nor a prototype can be considered
the end product of engineering design.</p>

<p>
The biggest idealization that this scheme of the design process
contains is arguably located at the start. Only in a minority of cases
does a design task originate in a customer need or wish for a
particular artifact. First of all, as already suggested, many design
tasks are defined by engineers themselves, for instance, by noticing
something to be improved in existing products. But more often than not
design starts with a problem pointed out by some societal agent, which
engineers are then invited to solve. Many such problems, however, are
ill-defined or <em>wicked</em> problems, meaning that it is not at all
clear what the problem is exactly and what a solution to the problem
would consist in. The &lsquo;problem&rsquo; is a situation that
people&mdash;not necessarily the people &lsquo;in&rsquo; the
situation&mdash;find unsatisfactory, but typically without being able
to specify a situation that they find more satisfactory in other terms
than as one in which the problem has been solved. In particular it is
not obvious that a solution to the problem would consist in some
artifact, or some artifactual system or process, being made available
or installed. Engineering departments all over the world advertise
that engineering is problem solving, and engineers easily seem
confident that they are best qualified to solve a problem when they
are asked to, whatever the nature of the problem. This has led to the
phenomenon of a <em>technological fix</em>, the solution of a problem
by a technical solution, that is, the delivery of an artifact or
artifactual process, where it is questionable, to say the least,
whether this solves the problem or whether it was the best way of
handling the problem.</p>

<p>
A candidate example of a technological fix for the problem of global
warming would be the currently much debated option of injecting
sulfate aerosols into the stratosphere to offset the warming effect of
greenhouse gases such as carbon dioxide and methane. Such schemes of
geoengineering would allow us to avoid facing the&mdash;in all
likelihood painful&mdash;choices that will lead to a reduction of the
emission of greenhouse gases into the atmosphere, but will at the same
time allow the depletion of the Earth&rsquo;s reservoir of fossil
fuels to continue. See for a discussion of technological fixing, e.g.,
Volti 2009: 26&ndash;32. Given this situation, and its hazards, the
notion of a problem and a taxonomy of problems deserve to receive more
philosophical attention than they have hitherto received.</p>

<p>
These wicked problems are often broadly social problems, which would
best be met by some form of &lsquo;social action&rsquo;, which would
result in people changing their behavior or acting differently in such
a way that the problem would be mitigated or even disappear
completely. In defense of the engineering view, it could perhaps be
said that the repertoire of &lsquo;proven&rsquo; forms of social
action is meager. The temptation of technical fixes could be
overcome&mdash;at least that is how an engineer might see it&mdash;by
the inclusion of the social sciences in the systematic development and
application of knowledge to the solution of human problems. This
however, is a controversial view. <em>Social engineering</em> is to
many a specter to be kept at as large a distance as possible instead
of an ideal to be pursued. Karl Popper referred to acceptable forms of
implementing social change as &lsquo;piecemeal social
engineering&rsquo; and contrasted it to the revolutionary but
completely unfounded schemes advocated by, e.g., Marxism. In the entry
on
 <a href="../popper/index.html">Karl Popper</a>,
 however, his choice of words is called &lsquo;rather
unfortunate&rsquo;. The notion of social engineering, and its cogency,
deserves more attention that it is currently receiving.</p>

<p>
An important input for the design process is scientific knowledge:
knowledge about the behavior of components and the materials they are
composed of in specific circumstances. This is the point where science
is applied. However, much of this knowledge is not directly available
from the sciences, since it often concerns extremely detailed behavior
in very specific circumstances. This scientific knowledge is therefore
often generated within technology, by the engineering sciences. But
apart from this very specific scientific knowledge, engineering design
involves various other sorts of knowledge. In his book <em>What
Engineers Know and How They Know It</em> (Vincenti 1990), the
aeronautical engineer Walter Vincenti gave a six-fold categorization
of engineering design knowledge (leaving aside production and
operation as the other two basic constituents of engineering
practice). Vincenti distinguishes</p>

<ol>

<li>Fundamental design concepts, including primarily the operational
principle and the normal configuration of a particular device;</li>

<li>Criteria and specifications;</li>

<li>Theoretical tools;</li>

<li>Quantitative data;</li>

<li>Practical considerations;</li>

<li>Design instrumentalities.</li>
</ol>

<p>
The fourth category concerns the quantitative knowledge just referred
to, and the third the theoretical tools used to acquire it. These two
categories can be assumed to match Bunge&rsquo;s notion of substantive
technological theories. The status of the remaining four categories is
much less clear, however, partly because they are less familiar, or
not at all, from the well-explored context of science. Of these
categories, Vincenti claims that they represent prescriptive forms of
knowledge rather than descriptive ones. Here, the activity of design
introduces an element of normativity, which is absent from scientific
knowledge. Take such a basic notion as &lsquo;operational
principle&rsquo;, which refers to the way in which the function of a
device is realized, or, in short, how it works. This is still a purely
descriptive notion. Subsequently, however, it plays a role in
arguments that seek to prescribe a course of action to someone who has
a goal that could be realized by the operation of such a device. At
this stage, the issue changes from a descriptive to a prescriptive or
normative one. An extensive discussion of the various kinds of
knowledge relevant to technology is offered by Houkes (2009).</p>

<p>
Although the notion of an operational principle&mdash;a term that
seems to originate with Polanyi (1958)&mdash;is central to engineering
design, no single clear-cut definition of it seems to exist. The issue
of disentangling descriptive from prescriptive aspects in an analysis
of the technical action and its constituents is therefore a task that
has hardly begun. This task requires a clear view on the extent and
scope of technology. If one follows Joseph Pitt in his book
<em>Thinking About Technology</em> (1999) and defines technology
broadly as &lsquo;humanity at work&rsquo;, then to distinguish between
technological action and action in general becomes difficult, and the
study of technological action must absorb all descriptive and
normative theories of action, including the theory of practical
rationality, and much of theoretical economics in its wake. There have
indeed been attempts at such an encompassing account of human action,
for example Tadeusz Kotarbinski&rsquo;s <em>Praxiology</em> (1965),
but a perspective of such generality makes it difficult to arrive at
results of sufficient depth. It would be a challenge for philosophy to
specify the differences among action forms and the reasoning grounding
them in, to single out three prominent fields of study, technology,
organization and management, and economics.</p>

<p>
A more restricted attempt at such an approach is Ilkka
Niiniluoto&rsquo;s (1993). According to Niiniluoto, the theoretical
framework of technology as the practice that is concerned with what
the world should be like rather than is, the framework that forms the
counterpoint to the descriptive framework of science, is <em>design
science</em>. The content of design science, the counterpoint to the
theories and explanations that form the content of descriptive
science, would then be formed by <em>technical norms</em>, statements
of the form &lsquo;If one wants to achieve <i>X</i>, one should do
<i>Y</i>&rsquo;. The notion of a technical norm derives from Georg
Henrik von Wright&rsquo;s <em>Norm and Action</em> (1963). Technical
norms need to be distinguished from anankastic statements expressing
natural necessity, of the form &lsquo;If <i>X</i> is to be achieved,
<i>Y</i> needs to be done&rsquo;; the latter have a truth value but
the former have not. Von Wright himself, however, wrote that he did
not understand the mutual relations between these statements. Ideas on
what design science is and can and should be are evidently related to
the broad problem area of practical rationality&mdash;see this
encyclopedia&rsquo;s entries on
 <a href="../practical-reason/index.html">practical reason</a>
 and
 <a href="../rationality-instrumental/index.html">instrumental rationality</a>&mdash;and
 also to means-ends reasoning, discussed in the next section.</p>

<h3 id="MethIssuDesiDeciMaki">2.4 Methodological Issues: Design as Decision Making</h3>

<p>
Design is an activity that is subject to rational scrutiny but in
which creativity is considered to play an important role as well.
Since design is a form of action, a structured series of decisions to
proceed in one way rather than another, the form of rationality that
is relevant to it is practical rationality, the rationality
incorporating the criteria on how to act, given particular
circumstances. This suggests a clear division of labor between the
part to be played by rational scrutiny and the part to be played by
creativity. Theories of rational action generally conceive their
problem situation as one involving a choice among various course of
action open to the agent. Rationality then concerns the question how
to decide among given options, whereas creativity concerns the
generation of these options. This distinction is similar to the
distinction between the context of justification and the context of
discovery in science. The suggestion that is associated with this
distinction, however, that rational scrutiny only applies in the
context of justification, is difficult to uphold for technological
design. If the initial creative phase of option generation is
conducted sloppily, the result of the design task can hardly be
satisfactory. Unlike the case of science, where the practical
consequences of entertaining a particular theory are not taken into
consideration, the context of discovery in technology is governed by
severe constraints of time and money, and an analysis of the problem
how best to proceed certainly seems in order. There has been little
philosophical work done in this direction; an overview of the issues
is given in Kroes, Franssen, and Bucciarelli (2009).</p>

<p>
The ideas of Herbert Simon on bounded rationality (see, e.g., Simon
1982) are relevant here, since decisions on when to stop generating
options and when to stop gathering information about these options and
the consequences when they are adopted are crucial in decision making
if informational overload and calculative intractability are to be
avoided. However, it has proved difficult to further develop
Simon&rsquo;s ideas on bounded rationality since their conception in
the 1950s. Another notion that is relevant here is means-ends
reasoning. In order to be of any help here, theories of means-ends
reasoning should then concern not just the evaluation of given means
with respect to their ability to achieve given ends, but also the
generation or construction of means for given ends. A comprehensive
theory of means-ends reasoning, however, is not yet available; for a
proposal on how to develop means-ends reasoning in the context of
technical artifacts, see Hughes, Kroes, and Zwart 2007. In the
practice of technology, alternative proposals for the realization of
particular functions are usually taken from &lsquo;catalogs&rsquo; of
existing and proven realizations. These catalogs are extended by
ongoing research in technology rather than under the urge of
particular design tasks.</p>

<p>
When engineering design is conceived as a process of decision making,
governed by considerations of practical rationality, the next step is
to specify these considerations. Almost all theories of practical
rationality conceive of it as a reasoning process where a match
between beliefs and desires or goals is sought. The desires or goals
are represented by their value or utility for the decision maker, and
the decision maker&rsquo;s problem is to choose an action that
realizes a situation that, ideally, has maximal value or utility among
all the situations that could be realized. If there is uncertainty
concerning he situations that will be realized by a particular action,
then the problem is conceived as aiming for maximal <em>expected</em>
value or utility. Now the instrumental perspective on technology
implies that the value that is at issue in the design process viewed
as a process of rational decision making is not the value of the
artifacts that are created. Those values are the domain of the
<em>users</em> of the technology so created. They are supposed to be
represented in the functional requirements defining the design task.
Instead the value to be maximized is the extent to which a particular
design meets the functional requirements defining the design task. It
is in this sense that engineers share an overall perspective on
engineering design as an exercise in <em>optimization</em>. But
although optimization is a value-orientated notion, it is not itself
perceived as a value driving engineering design.</p>

<p>
The functional requirements that define most design problems do not
prescribe explicitly what should be optimized; usually they set levels
to be attained minimally. It is then up to the engineer to choose how
far to go beyond meeting the requirements in this minimal sense.
<em>Efficiency</em>, in energy consumption and use of materials first
of all, is then often a prime value. Under the pressure of society,
other values have come to be incorporated, in particular
<em>safety</em> and, more recently, <em>sustainability</em>. Sometimes
it is claimed that what engineers aim to maximize is just one factor,
namely market success. Market success, however, can only be assessed
after the fact. The engineer&rsquo;s maximization effort will instead
be directed at what are considered the predictors of market success.
Meeting the functional requirements and being relatively efficient and
safe are plausible candidates as such predictors, but additional
methods, informed by market research, may introduce additional factors
or may lead to a hierarchy among the factors.</p>

<p>
Choosing the design option that maximally meets all the functional
requirements (which may but need not originate with the prospective
user) and all other considerations and criteria that are taken to be
relevant, then becomes the practical decision-making problem to be
solved in a particular engineering-design task. This creates several
methodological problems. Most important of these is that the engineer
is facing a <em>multi-criteria</em> decision problem. The various
requirements come with their own operationalizations in terms of
design parameters and measurement procedures for assessing their
performance. This results in a number of rank orders or quantitative
scales which represent the various options out of which a choice is to
be made. The task is to come up with a final score in which all these
results are &lsquo;adequately&rsquo; represented, such that the option
that scores best can be considered the optimal solution to the design
problem. Engineers describe this situation as one where
<em>trade-offs</em> have to be made: in judging the merit of one
option relative to other options, a relative bad performance on one
criterion can be balanced by a relatively good performance on another
criterion. An important problem is whether a rational method for doing
this can be formulated. It has been argued by Franssen (2005) that
this problem is structurally similar to the well-known problem of
social choice, for which Kenneth Arrow proved his notorious
impossibility theorem in 1950, implying that no general rational
solution method exists for this problem. This poses serious problems
for the claim of engineers that their designs are optimal solutions,
since Arrow&rsquo;s theorem implies that in most multi-criteria
problems the notion of &lsquo;optimal&rsquo; cannot be rigorously
defined.</p>

<p>
This result seems to except a crucial aspect of engineering activity
from philosophical scrutiny, and it could be used to defend the
opinion that engineering is at least partly an art, not a science.
Instead of surrendering to the result, however, which has a
significance that extends much beyond engineering and even beyond
decision making in general, we should perhaps conclude instead that
there is still a lot of work to be done on what might be termed,
provisionally, &lsquo;approximative&rsquo; forms of reasoning. One
form of reasoning to be included here is Herbert Simon&rsquo;s bounded
rationality, plus the related notion of &lsquo;satisficing&rsquo;.
Since their introduction in the 1950s (Simon 1957) these two terms
have found wide usage, but we are still lacking a general theory of
bounded rationality. It may be in the nature of forms of approximative
reasoning such as bounded rationality that a general theory cannot be
had, but even a systematic treatment from which such an insight could
emerge seems to be lacking.</p>

<p>
Another problem for the decision-making view of engineering design is
that in modern technology almost all design is done by teams. Such
teams are composed of experts from many different disciplines. Each
discipline has its own theories, its own models of interdependencies,
its own assessment criteria, and so forth, and the professionals
belonging to these disciplines must be considered as inhabitants of
different <em>object worlds</em>, as Louis Bucciarelli (1994) phrases
it. The different team members are, therefore, likely to disagree on
the relative rankings and evaluations of the various design options
under discussion. Agreement on one option as the overall best one can
here be even less arrived at by an algorithmic method exemplifying
engineering rationality. Instead, models of social interaction, such
as bargaining and strategic thinking, are relevant here. An example of
such an approach to an (abstract) design problem is presented by
Franssen and Bucciarelli (2004).</p>

<p>
To look in this way at technological design as a decision-making
process is to view it normatively from the point of view of practical
or instrumental rationality. At the same time it is descriptive in
that it is a description of how engineering methodology generally
presents the issue how to solve design problems. From that somewhat
higher perspective there is room for all kinds of normative questions
that are not addressed here, such as whether the functional
requirements defining a design problem can be seen as an adequate
representation of the values of the prospective users of an artifact
or a technology, or by which methods values such as safety and
sustainability can best be elicited and represented in the design
process. These issues will be taken up in
 <a href="#EthiSociAspeTech">Section 3</a>.</p>
 
<h3 id="MetaIssuStatCharArti">2.5 Metaphysical Issues: The Status and Characteristics of Artifacts</h3>

<p>
Understanding the process of designing artifacts is the theme in
philosophy of technology that most directly touches on the interests
of engineering practice. This is hardly true for another issue of
central concern to analytic philosophy of technology, which is the
status and the character of artifacts. This is perhaps not unlike the
situation in the philosophy of science, where working scientists seem
also to be much less interested in investigating the status and
character of models and theories than philosophers are.</p>

<p>
Artifacts are man-made objects: they have an author (see Hilpinen 1992
and Hilpinen&rsquo;s article
 <a href="../artifact/index.html">artifact</a>
 in this encyclopedia). The artifacts that are of relevance to
technology are, in particular, made to serve a purpose. This excludes,
within the set of all man-made objects, on the one hand byproducts and
waste products and on the other hand works of art. Byproducts and
waste products result from an intentional act to make something but
just not precisely, although the author at work may be well aware of
their creation. Works of art result from an intention directed at
their creation (although in exceptional cases of conceptual art, this
directedness may involve many intermediate steps) but it is contested
whether artists include in their intentions concerning their work an
intention that the work serves some purpose. A further discussion of
this aspect belongs to the philosophy of art. An interesting general
account has been presented by Dipert (1993).</p>

<p>
Technical artifacts, then, are made to serve some purpose, generally
to be used for something or to act as a component in a larger
artifact, which in its turn is either something to be used or again a
component. Whether end product or component, an artifact is &lsquo;for
something&rsquo;, and what it is for is called the artifact&rsquo;s
<em>function</em>. Several researchers have emphasized that an
adequate description of artifacts must refer both to their status as
tangible physical objects and to the intentions of the people engaged
with them. Kroes and Meijers (2006) have dubbed this view &ldquo;the
dual nature of technical artifacts&rdquo;; its most mature formulation
is Kroes 2012. They suggest that the two aspects are &lsquo;tied
up&rsquo;, so to speak, in the notion of artifact function. This gives
rise to several problems. One, which will be passed over quickly
because little philosophical work seems to have been done concerning
it, is that structure and function mutually constrain each other, but
the constraining is only partial. It is unclear whether a general
account of this relation is possible and what problems need to be
solved to arrive there. There may be interesting connections with the
issue of multiple realizability in the philosophy of mind and with
accounts of reduction in science; an example where this is explored is
Mahner and Bunge 2001.</p>

<p>
It is equally problematic whether a unified account of the notion of
function as such is possible, but this issue has received considerably
more philosophical attention. The notion of function is of paramount
importance for characterizing artifacts, but the notion is used much
more widely. The notion of an artifact&rsquo;s function seems to refer
necessarily to human intentions. Function is also a key concept in
biology, however, where no intentionality plays a role, and it is a
key concept in cognitive science and the philosophy of mind, where it
is crucial in grounding intentionality in non-intentional, structural
and physical properties. Up till now there is no accepted general
account of function that covers both the intentionality-based notion
of artifact function and the non-intentional notion of biological
function&mdash;not to speak of other areas where the concept plays a
role, such as the social sciences. The most comprehensive theory, that
has the ambition to account for the biological notion, cognitive
notion and the intentional notion, is Ruth Millikan&rsquo;s 1984; for
criticisms and replies, see B. Preston 1998, 2003; Millikan 1999;
Vermaas &amp; Houkes 2003; and Houkes &amp; Vermaas 2010. The
collection of essays edited by Ariew, Cummins and Perlman (2002)
presents a recent introduction to the general topic of defining the
notion of function in general, although the emphasis is, as is
generally the case in the literature on function, on biological
functions.</p>

<p>
Against the view that, at least in the case of artifacts, the notion
of function refers necessarily to intentionality, it could be argued
that in discussing the functions of the components of a larger device,
and the interrelations between these functions, the intentional
&lsquo;side&rsquo; of these functions is of secondary importance only.
This, however, would be to ignore the possibility of the
<em>malfunctioning</em> of such components. This notion seems to be
definable only in terms of a mismatch between actual behavior and
intended behavior. The notion of malfunction also sharpens an
ambiguity in the general reference to intentions when characterizing
technical artifacts. These artifacts usually engage many people, and
the intentions of these people may not all pull in the same direction.
A major distinction can be drawn between the intentions of the actual
user of an artifact for a particular purpose and the intentions of the
artifact&rsquo;s designer. Since an artifact may be used for a purpose
different from the one for which its designer intended it to be used,
and since people may also use natural objects for some purpose or
other, one is invited to allow that artifacts can have multiple
functions, or to enforce a hierarchy among all relevant intentions in
determining the function of an artifact, or to introduce a
classification of functions in terms of the sorts of determining
intentions. In the latter case, which is a sort of middle way between
the two other options, one commonly distinguishes between the
<em>proper function</em> of an artifact as the one intended by its
designer and the <em>accidental function</em> of the artifact as the
one given to it by some user on private considerations. Accidental use
can become so common, however, that the original function drops out of
memory.</p>

<p>
Closely related to this issue to what extent use and design determine
the function of an artifact is the problem of characterizing artifact
kinds. It may seem that we use functions to classify artifacts: an
object is a knife because it has the function of cutting, or more
precisely, of enabling us to cut. On closer inspection, however, the
link between function and kind-membership seems much less
straightforward. The basic kinds in technology are, for example,
&lsquo;knife&rsquo;, &lsquo;aircraft&rsquo; and &lsquo;piston&rsquo;.
The members of these kinds have been designed in order to be used to
cut something with, to transport something through the air and to
generate mechanical movement through thermodynamic expansion. However,
one cannot create a particular kind of artifact just by designing
something with the intention that it be used for some particular
purpose: a member of the kind so created must actually be useful for
that purpose. Despite innumerable design attempts and claims, the
perpetual motion machine is not a kind of artifact. A kind like
&lsquo;knife&rsquo; is defined, therefore, not only by the intentions
of the designers of its members that they each be useful for cutting
but also by a shared operational principle known to these designers,
and on which they based their design. This is, in a different setting,
also defended by Thomasson, who in her characterization of what she in
general calls an <em>artifactual kind</em> says that such a kind is
defined by the designer&rsquo;s intention to make something of that
kind, by a substantive idea that the designer has of how this can be
achieved, and by his or her largely successful achievement of it
(Thomasson 2003, 2007). Qua sorts of kinds in which artifacts can be
grouped, a distinction must therefore be made between a kind like
&lsquo;knife&rsquo; and a corresponding but different kind
&lsquo;cutter&rsquo;. A &lsquo;knife&rsquo; indicates a particular way
a &lsquo;cutter&rsquo; can be made. One can also cut, however, with a
thread or line, a welding torch, a water jet, and undoubtedly by other
sorts of means that have not yet been thought of. A
&lsquo;cutter&rsquo; would then refer to a truly functional kind. As
such, it is subject to the conflict between use and design: one could
mean by &lsquo;cutter&rsquo; anything than can be used for cutting or
anything that has been designed to be used for cutting, by the
application of whatever operational principle, presently known or
unknown.</p>

<p>
This distinction between artifact kinds and functional kinds is
relevant for the status of such kinds in comparison to other notions
of kinds. Philosophy of science has emphasized that the concept of
natural kind, such as exemplified by &lsquo;water&rsquo; or
&lsquo;atom&rsquo;, lies at the basis of science. On the other hand it
is generally taken for granted that there are no regularities that all
knives or airplanes or pistons answer to. This, however, is loosely
based on considerations of multiple realizability that fully apply
only to functional kinds, not to artifact kinds. Artifact kinds share
an operational principle that gives them some commonality in physical
features, and this commonality becomes stronger once a particular
artifact kind is subdivided into narrower kinds. Since these kinds are
specified in terms of physical and geometrical parameters, they are
much closer to the natural kinds of science, in that they support
law-like regularities; see for a defense of this position (Soavi
2009). A recent
collection of essays that discuss the metaphysics of artifacts and
artifact kinds is Franssen, Kroes, Reydon and Vermaas 2014.</p>

<h3 id="OtheTopi">2.6 Other Topics</h3>

<p>
There is at least one additional technology-related topic that ought
to be mentioned because it has created a good deal of analytic
philosophical literature, namely Artificial Intelligence and related
areas. A full discussion of this vast field is beyond the scope of
this entry, however. Information is to be found in the entries on
 <a href="../turing-machine/index.html">Turing machines</a>,
 <a href="../church-turing/index.html">the Church-Turing thesis</a>,
 <a href="../computability/index.html">computability and complexity</a>,
 <a href="../turing-test/index.html">the Turing test</a>,
 <a href="../chinese-room/index.html">the Chinese room argument</a>,
 <a href="../computational-mind/index.html">the computational theory of mind</a>,
 <a href="../functionalism/index.html">functionalism</a>,
 <a href="../multiple-realizability/index.html">multiple realizability</a>, and
 <a href="../computer-science/index.html">the philosophy of computer science</a>.</p>
 
<h2 id="EthiSociAspeTech">3. Ethical and Social Aspects of Technology</h2>

<h3 id="DeveEthiTech">3.1 The Development of the Ethics of Technology</h3>

<p>
It was not until the twentieth century that the development of the
ethics of technology as a systematic and more or less independent
subdiscipline of philosophy started. This late development may seem
surprising given the large impact that technology has had on society,
especially since the industrial revolution.</p>

<p>
A plausible reason for this late development of ethics of technology
is the instrumental perspective on technology that was mentioned in
 <a href="#RelaBetwTechScie">Section 2.2</a>.
 This perspective implies, basically, a positive ethical assessment of
technology: technology increases the possibilities and capabilities of
humans, which seems in general desirable. Of course, since antiquity,
it has been recognized that the new capabilities may be put to bad use
or lead to human <em>hubris</em>. Often, however, these undesirable
consequences are attributed to the users of technology, rather than
the technology itself, or its developers. This vision is known as the
instrumental vision of technology resulting in the so-called
neutrality thesis. The neutrality thesis holds that technology is a
neutral instrument that can be put to good or bad use by its users.
During the twentieth century, this neutrality thesis met with severe
critique, most prominently by Heidegger and Ellul, who have been
mentioned in this context in
 <a href="#AnalPhilTech">Section 2</a>,
but also by philosophers from the Frankfurt School, such as Horkheimer
and Adorno (1947 [2002]), Marcuse (1964), and Habermas (1968
[1970]).</p>

<p>
The scope and the agenda for ethics of technology to a large extent
depend on how technology is conceptualized. The second half of the
twentieth century has witnessed a richer variety of conceptualizations
of technology that move beyond the conceptualization of technology as
a neutral tool, as a world view or as a historical necessity. This
includes conceptualizations of technology as a political phenomenon
(Winner, Feenberg, Sclove), as a social activity (Latour, Callon, Bijker and others in the
area of science and technology studies), as a cultural phenomenon
(Ihde, Borgmann), as a professional activity (engineering ethics,
e.g., Davis), and as a cognitive activity (Bunge, Vincenti). Despite
this diversity, the development in the second half of the twentieth
century is characterized by two general trends. One is a move away
from technological determinism and the assumption that technology is a
given self-contained phenomenon which develops autonomously to an
emphasis on technological development being the result of choices
(although not necessarily the intended result). The other is a move
away from ethical reflection on technology as such to ethical
reflection of specific technologies and to specific phases in the
development of technology. Both trends together have resulted in an
enormous increase in the number and scope of ethical questions that
are asked about technology. The developments also imply that ethics of
technology is to be adequately empirically informed, not only about
the exact consequences of specific technologies but also about the
actions of engineers and the process of technological development.
This has also opened the way to the involvement of other disciplines
in ethical reflections on technology, such as Science and Technology
Studies (STS) and Technology Assessment (TA).</p>

<h3 id="ApprEthiTech">3.2 Approaches in the Ethics of Technology</h3>

<p>
Not only is the ethics of technology characterized by a diversity of
approaches, it might even be doubted whether something like a
subdiscipline of ethics of technology, in the sense of a community of
scholars working on a common set of problems, exists. The scholars
studying ethical issues in technology have diverse backgrounds (e.g.,
philosophy, STS, TA, law, political science) and they do not always
consider themselves (primarily) ethicists of technology. To give the
reader an overview of the field, three basic approaches or strands
that might be distinguished in the ethics of technology will be
discussed.</p>

<h4 id="CultPoliAppr">3.2.1 Cultural and political approaches</h4>

<p>
Both cultural and political approaches build on the traditional
philosophy and ethics of technology of the first half of the twentieth
century. Whereas cultural approaches conceive of technology as a
cultural phenomenon that influences our perception of the world,
political approaches conceive of technology as a political phenomenon,
i.e., as a phenomenon that is ruled by and embodies institutional
power relations between people.</p>

<p>
Cultural approaches are often phenomenological in nature or at least
position themselves in relation to phenomenology as
post-phenomenology. Examples of philosophers in this tradition are Don
Ihde, Albert Borgmann, Peter-Paul Verbeek and Evan Selinger (e.g.,
Borgmann 1984; Ihde 1990; Verbeek 2000 [2005], 2011). The approaches are
usually influenced by developments in STS, especially the idea that
technologies contain a script that influences not only people&rsquo;s
perception of the world but also human behavior, and the idea of the
absence of a fundamental distinction between humans and non-humans,
including technological artifacts (Akrich 1992; Latour 1992, 1993;
Ihde &amp; Selinger 2003). The combination of both ideas has led some
to claim that technology has (moral) agency, a claim that is discussed
below in
 <a href="#NeutVersMoraAgen">Section 3.3.1</a>.</p>
 
<p>
Political approaches to technology mostly go back to Marx, who assumed
that the material structure of production in society, in which
technology is obviously a major factor, determined the economic and
social structure of that society. Similarly, Langdon Winner has argued
that technologies can embody specific forms of power and authority
(Winner 1980). According to him, some technologies are inherently
normative in the sense that they require or are strongly compatible
with certain social and political relations. Railroads, for example,
seem to require a certain authoritative management structure. In other
cases, technologies may be political due to the particular way they
have been designed. Some political approaches to technology are
inspired by (American) pragmatism and, to a lesser extent, discourse
ethics. A number of philosophers, for example, have pleaded for a
democratization of technological development and the inclusion of
ordinary people in the shaping of technology (Winner 1983; Sclove
1995; Feenberg 1999).</p>

<p>
Although political approaches have obviously ethical ramifications,
many philosophers who have adopted such approaches do not engage in
explicit ethical reflection on technology. An interesting recent
exception, and an attempt to consolidate a number of recent
developments and to articulate them into a more general account of
what an ethics of technology should look like, is the volume
<em>Pragmatist Ethics for a Technological Culture</em> (Keulartz et
al. 2002). In this volume, the authors plead for a revival of the
pragmatist tradition in moral philosophy because it is better fit to
deal with a number of moral issues in technology. Instead of focusing
on how to reach and justify normative judgments about technology, a
pragmatist ethics focuses on how to recognize and trace moral problems
in the first place. Moreover, the process of dealing with these
problems is considered more important than the outcome.</p>

<h4 id="EngiEthi">3.2.2 Engineering ethics</h4>

<p>
Engineering ethics is a relatively new field of education and
research. It started off in the 1980s in the United States, merely as
an educational effort. Engineering ethics is concerned with &ldquo;the
actions and decisions made by persons, individually or collectively,
who belong to the profession of engineering&rdquo; (Baum 1980: 1).
According to this approach, engineering is a profession, in the same
way as medicine is a profession.</p>

<p>
Although there is no agreement on how a profession exactly should be
defined, the following characteristics are often mentioned:</p>

<ul>

<li>A profession relies on specialized knowledge and skills that
require a long period of study;</li>

<li>The occupational group has a monopoly on the carrying out of the
occupation;</li>

<li>The assessment of whether the professional work is carried out in
a competent way is done by, and it is accepted that this can only be
done by, professional peers;</li>

<li>A profession provides society with products, services or values
that are useful or worthwhile for society, and is characterized by an
ideal of serving society;</li>

<li>The daily practice of professional work is regulated by ethical
standards, which are derived from or relate to the society-serving
ideal of the profession.</li>
</ul>

<p>
Typical ethical issues that are discussed in engineering ethics are
professional obligations of engineers as exemplified in, for example,
codes of ethics of engineers, the role of engineers versus managers,
competence, honesty, whistle-blowing, concern for safety and conflicts
of interest (Davis 1998, 2005; Martin &amp; Schinzinger 2005; Harris,
Pritchard, &amp; Rabins 2008).</p>

<p>
Recently, a number of authors have pleaded for broadening the
traditional scope of engineering ethics (e.g., Herkert 2001;, van de
Poel &amp; Royakkers 2011). This call for a broader approach derives
from two concerns. One concern is that the traditional micro-ethical
approach in engineering ethics tends to take the contexts in which
engineers have to work for given, while major ethical issues pertain
to how this context is &lsquo;organized&rsquo;. Another concern is
that the traditional micro-ethical focus tends to neglect issues
relating to the impact of technology on society or issues relating to
decisions about technology. Broadening the scope of engineering ethics
would then, among others, imply more attention for such issues as
sustainability and social justice.</p>

<h4 id="EthiSpecTech">3.2.3 Ethics of specific technologies</h4>

<p>
The last decades have witnessed an increase in ethical inquiries into
specific technologies. This may now be the largest of the three
strands discussed, especially given the rapid growth in
technology-specific ethical inquiries in the last two decades. One of
the most visible new fields is probably computer ethics (e.g., Moor
1985; Floridi 2010; Johnson 2009; Weckert 2007; van den Hoven &amp;
Weckert 2008), with more recently a focus on robotics, artificial
intelligence, machine ethics, and the ethics of algorithms (Lin,
Abney, &amp; Jenkins 2017; Nucci &amp; Santoni de Sio 2016;
Mittelstadt et al. 2016; Bostrom &amp; Yudkowsky 2014; Wallach &amp;
Allen 2009). But biotechnology has spurred dedicated ethical
investigations as well (e.g., Sherlock &amp; Morrey 2002; P. Thompson
2007). More traditional fields like architecture and urban planning
have also attracted specific ethical attention (Fox 2000). More
recently, nanotechnology and so-called converging technologies have
led to the establishment of what is called nanoethics (Allhoff et al.
2007). Other examples are the ethics of nuclear deterrence (Finnis et
al. 1988), nuclear energy (Taebi &amp; Roeser 2015) and geoengineering
(C. Preston 2016).</p>

<p>
Obviously the establishment of such new fields of ethical reflection
is a response to social and technological developments. Still, the
question can be asked whether the social demand is best met by
establishing new fields of applied ethics. This issue is in fact
regularly discussed as new fields emerge. Several authors have for
example argued that there is no need for nanoethics because
nanotechnology does not raise any really new ethical issues (e.g.,
McGinn 2010). The alleged absence of newness here is supported by the
claim that the ethical issues raised by nanotechnology are a variation
on, and sometimes an intensification of, existing ethical issues, but
hardly really new, and by the claim that these issues can be dealt
with the existing theories and concepts from moral philosophy. For an
earlier, similar discussion concerning the supposed new character of
ethical issues in computer engineering, see Tavani 2002.</p>

<p>
The new fields of ethical reflection are often characterized as
applied ethics, that is, as applications of theories, normative
standards, concepts and methods developed in moral philosophy. For
each of these elements, however, application is usually not
straightforward but requires a further specification or revision. This
is the case because general moral standards, concepts and methods are
often not specific enough to be applicable in any direct sense to
specific moral problems. &lsquo;Application&rsquo; therefore often
leads to new insights which might well result in the reformulation or
at least refinement of existing normative standards, concepts and
methods. In some cases, ethical issues in a specific field might
require new standards, concepts or methods. Beauchamp and Childress
for example have proposed a number of general ethical principles for
biomedical ethics (Beauchamp &amp; Childress 2001). These principles
are more specific than general normative standards, but still so
general and abstract that they apply to different issues in biomedical
ethics. In computer ethics, existing moral concepts relating to for
example privacy and ownership has been redefined and adapted to deal
with issues which are typical for the computer age (Johnson 2003). New
fields of ethical application might also require new methods for, for
example, discerning ethical issues that take into account relevant
empirical facts about these fields, like the fact that technological
research and development usually takes place in networks of people
rather than by individuals (Zwart et al. 2006). Another more general
issue that applies to many new technologies is how to deal with the
uncertainties about (potential) social and ethical impacts that
typically surround new emerging technologies. Brey&rsquo;s (2012)
proposal for an anticipatory ethics may be seen as a reply to this
challenge. The issue of anticipation is also one of the central
concerns in the more recent interdisciplinary field of responsible
innovation (e.g., Owen et al. 2013).</p>

<p>
Although different fields of ethical reflection on specific
technologies might well raise their own philosophical and ethical
issues, it can be questioned whether this justifies the development of
separate subfields or even subdisciplines. One obvious argument might
be that in order to say something ethically meaningful about new
technologies, one needs specialized and detailed knowledge of a
specific technology. Moreover such subfields allow interaction with
relevant non-philosophical experts in for example law, psychology,
economy, science and technology studies (STS) or technology assessment
(TA). On the other side, it could also be argued that a lot can be
learned from interaction and discussion between ethicists specializing
in different technologies, and a fruitful interaction with the two
other strands discussed above (cultural and political approaches and
engineering ethics). Currently, such interaction in many cases seems
absent, although there are of course exceptions.</p>

<h3 id="SomeRecuThemEthiTech">3.3 Some Recurrent Themes in the Ethics of Technology</h3>

<p>
We now turn to the description of some themes in the ethics of
technology. We focus on a number of general themes that provide an
illustration of general issues in the ethics of technology and the way
these are treated.</p>

<h4 id="NeutVersMoraAgen">3.3.1 Neutrality versus moral agency</h4>

<p>
One important general theme in the ethics of technology is the
question whether technology is value-laden. Some authors have
maintained that technology is value-neutral, in the sense that
technology is just a neutral means to an end, and accordingly can be
put to good or bad use (e.g., Pitt 2000). This view might have some
plausibility in as far as technology is considered to be just a bare
physical structure. Most philosophers of technology, however, agree
that technological development is a goal-oriented process and that
technological artifacts by definition have certain functions, so that
they can be used for certain goals but not, or far more difficulty or
less effectively, for other goals. This conceptual connection between
technological artifacts, functions and goals makes it hard to maintain
that technology is value-neutral. Even if this point is granted, the
value-ladenness of technology can be construed in a host of different
ways. Some authors have maintained that technology can have moral
agency. This claim suggests that technologies can autonomously and
freely &lsquo;act&rsquo; in a moral sense and can be held morally
responsible for their actions.</p>

<p>
The debate whether technologies can have moral agency started off in
computer ethics (Bechtel 1985; Snapper 1985; Dennett 1997; Floridi
&amp; Sanders 2004) but has since broadened. Typically, the authors
who claim that technologies (can) have moral agency often redefine the
notion of agency or its connection to human will and freedom (e.g.,
Latour 1993; Floridi &amp; Sanders 2004, Verbeek 2011). A disadvantage
of this strategy is that it tends to blur the morally relevant
distinctions between people and technological artifacts. More
generally, the claim that technologies have moral agency sometimes
seems to have become shorthand for claiming that technology is morally
relevant. This, however, overlooks the fact technologies can be
value-laden in other ways than by having moral agency (see, e.g.,
Johnson 2006; Radder 2009; Illies &amp; Meijers 2009; Peterson &amp;
Spahn 2011). One might, for example, claim that technology enables (or
even invites) and constrains (or even inhibits) certain human actions
and the attainment of certain human goals and therefore is to some
extent value-laden, without claiming moral agency for technological
artifacts. A good overview of the debate can be found in Kroes and
Verbeek 2014.</p>

<p>
The debate about moral agency and technology is now particularly
salient with respect to the design of intelligent artificial agents.
James Moor (2006) has distinguished between four ways in which
artificial agents may be or become moral agents:</p>

<ol>

<li>Ethical impact agents are robots and computer systems that
ethically impact their environment; this is probably true of all
artificial agents.</li>

<li>Implicit ethical agents are artificial agents that have been
programmed to act according to certain values.</li>

<li>Explicit ethical agents are machines that can represent ethical
categories and that can &lsquo;reason&rsquo; (in machine language)
about these.</li>

<li>Full ethical agents in addition also possess some characteristics
we often consider crucial for human agency, like consciousness, free
will and intentionality.</li>
</ol>

<p>
It might perhaps never be possible to technologically design full
ethical agents, and if it were to become possible it might be
questionable whether it is morally desirable to do so (Bostrom &amp;
Yudkowsky 2014). As Wallach and Allen (2009) have pointed out, the
main problem might not be to design artificial agents that can
function autonomously and that can adapt themselves in interaction
with the environment, but rather to build enough, and the right kind
of, ethical sensitivity into such machines.</p>

<h4 id="Resp">3.3.2 Responsibility</h4>

<p>
Responsibility has always been a central theme in the ethics of
technology. The traditional philosophy and ethics of technology,
however, tended to discuss responsibility in rather general terms and
were rather pessimistic about the possibility of engineers to assume
responsibility for the technologies they developed. Ellul, for
example, has characterized engineers as the high priests of
technology, who cherish technology but cannot steer it. Hans Jonas
(1979 [1984]) has argued that technology requires an ethics in which
responsibility is the central imperative because for the first time in
history we are able to destroy the earth and humanity.</p>

<p>
In engineering ethics, the responsibility of engineers is often
discussed in relation to code of ethics that articulate specific
responsibilities of engineers. Such codes of ethics stress three types
of responsibilities of engineers: (1) conducting the profession with
integrity and honesty and in a competent way, (2) responsibilities
towards employers and clients and (3) responsibility towards the
public and society. With respect to the latter, most US codes of
ethics maintain that engineers &lsquo;should hold paramount the
safety, health and welfare of the public&rsquo;.</p>

<p>
As has been pointed out by several authors (Nissenbaum 1996; Johnson
&amp; Powers 2005; Swierstra &amp; Jelsma 2006), it may be hard to
pinpoint individual responsibility in engineering. The reason is that
the conditions for the proper attribution of individual responsibility
that have been discussed in the philosophical literature (like freedom
to act, knowledge, and causality) are often not met by individual
engineers. For example, engineers may feel compelled to act in a
certain way due to hierarchical or market constraints, and negative
consequences may be very hard or impossible to predict beforehand. The
causality condition is often difficult to meet as well due to the long
chain from research and development of a technology till its use and
the many people involved in this chain. Davis (2012) nevertheless
maintains that despite such difficulties individual engineers can and
do take responsibility.</p>

<p>
One issue that is at stake in this debate is the notion of
responsibility. Davis (2012), and also for example Ladd (1991), argue
for a notion of responsibility that focuses less on blame and stresses
the forward-looking or virtuous character of assuming responsibility.
But many others focus on backward-looking notions of responsibility
that stress accountability, blameworthiness or liability. Zandvoort
(2000), for example has pleaded for a notion of responsibility in
engineering that is more like the legal notion of strict liability, in
which the knowledge condition for responsibility is seriously
weakened. Doorn (2012) compares three perspectives on responsibility
ascription in engineering&mdash;a merit-based, a right-based and a
consequentialist perspective&mdash;and argues that the
consequentialist perspective, which applies a forward-looking notion
of responsibility, is most powerful in influencing engineering
practice.</p>

<p>
The difficulty of attributing individual responsibility may lead to
the Problem of Many Hands (PMH). The term was first coined by Dennis
Thompson (1980) in an article about the responsibility of public
officials. The term is used to describe problems with the ascription
of individual responsibility in collective settings. Doorn (2010) has
proposed a procedurals approach, based on Rawls&rsquo; reflective
equilibrium model, to deal with the PMH; other ways of dealing with
the PMH include the design of institutions that help to avoid it or an
emphasis on virtuous behavior in organizations (van de Poel, Royakers,
&amp; Zwart 2015).</p>

<h4 id="Desi">3.3.3 Design</h4>

<p>
In the last decades, increasingly attention is paid not only to
ethical issues that arise during the use of a technology, but also
during the design phase. An important consideration behind this
development is the thought that during the design phase technologies,
and their social consequences, are still malleable whereas during the
use phase technologies are more or less given and negative social
consequences may be harder to avoid or positive effects harder to
achieve.</p>

<p>
In computer ethics, an approach known as Value Sensitive Design (VSD)
has been developed to explicitly address the ethical nature of design.
VSD aims at integrating values of ethical importance in engineering
design in a systematic way (Friedman &amp; Kahn 2003). The approach
combines conceptual, empirical and technical investigations. There is
also a range of other approaches aimed at including values in design.
&lsquo;Design for X&rsquo; approaches in engineering aim at including
instrumental values (like maintainability, reliability and costs) but
they also include design for sustainability, inclusive design, and
affective design (Holt &amp; Barnes 2010). Inclusive design aims at
making designs accessible to the whole population including, for
example, handicapped people and the elderly (Erlandson 2008).
Affective design aims at designs that evoke positive emotions with the
users and so contributes to human well-being. Van de Hoven, Vermaas,
and van de Poel 2015 gives a good overview of the state-of-the art of
value sensitive design for various values and application domains.</p>

<p>
If one tries to integrate values into design one may run into the
problem of a conflict of values. The safest car is, due to its weight,
not likely to be the most sustainability. Here safety and
sustainability conflict in the design of cars. Traditional methods in
which engineers deal with such conflicts and make trade-off between
different requirements for design include cost-benefit analysis and
multiple criteria analysis. Such methods are, however, beset with
methodological problems like those discussed in
 <a href="#MethIssuDesiDeciMaki">Section 2.4</a>
 (Franssen 2005; Hansson 2007). Van de Poel (2009) discusses various
alternatives for dealing with value conflicts in design including the
setting of thresholds (satisficing), reasoning about values,
innovation and diversity.</p>

<h4 id="TechRisk">3.3.4 Technological risks</h4>

<p>
The risks of technology are one of the traditional ethical concerns in
the ethics of technology. Risks raise not only ethical issues but
other philosophical issues, such as epistemological and
decision-theoretical issues as well (Roeser et al. 2012).</p>

<p>
Risk is usually defined as the product of the probability of an
undesirable event and the effect of that event, although there are
also other definitions around (Hansson 2004b). In general it seems
desirable to keep technological risks as small as possible. The larger
the risk, the larger either the likeliness or the impact of an
undesirable event is. Risk reduction therefore is an important goal in
technological development and engineering codes of ethics often
attribute a responsibility to engineers in reducing risks and
designing safe products. Still, risk reduction is not always feasible
or desirable. It is sometimes not feasible, because there are no
absolutely safe products and technologies. But even if risk reduction
is feasible it may not be acceptable from a moral point of view.
Reducing risk often comes at a cost. Safer products may be more
difficult to use, more expensive or less sustainable. So sooner or
later, one is confronted with the question: what is safe enough? What
makes a risk (un)acceptable?</p>

<p>
The process of dealing with risks is often divided into three stages:
risk assessment, risk evaluation and risk management. Of these, the
second is most obviously ethically relevant. However, risk assessment
already involves value judgments, for example about which risks should
be assessed in the first place (Shrader-Frechette 1991). An important,
and morally relevant, issue is also the degree of evidence that is
needed to establish a risk. In establishing a risk on the basis of a
body of empirical data one might make two kinds of mistakes. One can
establish a risk when there is actually none (type I error) or one can
mistakenly conclude that there is no risk while there actually is a
risk (type II error). Science traditionally aims at avoiding type I
errors. Several authors have argued that in the specific context of
risk assessment it is often more important to avoid type II errors
(Cranor 1990; Shrader-Frechette 1991). The reason for this is that
risk assessment not just aims at establishing scientific truth but has
a practical aim, i.e., to provide the knowledge on basis of which
decisions can be made about whether it is desirable to reduce or avoid
certain technological risks in order to protect users or the
public.</p>

<p>
Risk evaluation is carried out in a number of ways (see, e.g.,
Shrader-Frechette 1985). One possible approach is to judge the
acceptability of risks by comparing them to other risks or to certain
standards. One could, for example, compare technological risks with
naturally occurring risks. This approach, however, runs the danger of
committing a naturalistic fallacy: naturally occurring risks may
(sometimes) be unavoidable but that does not necessarily make them
morally acceptable. More generally, it is often dubious to judge the
acceptability of the risk of technology A by comparing it to the risk
of technology B if A and B are not alternatives in a decision (for
this and other fallacies in reasoning about risks, see Hansson
2004a).</p>

<p>
A second approach to risk evaluation is risk-cost benefit analysis,
which is based on weighing the risks against the benefits of an
activity. Different decision criteria can be applied if a (risk) cost
benefit analysis is carried out (Kneese, Ben-David, and Schulze 1983).
According to Hansson (2003: 306), usually the following criterion is
applied: </p>

<blockquote>

<p>
&hellip; a risk is acceptable if and only if the total benefits that
the exposure gives rise to outweigh the total risks, measured as the
probability-weighted disutility of outcomes.</p>
</blockquote>

<p>
A third approach is to base risk acceptance on the consent of people
who suffer the risks after they have been informed about these risks
(informed consent). A problem of this approach is that technological
risks usually affect a large number of people at once. Informed
consent may therefore lead to a &ldquo;society of stalemates&rdquo;
(Hansson 2003: 300).</p>

<p>
Several authors have proposed alternatives to the traditional
approaches of risk evaluation on the basis of philosophical and
ethical arguments. Shrader-Frechette (1991) has proposed a number of
reforms in risk assessment and evaluation procedures on the basis of a
philosophical critique of current practices. Roeser (2012) argues for
a role of emotions in judging the acceptability of risks. Hansson has
proposed the following alternative principle for risk evaluation: </p>

<blockquote>

<p>
Exposure of a person to a risk is acceptable if and only if this
exposure is part of an equitable social system of risk-taking that
works to her advantage. (Hansson 2003: 305) </p>
</blockquote>

<p>
Hansson&rsquo;s proposal introduces a number of moral considerations
in risk evaluation that are traditionally not addressed or only
marginally addressed. These are the consideration whether individuals
profit from a risky activity and the consideration whether the
distribution of risks and benefits is fair.</p>

<p>
Some authors have criticized the focus on risks in the ethics of
technology. One strand of criticism argues that we often lack the
knowledge to reliably assess the risks of a new technology before it
has come into use. We often do not know the probability that something
might go wrong, and sometimes we even do not know, or at least not
fully, what might go wrong and what possible negative consequences may
be. To deal with this, some authors have proposed to conceive of the
introduction of new technology in society as a social experiment and
have urged to think about the conditions under which such experiments
are morally acceptable (Martin &amp; Schinzinger 2005; van de Poel
2016). Another strand of criticism states that the focus on risks has
led to a reduction of the impacts of technology that are considered
(Swierstra &amp; te Molder 2012). Only impacts related to safety and
health, which can be calculated as risks, are considered, whereas
&lsquo;soft&rsquo; impacts, for example of a social or psychological
nature, are neglected, thereby impoverishing the moral evaluation of
new technologies.</p>

</div>

<div id="bibliography">

<h2 id="Bib">Bibliography</h2>



<ul class="hanging">

<li>Agricola, Georgius, 1556 [1912], <em>De re metallica</em>,
Translated and edited by Herbert Clark Hoover and Lou Henry Hoover,
London: The Mining Magazine, 1912.
 [<a href="https://archive.org/details/deremetallica50agri" target="other">Agricola 1556 [1912] available online</a>]</li>
 
<li>Akrich, Madeleine, 1992, &ldquo;The Description of Technical
Objects&rdquo;, in Bijker and Law 1992: 205&ndash;224.</li>

<li>Allhoff, Fritz, Patrick Lin, James H. Moor and John Weckert (eds),
2007, <em>Nanoethics: The Ethical and Social Implications of
Nanotechnology</em>, Hoboken, NJ: Wiley-Interscience.</li>

<li>Anders, G&uuml;nther, 1956, <em>Die Antiquiertheit des
Menschen</em> (Volume I: <em>&Uuml;ber die Seele im Zeitalter der
zweiten industriellen Revolution</em>; Volume II: <em>&Uuml;ber die
Zerst&ouml;rung des Lebens im Zeitalter der dritten industriellen
Revolution</em>), M&uuml;nchen: C.H. Beck.</li>

<li>Arendt, Hannah, 1958, <em>The Human Condition</em>, Chicago:
University of Chicago Press.</li>

<li>Ariew, Andrew, Robert Cummins and Mark Perlman (eds), 2002,
<em>Functions: New Essays in the Philosophy of Psychology and
Biology</em>, New York/Oxford: Oxford University Press.</li>

<li>Aristotle, <em>Physics</em>, Translated in <em>The Complete Works
of Aristotle, Volume 1</em>, The Revised Oxford Translation 2014,
edited by Jonathan Barnes.</li>

<li>Bacon, Francis, 1627, <em>New Atlantis: A Worke Vnfinished</em>,
in his <em>Sylva Sylvarum: or a Naturall Historie, in Ten
Centuries</em>, London: William Lee.</li>

<li>Baum, Robert J., 1980, <em>Ethics and Engineering Curricula</em>,
Hastings-on-Hudson: The Hastings Center.</li>

<li>Beauchamp, Tom L., 2003, &ldquo;The Nature of Applied
Ethics&rdquo;, in Frey and Wellman 2003: 1&ndash;16.
doi:10.1002/9780470996621.ch1</li>

<li>Beauchamp, Tom L. and James F. Childress, 2001, <em>Principles of
Biomedical Ethics</em>, fifth edition, Oxford/New York: Oxford
University Press.</li>

<li>Bechtel, William, 1985, &ldquo;Attributing Responsibility to
Computer Systems&rdquo;, <em>Metaphilosophy</em>, 16(4):
296&ndash;306. doi:10.1111/j.1467-9973.1985.tb00176.x</li>

<li>Bijker, Wiebe E. and John Law (eds), 1992, <em>Shaping
Technology/Building Society: Studies in Sociotechnical Change</em>,
Cambridge, MA: MIT Press.</li>

<li>Bimber, Bruce, 1990, &ldquo;Karl Marx and the Three Faces of
Technological Determinism&rdquo;, <em>Social Studies of Science</em>,
20(2): 333&ndash;351. doi:10.1177/030631290020002006</li>

<li>Borgmann, Albert, 1984, <em>Technology and the Character of
Contemporary Life: A Philosophical Inquiry</em>, Chicago/London:
University of Chicago Press.</li>

<li>Bostrom, Nick and Eliezer Yudkowsky, 2014, &ldquo;The Ethics of
Artificial Intelligence&rdquo;, in <em>The Cambridge Handbook of
Artificial Intelligence</em>, edited by Keith Frankish and William M
Ramsey, Cambridge: Cambridge University Press, 316&ndash;334.
doi:10.1017/CBO9781139046855.020</li>

<li>Brey, Philip A.E., 2012, &ldquo;Anticipatory Ethics for Emerging
Technologies&rdquo;, <em>NanoEthics</em>, 6(1): 1&ndash;13.
doi:10.1007/s11569-012-0141-7</li>

<li>Briffault, R., 1930, <em>Rational Evolution (The Making of Humanity)</em>,
New York: The Macmillan Company.</li>

<li>Bucciarelli, Louis L., 1994, <em>Designing Engineers</em>,
Cambridge, MA: MIT Press.</li>

<li>Bunge, Mario, 1966, &ldquo;Technology as Applied Science&rdquo;,
<em>Technology and Culture</em>, 7(3): 329&ndash;347.
doi:10.2307/3101932</li>

<li>Butler, Samuel, 1872, <em>Erewhon</em>, London: Trubner and Co.
 [<a href="http://archive.org/details/erewhonoroverra00butl" target="other">Butler 1872 available online</a>]</li>

<li>Callon, Michel, 1986, &ldquo;The Sociology of an Actor-Network:
the Case of the Electric Vehicle&rdquo;, in <em>Mapping the Dynamics
of Science and Technology: Sociology of Science in the Real
World</em>, Michel Callon, John Law and Arie Rip (eds.), London:
Macmillan, pp. 19-34.</li>
 
<li>Cranor, Carl F., 1990, &ldquo;Some Moral Issues in Risk
Assessment&rdquo;, <em>Ethics</em>, 101(1): 123&ndash;143.
doi:10.1086/293263</li>

<li>Darwin, C. R., 1859, <em>On the Origin of Species by Means of
Natural Selection, or the Preservation of Favoured Races in the
Struggle for Life</em>, London: John Murray.</li>

<li>Davis, Michael, 1998, <em>Thinking Like an Engineer: Studies in
the Ethics of a Profession</em>, New York/Oxford: Oxford University
Press.</li>

<li>&ndash;&ndash;&ndash;, 2005, <em>Engineering Ethics</em>,
Aldershot/Burlington, VT: Ashgate.</li>

<li>&ndash;&ndash;&ndash;, 2012, &ldquo;&lsquo;Ain&rsquo;t No One Here
But Us Social Forces&rsquo;: Constructing the Professional
Responsibility of Engineers&rdquo;, <em>Science and Engineering
Ethics</em>, 18(1): 13&ndash;34. doi:10.1007/s11948-010-9225-3</li>

<li>Dennett, Daniel C., 1997, &ldquo;When HAL kills, who&rsquo;s to
blame? Computer ethics&rdquo;, in <em>HAL&rsquo;s Legacy: 2001&rsquo;s
Computer as Dream and Reality</em>, edited by David G. Stork.
Cambridge, MA: MIT Press, pp. 351&ndash;365.</li>

<li>Diels, H., 1903, <em>Die Fragmente der Vorsokratiker</em>,
Berlin: Weidmann.
</li>

<li>Dipert, Randall R., 1993, <em>Artifacts, Art Works, and
Agency</em>, Philadelphia: Temple University Press.</li>

<li>Doorn, Neelke, 2010, &ldquo;A Rawlsian Approach to Distribute
Responsibilities in Networks&rdquo;, <em>Science and Engineering
Ethics</em>, 16(2): 221&ndash;249. doi:10.1007/s11948-009-9155-0</li>

<li>&ndash;&ndash;&ndash;, 2012, &ldquo;Responsibility Ascriptions in
Technology Development and Engineering: Three Perspectives&rdquo;,
<em>Science and Engineering Ethics</em>, 18(1): 69&ndash;90.
doi:10.1007/s11948-009-9189-3</li>

<li>Ellul, Jacques, 1954 [1964], <em>La technique ou L'enjeu du
si&egrave;cle</em>, Paris: Armand Colin. Translated as <em>The
Technological Society</em>, by John Wilkinson, New York: Alfred A.
Knopf, 1964.</li>

<li>Erlandson, Robert F., 2008, <em>Universal and Accessible Design
for Products, Services, and Processes</em>, Boca Raton, LA: CRC
Press.</li>

<li>Feenberg, Andrew, 1999, <em>Questioning Technology</em>,
London/New York: Routledge.</li>

<li>Finnis, John, Joseph Boyle and Germain Grisez, 1988, <em>Nuclear
Deterrence, Morality and Realism</em>, Oxford: Oxford University
Press.</li>

<li>Floridi, Luciano, 2010, <em>The Cambridge Handbook of Information
and Computer Ethics</em>, Cambridge: Cambridge University Press.
doi:10.1017/CBO9780511845239</li>

<li>Floridi, Luciano and J.W. Sanders, 2004, &ldquo;On the Morality of
Artificial Agents&rdquo;, <em>Minds and Machines</em>, 14(3):
349&ndash;379. doi:10.1023/B:MIND.0000035461.63578.9d</li>

<li>Fox, Warwick, 2000, <em>Ethics and the Built Environment</em>,
(Professional Ethics), London/New York: Routledge.</li>

<li>Franssen, Maarten, 2005, &ldquo;Arrow&rsquo;s Theorem,
Multi-Criteria Decision Problems and Multi-Attribute Preferences in
Engineering Design&rdquo;, <em>Research in Engineering Design</em>,
16(1&ndash;2): 42&ndash;56. doi:10.1007/s00163-004-0057-5</li>

<li>Franssen, Maarten and Louis L. Bucciarelli, 2004, &ldquo;On
Rationality in Engineering Design&rdquo;, <em>Journal of Mechanical
Design</em>, 126(6): 945&ndash;949. doi:10.1115/1.1803850</li>

<li>Franssen, Maarten and Stefan Koller, 2016, &ldquo;Philosophy of
Technology as a Serious Branch of Philosophy: The Empirical Turn as a
Starting Point&rdquo;, in 2016, <em>Philosophy of Technology after the
Empirical Turn</em>, (Philosophy of Engineering and Technology, 23),
Maarten Franssen, Pieter E. Vermaas, Peter Kroes, and Anthonie W.M.
Meijers (eds.), Cham: Springer International Publishing, 31&ndash;61.
doi:10.1007/978-3-319-33717-3_3</li>

<li>Franssen, Maarten, Peter Kroes, Thomas A.C. Reydon and Pieter E.
Vermaas (eds), 2014, <em>Artefact Kinds: Ontology and the Human-Made
World</em>, Heidelberg/New York/Dordrecht/London: Springer.
doi:10.1007/978-3-319-00801-1</li>

<li>Freeman, K., 1948, <em>Ancilla to the Pre-Socratic
Philosophers</em> (<em>A complete translation of the Fragments in
Diels, Fragmente der Vorsokratiker</em>), Cambridge, MA: Harvard
University Press.</li>

<li>Frey, R. G. and Christopher Heath Wellman (eds), 2003, <em>A
Companion to Applied Ethics</em>, Oxford/Malden, MA: Blackwell.
doi:10.1002/9780470996621</li>

<li>Friedman, Batya and Peter H. Kahn, Jr., 2003, &ldquo;Human Values,
Ethics and Design&rdquo;, in <em>Handbook of Human-Computer
Interaction: Fundamentals, Evolving Technologies, and Emerging
Applications</em>, edited by Julie A. Jacko and Andrew Sears, Mahwah,
NJ: Lawrence Erlbaum, pp. 1177&ndash;1201.</li>

<li>Gehlen, Arnold, 1957, <em>Die Seele im technischen Zeitalter</em>,
Hamburg: Rowohlt; translated as <em>Man in the Age of Technology</em>,
Patricia Lipscomb (trans.), New York: Columbia University Press,
1980.</li>

<li>Habermas, J&uuml;rgen, 1968 [1970], &ldquo;Technik und
Wissenschaft als &lsquo;Ideologie&rsquo;&rdquo; in an an anthology of
the same name, Frankfurt: Suhrkamp Verlag. Translated as
&ldquo;Technology and Science as &lsquo;Ideology&rsquo;&rdquo;, in his
<em>Toward a Rational Society: Student Protest, Science, and
Politics</em>, Jeremy J. Shapiro (trans.), Boston, MA: Beacon Press,
pp. 81&ndash;122.</li>

<li>Hansson, Sven Ove, 2003, &ldquo;Ethical Criteria of Risk
Acceptance&rdquo;, <em>Erkenntnis</em>, 59(3): 291&ndash;309.
doi:10.1023/A:1026005915919</li>

<li>&ndash;&ndash;&ndash;, 2004a, &ldquo;Fallacies of Risk&rdquo;,
<em>Journal of Risk Research</em>, 7(3): 353&ndash;360.
doi:10.1080/1366987042000176262</li>

<li>&ndash;&ndash;&ndash;, 2004b, &ldquo;Philosophical Perspectives on
Risk&rdquo;, <em>Techn&eacute;</em>, 8(1): 10&ndash;35.
doi:10.5840/techne2004818</li>

<li>&ndash;&ndash;&ndash;, 2007, &ldquo;Philosophical Problems in
Cost-Benefit Analysis&rdquo;, <em>Economics and Philosophy</em>,
23(2): 163&ndash;183. doi:10.1017/S0266267107001356</li>

<li>Harris, Charles E., Michael S. Pritchard and Michael J. Rabins,
2008, <em>Engineering Ethics: Concepts and Cases</em>, fourth edition,
Belmont, CA: Wadsworth.</li>

<li>Heidegger, Martin, 1954 [1977], &ldquo;Die Frage nach der Technik&rdquo;, in
<em>Vortr&auml;ge und Aufs&auml;tze</em>, Pfullingen: G&uuml;nther Neske; translated
as &ldquo;The Question concerning Technology&rdquo;, in <em>The Question Concerning
Technology and Other Essays</em>, William Lovitt (trans.), New York:
Harper and Row, 1977, pp. 3&ndash;35.</li>

<li>Herkert, Joseph R., 2001, &ldquo;Future Directions in Engineering
Ethics Research: Microethics, Macroethics and the Role of Professional
Societies&rdquo;, <em>Science and Engineering Ethics</em>, 7(3):
403&ndash;414. doi:10.1007/s11948-001-0062-2</li>

<li>Hilpinen, Risto, 1992, &ldquo;Artifacts and Works of Art&rdquo;,
<em>Theoria</em>, 58(1): 58&ndash;82.
doi:10.1111/j.1755-2567.1992.tb01155.x</li>

<li>Holt, Raymond and Catherine Barnes, 2010, &ldquo;Towards an
Integrated Approach to &lsquo;Design for X&rsquo;: An Agenda for
Decision-Based DFX Research&rdquo;, <em>Research in Engineering
Design</em>, 21(2): 123&ndash;136. doi:10.1007/s00163-009-0081-6</li>

<li>Horkheimer, Max and Theodor W. Adorno, 1947 [2002], <em>Dialektik
der Aufkl&auml;rung: Philosophische Fragmente</em>, Amsterdam: Querido
Verlag; translated as <em>Dialectic of Enlightenment: Philosophical
Fragments</em>, Gunzelin Schmid Noerr (ed.), Edmund Jephcott (trans.),
Stanford, CA: Stanford University Press, 2002.</li>

<li>Houkes, Wybo, 2009, &ldquo;The Nature of Technological
Knowledge&rdquo;, in Meijers 2009: 309&ndash;350.
doi:10.1016/B978-0-444-51667-1.50016-1</li>

<li>Houkes, Wybo and Pieter E. Vermaas, 2010, <em>Technical Functions:
on the Use and Design of Artefacts</em>, Dordrecht/Heidelberg/London
/New York: Springer. doi:10.1007/978-90-481-3900-2</li>

<li>Hughes, Jesse, Peter A. Kroes, and Sjoerd Zwart, 2007, &ldquo;A
Semantics for Means-End Relations&rdquo;, <em>Synthese</em>, 158(2):
207&ndash;231. doi:10.1007/s11229-006-9036-x</li>

<li>Ihde, Don, 1979, <em>Technics and Praxis</em>,
Dordrecht/Boston/Lancaster: D. Reidel.</li>

<li>&ndash;&ndash;&ndash;, 1990, <em>Technology and the Lifeworld:
from Garden to Earth</em>, Bloomington: Indiana University Press.</li>

<li>&ndash;&ndash;&ndash;, 1993, <em>Philosophy of Technology: An
Introduction</em>, New York: Paragon.</li>

<li>Ihde, Don and Evan Selinger, 2003, <em>Chasing Technoscience:
Matrix for Materiality</em>, Bloomington: Indiana University
Press.</li>

<li>Illies, Christian and Anthonie Meijers, 2009, &ldquo;Artefacts
Without Agency&rdquo;, <em>The Monist</em>, 92(3): 420&ndash;440.
doi:10.5840/monist200992324</li>

<li>Jarvie, Ian C., 1966, &ldquo;The Social Character of Technological
Problems: Comments on Skolimowski&rsquo;s Paper&rdquo;, <em>Technology
and Culture</em>, 7(3): 384&ndash;390. doi:10.2307/3101936</li>

<li>Johnson, Deborah G., 2003, &ldquo;Computer Ethics&rdquo;, in Frey
and Wellman 2003: 608&ndash;619. doi:10.1002/9780470996621.ch45</li>

<li>&ndash;&ndash;&ndash;, 2006, &ldquo;Computer Systems: Moral
Entities But Not Moral Agents&rdquo;, <em>Ethics and Information
Technology</em>, 8(4): 195&ndash;205.
doi:10.1007/s10676-006-9111-5</li>

<li>&ndash;&ndash;&ndash;, 2009, <em>Computer Ethics</em>, fourth
edition. Upper Saddle River, NJ: Prentice Hall.</li>

<li>Johnson, Deborah G. and Thomas M. Powers, 2005, &ldquo;Computer
Systems and Responsibility: A Normative Look at Technological
Complexity&rdquo;, <em>Ethics and Information Technology</em>, 7(2):
99&ndash;107. doi:10.1007/s10676-005-4585-0</li>

<li>Jonas, Hans, 1979 [1984], <em>Das Prinzip Verantwortung: Versuch
einer Ethik f&uuml;r die technologische Zivilisation</em>,
Frankfurt/Main: Suhrkamp; extended English edition <em>The Imperative
of Responsibility: in Search of An Ethics for the Technological
Age</em>, Chicago/London: University of Chicago Press, 1984.</li>

<li>Kaplan, David M. (ed.), 2004 [2009], <em>Readings in the
Philosophy of Technology</em>, Lanham, MD/Oxford: Rowman and
Littlefield, first edition 2004, second revised edition 2009.</li>

<li>Kapp, Ernst, 1877 [2018], <em>Grundlinien Einer Philosophie Der
Technik: Zur Entstehungsgeschichte Der Cultur Aus Neuen
Gesichtspunkten</em>, Braunschweig: Westermann 
[<a href="http://archive.org/details/grundlinieneine00kappgoog" target="other">Kapp 1877 available online</a>]; 
translated as <em>Elements of a Philosophy of Technology: On the Evolutionary
History of Culture</em>, Jeffrey West Kirkwood and Leif Weatherby
(eds.), Lauren K. Wolfe (trans.), Minneapolis, MN: University of
Minnesota Press, 2018.</li>
 
<li>Keulartz, Jozef, Michiel Korthals, Maartje Schermer, and Tsjalling
Swierstra (eds), 2002, <em>Pragmatist Ethics for a Technological
Culture</em>, Dordrecht: Kluwer Academic.
doi:10.1007/978-94-010-0301-8</li>

<li>Kitcher, Philip, 2001, <em>Science, Truth, and Democracy</em>,
Oxford, New York: Oxford University Press.</li>

<li>&ndash;&ndash;&ndash;, 2011. <em>The Ethical Project</em>,
Cambridge, MA: Harvard University Press.</li>

<li>Kneese, Allen V., Shaul Ben-David and William D. Schulze, 1983,
&ldquo;The Ethical Foundations of Benefit-Cost Analysis&rdquo;, in
<em>Energy and the Future</em>, edited by Douglas E. MacLean and Peter
G. Brown, Totowa, NJ: Rowman and Littefield, pp. 59&ndash;74.</li>

<li>Kotarbinski, Tadeusz, 1965, <em>Praxiology: An Introduction to the
Sciences of Efficient Action</em>, Oxford: Pergamon Press.</li>

<li>Kroes, Peter, 2012, <em>Technical Artefacts: Creations of Mind and
Matter</em>, Dordrecht/Heidelberg/New York/London: Springer.
doi:10.1007/978-94-007-3940-6</li>

<li>Kroes, Peter and Anthonie Meijers (eds), 2006, &ldquo;The Dual
Nature of Technical Artifacts&rdquo;, Special issue of <em>Studies in
History and Philosophy of Science</em>, 37(1): 1&ndash;158.
doi:10.1016/j.shpsa.2005.12.001</li>

<li>Kroes, Peter, Maarten Franssen, and Louis Bucciarelli, 2009,
&ldquo;Rationality in Design&rdquo;, in Meijers 2009: 565&ndash;600.

doi:10.1016/B978-0-444-51667-1.50025-2</li>

<li>Kroes, Peter and Peter-Paul Verbeek (eds), 2014, <em>The Moral

Status of Technical Artefacts</em>, Dordrecht: Springer.

doi:10.1007/978-94-007-7914-3</li>

<li>Kuhn, Thomas S., 1962, <em>The Structure of Scientific
Revolutions</em>, Chicago: University of Chicago Press.</li>

<li>Ladd, John, 1991, &ldquo;Bhopal: An Essay on Moral Responsibility

and Civic Virtue&rdquo;, <em>Journal of Social Philosophy</em>, 22(1):

73&ndash;91. doi:10.1111/j.1467-9833.1991.tb00022.x</li>

<li>Latour, Bruno, 1992, &ldquo;Where Are the Missing Masses?&rdquo;,

in Bijker and Law 1992: 225&ndash;258.</li>

<li>&ndash;&ndash;&ndash;, 1993, <em>We Have Never Been Modern</em>,
New York: Harvester Wheatsheaf.</li>

<li>&ndash;&ndash;&ndash;, 2005, <em>Reassembling the Social: An
Introduction to Actor-Network-Theory</em>, Oxford, New York: Oxford
University Press.</li>

<li>Lawson, Clive, 2008, &ldquo;An Ontology of Technology: Artefacts,
Relations and Functions&rdquo;, <em>Techn&egrave;</em>, 12(1):
48&ndash;64. doi:10.5840/techne200812114</li>

<li>&ndash;&ndash;&ndash;, 2017, <em>Technology and Isolation</em>,
Cambridge/New York: Cambridge University Press.
doi:10.1017/9781316848319</li>

<li>Lin, Patrick, Keith Abney and Ryan Jenkins (eds), 2017, <em>Robot
Ethics 2.0: From Autonomous Cars to Artificial Intelligence</em>,
Oxford/New York: Oxford University Press.</li>

<li>Lloyd, G.E.R., 1973, &ldquo;Analogy in Early Greek Thought&rdquo;,
in <em>The Dictionary of the History of Ideas</em>, edited by Philip
P. Wiener, New York: Charles Scribner&rsquo;s Sons, vol. 1 pp.
60&ndash;64.
 [<a href="http://xtf.lib.virginia.edu/xtf/view?docId=DicHist/uvaBook/tei/DicHist1.xml;chunk.id=dv1-09;toc.depth=1;toc.id=dv1-09;brand=default" target="other">Lloyd 1973 available online</a>]</li>
 
<li>Lloyd, Peter A. and Jerry A. Busby, 2003, &ldquo;&lsquo;Things
that Went Well&mdash;No Serious Injuries or Deaths&rsquo;: Ethical
Reasoning in a Normal Engineering Design Process&rdquo;, <em>Science
and Engineering Ethics</em>, 9(4): 503&ndash;516.
doi:10.1007/s11948-003-0047-4</li>

<li>Mahner, Martin and Mario Bunge, 2001, &ldquo;Function and
Functionalism: A Synthetic Perspective&rdquo;, <em>Philosophy of
Science</em>, 68(1): 73&ndash;94. doi:10.1086/392867</li>

<li>Marcuse, Herbert, 1964, <em>One-Dimensional Man: Studies in the
Ideology of Advanced Industrial Society</em>, New York: Beacon
Press/London: Routledge and Kegan Paul.</li>

<li>Martin, Miles W. and Roland Schinzinger, 2005, <em>Ethics in
Engineering</em>, fourth edition, Boston, MA: McGraw-Hill.</li>

<li>McGinn, Robert E., 2010, &ldquo;What&rsquo;s Different, Ethically,
About Nanotechnology? Foundational Questions and Answers&rdquo;,
<em>NanoEthics</em>, 4(2): 115&ndash;128.
doi:10.1007/s11569-010-0089-4</li>

<li>Meijers, Anthonie (ed.), 2009, <em>Philosophy of Technology and
Engineering Sciences</em>, (Handbook of the Philosophy of Science,
volume 9), Amsterdam: North-Holland.</li>

<li>Millikan, Ruth Garrett, 1999, &ldquo;Wings, Spoons, Pills, and
Quills: A Pluralist Theory of Function&rdquo;, <em>The Journal of
Philosophy</em>, 96(4): 191&ndash;206. doi:10.5840/jphil199996428</li>

<li>Mitcham, Carl, 1994, <em>Thinking Through Technology: The Path
Between Engineering and Philosophy</em>, Chicago: University of
Chicago Press.</li>

<li>Mittelstadt, Brent Daniel, Patrick Allo, Mariarosaria Taddeo,
Sandra Wachter and Luciano Floridi, 2016, &ldquo;The Ethics of
Algorithms: Mapping the Debate&rdquo;, <em>Big Data &amp;
Society</em>, 3(2): 1&ndash;21. doi:10.1177/2053951716679679</li>

<li>Moor, James H., 1985, &ldquo;What is Computer Ethics?&rdquo;
<em>Metaphilosophy</em>, 16(4): 266&ndash;275.
doi:10.1111/j.1467-9973.1985.tb00173.x</li>

<li>&ndash;&ndash;&ndash;, 2006, &ldquo;The Nature, Importance, and
Difficulty of Machine Ethics&rdquo;, <em>IEEE Intelligent
Systems</em>, 21(4): 18&ndash;21. doi:10.1109/MIS.2006.80</li>

<li>Mumford, Lewis, 1934, <em>Technics and Civilization</em>, New
York: Harcourt, Brace and Company/London: Routledge and Kegan
Paul.</li>

<li>Newman, William R., 2004, <em>Promethean Ambitions: Alchemy and
the Quest to Perfect Nature</em>, Chicago: University of Chicago
Press.</li>

<li>Niiniluoto, Ilkka, 1993, &ldquo;The Aim and Structure of Applied
Research&rdquo;, <em>Erkenntnis</em>, 38(1): 1&ndash;21.
doi:10.1007/BF01129020</li>

<li>Nissenbaum, Helen, 1996, &ldquo;Accountability in a Computerized
Society&rdquo;, <em>Science and Engineering Ethics</em>, 2(1):
25&ndash;42. doi:10.1007/BF02639315</li>

<li>Nucci, Ezio Di and Filippo Santoni de Sio, 2016, <em>Drones and
Responsibility: Legal, Philosophical and Socio-Technical Perspectives
on Remotely Controlled Weapons</em>, Milton Park: Routledge.</li>

<li>Olsen, Jan Kyrre Berg, Evan Selinger and S&oslash;ren Riis (eds),
2009, <em>New Waves in Philosophy of Technology</em>, Basingstoke/New
York: Palgrave Macmillan. doi:10.1057/9780230227279</li>

<li>Owen, Richard, John Bessant, and Maggy Heintz, 2013,
<em>Responsible Innovation: Managing the Responsible Emergence of
Science and Innovation in Society</em>, Chichester: John Wiley.
doi:10.1002/9781118551424</li>

<li>Peterson, Martin and Andreas Spahn, 2011, &ldquo;Can Technological
Artefacts be Moral Agents?&rdquo; <em>Science and Engineering
Ethics</em>, 17(3): 411&ndash;424. doi:10.1007/s11948-010-9241-3</li>

<li>Pitt, Joseph C., 1999, <em>Thinking About Technology: Foundations
of the Philosophy of Technology</em>, New York: Seven Bridges
Press.</li>

<li>Plato, <em>Laws</em>, 2016, M. Schofield (ed.), T. Griffith (tr.),
Cambridge: Cambridge University Press.</li>

<li>&ndash;&ndash;&ndash;, <em>Timaeus and Critias</em>, 2008,
R. Waterfield (tr.), with introduction and notes by A. Gregory,
Oxford: Oxford University Press.</li>

<li>Polanyi, Michael, 1958, <em>Personal Knowledge: Towards a
Post-Critical Philosophy</em>, London: Routledge and Kegan Paul.</li>

<li>Preston, Beth, 1998, &ldquo;Why is a Wing Like a Spoon? A
Pluralist Theory of Function&rdquo;, <em>The Journal of
Philosophy</em>, 95(5): 215&ndash;254. doi:10.2307/2564689</li>

<li>&ndash;&ndash;&ndash;, 2003, &ldquo;Of Marigold Beer: A Reply to
Vermaas and Houkes&rdquo;, <em>British Journal for the Philosophy of
Science</em>, 54(4): 601&ndash;612. doi:10.1093/bjps/54.4.601</li>

<li>&ndash;&ndash;&ndash;, 2012, <em>A Philosophy of Material Culture:
Action, Function, and Mind</em>, New York/Milton Park: Routledge.</li>

<li>Preston, Christopher J. (ed.), 2016, <em>Climate Justice and
Geoengineering: Ethics and Policy in the Atmospheric
Anthropocene</em>, London/New York: Rowman &amp; Littlefield
International.</li>

<li>Radder, Hans, 2009, &ldquo;Why Technologies Are Inherently
Normative&rdquo;, in Meijers 2009: 887&ndash;921.
doi:10.1016/B978-0-444-51667-1.50037-9</li>

<li>Roeser, Sabine, 2012, &ldquo;Moral Emotions as Guide to Acceptable
Risk&rdquo;, in Roeser et al. 2012: 819&ndash;832.
doi:10.1007/978-94-007-1433-5_32</li>

<li>Roeser, Sabine, Rafaela Hillerbrand, Per Sandin, and Martin
Peterson (eds), 2012, <em>Handbook of Risk Theory: Epistemology,
Decision Theory, Ethics, and Social Implications of Risk</em>,
Dordrecht/Heidelberg/London/New York: Springer.
doi:10.1007/978-94-007-1433-5</li>

<li>Ryle, Gilbert, 1949, <em>The Concept of Mind</em>, London:
Hutchinson.</li>

<li>Scharff, Robert C. and Val Dusek (eds), 2003 [2014],
<em>Philosophy of Technology: The Technological Condition</em>,
Malden, MA/Oxford: Blackwell, first edition 2003, second [revised]
edition 2014.</li>

<li>Schummer, Joachim, 2001, &ldquo;Aristotle on Technology and
Nature&rdquo;, <em>Philosophia Naturalis</em>, 38: 105&ndash;120.</li>

<li>Sclove, Richard E., 1995, <em>Democracy and Technology</em>, New
York: The Guilford Press.</li>

<li>Sellars, Wilfrid, 1962, &ldquo;Philosophy and the Scientific Image
of Man&rdquo;, in <em>Frontiers of Science and Philosophy</em>, edited
by R. Colodny, Pittsburgh: University of Pittsburgh Press, pp.
35&ndash;78.</li>

<li>Sherlock, Richard and John D. Morrey (eds), 2002, <em>Ethical
Issues in Biotechnology</em>, Lanham: Rowman and Littlefield.</li>

<li>Shrader-Frechette, Kristen S., 1985, <em>Risk Analysis and
Scientific Method: Methodological and Ethical Problems with Evaluating
Societal Hazards</em>, Dordrecht/Boston: D. Reidel.</li>

<li>&ndash;&ndash;&ndash;, 1991, <em>Risk and Rationality:
Philosophical Foundations for Populist Reform</em>, Berkeley etc.:
University of California Press.</li>

<li>Simon, Herbert A., 1957, <em>Models of Man, Social and Rational:
Mathematical Essays on Rational Human Behavior in a Social
Setting</em>, New York: John Wiley.</li>

<li>&ndash;&ndash;&ndash;, 1969, <em>The Sciences of the
Artificial</em>, Cambridge, MA/London: MIT Press.</li>

<li>&ndash;&ndash;&ndash;, 1982, <em>Models of Bounded
Rationality</em>, Cambridge, MA/London: MIT Press.</li>

<li>Skolimowski, Henryk, 1966, &ldquo;The Structure of Thinking in
Technology&rdquo;, <em>Technology and Culture</em>, 7(3):
371&ndash;383. doi:10.2307/3101935</li>

<li>Snapper, John W., 1985, &ldquo;Responsibility for Computer-Based
Errors&rdquo;, <em>Metaphilosophy</em>, 16(4): 289&ndash;295.
doi:10.1111/j.1467-9973.1985.tb00175.x</li>

<li>Soavi, Marzia, 2009, &ldquo;Realism and Artifact Kinds&rdquo;, in
<em>Functions in Biological and Artificial Worlds: Comparative
Philosophical Perspectives</em>, edited by Ulrich Krohs and Peter
Kroes. Cambridge, MA: MIT Press, pp. 185&ndash;202.
doi:10.7551/mitpress/9780262113212.003.0011 </li>

<li>Suh, Nam Pyo, 2001, <em>Axiomatic Design: Advances and
Applications</em>, Oxford/New York: Oxford University Press.</li>

<li>Swierstra, Tsjalling and Jaap Jelsma, 2006, &ldquo;Responsibility
Without Moralism in Technoscientific Design Practice&rdquo;,
<em>Science, Technology and Human Values</em>, 31(1): 309&ndash;332.
doi:10.1177/0162243905285844</li>

<li>Swierstra, Tsjalling and Hedwig te Molder, 2012, &ldquo;Risk and
Soft Impacts&rdquo;, in Roeser et al. 2012: 1049&ndash;1066.
doi:10.1007/978-94-007-1433-5_42</li>

<li>Taebi, Behnam and Sabine Roeser (eds), 2015, <em>The Ethics of
Nuclear Energy: Risk, Justice, and Democracy in the Post-Fukushima
Era</em>, Cambridge: Cambridge University Press.
doi:10.1017/CBO9781107294905</li>

<li>Tavani, Herman T., 2002, &ldquo;The Uniqueness Debate in Computer
Ethics: What Exactly is at Issue, and Why Does it Matter?&rdquo;
<em>Ethics and Information Technology</em>, 4(1): 37&ndash;54.
doi:10.1023/A:1015283808882</li>

<li>Thomasson, Amie L., 2003, &ldquo;Realism and Human Kinds&rdquo;,
<em>Philosophy and Phenomenological Research</em>, 67(3):
580&ndash;609. doi:10.1111/j.1933-1592.2003.tb00309.x</li>

<li>&ndash;&ndash;&ndash;, 2007, &ldquo;Artifacts and Human
Concepts&rdquo;, in <em>Creations of the Mind: Essays on Artifacts and
Their Representation</em>, edited by Eric Margolis and Stephen
Laurence, Oxford: Oxford University Press, pp. 52&ndash;73.</li>

<li>Thompson, Dennis F., 1980, &ldquo;Moral Responsibility and Public
Officials: The Problem of Many Hands&rdquo;, <em>American Political
Science Review</em>, 74(4): 905&ndash;916. doi:10.2307/1954312</li>

<li>Thompson, Paul B., 2007, <em>Food Biotechnology in Ethical
Perspective</em>, second edition, Dordrecht: Springer.
doi:10.1007/1-4020-5791-1</li>

<li>van den Hoven, Jeroen and John Weckert (eds), 2008,
<em>Information Technology and Moral Philosophy</em>, Cambridge/New
York: Cambridge University Press.</li>

<li>van den Hoven, Jeroen, Pieter E. Vermaas and Ibo van de Poel
(eds), 2015, <em>Handbook of Ethics and Values in Technological
Design: Sources, Theory, Values and Application Domains</em>,
Dordrecht: Springer. doi:10.1007/978-94-007-6994-6</li>

<li>van de Poel, Ibo, 2009, &ldquo;Values in Engineering
Design&rdquo;, in Meijers 2009: 973&ndash;1006.
doi:10.1016/B978-0-444-51667-1.50040-9</li>

<li>&ndash;&ndash;&ndash;, 2016, &ldquo;An Ethical Framework for
Evaluating Experimental Technology&rdquo;, <em>Science and Engineering
Ethics</em>, 22(3): 667&ndash;686. doi:10.1007/s11948-015-9724-3</li>

<li>van de Poel, Ibo and Lamb&egrave;r Royakkers, 2011, <em>Ethics,
Technology and Engineering</em>, Oxford: Wiley-Blackwell.</li>

<li>van de Poel, Ibo, Lamb&egrave;r Royakkers, and Sjoerd D. Zwart,
2015, <em>Moral Responsibility and the Problem of Many Hands</em>,
London: Routledge.</li>

<li>van der Pot, Johan Hendrik Jacob, 1985 [1994/2004], <em>Die
Bewertung des technischen Fortschritts: eine systematische
&Uuml;bersicht der Theorien</em>, 2 volumes, Assen/Maastricht: Van
Gorcum; translated as <em>Steward or Sorcerer&rsquo;s Apprentice? the
Evaluation of Technical Progress: A Systematic Overview of Theories
and Opinions</em>, Chris Turner (trans.), 2 volumes., Delft: Eburon,
1994, second edition, 2004, under the title <em>Encyclopedia of
Technological Progress: A Systematic Overview of Theories and
Opinions</em>.</li>

<li>Verbeek, Peter-Paul, 2000 [2005], <em>De daadkracht der Dingen:
Over Techniek, Filosofie En Vormgeving</em>, Amsterdam: Boom.
Translated as <em>What Things Do: Philosophical Reflections on
Technology, Agency, and Design</em>, by Robert P. Crease. University
Park, PA: Penn State University Press, 2005.</li>

<li>&ndash;&ndash;&ndash;, 2011, <em>Moralizing Technology:
Understanding and Designing the Morality of Things</em>,
Chicago/London: The University of Chicago Press.</li>

<li>Vermaas, Peter E. and Wybo Houkes, 2003, &ldquo;Ascribing
Functions to Technical Artefacts: A Challenge to Etiological Accounts
of Functions&rdquo;, <em>British Journal for the Philosophy of
Science</em>, 54(2): 261&ndash;289. doi:10.1093/bjps/54.2.261</li>

<li>Vincenti, Walter A., 1990, <em>What Engineers Know and How They
Know It: Analytical Studies from Aeronautical History</em>, Baltimore,
MD/London: Johns Hopkins University Press.</li>

<li>Vitruvius, first ct BC, <em>De architecture</em>, translated as
<em>The Ten Books on Architecture</em>, by Morris H. Morgan.
Cambridge, MA: Harvard University Press, 1914.
 [<a href="http://www.gutenberg.org/ebooks/20239" target="other">Vitruvius Morgan's translation 1914 available online</a>]</li>
 
<li>Volti, Rudi, 2009, <em>Society and Technological Change</em>,
sixth edition, New York: Worth Publications.</li>

<li>Von Wright, Georg Henrik, 1963, <em>Norm and Action: A Logical
Enquiry</em>, London: Routledge and Kegan Paul.</li>

<li>Wallach, Wendell, and Colin Allen, 2009, <em>Moral Machines:
Teaching Robots Right from Wrong</em>, Oxford/New York: Oxford
University Press. doi:10.1093/acprof:oso/9780195374049.001.0001</li>

<li>Weckert, John, 2007, <em>Computer Ethics</em>,
Aldershot/Burlington, VT: Ashgate.</li>

<li>Wiggins, David, 1980, <em>Sameness and Substance</em>, Oxford:
Blackwell.</li>

<li>Winner, Langdon, 1977, <em>Autonomous Technology:
Technics-out-of-Control as a Theme in Political Thought</em>,
Cambridge, MA, London: MIT Press.</li>

<li>&ndash;&ndash;&ndash;, 1980, &ldquo;Do Artifacts Have Politics?&rdquo;
<em>Daedalus</em>, 109(1): 121&ndash;136.</li>

<li>&ndash;&ndash;&ndash;, 1983, &ldquo;Techn&eacute; and Politeia:
The Technical Constitution of Society&rdquo;, in <em>Philosophy and
Technology</em>, (Boston studies in the philosophy of science vol.
80), edited by Paul T. Durbin and Friedrich Rapp.
Dordrecht/Boston/Lancaster: D. Reidel, pp. 97&ndash;111.
doi:10.1007/978-94-009-7124-0_7</li>

<li>Zandvoort, H., 2000, &ldquo;Codes of Conduct, the Law, and
Technological Design and Development&rdquo;, in <em>The Empirical Turn
in the Philosophy of Technology</em>, edited by Peter Kroes and
Anthonie Meijers, Amsterdam: JAI/Elsevier, pp. 193&ndash;205.</li>

<li>Zwart, Sjoerd D., Ibo van de Poel, Harald van Mil and Michiel
Brumsen, 2006, &ldquo;A Network Approach for Distinguishing Ethical
Issues in Research and Development&rdquo;, <em>Science and Engineering
Ethics</em>, 12(4): 663&ndash;684. doi:10.1007/s11948-006-0063-2</li>
</ul>

<h3 id="Jour">Journals</h3>


<ul>

 <li><em>Philosophy &amp; Technology</em></li>
 
 <li><a href="http://scholar.lib.vt.edu/ejournals/SPT/" target="other"><em>Techn&eacute;: Research in Philosophy and Technology</em></a></li>
 
 <li><em>Science and Engineering Ethics</em></li>
 
 <li><a href="http://sth.sagepub.com/" target="other"><em>Science, Technology &amp; Human Values</em></a></li>
 
 <li><em>Ethics and Information Technology</em></li>
 
 <li><em>NanoEthics</em></li>
 
 <li><em>Neuroethics</em></li>
 </ul>

<h3 id="Ency">Encyclopedias</h3>

<ul>

<li><em>Encyclopedia of Science, Technology, and Ethics</em>, 4
volumes, Carl Mitcham (ed.), Macmillan, 2005.</li>

<li><em>Encyclopedia of Applied Ethics</em>, second edition, 4
volumes, Ruth Chadwick (editor-in-chief), Elsevier, 2012.</li>

</ul>

</div>

<div id="academic-tools">

<h2 id="Aca">Academic Tools</h2>

<blockquote>
<table class="vert-top">
<tr>
<td><img src="../../symbols/sepman-icon.jpg" alt="sep man icon" /></td>
<td><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=technology" target="other">How to cite this entry</a>.</td>
</tr>

<tr>
<td><img src="../../symbols/sepman-icon.jpg" alt="sep man icon" /></td>
<td><a href="https://leibniz.stanford.edu/friends/preview/technology/" target="other">Preview the PDF version of this entry</a> at the
 <a href="https://leibniz.stanford.edu/friends/" target="other">Friends of the SEP Society</a>.</td>
</tr>

<tr>
<td><img src="../../symbols/inpho.png" alt="inpho icon" /></td>
<td><a href="https://www.inphoproject.org/entity?sep=technology&amp;redirect=True" target="other">Look up topics and thinkers related to this entry</a>
 at the Internet Philosophy Ontology Project (InPhO).</td>
</tr>

<tr>
<td><img src="../../symbols/pp.gif" alt="phil papers icon" /></td>
<td><a href="http://philpapers.org/sep/technology/" target="other">Enhanced bibliography for this entry</a>
at <a href="http://philpapers.org/" target="other">PhilPapers</a>, with links to its database.</td>
</tr>

</table>
</blockquote>

</div>




<div id="other-internet-resources">

<h2 id="Oth">Other Internet Resources</h2>



<ul>

 <li><a href="http://www.spt.org/" target="other">Society for Philosophy and Technology</a></li>
 
 <!--LINK CHECKER COMMENTED OUT (Fri Mar 11 16:20:37 PST 2022)

<li><a href="http://philengtech.org/" target="other">Forum for Philosophy, Engineering &amp; Technology</a></li>

LINK CHECKER-->
 
 <!--LINK CHECKER COMMENTED OUT (Fri Mar 11 16:20:38 PST 2022)

<li><a href="http://www.onlineethics.org/" target="other">Online Ethics Center</a></li>

LINK CHECKER-->
 
 <li><a href="http://www.ethicsandtechnology.eu/" target="other">3TU.Centre for Ethics and Technology</a></li>
 
 <li><a href="http://www.practicalethics.ox.ac.uk/" target="other">Oxford Uehiro Centre for Practical Ethics</a></li>
 </ul>

</div>

<div id="related-entries">

<h2 id="Rel">Related Entries</h2>

<p>

 <a href="../aristotle-causality/index.html">Aristotle, Special Topics: causality</a> |
 <a href="../artifact/index.html">artifact</a> |
 <a href="../francis-bacon/index.html">Bacon, Francis</a> |
 <a href="../chinese-room/index.html">Chinese room argument</a> |
 <a href="../church-turing/index.html">Church-Turing Thesis</a> |
 <a href="../computability/index.html">computability and complexity</a> |
 <a href="../computer-science/index.html">computer science, philosophy of</a> |
 <a href="../computing-responsibility/index.html">computing: and moral responsibility</a> |
 <a href="../episteme-techne/index.html"><em>episteme</em> and <em>techne</em> [= scientific knowledge and expertise]</a> |
 <a href="../functionalism/index.html">functionalism</a> |
 <a href="../identity-time/index.html">identity: over time</a> |
 <a href="../identity-relative/index.html">identity: relative</a> |
 <a href="../it-moral-values/index.html">information technology: and moral values</a> |
 <a href="../knowledge-how/index.html">knowledge how</a> |
 <a href="../material-constitution/index.html">material constitution</a> |
 <a href="../computational-mind/index.html">mind: computational theory of</a> |
 <a href="../moral-responsibility/index.html">moral responsibility</a> |
 <a href="../multiple-realizability/index.html">multiple realizability</a> |
 <a href="../popper/index.html">Popper, Karl</a> |
 <a href="../practical-reason/index.html">practical reason</a> |
 <a href="../rationality-instrumental/index.html">rationality: instrumental</a> |
 <a href="../collective-responsibility/index.html">responsibility: collective</a> |
 <a href="../risk/index.html">risk</a> |
 <a href="../sortals/index.html">sortals</a> |
 <a href="../turing-machine/index.html">Turing machines</a> |
 <a href="../turing-test/index.html">Turing test</a>

</p>

</div>



<div id="acknowledgments">

<h3>Acknowledgments</h3>

<p>
The SEP Editors would like to thank Carl Mitcham for his helpful
comments on, and suggestions for, this entry. The authors would like
to thank Gintautas Miliauskas (Vilnius University) for carefully
proofreading the original version of this text and suggesting numerous
improvements.</p> 


</div>

</div><!-- #aueditable --><!--DO NOT MODIFY THIS LINE AND BELOW-->

<!-- END ARTICLE HTML -->

</div> <!-- End article-content -->

  <div id="article-copyright">
    <p>
 <a href="../../info.html#c">Copyright &copy; 2018</a> by

<br />
<a href="http://www.tbm.tudelft.nl/en/about-faculty/departments/values-technology-and-innovation/sections/ethicsphilosophy-of-technology/staff/dr-mpm-maarten-franssen/" target="other">Maarten Franssen</a>
&lt;<a href="m&#97;ilto:m&#37;2ep&#37;2em&#37;2efranssen&#37;40tudelft&#37;2enl"><em>m<abbr title=" dot ">&#46;</abbr>p<abbr title=" dot ">&#46;</abbr>m<abbr title=" dot ">&#46;</abbr>franssen<abbr title=" at ">&#64;</abbr>tudelft<abbr title=" dot ">&#46;</abbr>nl</em></a>&gt;<br />
<a href="http://gjclokhorst.nl/" target="other">Gert-Jan Lokhorst</a>
&lt;<a href="m&#97;ilto:g&#37;2ej&#37;2ec&#37;2elokhorst&#37;40tudelft&#37;2enl"><em>g<abbr title=" dot ">&#46;</abbr>j<abbr title=" dot ">&#46;</abbr>c<abbr title=" dot ">&#46;</abbr>lokhorst<abbr title=" at ">&#64;</abbr>tudelft<abbr title=" dot ">&#46;</abbr>nl</em></a>&gt;<br />
<a href="http://www.tbm.tudelft.nl/en/about-faculty/departments/values-technology-and-innovation/sections/ethicsphilosophy-of-technology/staff/profdrir-ir-ibo-van-de-poel/" target="other">Ibo van de Poel</a>
&lt;<a href="m&#97;ilto:I&#37;2eR&#37;2evandepoel&#37;40tudelft&#37;2enl"><em>I<abbr title=" dot ">&#46;</abbr>R<abbr title=" dot ">&#46;</abbr>vandepoel<abbr title=" at ">&#64;</abbr>tudelft<abbr title=" dot ">&#46;</abbr>nl</em></a>&gt;
    </p>
  </div>

</div> <!-- End article -->

<!-- NOTE: article banner is outside of the id="article" div. -->
<div id="article-banner" class="scroll-block">
  <div id="article-banner-content">
    <a href="../../fundraising/index.html">
    Open access to the SEP is made possible by a world-wide funding initiative.<br />
    The Encyclopedia Now Needs Your Support<br />
    Please Read How You Can Help Keep the Encyclopedia Free</a>
  </div>
</div> <!-- End article-banner -->

    </div> <!-- End content -->

    <div id="footer">

      <div id="footer-menu">
        <div class="menu-block">
          <h4><i class="icon-book"></i> Browse</h4>
          <ul role="menu">
            <li><a href="../../contents.html">Table of Contents</a></li>
            <li><a href="../../new.html">What's New</a></li>
            <li><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/random">Random Entry</a></li>
            <li><a href="../../published.html">Chronological</a></li>
            <li><a href="../../archives/index.html">Archives</a></li>
          </ul>
        </div>
        <div class="menu-block">
          <h4><i class="icon-info-sign"></i> About</h4>
          <ul role="menu">
            <li><a href="../../info.html">Editorial Information</a></li>
            <li><a href="../../about.html">About the SEP</a></li>
            <li><a href="../../board.html">Editorial Board</a></li>
            <li><a href="../../cite.html">How to Cite the SEP</a></li>
            <li><a href="../../special-characters.html">Special Characters</a></li>
            <li><a href="../../tools/index.html">Advanced Tools</a></li>
            <li><a href="../../contact.html">Contact</a></li>
          </ul>
        </div>
        <div class="menu-block">
          <h4><i class="icon-leaf"></i> Support SEP</h4>
          <ul role="menu">
            <li><a href="../../support/index.html">Support the SEP</a></li>
            <li><a href="../../support/friends.html">PDFs for SEP Friends</a></li>
            <li><a href="../../support/donate.html">Make a Donation</a></li>
            <li><a href="../../support/sepia.html">SEPIA for Libraries</a></li>
          </ul>
        </div>
      </div> <!-- End footer menu -->

      <div id="mirrors">
        <div id="mirror-info">
          <h4><i class="icon-globe"></i> Mirror Sites</h4>
          <p>View this site from another server:</p>
        </div>
        <div class="btn-group open">
          <a class="btn dropdown-toggle" data-toggle="dropdown" href="https://plato.stanford.edu/">
            <span class="flag flag-usa"></span> USA (Main Site) <span class="caret"></span>
            <span class="mirror-source">Philosophy, Stanford University</span>
          </a>
          <ul class="dropdown-menu">
            <li><a href="../../mirrors.html">Info about mirror sites</a></li>
          </ul>
        </div>
      </div> <!-- End mirrors -->
      
      <div id="site-credits">
        <p>The Stanford Encyclopedia of Philosophy is <a href="../../info.html#c">copyright &copy; 2022</a> by <a href="http://mally.stanford.edu/">The Metaphysics Research Lab</a>, Department of Philosophy, Stanford University</p>
        <p>Library of Congress Catalog Data: ISSN 1095-5054</p>
      </div> <!-- End site credits -->

    </div> <!-- End footer -->

  </div> <!-- End container -->

   <!-- NOTE: Script required for drop-down button to work (mirrors). -->
  <script>
    $('.dropdown-toggle').dropdown();
  </script>

</body>

<!-- Mirrored from seop.illc.uva.nl/entries/technology/ by HTTrack Website Copier/3.x [XR&CO'2014], Wed, 22 Jun 2022 19:55:52 GMT -->
</html>
