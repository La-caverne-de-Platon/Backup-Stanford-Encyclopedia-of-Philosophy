<!DOCTYPE html>
<!--[if lt IE 7]> <html class="ie6 ie"> <![endif]-->
<!--[if IE 7]>    <html class="ie7 ie"> <![endif]-->
<!--[if IE 8]>    <html class="ie8 ie"> <![endif]-->
<!--[if IE 9]>    <html class="ie9 ie"> <![endif]-->
<!--[if !IE]> --> <html> <!-- <![endif]-->

<!-- Mirrored from seop.illc.uva.nl/entries/computational-philosophy/ by HTTrack Website Copier/3.x [XR&CO'2014], Wed, 22 Jun 2022 19:42:48 GMT -->
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>
Computational Philosophy (Stanford Encyclopedia of Philosophy)
</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="robots" content="noarchive, noodp" />
<meta property="citation_title" content="Computational Philosophy" />
<meta property="citation_author" content="Grim, Patrick" />
<meta property="citation_author" content="Singer, Daniel" />
<meta property="citation_publication_date" content="2020/03/16" />
<meta name="DC.title" content="Computational Philosophy" />
<meta name="DC.creator" content="Grim, Patrick" />
<meta name="DC.creator" content="Singer, Daniel" />
<meta name="DCTERMS.issued" content="2020-03-16" />
<meta name="DCTERMS.modified" content="2020-03-16" />

<!-- NOTE: Import webfonts using this link: -->
<link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,300,600,200&amp;subset=latin,latin-ext" rel="stylesheet" type="text/css" />

<link rel="stylesheet" type="text/css" media="screen,handheld" href="../../css/bootstrap.min.css" />
<link rel="stylesheet" type="text/css" media="screen,handheld" href="../../css/bootstrap-responsive.min.css" />
<link rel="stylesheet" type="text/css" href="../../css/font-awesome.min.css" />
<!--[if IE 7]> <link rel="stylesheet" type="text/css" href="../../css/font-awesome-ie7.min.css"> <![endif]-->
<link rel="stylesheet" type="text/css" media="screen,handheld" href="../../css/style.css" />
<link rel="stylesheet" type="text/css" media="print" href="../../css/print.css" />
<link rel="stylesheet" type="text/css" href="../../css/entry.css" />
<!--[if IE]> <link rel="stylesheet" type="text/css" href="../../css/ie.css" /> <![endif]-->
<script type="text/javascript" src="../../js/jquery-1.9.1.min.js"></script>
<script type="text/javascript" src="../../js/bootstrap.min.js"></script>

<!-- NOTE: Javascript for sticky behavior needed on article and ToC pages -->
<script type="text/javascript" src="../../js/jquery-scrolltofixed-min.js"></script>
<script type="text/javascript" src="../../js/entry.js"></script>

<!-- SEP custom script -->
<script type="text/javascript" src="../../js/sep.js"></script>
</head>

<!-- NOTE: The nojs class is removed from the page if javascript is enabled. Otherwise, it drives the display when there is no javascript. -->
<body class="nojs article" id="pagetopright">
<div id="container">
<div id="header-wrapper">
  <div id="header">
    <div id="branding">
      <div id="site-logo"><a href="../../index.html"><img src="../../symbols/sep-man-red.png" alt="SEP home page" /></a></div>
      <div id="site-title"><a href="../../index.html">Stanford Encyclopedia of Philosophy</a></div>
    </div>
    <div id="navigation">
      <div class="navbar">
        <div class="navbar-inner">
          <div class="container">
            <button class="btn btn-navbar collapsed" data-target=".collapse-main-menu" data-toggle="collapse" type="button"> <i class="icon-reorder"></i> Menu </button>
            <div class="nav-collapse collapse-main-menu in collapse">
              <ul class="nav">
                <li class="dropdown open"><a id="drop1" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-book"></i> Browse</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop1">
                    <li><a href="../../contents.html">Table of Contents</a></li>
                    <li><a href="../../new.html">What's New</a></li>
                    <li><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/random">Random Entry</a></li>
                    <li><a href="../../published.html">Chronological</a></li>
                    <li><a href="../../archives/index.html">Archives</a></li>
                  </ul>
                </li>
                <li class="dropdown open"><a id="drop2" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-info-sign"></i> About</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop2">
                    <li><a href="../../info.html">Editorial Information</a></li>
                    <li><a href="../../about.html">About the SEP</a></li>
                    <li><a href="../../board.html">Editorial Board</a></li>
                    <li><a href="../../cite.html">How to Cite the SEP</a></li>
                    <li><a href="../../special-characters.html">Special Characters</a></li>
                    <li><a href="../../tools/index.html">Advanced Tools</a></li>
                    <li><a href="../../contact.html">Contact</a></li>
                  </ul>
                </li>
                <li class="dropdown open"><a id="drop3" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-leaf"></i> Support SEP</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop3">
                    <li><a href="../../support/index.html">Support the SEP</a></li>
                    <li><a href="../../support/friends.html">PDFs for SEP Friends</a></li>
                    <li><a href="../../support/donate.html">Make a Donation</a></li>
                    <li><a href="../../support/sepia.html">SEPIA for Libraries</a></li>
                  </ul>
                </li>
              </ul>
            </div>
          </div>
        </div>
      </div>
    </div>
    <!-- End navigation -->
    
    <div id="search">
      <form id="search-form" method="get" action="https://seop.illc.uva.nl/search/searcher.py">
        <input type="search" name="query" placeholder="Search SEP" />
        <div class="search-btn-wrapper"><button class="btn search-btn" type="submit"><i class="icon-search"></i></button></div>
      </form>
    </div>
    <!-- End search --> 
    
  </div>
  <!-- End header --> 
</div>
<!-- End header wrapper -->

<div id="content">

<!-- Begin article sidebar -->
<div id="article-sidebar" class="sticky">
  <div class="navbar">
    <div class="navbar-inner">
      <div class="container">
        <button class="btn btn-navbar" data-target=".collapse-sidebar" data-toggle="collapse" type="button"> <i class="icon-reorder"></i> Entry Navigation </button>
        <div id="article-nav" class="nav-collapse collapse-sidebar in collapse">
          <ul class="nav">
            <li><a href="#toc">Entry Contents</a></li>
            <li><a href="#Bib">Bibliography</a></li>
            <li><a href="#Aca">Academic Tools</a></li>
            <li><a href="https://leibniz.stanford.edu/friends/preview/computational-philosophy/">Friends PDF Preview <i class="icon-external-link"></i></a></li>
            <li><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=computational-philosophy">Author and Citation Info <i class="icon-external-link"></i></a> </li>
            <li><a href="#pagetopright" class="back-to-top">Back to Top <i class="icon-angle-up icon2x"></i></a></li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</div>
<!-- End article sidebar --> 

<!-- NOTE: Article content must have two wrapper divs: id="article" and id="article-content" -->
<div id="article">
<div id="article-content">

<!-- BEGIN ARTICLE HTML -->


<div id="aueditable"><!--DO NOT MODIFY THIS LINE AND ABOVE-->

<h1>Computational Philosophy</h1><div id="pubinfo"><em>First published Mon Mar 16, 2020</em></div>

<div id="preamble">

<p>
Computational philosophy is the use of mechanized computational
techniques to instantiate, extend, and amplify philosophical research.
Computational philosophy is not philosophy <em>of</em> computers or
computational techniques; it is rather philosophy <em>using</em>
computers and computational techniques. The idea is simply to apply
advances in computer technology and techniques to advance discovery,
exploration and argument within any philosophical area.</p>

<p>
After touching on historical precursors, this article discusses
contemporary computational philosophy across a variety of fields:
epistemology, metaphysics, philosophy of science, ethics and social
philosophy, philosophy of language and philosophy of mind, often with
examples of operating software. Far short of any attempt at an
exhaustive treatment, the intention is to introduce the spirit of each
application by using some representative examples.</p>
</div>

<div id="toc">
<!--Entry Contents-->
<ul>
<li><a href="#Intr">1. Introduction </a></li>
<li><a href="#AntiLeib">2. Anticipations in Leibniz</a></li>
<li><a href="#CompPhilExam">3. Computational Philosophy by Example</a>
   <ul>
   <li><a href="#SociEpisAgenBaseMode">3.1 Social Epistemology and Agent-Based Modeling</a>
      <ul>
      <li><a href="#BeliChanOpinPola">3.1.1 Belief change and opinion polarization</a></li>
      <li><a href="#SociDynaArgu">3.1.2 The social dynamics of argument</a></li>
      </ul></li>
   <li><a href="#CompPhilScie">3.2 Computational Philosophy of Science</a>
      <ul>
      <li><a href="#NetwModeScieTheo">3.2.1 Network models of scientific theory</a></li>
      <li><a href="#NetwModeScieComm">3.2.2 Network models of scientific communication</a></li>
      <li><a href="#DiviLaboDiveExpl">3.2.3 Division of labor, diversity, and exploration</a></li>
      </ul></li>
   <li><a href="#EthiSociPoliPhil">3.3 Ethics and Social-Political Philosophy</a>
      <ul>
      <li><a href="#GameTheoEvolCoop">3.3.1 Game theory and the evolution of cooperation</a></li>
      <li><a href="#ModeDemo">3.3.2 Modeling democracy</a></li>
      <li><a href="#SociOutcCompSyst">3.3.3 Social outcomes as complex systems</a></li>
      </ul></li>
   <li><a href="#CompPhilLang">3.4 Computational Philosophy of Language</a>
      <ul>
      <li><a href="#SemaWebsAnalMeta">3.4.1 Semantic webs, analogy and metaphor</a></li>
      <li><a href="#SignGameEmerComm">3.4.2 Signaling games and the emergence of communication</a></li>
      </ul></li>
   <li><a href="#TheoProvEthiReasMetaPhilReli">3.5 From Theorem-Provers to Ethical Reasoning, Metaphysics, and Philosophy of Religion</a></li>
   <li><a href="#ArtiIntePhilMind">3.6 Artificial Intelligence and Philosophy of Mind</a></li>
   </ul></li>
<li><a href="#EvalCompPhil">4. Evaluating Computational Philosophy</a>
   <ul>
   <li><a href="#Crit">4.1 Critiques</a></li>
   <li><a href="#ProsUndeAspe">4.2 Prospects and Undeveloped Aspects</a></li>
   </ul></li>
<li><a href="#Bib">Bibliography</a></li>
<li><a href="#Aca">Academic Tools</a></li>
<li><a href="#Oth">Other Internet Resources</a>
   <ul>
   <li><a href="#CompModeExam">Computational Model Examples</a></li>
   <li><a href="#AddiInteReso">Additional Internet Resources</a></li>
   </ul></li>
<li><a href="#Rel">Related Entries</a></li>
</ul>

<!--Entry Contents-->
<hr />

</div>

<div id="main-text">

<h2 id="Intr">1. Introduction </h2>

<p>
Computational philosophy is not an area or subdiscipline of philosophy
but a set of computational techniques applicable across many
philosophical areas. The idea is simply to apply computational
modeling and techniques to advance philosophical discovery,
exploration and argument. One should not therefore expect a sharp
break between computational and non-computational philosophy, nor a
sharp break between computational philosophy and other computational
disciplines.</p>

<p>
The past half-century has seen impressive advances in raw computer
power as well as theoretical advances in automated theorem proving,
agent-based modeling, causal and system dynamics, neural networks,
machine learning and data mining. What might contemporary
computational technologies and techniques have to offer in advancing
our understanding of issues in epistemology, ethics, social and
political philosophy, philosophy of language, philosophy of mind,
philosophy of science, or philosophy of religion? Suggested by Leibniz
and with important precursors in the history of formal logic, the idea
is to apply new computational advances within long-standing areas of
philosophical interest.</p>

<p>
Computational philosophy is not the philosophy <em>of</em>
computation, an area that asks about the nature of computation itself.
Although applicable and informative regarding artificial intelligence,
computational philosophy is not the philosophy <em>of</em> artificial
intelligence. Nor is it an umbrella term for the questions about the
social impact of computer use explored for example in philosophy of
information, philosophy of technology, and computer ethics. More
generally, there is no &ldquo;of&rdquo; that computational philosophy
can be said to be the philosophy <em>of</em>. Computational philosophy
represents not an isolated topic area but the widespread application
of whatever computer techniques are available across the full range of
philosophical topics. Techniques employed in computational philosophy
may draw from standard computer programming and software engineering,
including aspects of artificial intelligence, neural networks, systems
science, complex adaptive systems, and a variety of computer modeling
methods. As a growing set of methodologies, it includes the prospect
of computational textual analysis, big data analysis, and other
techniques as well. Its field of application is equally broad,
unrestricted within the traditional discipline and domain of
philosophy.</p>

<p>
This article is an introduction to computational philosophy rather
than anything like a complete survey. The goal is to offer a handful
of suggestive examples across computational techniques and fields of
philosophical application.</p>

<h2 id="AntiLeib">2. Anticipations in Leibniz</h2>

<blockquote class="bigindent">

<p>
The only way to rectify our reasonings is to make them as tangible as
those of the Mathematicians, so that we can find our error at a
glance, and when there are disputes among persons, we can simply say:
Let us calculate, without further ado, to see who is right. <span class="blockright smaller">&mdash;Leibniz,
<em>The Art of Discovery</em>&nbsp;(1685&nbsp;[1951:&nbsp;51])</span></p>
</blockquote>

<p>
Formalization of philosophical argument has a history as old as
 logic.<sup>[<a href="notes.html#note-1" id="ref-1">1</a>]</sup>
 Logic is the historical source and foundation of contemporary
 computing.<sup>[<a href="notes.html#note-2" id="ref-2">2</a>]</sup>
 Our topic here is more specific: the application of contemporary
computing to a range of philosophical questions. But that too has a
history, evident in Leibniz&rsquo;s vision of the power of
computation.</p>

<p>
Leibniz is known for both the development of formal techniques in
philosophy and the design and production of actual computational
machinery. In 1642, the philosopher Blaise Pascal had invented the
Pascaline, designed to add with carry and subtract. Between 1673 and
1720 Leibniz designed a series of calculating machines intended to
instantiate multiplication and division as well: the stepped reckoner,
employing what is still known as the Leibniz wheel (Martin 1925). The
sole surviving Leibniz step reckoner was discovered in 1879 as workmen
were fixing a leaking roof at the University of G&ouml;ttingen. In
correspondence, Leibniz alluded to a cryptographic encoder and decoder
using the same mechanical principles. On the basis of those
descriptions, Nicholas Rescher has produced a working conjectural
reconstruction (Rescher 2012).</p>

<p>
But Leibniz had visions for the power of computation far beyond mere
arithmetic and cryptography. Leibniz&rsquo;s 1666 <em>Dissertatio De
Arte Combinatoria</em>
trumpets the &ldquo;art of combinations&rdquo; as a method of
producing novel ideas and inventions as well as analyzing complex
ideas into simpler elements (Leibniz 1666 [1923]). Leibniz describes it as the &ldquo;mother
of inventions&rdquo; that would lead to the &ldquo;discovery of all
things&rdquo;, with applications in logic, law, medicine, and physics.
The vision was of a set of formal methods applied within a perfect
language of pure concepts which would make possible the general
mechanization of reason (Gray
 2016).<sup>[<a href="notes.html#note-3" id="ref-3">3</a>]</sup></p>
 
<p>
The specifics of Leibniz&rsquo;s combinatorial vision 
can be traced back to the mystical mechanisms of Raymond Llull circa 1308, combinatorial mechanisms lampooned in
Jonathan Swift&rsquo;s <em>Gulliver&rsquo;s Travels</em> of 1726 as allowing one to </p>

<blockquote>

<p>
write books in philosophy, poetry, politics, mathematics, and
theology, without the least assistance from genius or study. (Swift
1726: 174, Lem 1964 [2013: 359])
</p>
</blockquote>

<p>
Combinatorial specifics aside, however, Leibniz&rsquo;s vision of an
application of computational methods to substantive questions remains.
It is the vision of computational physics, computational biology,
computational social science, and&mdash;in application to perennial
questions within philosophy&mdash;of computational philosophy.</p>

<h2 id="CompPhilExam">3. Computational Philosophy by Example</h2>

<p>
Despite Leibniz&rsquo;s hopes for a single computational method that
would serve as a universal key to discovery, computational philosophy
today is characterized by a number of distinct computational
approaches to a variety of philosophical questions. Particular
questions and particular areas have simply seemed ripe for various
models, methodologies, or techniques. Both attempts and results are
therefore scattered across a range of different areas. In what follows
we offer a survey of various explorations in computational
philosophy.</p>

<h3 id="SociEpisAgenBaseMode">3.1 Social Epistemology and Agent-Based Modeling</h3>

<p>
Computational philosophy is perhaps most easily introduced by focusing
on applications of agent-based modeling to questions in social
epistemology, social and political philosophy, philosophy of science,
and philosophy of language. Sections 3.1 through 3.3 are therefore
structured around examples of agent-based modeling in these areas.
Other important computational approaches and other areas are discussed
in 3.4 through 3.6.</p>

<p>
Traditional epistemology&mdash;the epistemology of Plato, Hume,
Descartes, and Kant&mdash;treats the acquisition and validation of
knowledge on the individual level. The question for traditional
epistemology was always how I as an <em>individual</em> can acquire
knowledge of the objective world, when all I have to work with is my
subjective experience. Perennial questions of individual epistemology
remain, but the last few decades have seen the rise of a very
different form of epistemology as well. Anticipated in early work by
Alvin I. Goldman, Helen Longino, Philip Kitcher, and Miriam Solomon,
<em>social</em> epistemology is now evident both within dedicated
journals and across philosophy quite generally (Goldman 1987; Longino
1990; Kitcher 1993; Solomon 1994a, 1994b; Goldman &amp; Whitcomb 2011;
Goldman &amp; O&rsquo;Connor 2001 [2019]; Longino 2019). I acquire my
knowledge of the world as a member of a social group: a group that
includes those inquirers that constitute the scientific enterprise,
for example. In order to understand the acquisition and validation of
knowledge we have to go beyond the level of individual epistemology:
we need to understand the social structure, dynamics, and process of
scientific investigation. It is within this social turn in
epistemology that the tools of computational
modelling&mdash;agent-based modeling in particular&mdash;become
particularly useful. (Klein, Marx and Fischbach 2018).</p>

<p>
The following two sections use computational work on belief change as
an introduction to agent-based modeling in social epistemology.
Closely related questions regarding scientific communication are left
to sections
 <a href="#NetwModeScieComm">3.2.2</a>
 and
 <a href="#DiviLaboDiveExpl">3.2.3</a>.</p>
 
<h4 id="BeliChanOpinPola">3.1.1 Belief change and opinion polarization</h4>

<p>
How should we expect beliefs and opinions to change within a social
group? How might they <em>rationally</em> change? The computational
approach to these kinds of questions attempts to understand basic
dynamics of the target phenomenon by building, running, and analyzing
simulations. Simulations may start with a model of interactive
dynamics and initial conditions, which might include, for example, the
initial beliefs of individual agents and how prone those agents are to
share information and listen to others. The computer calculates
successive states of the model (&ldquo;steps&rdquo;) as a function
(typically stochastic) of preceding stages. Researchers collect and
analyze simulation outputs, which might include, for example, the
distribution of beliefs in the simulated society after a certain
number of rounds of communication. Because simulations typically
involve many stochastic elements (which agents talk with which agents
at what point in the simulation, what specific beliefs specific agents
start with, etc.), data is usually collected and analyzed across a
large number of simulation runs.</p>

<p>
One model of belief change and opinion polarization that has been of
wide interest is that of Hegselmann and Krause (2002, 2005, 2006),
which offers a clear and simple example of the application of
agent-based techniques.</p>

<p>
Opinions in the Hegselmann-Krause model are mapped as numbers in the
[0, 1] interval, with initial opinions spread uniformly at random in
an artificial population. Individuals update their beliefs by taking
an average of the opinions that are &ldquo;close enough&rdquo; to an
agent&rsquo;s own. As agents&rsquo; beliefs change, a different set of
agents or a different set of values can be expected to influence
further updating. A crucial parameter in the model is the threshold of
what counts as &ldquo;close enough&rdquo; for actual
 influence.<sup>[<a href="notes.html#note-4" id="ref-4">4</a>]</sup></p>
 
<p>

 <a href="#fig1">Figure 1</a>
 shows the changes in agent opinions over time in single runs with
thresholds &epsilon; set at 0.01, 0.15, and 0.25 respectively. With a
threshold of 0.01, individuals remain isolated in a large number of
small local groups. With a threshold of 0.15, the agents form two
permanent groups. With a threshold of 0.25, the groups fuse into a
single consensus opinion. These are typical representative cases, and
runs vary slightly. As might be expected, all results depend on both
the number of individual agents and their initial random locations
across the opinion space. See the
 <a href="#OIR-HK">interactive simulation of the Hegselmann and Krause bounded confidence model</a>
 in the Other Internet Resources section below.</p>

<div class="figure avoid-break" id="fig1">

<p>
<img src="Picture1.png" alt="three graphs: link to extended description below" />
</p>

<p>
<span class="figlabel">Figure 1:</span> Example changes in opinion
across time from single runs with different threshold values
\(&epsilon; \in \{0.01, 0.15, 0.25\}\) in the Hegselmann and Krause
(2002) model. [An
 <a href="figdesc.html#fig1">extended description of figure 1</a>
 is in the supplement.]</p>
</div>

<p>
An illustration of average outcomes for different threshold values
appears as
 <a href="#fig2">figure 2</a>.
 What is represented here is not change over time but rather the final
opinion positions given different threshold values. As the threshold
value climbs from 0 to roughly 0.20, there is an increasing number of
results with concentrations of agents at the outer edges of the
distribution, which themselves are moving inward. Between 0.22 and
0.26 there is a quick transition from results with two final groups to
results with a single final group. For values still higher, the two
sides are sufficiently within reach that they coalesce on a central
consensus, although the exact location of that final monolithic group
changes from run to run creating the fat central spike shown.
Hegselmann and Krause describe the progression of outcomes with an
increasing threshold as going through three phases: </p>

<blockquote>

<p>
As the homogeneous and symmetric confidence interval increases we
transit from phase to phase. More exactly, <em>we step from fragmentation
(plurality) over polarisation (polarity) to consensus (conformity)</em>.
(2002: 11, authors&rsquo; italics)</p>
</blockquote>

<div class="figure avoid-break" id="fig2">
<img src="Picture2.png" alt="a 3-d graph: link to extended description below" />

<p>
<span class="figure">Figure 2:</span> Frequency of equilibrium opinion
positions for different threshold values in the Hegselmann and Krause
model scaled to [0, 100] (as original with axes relabeled; Hegselmann
and Krause 2002). [An
 <a href="figdesc.html#fig2">extended description of figure 2</a>
 is in the supplement.]</p>
</div>

<p>
A number of models further refine the &ldquo;bounded confidence&rdquo;
mechanisms of the Hegselmann Krause model. Deffuant et al., for
example, replace the sharp cutoff of influence in Hegselmann-Krause
with continuous influence values (Deffuant et al. 2002; Deffuant 2006;
Meadows &amp; Cliff 2012). Agents are again assigned both opinion
values and threshold (&ldquo;uncertainty&rdquo;) ranges, but the
extent to which the opinion of agent <em>i</em> is influential on
agent <em>j</em> is proportional to the ratio of the overlap of their
ranges (opinion plus or minus threshold) over <em>i</em>&rsquo;s
range. Opinion centers and threshold ranges are updated accordingly,
resulting in the possibility of individuals with narrower and wider
ranges. Given the updating algorithm, influence may also be
asymmetric: individuals with a narrower range of tolerance, which
Deffuant et al. interpret as higher confidence or lower uncertainty,
will be more influential on individuals with a wider range than vice
versa. The influence on polarization of &ldquo;stubborn&rdquo;
individuals who do not change, and of agents on extremes, has also
been studied, showing a clear impact on the dynamics of belief change
in the
 group.<sup>[<a href="notes.html#note-5" id="ref-5">5</a>]</sup></p>
 
<p>
Eric Olsson and Sofi Angere have developed a sophisticated program in
which the interaction of agents is modelled within a Bayesian network
of both information and trust (Olsson 2011). Their program,
 <a href="#OIR-Laputa">Laputa</a>
 (see Other Internet Resources) has a wide range of applications, one
of which is a model of polarization interpreted in terms of the
Persuasive Argument Theory in psychology and which replicates an
effect seen in empirical studies: the increasing divergence of
polarized groups (Lord, Ross, &amp; Lepper 1979; Isenberg 1986; Olsson
2013). Olsson raises the question of whether polarization may be
epistemically rational, offering a positive answer. O&rsquo;Connor and
Weatherall (2018) and Singer et al. (2019) also argue that polarization
can be rational, using different models and perhaps different senses
of polarization (Bramson et al. 2017).</p>

<p>
The topic of polarization is anticipated in an earlier tradition of
cellular automata models initiated by Robert Axelrod. The basic
premise of Axelrod (1997) is that people tend to interact more with
those like themselves and tend to become more like those with whom
they interact. But if people come to share one another&rsquo;s beliefs
(or other cultural features) over time, why do we not observe complete
cultural convergence? At the core of Axelrod&rsquo;s model is a
spatially instantiated imitative mechanism that produces cultural
convergence within local groups but also results in progressive
differentiation and cultural isolation between groups.</p>

<p>
100 agents are arranged on a \(10 \times 10\) lattice such as that
illustrated in
 <a href="#fig3">Figure 3</a>.
 Each agent is connected to four others: top, bottom, left, and right.
The exceptions are those at the edges or corners of the array,
connected to only three and two neighbors, respectively. Agents in the
model have multiple cultural &ldquo;features&rdquo;, each of which
carries one of multiple possible &ldquo;traits&rdquo;. One can think
of the features as categorical variables and the traits as options or
values within each category. For example, the first feature might
represent culinary tradition, the second one the style of dress, the
third music, and so on. In the base configuration an agent&rsquo;s
&ldquo;culture&rdquo; is defined by five features \((F = 5)\) each
having one of 10 traits \((q =10),\) numbered 0 through 9. Agent
<i>x</i> might have \(\langle 8, 7, 2, 5, 4\rangle\) as a cultural
signature while agent <i>y</i> is characterized \(\langle 1, 4, 4, 8,
4\rangle\). Agents are fixed in their lattice location and hence their
interaction partners. Agent interaction and imitation rates are
determined by neighbor similarity, where similarity is measured as the
percentage of feature positions that carry identical traits. With five
features, if a pair of agents share exactly one such element they are
20% similar; if two elements match then they are 40% similar, and so
forth. In the example just given, agents <i>x</i> and <i>y</i> and
have a similarity of 20% because they share only one feature.</p>

<div class="figure avoid-break" id="fig3">
<!-- <img src="Picture3.png" alt= "A screenshot of a cell phone Description automatically generated" />
-->
<hr />
<table class="cellpad-small-dense smaller">
<tr>
  <td>41846</td>
  <td>09617</td>
  <td>06227</td>
  <td>73975</td>
  <td>78196</td>
  <td>98865</td>
  <td>67856</td>
  <td>39579</td>
  <td>46292</td>
  <td>39070</td> </tr>
<tr>
  <td>95667</td>
  <td>34557</td>
  <td>85463</td>
  <td>49129</td>
  <td>83446</td>
  <td>31042</td>
  <td>78640</td>
  <td>70518</td>
  <td>61745</td>
  <td>96211</td> </tr>
<tr>
  <td>47298</td>
  <td>86948</td>
  <td>54261</td>
  <td>75923</td>
  <td>02665</td>
  <td>97330</td>
  <td>67790</td>
  <td>69719</td>
  <td>45520</td>
  <td>37354</td> </tr>
<tr>
  <td>09575</td>
  <td>72785</td>
  <td style="background-color: yellow">94991</td>
  <td>70805</td>
  <td>04952</td>
  <td>52299</td>
  <td>99741</td>
  <td>12929</td>
  <td>18932</td>
  <td>81593</td> </tr>
<tr>
  <td>02029</td>
  <td>94602</td>
  <td>14852</td>
  <td>94392</td>
  <td>83121</td>
  <td>84309</td>
  <td>33260</td>
  <td>44121</td>
  <td>19166</td>
  <td>73581</td> </tr>
<tr>
  <td>84484</td>
  <td>93579</td>
  <td>09052</td>
  <td>12567</td>
  <td>72371</td>
  <td>08352</td>
  <td>25212</td>
  <td>39743</td>
  <td>45785</td>
  <td>55341</td> </tr>
<tr>
  <td>69263</td>
  <td>94414</td>
  <td>25246</td>
  <td>68061</td>
  <td>12208</td>
  <td>44813</td>
  <td>02717</td>
  <td>90699</td>
  <td>94938</td>
  <td>05728</td> </tr>
<tr>
  <td>98129</td>
  <td>44971</td>
  <td>86427</td>
  <td>26499</td>
  <td>05885</td>
  <td>45788</td>
  <td>40317</td>
  <td>08520</td>
  <td>35527</td>
  <td>73303</td> </tr>
<tr>
  <td>18261</td>
  <td>18215</td>
  <td>70977</td>
  <td>15211</td>
  <td>92822</td>
  <td>74561</td>
  <td>60786</td>
  <td>34255</td>
  <td>07420</td>
  <td>42317</td> </tr>
<tr>
  <td>30487</td>
  <td>23057</td>
  <td>24656</td>
  <td>03204</td>
  <td>60418</td>
  <td>56359</td>
  <td>57759</td>
  <td>01783</td>
  <td>21967</td>
  <td>84773</td> </tr>
</table>

<hr />

<p>
<span class="figlabel">Figure 3:</span> Typical initial set of
&ldquo;cultures&rdquo; for a basic Axelrod-style model consisting of
100 agents on a \(10 \times 10\) lattice with five features and 10
possible traits per agent. The marked sight shares two of five traits
with the site above it, giving it a cultural similarity score of 40%
(Axelrod 1997).</p>
</div>

<p>
For each iteration, the model picks at random an agent to be active
and one of its neighbors. With probability equal to their cultural
similarity, the two sites interact and the active agent changes one of
its dissimilar elements to that of its neighbor. If agent \(i =
\langle 8, 7, 2, 5, 4\rangle\) is chosen to be active and it is paired
with its neighbor agent \(j = \langle 8, 4, 9, 5, 1\rangle,\) for
example, the two will interact with a 40% probability because they
have two elements in common. If the interaction does happen, agent
<i>i</i> changes one of its mismatched elements to match that of
<i>j</i>, becoming perhaps \(\langle 8, 7, 2, 5, 1\rangle.\) This
change creates a similarity score of 60%, yielding an increased
probability of future interaction between the two.</p>

<p>
In the course of approximately 80,000 iterations, Axelrod&rsquo;s
model produces large areas in which cultural features are identical:
local convergence. It is also true, however, that arrays such as that
illustrated do not typically move to full convergence. They instead
tend to produce a small number of culturally isolated stable
regions&mdash;groups of identical agents none of whom share features
in common with adjacent groups and so cannot further interact. As an
array develops, agents interact with increasing frequency with those
with whom they become increasingly similar, interacting less
frequently with the dissimilar agents. With only a mechanism of local
convergence, small pockets of similar agents emerge that move toward
their own homogeneity and away from that of other groups. With the
parameters described above, Axelrod reports a median of three stable
regions at equilibrium. It is this phenomenon of global separation
that Axelrod refers to as &ldquo;polarization&rdquo;. See the
 <a href="#OIR-NetlogoAxelrod">interactive simulation of the Axelrod polarization model</a>
 in the Other Internet Resources section below.</p>

<p>
Axelrod notes a number of intriguing results from the model, many of
which have been further explored in later work. Results are very
sensitive to the number of features <i>F</i> and traits <i>q</i> used
as parameters, for example. Changing numbers of features and traits
changes the final number of stable regions in opposite directions: the
number of stable regions correlates negatively with the number of
features <i>F</i> but positively with the number of traits <i>q</i>
(Klemm et al. 2003). In Axelrod&rsquo;s base case with \(F = 5\) and
\(q = 10\) on a \(10 \times 10\) lattice, the result is a median of
three stable regions. When <i>q</i> is increased from 10 to 15, the
number of final regions increases from three to 20; increasing the
number of traits increases the number of stable groups dramatically.
If the number of features <i>F</i> is increased to 15, in contrast,
the average number of stable regions drops to only 1.2 (Axelrod 1997).
Further explorations of parameters of population size, configuration,
and dynamics, with measures of relative size of resultant groups,
appear in Klemm et al. (2003a, b, c, 2005) and in Centola et al. (2007).</p>

<p>
One result that computational modeling promises regarding a phenomenon
such as opinion polarization is an understanding of the phenomenon
itself: how real opinion polarization might happen, and how it might
be avoided. Another and very different outcome, however, is created by
the fact that computational modeling both offers and demands precision
about concepts and measures that may otherwise be lacking in theory.
Bramson et al. (2017), for example, argues that
&ldquo;polarization&rdquo; has a range of possible meanings across the
literature in which it appears, different aspects of which are
captured by different computational models with different
measures.</p>

<h4 id="SociDynaArgu">3.1.2 The social dynamics of argument</h4>

<p>
In general, the social dynamics of belief change reviewed above treats
beliefs as items that spread by contact, much on the model of
infection dynamics (Grim, Singer, Reade, &amp; Fisher 2015, though
Riegler &amp; Douven 2009
can be seen as an exception). Other attempts have been made to model
belief change in greater detail, motivated by reasons or
arguments.</p>

<p>
With gestures toward earlier work by Phan Minh Dung (1995), Gregor Betz
constructs a model of belief change based on &ldquo;dialectical
structures&rdquo; of linked arguments (Betz 2013). Sentences and their
negations are represented as digits positive and negative, arguments
as ordered sets of sentences, and two forms of links between
arguments: an attack relation in which a conclusion of one argument
contradicts a premise of another and support relations in which the
conclusion of one argument is equivalent to the premise of another
 (<a href="#fig4">Figure 4</a>).
 A &ldquo;position&rdquo; on a dynamical structure, complete or
partial, consists of an assignment of truth values T or F to the
elements of the set of sentences involved. Consistent positions
relative to a structure are those in which contradictory sentences are
signed opposite truth values and every argument in which all premises
are assigned T has a conclusion which is assigned T as well. Betz then
maps the space of coherent positions for a given dialectical structure
as an undirected network, with links between positions that differ in
the truth-value of just one sentence of the set.</p>

<div class="figure avoid-break" id="fig4">

<p>
<!-- <img src="Picture4.png" alt= "A close up of a map Description automatically generated" /> -->
<img src="fig4.svg" alt="a diagram: link to extended description below" />
</p>

<p>
<span class="figlabel">Figure 4:</span> A dialectical structure of
propositions and their negations as positive and negative numbers,
with two complete positions indicated by values of T and F. The left
assignment is consistent; the right assignment is not (after Betz
2013). [An
 <a href="figdesc.html#fig4">extended description of figure 4</a>
 is in the supplement.]</p>
</div>

<p>
In the simplest form of the model, two agents start with random
assignments to a set of 20 sentences with consistent assignments to
their negations. Arguments are added randomly, starting from a blank
slate, and agents move to the coherent position closest to their
previous position, with a random choice in the case of a draw. In
variations on the basic structure, Betz considers (a) cases in which
an initial background agreement is assumed, (b) cases of
&ldquo;controversial&rdquo; argumentation, in which arguments are
introduced which support a proponent&rsquo;s position or attack an
opponent&rsquo;s, and (c) in which up to six agents are involved. In
two series of simulations, he tracks both the consensus-conduciveness
of different parameters, and&mdash;with an assumption of a specific
assignment as the &ldquo;truth&rdquo;&mdash;the truth-conduciveness of
different parameters.</p>

<p>
In individual runs, depending on initial positions and arguments
introduced, Betz finds that argumentation of the sort modeled can
either increase or decrease agreement, and can track the truth or lead
astray. Averaging across many debates, however, Betz finds that
controversial argumentation in particular is both consensus-conducive
and better tracks the
 truth.<sup>[<a href="notes.html#note-6" id="ref-6">6</a>]</sup></p>
 
<h3 id="CompPhilScie">3.2 Computational Philosophy of Science</h3>

<p>
Computational models have been used in philosophy of science in two
very different respects: (a) as models of scientific theory, and (b)
as models of the social interaction characteristic of collective
scientific research. The next sections review some examples of
each.</p>

<h4 id="NetwModeScieTheo">3.2.1 Network models of scientific theory</h4>

<p>
&ldquo;Computational philosophy of science&rdquo; is enshrined as a
book title as early as Paul Thagard&rsquo;s 1988. A central core of
his work is a connectionist ECHO program, which constructs network
structures of scientific explanation (Thagard 1992, 2012). From inputs
of &ldquo;explain&rdquo;,, &ldquo;contradict&rdquo;,
&ldquo;data&rdquo;, and &ldquo;analogous&rdquo; for the status and
relation of nodes, ECHO uses a set of principles of explanatory
coherence to construct a network of undirected excitatory and
inhibitory links between nodes which &ldquo;cohere&rdquo; and those
which &ldquo;incohere&rdquo;, respectively. If p1 through pm explain
<i>q</i>, for example, all of p1 through pm cohere with <i>q</i> and
with each other, for example, though the weight of coherence is
divided by the number of p1 through pm. If p1 contradicts p2 or p1 and
p2 are parts of competing explanations for the same phenomenon, they
&ldquo;incohere&rdquo;.</p>

<p>
Starting with initial node activations close to zero, the nodes of the
coherence network are synchronously updated in terms of their old
activation and weighted input from linked nodes, with
&ldquo;data&rdquo; nodes set as a constant input of 1. Once the
network settles down to equilibrium, an explanatory hypothesis p1 is
taken to defeat another p2 if its activation value is higher&mdash;at
least generally, positive as opposed to negative
 (<a href="#fig5">Figure 5</a>).</p>
 
<div class="figure avoid-break" id="fig5">
<!-- <img src="Picture5.png" alt= "A picture containing object Description automatically generated" /> -->
<img src="fig5.svg" alt="E and P1 each have solid lines connecting them to Q1 and Q2. P2 has a dotted line connecting it to P1 and a solid line connecting it to Q2." />

<p>
<span class="figlabel">Figure 5:</span> An ECHO network for hypotheses
P1 and P2 and evidence units Q1 and Q2. Solid lines represent
excitatory links, the dotted line an inhibitory link. Because Q1 and
Q2 are evidence nodes, they take a constant excitatory value of 1 from
E. Started from values of .01 and following Thagard&rsquo;s updating,
P1 dominates P2 once the network has settled down: a hypothesis that
explains more dominates its alternative. Adapted from Thagard
1992.</p>
</div>

<p>
Thagard is able to show that such an algorithm effectively echoes a
range of familiar observations regarding theory selection. Hypotheses
that explain more defeat those that explain less, for example, and
simpler hypotheses are to be preferred. In contrast to simple
Popperian refutation, ECHO abandons a hypothesis only when a
dominating hypothesis is available. Thagard uses the basic approach of
explanatory coherence, instantiated in ECHO, in an analysis of a
number of historical cases in the history of science, including the
abandonment of phlogiston theory in favor of oxygen theory, the
Darwinian revolution, and the eventual triumph of Wegener&rsquo;s
plate tectonics and continental drift.</p>

<p>
The influence of Bayesian networks has been far more widespread, both
across disciplines and in technological application&mdash;application
made possible only with computers. Grounded in the work of Judea Pearl
(1988, 2000; Pearl &amp; Mackenzie 2018), Bayesian networks are
directed acyclic graphs in which nodes represent variables that can be
read as either probabilities or degrees of belief and directed edges
as conditional probabilities from &ldquo;parent&rdquo; to
&ldquo;child&rdquo;. By the Markov convention, the value of a node is
independent of all other nodes that are not its descendants,
conditional on its parents. A standard textbook example is shown in
 <a href="#fig6">Figure 6</a>.</p>
 
<div class="figure avoid-break" id="fig6">
<!-- <img src="Picture6.png" alt= "A close up of text on a white background Description automatically generated" /> -->
<img src="fig6.svg" alt="a diagram: link to extended description below" />

<p class="center">
<span class="figlabel">Figure 6:</span> A standard example of a simple
Bayesian net. [An
 <a href="figdesc.html#fig6">extended description of figure 6</a>
 is in the supplement.]</p>
</div>

<p>
Changes of values at the nodes of a Bayesian network (in response to
evidence, for example) are updated through belief propagation
algorithms applied at every node. The update of a response to input
from a parent uses the conditional probabilities of the link. A
parent&rsquo;s response to input from a child uses the related
likelihood ratio (see also the supplement on Bayesian networks in
Bringsjord &amp; Govindarajulu 2018 [2019]). Reading some variables as
hypotheses and others as pieces of evidence, simple instances of core
scientific concepts can easily be read off such a structure. Simple
explanation amounts to showing how the value of a variable
&ldquo;downstream&rdquo; depends on the pattern
&ldquo;upstream&rdquo;. Simple confirmation amounts to an increase in
the probability or degree of belief of a node <em>h</em> upstream
given a piece of evidence <em>e</em> downstream. Evaluating competing
hypotheses consists in calculating the comparative probability of
different patterns upstream. One clear reading of networks is as
causal graphs.</p>

<p>
As Pearl notes, a Bayesian network is nothing more than a graphical
representation of a huge table of joint probabilities for the
variables involved (Pearl &amp; Mackenzie 2018: 129). Given any
sizable number of variables, however, calculation becomes humanly
unmanageable&mdash;hence the crucial use of computers. The fact that
Bayesian networks are so computationally intensive is in fact a point
that Thagard makes against using them as models of human cognitive
processing (Thagard 1992: 201). But that is not an objection against
other philosophical interpretations. Application to philosophical
questions of causality in philosophy of science is detailed in
Spirtes, Glymour, and Scheines (1993) and Sprenger and Hartmann
(2019). Bayesian networks are now something of a standard in
artificial intelligence, ubiquitous in its applications, and powerful
algorithms have been developed to extract causal networks from the
massive amounts of data available.</p>

<h4 id="NetwModeScieComm">3.2.2 Network models of scientific communication</h4>

<p>
It should be no surprise that the computational studies of belief
change and opinion dynamics noted above blend smoothly into a range of
computational studies in philosophy of science. Here a central
motivating question has been one of optimal investigatory structure:
what pattern of scientific communication and cooperation, between what
kinds of investigators, is best positioned to advance science? There
are two strands of computational philosophy of science that attempt to
work toward an answer to this question. The first strand models the
effect of communicative networks within groups. The second strand,
left to the next section, models the effects of cognitive diversity
within groups. This section outlines what makes modeling of both sorts
promising, but also notes limitations and some failures as well.</p>

<p>
One might think that access to more data by more investigators would
inevitably optimize the truth-seeking goals of communities of
investigators. On that intuition, faster and more complete
communication&mdash;the contemporary science of the
internet&mdash;would allow faster, more accurate, and more exploration
of nature. Surprisingly, however, this first strand of modeling offers
robust arguments for the potential benefits of <em>limited</em>
communication.</p>

<p>
In the spirit of rational choice theory, much of this work was
inspired by analytical work in economics on infinite populations by
Venkatesh Bala and Sanjeev Goyal (1998), computationally implemented
for small populations in a finite context and with an eye to
philosophical implications by Kevin Zollman (2007, 2010a, 2010b). In Zollman&rsquo;s model, Bayesian agents choose between a
current method \(\phi_1\) and what is set as a better method
\(\phi_2,\) starting with random beliefs and allowing agents to pursue
the investigatory action with the highest subjective utility. Agents
update their beliefs based on the results of their own testing
results&mdash;drawn from a distribution for that action&mdash;together
with results from the other agents to which they are communicatively
connected. A community is taken to have successfully learned when all
agents converge on the better \(\phi_2.\)</p>

<p>
Zollman&rsquo;s results are shown in
 <a href="#fig7">Figure 7</a>
 for the three simple networks shown in
 <a href="#fig8">Figure 8</a>.
 The communication network which performs the best is not the fully
connected network in which all investigators have access to all
results from all others, but the maximally distributed network
represented by the ring. As Zollman also shows, this is also that
configuration which takes the longest time to achieve convergence. See
 <a href="#OIR-NetlogoZollman">an interactive simulation of a simplified version of Zollman&rsquo;s model</a>
 in the Other Internet Resources section below.</p>

<div class="figure pdfwide avoid-break" id="fig7">
 <div class="figures pad-small">
  

<div class="inner-fig wid25">
  <img src="fig7a.svg" alt="10 person ring graph: 10 points in a ring each connected to its adjacent points by a line" />
  </div>

  <div class="inner-fig wid25">
  <img src="fig7b.svg" alt="wheel graph: 10 points in a ring each connected to its adjacent points by a line and each also connected to the center by a line" />
  </div>

  <div class="inner-fig wid25">
  <img src="fig7c.svg" alt="complete graph: 10 points in a ring each connected to all the other points and to the center by a line." />
  </div>
 </div>
<p class="center"><span class="figlabel">Figure 7:</span> A 10 person ring, wheel, and
complete graph. After Zollman (2010a).</p>
</div>

<div class="figure avoid-break" id="fig8">
<img src="Picture8.png" style="width:400px;height:auto" alt="a 2-d graph: link to extended description below" />

<p>
<span class="figlabel">Figure 8:</span> Learning results of computer
simulations: ring, wheel, and complete networks of Bayesian agents.
Adapted from Zollman (2010a).
 [An
 <a href="figdesc.html#fig8">extended description of figure 8</a>
 is in the supplement.]</p>
</div>

<p>
Olsson and Angere&rsquo;s Bayesian network Laputa (mentioned above)
has also been applied to the question of optimal networks for
scientific communication. Their results essentially confirm
Zollman&rsquo;s result, though sampled over a larger range of networks
(Angere &amp; Olsson 2017). Distributed networks with low connectivity
are those that most reliably fix on the truth, though they are bound
to do so more slowly.</p>

<p>
The concept of an <em>epistemic landscape</em> has also emerged as of
central importance in this strand of research. Analogous to a fitness
landscape in biology (Wright 1932), an epistemic landscape offers an
abstract representation of ideal data that might in principle be
obtained in testing a range of hypotheses (Grim 2006, 2009; Weisberg
&amp; Muldoon 2009; Hong &amp; Page 2004, Page 2007).
 <a href="#fig9">Figure 9</a>
 uses the example of data that might be obtained by testing
alternative medical treatments. In such a graph points in the
chemotherapy-radiation plane represent particular hypotheses about the
most effective combination of radiation and chemotherapy. Graph height
at each location represents some measure of success: the percentage of
patients with 5-years survival on that treatment, for example.</p>

<div class="figure avoid-break" id="fig9">
<img src="Picture9.png" alt="3-d graph: link to extended description below" />

<p>
<span class="figlabel">Figure 9:</span> A three-dimensional epistemic
landscape. Points on the xz plane represent hypotheses regarding
optimal combination of radiation and chemotherapy; graph height on the
y axis represents some measure of success. [An
 <a href="figdesc.html#fig9">extended description of figure 9</a>
 is in the supplement.]</p>
</div>

<p>
An epistemic landscape is intended to be an abstract representation of
the real-world phenomenon being explored. The key word, of course, is
&ldquo;abstract&rdquo;: few would argue that such a model is fully
realistic either in terms of the simplicity of limited dimensions or
the precision in which one hypothesis has a distinctly higher value
than a close neighbor. As in all modeling, the goal is to represent as
simply as possible those aspects of a situation relevant to answering
a specific: in this case, the question of optimal scientific
organization. Epistemic landscapes&mdash;even those this
simple&mdash;have been assumed to offer a promising start. As outlined
below, however, one of the deeper conclusions that has emerged is how
sensitive results can be to the specific topography of the epistemic
landscape.</p>

<p>
Is there a form of scientific communication which optimizes its
truth-seeking goals in exploration of a landscape? In a series of
agent-based models, agents are communicatively linked explorers
situated at specific points on an epistemic landscape (Grim 2006;
Grim, Singer et al. 2013). In such a design, simulation can be used to
explore the effect of network structure, the topography of the
epistemic landscape, and the interaction of the two.</p>

<p>
The simplest form of the results echo the pattern seen in different
forms in Bala and Goyal (1998) and in Zollman
(2010a, 2010b), here played out on epistemic landscapes. Agents start with
random hypotheses as points on the x-axis of a two-dimensional
landscape. They compare their results (the height of the y axis at
that point) with those of the other agents to which they are
networked. If a networked neighbor has a higher result, the agent
moves toward an approximation of that point (in the interval of a
&ldquo;shaking hand&rdquo;) with an inertia factor (generally 50%, or
a move halfway). The process is repeated by all agents, progressively
exploring the landscape in attempting to move toward more successful
results.</p>

<p>
On &ldquo;smooth&rdquo; landscapes of the form of the first two graphs
in
 <a href="#fig10">Figure 10</a>,
 agents in any of the networks shown in Figure 10 succeed in finding
the highest point on the landscape. Results become much more
interesting for epistemic landscapes that contain a &ldquo;needle in a
haystack&rdquo; as in the third graph in Figure 10.</p>

<div class="figure pdfwide avoid-break" id="fig10">
 <div class="figures pad-small">
  <div class="inner-fig">
  <img src="Picture10a.png" style="width:150px;height:auto" alt="first of three graphs each labeled 'The Epistemic Landscape' and with x and y axes both going from 0 to 100. This one has a sine like curve starting about 50 and going up and then down before ending below 50." />
  </div>

  <div class="inner-fig">
  <img src="Picture10b.png" style="width:150px;height:auto" alt="second graph. This has a more irregular curve that goes down then up before a small dip then going up some more before dipping." />
  </div>

  <div class="inner-fig">
  <img src="Picture10c.png" style="width:150px;height:auto" alt="third graph: This line has a sharp down before a sharp up that reaches 100 before a sharp down almost to zero (the 'needle') then, similar to the second graph, curves up with a small dip before up again and a final dip" />
  </div>
</div>
<p class="center">
<span class="figlabel">Figure 10:</span> Two-dimensional epistemic
landscapes. Adapted from Grim (2009).</p>
</div>

<div class="figure centered pdfwide avoid-break" id="fig11">
 <div class="figures pad-small">
  <div class="inner-fig wid25">
  <img src="fig11a.svg" alt="ring radius 1: a ring of 15 points each connected to their adjacent points by a line" />
  <p class="center">ring radius 1</p>
  </div>

  <div class="inner-fig wid25">
  <img src="fig11b.svg" alt="small world: a ring of 15 points most connected to their adjacents and two pairs of non-adjacent points also by a line" />
  

<p class="center">small world</p>
  </div>

  <div class="inner-fig wid25">
  <img src="fig11c.svg" alt="wheel: a ring of 15 points each connected to their adjacent points by a line and also each connected to the center by a line" />
  <p class="center">wheel</p>
  </div>
 </div>
 <div class="figures pad-small">
  <div class="inner-fig wid25">
  <img src="fig11d.svg" alt="hub: a ring of 15 points each connected to the center by a line" />
  <p class="center">hub</p>
  </div>

  <div class="inner-fig wid25">
  <img src="fig11e.svg" alt="random: a ring of 15 points several lines randomly connecting two of the points" />
  <p class="center">random</p>
  </div>

  <div class="inner-fig wid25">
  <img src="fig11f.svg" alt="complete: a ring of 15 points each connected by a line to all the other points and to the center" />
  <p class="center">complete</p>
  </div>
 </div>
<p class="center"><span class="figlabel">Figure 11:</span> Sample networks.</p>
</div>

<p>
In a ring with radius 1, each agent is connected with just its
immediate neighbors on each side. Using an inertia of 50% and a
&ldquo;shaking hand&rdquo; interval of 8 on a 100-point landscape, 50
agents in that configuration converge on the global maximum in the
&ldquo;needle in the haystack&rdquo; landscape in 66% of simulation
runs. If agents are connected to the two closest neighbors on each
side, results drop immediately to 50% of runs in which agents find the
global maximum. A small world network can be envisaged as a ring in
which agents have a certain probability of &ldquo;rewiring&rdquo;:
breaking an existing link and establishing another one to some other
agent at random (Watts &amp; Strogatz 1998). If each of 50 agents has
a 9% probability of rewiring, the success rate of small worlds drops
to 55%. Wheels and hubs have a 42% and 37% success rate, respectively.
Random networks with a 10% probability of connection between any two
nodes score at 47%. The worst performing communication network on a
&ldquo;needle in a haystack&rdquo; landscape is the &ldquo;internet of
science&rdquo; of a complete network in which everyone instantly sees
everyone else&rsquo;s result.</p>

<p>
Extensions of these results appear in Grim, Singer et al. (2013).
There a small sample of landscapes is replaced with a quantified
&ldquo;fiendishness index&rdquo;, roughly representing the extent to
which a landscape embodies a &ldquo;needle in a haystack&rdquo;.
Higher fiendishness quantifies a lower probability that hill-climbing
from a randomly chosen point &ldquo;finds&rdquo; the landscape&rsquo;s
global maximum. Landscapes, though still two-dimensional, are
&ldquo;looped&rdquo; so as to avoid edge-effects also noted in
Hegselmann and Krause (2006). Here again results emphasize the
epistemic advantages of ring-like or distributed network over fully
connected networks in the exploration of intuitively difficult
epistemic landscapes. Distributed single rings achieve the highest
percentage of cases in which the highest point on the landscape is
found, followed by all other network configurations. Total or
completely connected networks show the worst results over all. Times
to convergence are shown to be roughly though not precisely the
inverse of these relationships. See
 <a href="#OIR-NetlogoEpistemicNetworks">the interactive simulation of a Grim and Singer et al.&rsquo;s model</a>
 in the Other Internet Resources section below.</p>

<p>
What all these models suggest is that it is distributed networks of
communication between investigators, rather than full and immediate
communication between all, that will&mdash;or at least
<em>can</em>&mdash;give us more accurate scientific outcomes. In the
seventeenth century, scientific results were exchanged slowly, from
person to person, in the form of individual correspondence. In
today&rsquo;s science results are instantly available to everyone.
What these models suggest is that the communication mechanisms of
seventeenth century science may be more reliable than the highly
connected communications of today. Zollman draws the corollary
conclusion that loosely connected communities made up of less informed
scientists might be more reliable in seeking the truth than
communities of more informed scientists that are better connected
 (Zollman 2010b).</p>
 
<p>
The explanation is not far to seek. In all the models noted, more
connected networks produce inferior results because agents move too
quickly to salient but sub-optimal positions: to local rather than
global maxima. In the landscape models surveyed, connected networks
result in all investigators moving toward the same point, currently
announced to everyone as highest, skipping over large areas in the
process&mdash;precisely where the &ldquo;needle in the haystack&rdquo;
might be hidden. In more distributed networks, local action results in
a far more even and effective exploration of widespread areas of the
landscape; exploration rather than exploitation (Holland 1975).</p>

<p>
How should we structure the funding and communication structure of our
scientific communities? It is clear both from these results in their
current form, and in further work along these general lines, that the
answer may well be &ldquo;landscape&rdquo;-relative: it may well
depend on what kind of question is at issue what form scientific
communication ought to take. It may also depend on what desiderata are
at issue. The models surveyed emphasize accuracy of results,
abstractly modeled. All those surveyed concede that there is a clear
trade-off between accuracy of results and the speed of community
consensus
 (Zollman 2007;
 Zollman 2010b; Grim, Singer et al. 2013). But for many purposes, and
reasons both ethical and practical, it may often be far better to work
with a result that is only roughly accurate but available today than
to wait 10 years for a result that is many times more accurate but
arrives far too late.</p>

<h4 id="DiviLaboDiveExpl">3.2.3 Division of labor, diversity, and exploration</h4>

<p>
A second tradition of work in computational philosophy of science also
uses epistemic landscapes, but attempts to model the effect not of
network structure but of the division of labor and diversity within
scientific groups. An influential but ultimately flawed precursor in
this tradition is the work of Weisberg and Muldoon (2009).</p>

<p>
Two views of Weisberg and Muldoon&rsquo;s landscape appear in
 <a href="#fig12">Figure 12</a>.
 In their treatment, points on the base plane of the landscape
represent &ldquo;approaches&rdquo;&mdash;abstract representations of
the background theories, methods, instruments and techniques used to
investigate a particular research question. Heights at those points
are taken to represent scientific significance (following Kitcher
1993).</p>

<div class="figure centered pdfwide avoid-break" id="fig12">
 <div class="figures">
  <div class="inner-fig">
  <img src="Picture12a.png" style="height:180px; width:auto" alt="A three-D graph, mostly flat with two peaks, one at the center and one in the upper left hand corner." />
  </div>

  <div class="inner-fig">
  <img src="Picture12b.png" style="height:170px; width:auto" alt="A black square with two light oval patches, one in the upper right hand corner and one, slightly larger, in the lower left hand corner." />
  </div>
 </div>
<p>
<span class="figlabel">Figure 12:</span> Two visions of Weisberg and
Muldoon&rsquo;s landscape of scientific significance (height) at
different approaches to a research topic.</p>
</div>

<p>
The agents that traverse this landscape are not networked, as in the
earlier studies noted, except to the extent that they are influenced
by agents with &ldquo;approaches&rdquo; near theirs on the landscape.
What is significant about the Weisberg &amp; Muldoon model, however,
is that their agents are not homogeneous. Two types of agents play a
primary role.</p>

<p>
&ldquo;Followers&rdquo; take previous investigation of the territory
by others into account in order to follow successful trends. If any
previously investigated points in their immediate neighborhood have a
higher significance than the point they stand on, they move to that
point (randomly breaking any
 tie).<sup>[<a href="notes.html#note-7" id="ref-7">7</a>]</sup>
 Only if no neighboring investigated points have higher significance
and uninvestigated point remain, followers move to one of those.</p>

<p>
&ldquo;Mavericks&rdquo; avoid previously investigated points much as
followers prioritize them. Mavericks choose <em>un</em>explored points
in their neighborhoods, testing significance. If higher than their
current spot, they move to that point.</p>

<p>
Weisberg and Muldoon measure both the percentages of runs in which
groups of agents find the highest peak and the speed at which peaks
are found. They report that the epistemic success of a population of
followers is increased when mavericks are included, and that the
explanation for that effect lies in the fact that mavericks can
provide pathways for followers: &ldquo;[m]avericks help many of the
followers to get unstuck, and to explore more fruitful areas of the
epistemic landscape&rdquo; (for details see Weisberg &amp; Muldoon
2009: 247 ff). Against that background they argue for broad claims
regarding the value for an epistemic community of combining different
research strategies. The optimal division of labor that their model
suggests is &ldquo;a healthy number of followers with a small number
of mavericks&rdquo;.</p>

<p>
Critics of Weisberg and Muldoon&rsquo;s model argue that it is flawed by simple implementation errors in which &gt;= was used in place of &gt;, with the result that their software agents do not in fact operate in accord with their outlined strategies (Alexander, Himmelreich,&amp; Thomson 2015). As
implemented, their followers tend to get trapped into oscillating
between two equivalent spaces (often of value 0). According to the critics, when followers are properly implemented, it turns out that mavericks help the success of
a community solely in terms of discovery by the mavericks themselves,
not by getting followers &ldquo;unstuck&rdquo; who shouldn&rsquo;t
have been stuck in the first place (see also Thoma 2015). If the critics are right, the Weisberg-Muldoon model as originally implemented proves inadequate as philosophical support for the claim that division of labor and strategic diversity are important epistemic drivers. There&rsquo;s
 <a href="#OIR-NetlogoWeisbergMuldoon">an interactive simulation of the Weisberg and Muldoon model, which includes a switch to change the &gt;= to &gt;</a>,
 in the Other Internet Resources section below.</p>

<p>
Critics of the model don&rsquo;t deny the general conclusion that
Weisberg and Muldoon draw: that cognitive diversity or division of
cognitive labor can favor social epistemic
 outcomes.<sup>[<a href="notes.html#note-8" id="ref-8">8</a>]</sup>
 What they deny is that the Weisberg and Muldoon model adequately
supports that conclusion. A particularly intriguing model that does
support that conclusion, built on a very different model of diversity,
is that of Hong and Page (2004). But it also supports a point that
Alexander et al. emphasize: that the advantages of cognitive
diversity can very much depend on the epistemic landscape being
explored.</p>

<p>
Lu Hong and Scott Page work with a two-dimensional landscape of 2000
points, wrapped around as a loop. Each point is assigned a random
value between 1 and 100. Their epistemic individuals explore that
landscape using heuristics composed of three ordered numbers between,
say, 1 and 12. An example helps. Consider an individual with heuristic
\(\langle 2, 4, 7\rangle\) at point 112 on the landscape. He first
uses his heuristic 2 to see if a point two to the right&mdash;at
114&mdash;has a higher value than his current position. If so, he
moves to that point. If not, he stays put. From that point, whichever
it is, he uses his heuristic 4 in order to see if a point 4 steps to
the right has a higher peak, and so forth. An agent circles through
his heuristic numbers repeatedly until he reaches a point from which
none within reach of his heuristic offers a higher value. The basic
dynamic is illustrated in
 <a href="#fig13">Figure 13</a>.</p>
 
<div class="figure avoid-break" id="fig13">
<img src="Picture13.png" alt="a jagged line: link to extended description below" />

<p>
<span class="figlabel">Figure 13:</span> An example of exploration of
a landscape by an individual using heuristics as in Hong and Page
(2004). Explored points can be read left to right. [An
 <a href="figdesc.html#fig13">extended description of figure 13</a>
 is in the supplement.]</p>
</div>

<p>
Hong and Page score individuals on a given landscape in terms of the
average height they reach starting from each of the 2000 points. But
their real target is the value of diversity in groups. With that in
mind, they compare the performance of (a) groups composed of the 9
individuals with highest-scoring heuristics on a given landscape with
(b) groups composed of 9 individuals with random heuristics on that
landscape. In each case groups function together in what has been
termed a &ldquo;relay&rdquo;. For each point on the 2000-point
landscape, the first individual of the group finds his highest
reachable value. The next individual of the group starts from there,
and so forth, circling through the individuals until a point is
reached at which none can achieve a higher value. The score for the
group as a whole is the average of values achieved in such a way
across all of the 2000 points</p>

<p>
What Hong and Page demonstrate in simulation is that groups with
random heuristics routinely outperform groups composed entirely of the
&ldquo;best&rdquo; individual performers. They christen their findings
the &ldquo;Diversity Trumps Ability&rdquo; result. In a replication of
their study, the average maximum on the 2000-point terrain for the
group of the 9 best individuals comes in at 92.53, with a median of
92.67. The average for a group of 9 random individuals comes in at
94.82, with a median of 94.83. Across 1000 runs in that replication, a
higher score was achieved by groups of random agents in 97.6% of all
cases (Grim et al. 2019). See
 <a href="#OIR-NetlogoHongPageModel">an interactive simulation of Hong and Page&rsquo;s group deliberation model</a>
 in the Other Internet Resources section below. Hong and Page also
offer a mathematical theorem as a partial explanation of such a result
(Hong &amp; Page 2004). That component of their work has been attacked
as trivial or irrelevant (Thompson 2014), though the attack itself has
come under criticism as well (Kuehn 2017, Singer 2019).</p>

<p>
The Hong-Page model solidly demonstrates a general claim attempted in
the disputed Weisberg-Muldoon model: cognitive diversity can indeed be a
social epistemic advantage. In application, however, the Hong-Page
result has sometimes been appealed to as support for much broader
claims: that diversity is always or quite generally of epistemic
advantage (Anderson 2006, Landemore 2013, Gunn 2014, Weymark 2015).
The result itself is limited in ways that have not always been
acknowledged. In particular, it proves sensitive to the precise
character of the epistemic landscape employed.</p>

<p>
Hong and Page&rsquo;s landscape is one in which each of 2000 points is
given a random value between 1 and 100: a purely random landscape. One
consequence of that fact is that the group of 9 best heuristics on
different random Hong-Page landscapes have essentially no correlation:
a high-performing individual on one landscape need have no carry-over
to another. Grim et al. (2019) expands the Hong-Page model to
incorporate other landscapes as well, in ways which challenge the
general conclusions regarding diversity that have been drawn from the
model but which also suggest the potential for further interesting
applications.</p>

<p>
An easy way to &ldquo;smooth&rdquo; the Hong-Page landscapes is to
assign random values not to every point on the 2000-point loop but
every second point, for example, with intermediate points taking an
average between those on each side. Where a random landscape has a
&ldquo;smoothness&rdquo; factor of 0, this variation will have a
randomness factor of 1. A still &ldquo;smoother&rdquo; landscape of
degree 2 would be one in which slopes are drawn between random values
assigned to every third point. Each degree of smoothness increases the
average value correlation between a point and its neighbors. Grim et
al. consider landscapes of varying &ldquo;smoothness&rdquo; along
roughly these lines, though with a randomization that avoids the
lock-step intervals suggested (Grim et al. 2019).</p>

<p>
Using Hong and Page&rsquo;s parameters in other respects, it turns out
that the &ldquo;Diversity Trumps Ability&rdquo; result holds only for
landscapes with a smoothness factor less than 4. Beyond that point, it
is &ldquo;ability&rdquo;&mdash;the performance of groups of the 9
best-performing individuals&mdash;that trumps
&ldquo;diversity&rdquo;&mdash;the performance of groups of random
heuristics.</p>

<p>
The Hong-Page result is therefore very sensitive to the
&ldquo;smoothness&rdquo; of the epistemic landscape modeled. As hinted
in
 <a href="#NetwModeScieComm">section 3.2.2</a>,
 this is an indication from within the modeling tradition itself of
the danger of restricted and over-simple abstractions regarding
epistemic landscapes. Moreover, the model&rsquo;s sensitivity is not
limited to landscape smoothness: social epistemic success depends on
the pool of numbers from which heuristics are drawn as well, with
&ldquo;diversity&rdquo; showing strength on smoother landscapes if the
pool of heuristics is expanded. Results also depend on whether social
interaction is modeled using of Hong-Page&rsquo;s &ldquo;relay&rdquo;
or an alternative dynamics in which individuals collectively (rather
than sequentially) announce their results, with all moving to the
highest point announced by any. Different landscape smoothnesses,
different heuristic pool sizes, and different interactive dynamics
will favor the epistemic advantages of different compositions of
groups, with different proportions of random and best-performing
individuals (Grim et al. 2019).</p>

<h3 id="EthiSociPoliPhil">3.3 Ethics and Social-Political Philosophy</h3>

<blockquote class="bigindent">

<p>
What, then, is the conduct that ought to be adopted, the reasonable
course of conduct, for this egoistic, naturally unsocial being, living
side by side with similar beings? <span class="blockright">&mdash;Henry
Sidgwick, <em>Outlines of the History
of Ethics</em> (1886: 162)</span></p>
</blockquote>

<p>
Hobbes&rsquo; <em>Leviathan</em> can be read as asking, with Sidgwick,
how cooperation can emerge in a society of egoists (Hobbes 1651).
Cooperation is thus a central theme in both ethics and
social-political philosophy.</p>

<h4 id="GameTheoEvolCoop">3.3.1 Game theory and the evolution of cooperation</h4>

<p>
Game theory has been a major tool in many of the philosophical
considerations of cooperation, extended with computational
methodologies. Here the primary example is the Prisoner&rsquo;s
Dilemma, a strategic interaction between two agents with a payoff
matrix in which joint cooperation gets a higher payoff than joint
defection, but the highest payoff goes to a player who defects when
the other player cooperates (see esp. Kuhn 1997 [2019]). Formally, the
Prisoner&rsquo;s Dilemma requires the value DC for defection against
cooperation to be higher than CC for joint cooperation, with CC higher
than the payoff CD for cooperation against defection. In order to
avoid an advantage to alternating trade-offs, CC should also be higher
than \((\textrm{CD} + \textrm{DC}) / 2.\) A simple set of values that
fits those requirements is shown in the matrix in
 <a href="#fig14">Figure 14</a>.</p>
 
<div class="figure avoid-break" id="fig14">

<table class="all-rules cell-center centered cellpad-small avoid-break">

<tr>
<td colspan="2" rowspan="2" style="border-top: 0px; border-left: 0px;"></td>
<td colspan="2"><strong>Player A</strong></td>
</tr>

<tr>
<td><em>Cooperate</em></td>
<td><em>Defect</em></td>
</tr>

<tr>
<td rowspan="2"><strong>Player B</strong></td>
<td><em>Cooperate</em></td>
<td>3,3</td>
<td>0,5</td>
</tr>

<tr>
<td><em>Defect</em></td>
<td>5,0</td>
<td>1,1</td>
</tr>
</table>

<p class="center">
<span class="figlabel">Figure 14:</span> A Prisoner&rsquo;s Dilemma
payoff matrix</p>
</div>

<p>
It is clear in the &ldquo;one-shot&rdquo; Prisoner&rsquo;s Dilemma
that defection is strictly dominant: whether the other player
cooperates or defects, one gains more points by defecting. But if
defection always gives a higher payoff, what sense does it make to
cooperate? In a Hobbesian population of egoists, with payoffs as in
the Prisoner&rsquo;s Dilemma, it would seem that we should expect
mutual defection as both a matter of course and the rational
outcome&mdash;Hobbes&rsquo; &ldquo;war of all against all&rdquo;. How
could a population of egoists come to cooperate? How could the ethical
desideratum of cooperation arise and persist?</p>

<p>
A number of mechanisms have been shown to support the emergence of
cooperation: kin selection (Fisher 1930; Haldane 1932), green beards
(Hamilton 1964a,b; Dawkins 1976), secret handshakes (Robson 1990;
Wiseman &amp; Yilankaya 2001), iterated games, spatialized and
structured interactions (Grim 1995; Skyrms 1996, 2004; Grim, Mar, &amp; St. Denis
1998; Alexander 2007), and noisy signals (Nowak &amp; Sigmund
1992). This section offers examples of the last two of these.</p>

<p>
In the iterated Prisoner&rsquo;s Dilemma, players repeat their
interactions, either in a fixed number of rounds or in an infinite or
indefinite repetition. Robert Axelrod&rsquo;s tournaments in the early
1980s are the classic studies in the iterated prisoner&rsquo;s
dilemma, and early examples of the application of computational
techniques. Strategies for playing the Prisoner&rsquo;s Dilemma were
solicited from experts in various fields, pitted against all others
(and themselves) in round-robin competition over 200 rounds. Famously,
the strategy that triumphed was Tit for Tat, a simple strategy which
responds to cooperation from the other player on the previous round
with cooperation, responding to defection on the previous round with
defection. Even more surprisingly, Tit for Tat again came out in front
in a second tournament, despite the fact that submitted strategies
knew that Tit for Tat was the opponent to aim for. When those same
strategies were explored with replicator dynamics in place of
round-robin competition, Tit for Tat again was the winner (Axelrod and
Hamilton 1981). Further work has tempered Tit for Tat&rsquo;s
reputation somewhat, emphasizing the constraints of Axelrod&rsquo;s
tournaments both in terms of structure and the strategies submitted
(Kendall, Yao, &amp; Chang 2007; Kuhn 1997 [2019]).</p>

<p>
A simple set of eight &ldquo;reactive&rdquo; strategies, in which a
player acts solely on the basis of the opponent&rsquo;s previous move,
is shown in
 <a href="#fig15">Figure 15</a>.
 Coded with &ldquo;1&rdquo; for cooperate and &ldquo;0&rdquo; for
defect and three places representing first move <em>i</em>, response
to cooperation on the other side <em>c</em>, and response to defection
on the other side <em>d</em>, these give us 8 strategies that include
all defect, all cooperate, tit for tat as well as several other
variations. </p>

<div class="figure avoid-break" id="fig15">

<table class="cellpad-med-dense hrules centered">
<tr>
  <td><i>i</i></td>
  <td><i>c</i></td>
  <td><i>d</i></td>
  <td><em>reactive strategy</em></td>
</tr>
<tr>
  <td>0</td>
  <td>0</td>
  <td>0</td>
  <td>All Defect</td></tr>
<tr>
  <td>0</td>
  <td>0</td>
  <td>1</td>
  <td></td></tr>
<tr>
  <td>0</td>
  <td>1</td>
  <td>0</td>
  <td>Suspicious Tit for Tat</td></tr>
<tr>
  <td>0</td>
  <td>1</td>
  <td>1</td>
  <td>Suspicious All Cooperate</td></tr>
<tr>
  <td>1</td>
  <td>0</td>
  <td>0</td>
  <td>Deceptive All Defect</td></tr>
<tr>
  <td>1</td>
  <td>0</td>
  <td>1</td>
  <td></td></tr>
<tr>
  <td>1</td>
  <td>1</td>
  <td>0</td>
  <td>Tit for Tat</td></tr>
<tr>
  <td>1</td>
  <td>1</td>
  <td>1</td>
  <td>All Cooperate</td></tr>
</table>

<p class="center">
<span class="figlabel">Figure 15:</span> 8 reactive strategies in the
Prisoner&rsquo;s Dilemma</p>
</div>

<p>
If these strategies are played against each other and themselves, in
the manner of Axelrod&rsquo;s tournaments, it is &ldquo;all
defect&rdquo; that is the clear winner. If agents imitate the most
successful strategy, a population will thus immediately go to All
Defect&mdash;a game-theoretic image of Hobbes&rsquo; war of all
against all, perhaps.</p>

<p>
Consider, however, a spatialized Prisoner&rsquo;s Dilemma in the form
of cellular automata, easily run and analyzed on a computer. Cells are
assigned one of these eight strategies at random, play an iterated
game locally with their eight immediate neighbors in the array, and
then adopt the strategy of that neighbor (if any) that achieves a
higher total score. In this case, with the same 8 strategies,
occupation of the array starts with a dominance by All Defect, but
clusters of Tit for Tat grow to dominate the space
 (<a href="#fig16">Figure 16</a>).
 <a href="#OIR-NetlogoPrisonersDilemma">An interactive simulation in which one can choose which competing reactive strategies play in a spatialized array</a> is available in the Other Internet Resources section
below.</p>

<div class="figure centered avoid-break" id="fig16">
 <div class="figures" style="margin-bottom:4px;">
  <div class="inner-fig">
  <img src="Picture16a.png" style="width:150px;height:auto" alt="first of six 64x64 squares. The cells in this square are randomly colored with no apparent clustering " />
  </div>

  <div class="inner-fig">
  <img src="Picture16b.png" style="width:150px;height:auto" alt="second square, the cells are mostly green with some clusters of yellow and some of gray." />
  </div>

  <div class="inner-fig">
  <img src="Picture16c.png" style="width:150px;height:auto" alt="third square, the cells are about half green with 6 large clumps of gray and a few yellow cells adjacent to the gray clumps in places." />
  </div>
 </div>
 <div class="figures">
  <div class="inner-fig">
  <img src="Picture16d.png" style="width:150px;height:auto" alt="fourth square, more than half the cells are gray with one large clump of green and two very small clumps of green. Again a few yellow cells adjacent to the gray cells in places." />
  </div>

  <div class="inner-fig">
  <img src="Picture16e.png" style="width:150px;height:auto" alt="fifth square, two small clumps of green cells with a few yellow cells on the edge." />
  </div>

  <div class="inner-fig">
  <img src="Picture16f.png" style="width:150px;height:auto" alt="sixth square, all gray." />
  </div>
 </div>

<p>
<span class="figlabel">Figure 16:</span> Conquest by Tit for Tat in
the Spatialized Prisoner&rsquo;s Dilemma. All defect is shown in
green, Tit for Tat in gray (Grim, Mar, &amp; St. Denis 1998)</p>
</div>

<p>
In this case, there are two aspects to the emergence of cooperation in
the form of Tit for Tat. One is the fact that play is local:
strategies total points over just local interactions, rather than play
with all other cells. The other is that imitation is local as well:
strategies imitate their most successful neighbor, rather than that
strategy in the array that gained the most points. The fact that both
conditions play out in the local structure of the lattice allows
clusters of Tit for Tat to form and grow. In Axelrod&rsquo;s
tournaments it is particularly important that Tit for Tat does well in
play against itself; the same is true here. If either game interaction
or strategy updating is made global rather than local, dominance goes
to All Defect instead. One way in which cooperation can emerge, then,
is through structured interactions (Grim 1995; Skyrms 1996, 2004; Grim, Mar, &amp; St. Denis
1998). Alexander (2007) offers a particularly thorough
investigation of different interaction structures and different
games.</p>

<p>
Martin Nowak and Karl Sigmund offer a further variation that results
in an even more surprising level of cooperation in the
Prisoner&rsquo;s Dilemma (Nowak &amp; Sigmund 1992). The reactive
strategies outlined above are communicatively perfect strategies.
There is no noise in &ldquo;hearing&rdquo; a move as cooperation or
defection on the other side, and no &ldquo;shaking hand&rdquo; in
response. In Tit for Tat a cooperation on the other side is flawlessly
perceived as such, for example, and is perfectly responded to with
cooperation. If signals are noisy or responses are less than flawless,
however, Tit for Tat loses its advantage in play against itself. In
that case a chancy defection will set up a chain of mutual defections
until a chancy cooperation reverses the trend. A &ldquo;noisy&rdquo;
Tit for Tat played against itself in an infinite game does no better
than a random strategy.</p>

<p>
Nowak and Sigmund replace the &ldquo;perfect&rdquo; strategies of
 <a href="#fig14">Figure 14</a>
 with uniformly stochastic ones, reflecting a world of noisy signals
and actions. The closest to All Defect will now be a strategy .01,
.01, .01, indicating a strategy that has only a 99% chance of
defecting initially and in response to either cooperation or
defection. The closest to Tit for Tat will be a strategy .99, .99,
.01, indicating merely a high probability of starting with cooperation
and responding to cooperation with cooperation, defection with
defection. Using the mathematical fiction of an infinite game, Nowak
and Sigmund are able to ignore the initial value.</p>

<p>
Pitting a full range of stochastic strategies of this type against
each other in a computerized tournament, using replicator dynamics in
the manner of Axelrod and Hamilton (1981), Nowak and Sigmund trace a
progressive evolution of strategies. Computer simulation shows
imperfect All Defect to be an early winner, followed by Imperfect Tit
for Tat. But at that point dominance in the population goes to a still
more cooperative strategy which cooperates with cooperation 99% of the
time but cooperates even against defection 10% of the time. That
strategy is eventually dominated by one that cooperates against
defection 20% of the time, and then by one that cooperates against
defection 30% of the time. A replication of the Nowak and Sigmund
result is shown in
 <a href="#fig17">Figure 17</a>.
 Nowak and Sigmund show analytically that the most successful strategy
in a world of noisy information will be &ldquo;Generous Tit for
Tat&rdquo;, with probabilities of \(1 - &epsilon;\) and 1/3 for
cooperation against cooperation and defection respectively.</p>

<div class="figure centered avoid-break" id="fig17">
<img src="Picture17.png" style="width:100%;height:auto" alt="a 2-d graph; link to extended description below" />

<p>
<span class="figlabel">Figure 17:</span> Evolution toward Nowak and
Sigmund&rsquo;s &ldquo;Generous Tit for Tat&rdquo; in a world of
imperfect information (Nowak &amp; Sigmund 1992). Population
proportions are shown vertically for labelled strategies shown over
12,000 generations for an initial pool of 121 stochastic strategies
\(\langle c,d\rangle\) at .1 intervals, full value of 0 and 1 replaced
with 0.01 and 0.99 (Grim, Mar, &amp; St. Denis 1998). [An
 <a href="figdesc.html#fig17">extended description of figure 17</a>
 is in the supplement.]</p>
</div>

<p>
How can cooperation emerge in a society of self-serving egoists? In
the game-theoretic context of the Prisoner&rsquo;s Dilemma, these
results indicate that iterated interaction, spatialization and
structured interaction, and noisy information can all facilitate
cooperation, at least in the form of strategies such as Tit for Tat.
When all three effects are combined, the result appears to be a level
of cooperation even greater than that indicated in Nowak and Sigmund.
Within a spatialized Prisoner&rsquo;s Dilemma using stochastic
strategies, it is strategies in the region of probabilities \(1 -
&epsilon;\) and 2/3 that emerge as optimal in the sense of having the
highest scores in play against themselves without being open to
invasion from small clusters of other strategies (Grim 1996; Grim, Mar
&amp; St. Denis 1998).</p>

<p>
This outline has focused on some basic background regarding the
Prisoner&rsquo;s Dilemma and emergence of cooperation. More recently a
generation of richer game-theoretic models has appeared, using a wider
variety of games of conflict and coordination and more closely tied to
historical precedents in social and political philosophy. Newer
game-theoretic analyses of state of nature scenarios in Hobbes appear
in Vanderschraaf (2006) and Chung (2015), extended with simulation to
include Locke and Nozick in Bruner (forthcoming).</p>

<p>
There is also a new body of work that extends game-theoretic modeling
and simulation to questions of social inequity. Bruner (2017) shows that
the mere fact that one group is a minority in a population, and thus
interacts more frequently with majority than with minority members,
can result in its being disadvantaged where exchanges are
characterized by bargaining in a Nash demand game (Young 1993). Termed
the &ldquo;cultural Red King&rdquo;, the effect has been further
explored through simulation, with links to experiment, and with
extensions to questions of &ldquo;intersectional disadvantage&rdquo;,
in which overlapping minority categories are in play (O&rsquo;Connor
2017;
 <a href="#OIR-mohseni">Mohseni, O&rsquo;Connor, &amp; Rubin 2019 [Other Internet Resources]</a>;
 O&rsquo;Connor, Bright, &amp; Bruner 2019). The relevance of this to
the focus of the previous section is made clear in Rubin and
O&rsquo;Connor (2018) and O&rsquo;Connor and Bruner (2019), modeling
minority disadvantage in scientific communities.</p>

<h4 id="ModeDemo">3.3.2 Modeling democracy</h4>

<p>
In computational simulations, game-theoretic cooperation has been
appealed to as a model for aspects of both ethics in the sense of
Sidgwick and social-political philosophy on the model of Hobbes. That
model is tied to game-theoretic assumptions in general, however, and
often to the structure of the Prisoner&rsquo;s Dilemma in particular
(though Skyrms 2003 and Alexander 2007 are notable
exceptions). With regard to a wide range of questions in social and
political philosophy in particular, the limitations of game theory may
seem unhelpfully abstract and artificial.</p>

<p>
While still abstract, there are other attempts to model questions in
social political philosophy computationally. Here the studies
mentioned earlier regarding polarization are relevant. There have also
been recent attempts to address questions regarding epistemic
democracy: the idea that among its other virtues, democratic
decision-making is more likely to track the truth.</p>

<p>
There is a contrast, however, between open democratic decision-making,
in which a full population takes part, and representative democracy,
in which decision-making is passed up through a hierarchy of
representation. There is also a contrast between democracy seen as
purely a matter of voting and as a deliberative process that in some
way involves a population in wider discussion (Habermas 1992 [1996];
Anderson 2006; Landemore 2013).</p>

<div class="figure centered avoid-break" id="fig18">
<img src="Picture18.png" style="width:400px; height:auto" alt="a 2-d graph: link to extended description below" />

<p>
<span class="figlabel">Figure 18:</span> The Condorcet result:
probability of a majority of different odd-numbered sizes being
correct on a binary question with different homogeneous probabilities
of individual members being correct. [An
 <a href="figdesc.html#fig18">extended description of figure 18</a>
 is in the supplement.]</p>
</div>

<p>
The classic result for an open democracy and simple voting is the
Condorcet jury theorem (Condorcet 1785). As long as each voter has a
uniform an independent probability greater than 0.5 of getting an
answer right, the probability of a correct answer from a majority vote
is significantly higher than that of any individual, and it quickly
increases with the size of the population
 (<a href="#fig18">Figure 18</a>).</p>
 
<p>
It can be shown analytically that the basic thrust of the Condorcet
result remains when assumptions regarding uniform and independent
probabilities are relaxed (Boland, Proschan, &amp; Tong 1989; Dietrich
&amp; Spiekermann 2013). The Condorcet result is significantly
weakened, however, when applied in hierarchical representation, in
which smaller groups first reach a majority verdict which is then
carried to a second level of representatives who use a majority vote
on that level (Boland 1989). More complicated questions regarding
deliberative dynamics and representation require simulation using
computers.</p>

<p>
The Hong-Page structure of group deliberation, outlined in the context
of computational philosophy of science above, can also be taken as a
model of &ldquo;deliberative democracy&rdquo; beyond a simple vote.
The success of deliberation in a group can be measured as the average
value height of points found. In a representative instantiation of
this kind of deliberation, smaller groups of individuals first use
their individual heuristics to explore a landscape collectively, then
handing their collective &ldquo;best&rdquo; for each point on the
landscape to a representative. In a second round of deliberation, the
representatives work from the results from their constituents in a
second round of exploration.</p>

<p>
Unlike in the case of pure voting and the Condorcet result,
computational simulations show that the use of a representative
structure does not dull the effect of deliberation on this model:
average scores for three groups of three in a representative structure
are if anything slightly higher than average scores from an open
deliberation involving 9 agents (Grim, Bramson et al. forthcoming).
Results like these show how computational models might help expand the
political philosophical arguments for representative democracy.</p>

<p>
Social and political philosophy appears to be a particularly promising
area for big data and computational philosophy employing the data
mining tools of computational social science, but as of this writing
that development remains largely a promise for the future.</p>

<h4 id="SociOutcCompSyst">3.3.3 Social outcomes as complex systems</h4>

<p>
The guiding idea of the interdisciplinary theme known as
&ldquo;complex systems&rdquo; is that phenomena on a higher level can
&ldquo;emerge&rdquo; from complex interactions on a lower level
(Waldrop 1992, Kauffman 1995, Mitchell 2011, Krakauer 2019). The
emergence of social outcomes from the interaction of individual
choices is a natural target, and agent-based modeling is a natural
tool.</p>

<p>
Opinion polarization and the evolution of cooperation, outlined above,
both fit this pattern. A further classic example is the work of Thomas
C. Schelling on residential segregation. A glance at demographic maps
of American cities makes the fact of residential segregation obvious:
ethnic and racial groups appear as clearly distinguished patches
 (<a href="#fig19">Figure 19</a>).
 Is this an open and shut indication of rampant racism in American
life?</p>

<div class="figure centered avoid-break" id="fig19">
<img src="Picture19.png" style="width:100%; height:auto" alt="see caption, red, purple, green, and orange are all clustered" />

<p>
<span class="figlabel">Figure 19:</span> A demographic map of Los
Angeles. White households are shown in red, African-American in
purple, Asian-American in green, and Hispanic in orange.
 (<a href="#OIR-fischer">Fischer 2010 in Other Internet Resources</a>)
 </p>
</div>

<p>
Schelling attempted an answer to this question with an agent-based
model that originally consisted of pennies and dimes on a checkerboard
array (Schelling 1971, 1978), but which has been studied
computationally in a number of variations. Two types of agents
(Schelling&rsquo;s pennies and dimes) are distributed at random across
a cellular automata lattice, with given preferences regarding their
neighbors. In its original form, each agent has a threshold regarding
neighbors of &ldquo;their own kind&rdquo;. At that threshold level and
above, agents remain in place. Should they not have that number of
like neighbors, they move to another spot (in some variations, a move
at random, in others a move to the closest spot that satisfies their
threshold).</p>

<p>
What Schelling found was that residential segregation occurs even
without a strong racist demand that all of one&rsquo;s neighbors, or
even most, are &ldquo;of one&rsquo;s kind&rdquo;. Even when preference
is that just a third of one&rsquo;s neighbors are &ldquo;of
one&rsquo;s kind&rdquo;, clear patches of residential segregation
appear. The iterated evolution of such an array is shown in
 <a href="#fig20">Figure 20</a>.
 See
 <a href="#OIR-NetlogoSegregation">the interactive simulation of this residential segregation model</a>
 in the Other Internet Resources section below. </p>

<div class="figure centered avoid-break" id="fig20">
 <div class="figures">
  <div class="inner-fig">
  <img src="Picture20a.png" style="width:150px;height:auto" alt="a large grid of red and green circles on a black background (with a few places with no circles), randomly distributed with only a few small clumps of either red or green." />
</div>

  <div class="inner-fig">
  <img src="Picture20b.png" style="width:150px;height:auto" alt="same large grid but now some moderate size clumps of red and green circles." />
  </div>

  <div class="inner-fig">
  <img src="Picture20c.png" style="width:150px;height:auto" alt="same large grid but now almost all the red or green circles are adjacent to several circles of the same color (large clumps)." />
  </div>
 </div>
<p>
<span class="figlabel">Figure 20:</span> Emergence of residential
segregation in the Schelling model with preference threshold set at
33%</p>
</div>

<p>
The conclusion that Schelling is careful to draw from such a model is
simply that a low level of preference can be sufficient for
residential segregation. It does not follow that more egregious social
and economic factors aren&rsquo;t operative or even dominant in the
residential segregation we actually observe. </p>

<p>
In this case basic modeling assumptions have been challenged on
empirical grounds. Elizabeth Bruch and Robert Mare use sociological
data on racial preferences, challenging the sharp cut-off employed in
the Schelling model (Bruch &amp; Mare 2006). They claim on the basis
of simulation that the Schelling effect disappears when more
realistically smooth preference functions are used instead. Their
simulations and the latter claim turn out to be in error (van de Rijt,
Siegel, &amp; Macy 2009), but the example of testing the robustness of
simple models with an eye to real data remains a valuable one.</p>

<h3 id="CompPhilLang">3.4 Computational Philosophy of Language</h3>

<p>
Computational modeling has been applied in philosophy of language
along two main lines. First, there are investigations of analogy and
metaphor using models of semantic webs that share a developmental
history with some of the models of scientific theory outlined above.
Second, there are investigations of the emergence of signaling, which
have often used a game-theoretic base akin to some approaches to the
emergence of cooperation discussed above.</p>

<h4 id="SemaWebsAnalMeta">3.4.1 Semantic webs, analogy and metaphor</h4>

<p>
WordNet is a computerized lexical database for English built by George
Miller in 1985 with a hierarchical structure of semantic categories
intended to reflect empirical observations regarding human processing.
A category &ldquo;bird&rdquo; includes a sub-category
&ldquo;songbirds&rdquo; with &ldquo;canary&rdquo; as a particular, for
example, intended to explain the fact that subjects could more quickly
process &ldquo;canaries sing&rdquo;&mdash;which involves traversing
just one categorical step&mdash;than they could process
&ldquo;canaries fly&rdquo; (Miller, Beckwith, Fellbaum, Gross, &amp;
Miller 1990).</p>

<p>
There is a long tradition, across psychology, linguistics, and
philosophy, in which analogy and metaphor are seen as an important key
to abstract reasoning and creativity (Black 1962; Hesse 1943 [1966];
Lakoff &amp; Johnson 1980; Gentner 1982; Lakoff &amp; Turner 1989).
Beginning in the 1980s several notable attempts have been made to
apply computational tools in order to both understand and generate
analogies. Douglas Hofstadter and Melanie Mitchell&rsquo;s Copycat,
developed as a model of high-level cognition, has
&ldquo;codelets&rdquo; compete within a network in order to answer
simple questions of analogy: &ldquo;abc is to abd as ijk is to
what?&rdquo; (Hofstadter 2008). Holyoak and Thagard envisage metaphors
as analogies in which the source and target domain are semantically
distinct, calling for relational comparison between two semantic nets
(Holyoak &amp; Thagard 1989, 1995; see also Falkenhainer, Forbus,
&amp; Gentner 1989). In the Holyoak and Thagard model those
comparisons are constrained in a number of different ways that call
for coherence; their computational modeling for coherence in the case
of metaphor was in fact a direct ancestor to Thagard&rsquo;s coherence
modeling of scientific theory change discussed above (Thagard 1988,
1992).</p>

<p>
Eric Steinhart and Eva Kittay&rsquo;s
 <a href="#OIR-NETMET">NETMET (see Other Internet Resources)</a>
 offers an illustration of the relational approach to analogy and
metaphor. They use one semantic and inferential subnet related to
birth another related to the theory of ideas in the Theatetus. Each
subnet is categorized in terms of relations of containment,
production, discarding, helping, passing, expressing and opposition.
On that basis NETMET generates metaphors including &ldquo;Socrates is
a midwife&rdquo;, &ldquo;the mind is an intellectual womb&rdquo;,
&ldquo;an idea is a child of the mind&rdquo;, &ldquo;some ideas are
stillborn&rdquo;, and the like (Steinhart 1994; Steinhart &amp; Kittay
1994). NETMET can be applied to large linguistic databases such as
WordNet.</p>

<h4 id="SignGameEmerComm">3.4.2 Signaling games and the emergence of communication</h4>

<blockquote class="bigindent">

<p>
Suppose we start without pre-existing meaning. Is it possible that
under favorable conditions, unsophisticated learning dynamics can
spontaneously generate meaningful signaling? The answer is
affirmative. <span class="blockright">&mdash;Brian Skyrms,
<em>Signals</em> (2010: 19)</span></p>
</blockquote>

<p>
David Lewis&rsquo; sender-receiver game is a cooperative game in which
a sender observes a state of nature and chooses a signal, a receiver
observes that signal and chooses an act, with both sender and receiver
benefiting from an appropriate coordination between state of nature
and act (Lewis 1969). A number of researchers have explored both
analytic and computational models of signaling games with an eye to
ways in which initially arbitrary signals can come to function in ways
that start to look like meaning.</p>

<p>
Communication can be seen as a form of cooperation, and here as in the
case of the emergence of cooperation the methods of (communicative)
strategy change seem less important than the interactive structure in
which those strategies play out. Computer simulations show that simple
imitation of a neighbor&rsquo;s successful strategy, various forms of
reinforcement learning, and training up of simple neural nets on
successful neighbors&rsquo; behaviors can all result in the emergence
and spread of signaling systems, sometimes with different dialects
(Zollman 2005; Grim, St.
Denis &amp; Kokalis 2002; Grim, Kokalis, Alai-Tafti, Kilb &amp; St. Denis, 2004).<sup>[<a href="notes.html#note-9" id="ref-9">9</a>]</sup>
 Development on a cellular automata grid produces communication with
any of these techniques, even when the rewards are one-sided rather
than mutual in a strict Lewis signaling game, but structures of
interaction that facilitate communication can also co-evolve with the
communication they facilitate as well (Skyrms 2010). Elliot Wagner
extends the study of communication on interaction structures to other
networks as well (Wagner 2009).</p>

<p>
On an interpretation in terms of biological evolution, computationally
emergent signaling of this sort can be seen as modeling communication
in Vervet monkeys (Cheney &amp; Seyfarth 1990) or even chemical
&ldquo;signals&rdquo; in bacteria (Berleman, Scott, Chumley, &amp;
Kirby 2008). If interpreted in terms of learned culture, particularly
with an eye to more complex signal combination, these have been
offered as models of mechanisms at play in the development of human
language (Skyrms 2010).
 <a href="#OIR-NetlogoSignalingModel">A simple interactive model in which signaling emerges in a situated population of agents harvesting food sources and avoiding predators</a>
 is available in the Other Internet Resources section below.</p>

<h3 id="TheoProvEthiReasMetaPhilReli">3.5 From Theorem-Provers to Ethical Reasoning, Metaphysics, and Philosophy of Religion</h3>

<p>
Many of our examples of computational philosophy have been examples of
simulation&mdash;often social simulation by way of agent-based
modeling. But there is also a strong tradition in which computation is
used not in simulations but as a way of mechanizing and extending
philosophical argument (typically understood as deductive proof), with
applications in philosophy of logic and ultimately in deontic logic,
metaphysics, and philosophy of
 religion.<sup>[<a href="notes.html#note-10" id="ref-10">10</a>]</sup></p>
 
<p>
Entitling a summer Dartmouth conference in 1956, the organizers coined
the term &ldquo;artificial intelligence&rdquo;. One of the high points
of that conference was a computational program for the construction of
logical proofs, developed by Allen Newell and Herbert Simon at
Carnegie Mellon and programmed by J. C. Shaw using the vacuum tubes of
the JOHNNIAC computer at the Institute for Advanced Study (Bringsjord
&amp; Govindarajulu 2018 [2019]). Newell and Simon&rsquo;s
&ldquo;Logic Theorist&rdquo; was given 52 theorems from chapter two of
Whitehead and Russell&rsquo;s <em>Principia Mathematica</em> (1910, 1912, 1913), of which it successfully
proved 38, including a proof more elegant than one of Whitehead and
Russell&rsquo;s own (MacKenzie 1995, Loveland 1984, Davis 1957
[1983]). Russell himself was impressed:</p>

<blockquote>

<p>
I am delighted to know that <em>Principia Mathematica</em> can now be
done by machinery&hellip; I am quite willing to believe that
everything in deductive logic can be done by machinery. (letter to
Herbert Simon, 2 November 1956; quoted in O&rsquo;Leary 1991: 52) </p>
</blockquote>

<p>
Despite possible claims to anticipation, the most compelling of which
may be Martin Davis&rsquo;s 1950 computer implementation of Mojsesz
Presburger&rsquo;s decision procedure for a fragment of arithmetic
(Davis 1957), the Logic Theorist is standardly regarded as the first
automated theorem-prover. Newell and Simon&rsquo;s target, however,
was not so much a logic prover as a proof of concept for an
intelligent or thinking machine. Having rejected geometrical proof as
too reliant on diagrams, and chess as too hard, by Simon&rsquo;s own
account they turned to logic because <em>Principia Mathematica</em>
happened to be on his
 shelf.<sup>[<a href="notes.html#note-11" id="ref-11">11</a>]</sup>
 </p>

<p>
Simon and Newell&rsquo;s primary target was not an optimized
theorem-prover but a &ldquo;thinking machine&rdquo; that in some way
matched human intelligence. They therefore relied in heuristics
thought of as matching human strategies, an approach later ridiculed
by Hao Wang:</p>

<blockquote>

<p>
There is no need to kill a chicken with a butcher&rsquo;s knife, yet
the net impression is that Newell-Shaw-Simon failed even to kill the
chicken&hellip;to argue the superiority of &ldquo;heuristic&rdquo;
over algorithmic methods by choosing a particularly inefficient
algorithm seems hardly just. (Wang 1960: 3)</p>
</blockquote>

<p>
Later theorem-provers were focused on proof itself rather than a model
of human reasoning. By 1960 Hao Wang, Paul Gilmore, and Dag Prawitz
had developed computerized theorem-provers for the full first-order
predicate calculus (Wang 1960, MacKenzie 1995). In the 1990s William
McCune developed Otter, a widely distributed and accessible prover for
first-order logic (McCune &amp; Wos 1997, Kalman 2001). A more recent
incarnation is Prover9, coupled with search for models and
counter-examples in <a href="#OIR-mace4">Mace4</a>. <a href="#OIR-prover9">Examples of Prover9 derivations are offered in Other Internet Resources.</a> A contemporary alternative is <a href="#OIR-vampire">Vampire</a>, developed by Andrei Voronkov, Kry&scaron;tof Hodere, and Alexander Rizanov (Riazanov &amp; Voronkov 2002).</p>

<p>
Theorem-provers developed for higher-order logics, working from a
variety of approaches, include TPS (Andrews and Brown 2006), Leo-II
and -III (Benzm&uuml;ller, Sultana, Paulson, &amp; Thei&szlig; 2015;
Steen &amp; Benzm&uuml;ller 2018), and perhaps most prominently HOL
and particularly development-friendly
 <a href="#OIR-vampire">Isabelle/HOL</a>
 (Gordon &amp; Melham 1993; Paulson 1990). With clever implementation
and extension, these also allow automation of aspects of modal,
deontic, epistemic, intuitionistic and paraconsistent logics, of
interest both in their own terms and in application within computer
science, robotics, and artificial intelligence (McRobbie 1991; Abe,
Akama, &amp; Nakamatsu 2015).</p>

<p>
Within pure logic, Portararo (2001 [2019]) lists a number of results
that have been established using automated theorem-provers. It was
conjectured for 50 years that a particular equation in a Robbins
algebra could be replaced by a simpler one, for example. Even Tarski
had failed in the attempt at proof, but McCune produced an automated
proof in 1997 (McCune 1997). Shortest and simplest axiomatizations for
implicational fragments of modal logics S4 and S5 had been studied for
years as open questions, with eventual results by automated reasoning
in 2002 (Ernst, Fitelson, Harris, &amp; Wos
 2002).<sup>[<a href="notes.html#note-12" id="ref-12">12</a>]</sup></p>
 
<p>
Theorem provers have been applied within deontic logics in the attempt
to mechanize ethical reasoning and decision-making (Meyer &amp;
Wierenga 1994; Van Den Hoven &amp; Lokhorst 2002; Balbiani, Broersen,
&amp; Brunel 2009; Governatori &amp; Sartor 2010; Benzm&uuml;ller,
Parent, &amp; van der Torre 2018; Benzm&uuml;ller, Farjami, &amp;
Parent, 2018). Alan Gewirth has argued that agents contradict their
status as agents if they don&rsquo;t accept a principle of generic
consistency&mdash;respecting the agency-necessary rights of
others&mdash;as a supreme principle of practical rationality (Gewirth
1978; Beyleveld 1992, 2012). Fuenmayor and Benzm&uuml;ller have shown
that even an ethical theory of this complexity can be formally encoded
and assessed computationally (Fuenmayor &amp; Benzm&uuml;ller
2018).</p>

<p>
One of the major advances in computational philosophy has been the
application of theorem-provers to the analysis of classical
philosophical positions and arguments. From axioms of a metaphysical
object theory, Zalta and his collaborators use Prover9 and Mace to
establish theorems regarding possible worlds, such as the claim that
every possible world is maximal, modal theorems in Leibniz, and
consequences from Plato&rsquo;s theory of Forms (Fitelson &amp; Zalta
2007; Alama, Oppenheimer, &amp; Zalta 2015; Kirchner, Benzm&uuml;ller,
&amp; Zalta 2019).</p>

<p>
Versions of the ontological argument have formed an important thread
in recent work employing theorem provers, both because of their
inherent interest and the technical challenges they bring with them.
Prover9 and Mace have again been used recently by Jack Horner in order
to analyze a version of the ontological argument in Spinoza&rsquo;s
<em>Ethics</em> (found invalid) and to propose an alternative (Horner
2019). Significant work has been done on versions of Anselm&rsquo;s
ontological argument (Oppenheimer &amp; Zalta 2011; Garbacz 2012;
Rushby 2018). Christoph Benzm&uuml;ller and his colleagues have
applied higher-order theorem provers, including including Isabelle/HOL
and their own Leo-II and Leo-III, in order to analyze a version of the
ontological argument found in the papers of Kurt G&ouml;del
(Benzm&uuml;ller &amp; Paelo 2016a, 2016b; Benzm&uuml;ller, Weber,
&amp; Paleo 2017; Benzm&uuml;ller &amp; Fuenmayor 2018). A previously
unnoticed inconsistency was found in G&ouml;del&rsquo;s original,
though avoided in Dana Scott&rsquo;s transcription. Theorem-provers
confirmed that G&ouml;del&rsquo;s argument forces modal
collapse&mdash;all truths become necessary truths. Analysis with
theorem-provers makes it clear that variations proposed by C. Anthony
Anderson and Melvin Fitting avoid that consequence, but in importantly
different ways (Benzm&uuml;ller &amp; Paleo 2014; Kirchner,
Benzm&uuml;ller, &amp; Zalta
 2019).<sup>[<a href="notes.html#note-13" id="ref-13">13</a>]</sup></p>
 

<p>
Work in metaphysics employing theorem-provers continues. Here of
particular note is Ed Zalta&rsquo;s ambitious and long-term attempt to
ground metaphysics quite generally in computationally instantiated
object theory (Fitelson &amp; Zalta 2007; Zalta 2020).
 <a href="#OIR-mally">A link to Zalta&rsquo;s project can be found in the Other Internet Resources section below.</a>
 </p>

<h3 id="ArtiIntePhilMind">3.6 Artificial Intelligence and Philosophy of Mind</h3>

<p>
The Dartmouth conference of 1956 is standardly taken as marking the
inception of both the field and the term &ldquo;artificial
intelligence&rdquo; (AI). There were, however, two distinct
trajectories apparent in that conference. Some of the participants
took as their goal to be the development of intelligent or thinking
machines, with perhaps an understanding of human processing as a
begrudging means to that end. Others took their goal to be a
philosophical and psychological understanding of human processing,
with the development of machines a means to that end. Those in the
first group were quick to exploit linear programming: what came to be
known as &ldquo;GOFAI&rdquo;, or &ldquo;good old-fashioned artificial
intelligence&rdquo;. Those in the second group rejoiced when
connectionist and neural net architectures came to maturity several
decades later, promising models directly built on and perhaps
reflective of mechanisms in the human brain (Churchland 1995).</p>

<p>
Attempts to understand perception, conceptualization, belief change,
and intelligence are all part of philosophy of mind. The use of
computational models toward that end&mdash;the second strand
above&mdash;thus comes close to computational philosophy of mind.
Daniel Dennett has come close to saying that AI <em>is</em> philosophy
of mind: &ldquo;a most abstract inquiry into the possibility of
intelligence or knowledge&rdquo; (Dennett 1979: 60; Bringsjord &amp;
Govindarajulu 2018 [2019]).</p>

<p>
The bulk of AI research remains strongly oriented toward producing
effective and profitable information processing, whether or not the
result offers philosophical understanding. So it is perhaps better not
to identify AI with philosophy of mind, though AI has often been
guided by philosophical conceptions and aspects of AI have proven
fruitful for philosophical exploration. Philosophy <em>of</em> AI and
philosophy of mind <em>inspired by</em> and <em>in response</em> to
AI, which are not the topic here, have both been far more common than
philosophy of mind developed with the techniques of AI.</p>

<p>
One example of a program in artificial intelligence that was
explicitly conceived in philosophical terms and designed for
philosophical ends was the OSCAR project, developed by John Pollock
but cut short by his death (Pollock 1989, 1995, 2006). The goal of
OSCAR was construction of a computational agent: an &ldquo;artificial
intellect&rdquo;. At the core of OSCAR was implementation of a theory
of rationality. Pollock was explicit regarding the intersection of AI
and philosophy of mind in that project: </p>

<blockquote>

<p>
The implementability of a theory of rationality is a necessary
condition for its correctness. This amounts to saying that philosophy
needs AI just as much as AI needs philosophy. (Pollock 1995: xii;
Bringsjord &amp; Govindarajulu 2018 [2019])</p>
</blockquote>

<p>
At the core of OSCAR&rsquo;s rationality is implementation of
defeasible non-monotonic logic employing prima facie reasons and
potential defeaters. Among its successes, Pollock claims an ability to
handle the lottery paradox and preface paradoxes. Informally, the fact
that we know that one of the many tickets in a lottery will win means
that we must treat &ldquo;ticket 1 will not win&hellip;&rdquo;,
&ldquo;ticket 2 will not win&hellip;&rdquo; and the like not as items
of knowledge but as defeasible beliefs for which we have strong prima
facie reasons. Pollock&rsquo;s formal treatment in terms of collective
defeat is nicely outlined in a supplement on OSCAR in Bringsjord &amp;
Govindarajulu (2018 [2019]).</p>

<h2 id="EvalCompPhil">4. Evaluating Computational Philosophy</h2>

<p>
The sections above were intended to be an introduction to
computational philosophy largely by example, emphasizing both the
variety of computational techniques employed and the spread of
philosophical topics to which they are applied. This final section is
devoted to the problems and prospects of computational philosophy.</p>

<h3 id="Crit">4.1 Critiques</h3>

<p>
Although computational instantiations of logic are of an importantly
different character, simulation&mdash;including agent-based
simulation&mdash;plays a major role in much of computational
philosophy. Beyond philosophy, across all disciplines of its
application, simulation often raises suspicions.</p>

<p>
A standard suspicion of simulation in various fields is that it one
&ldquo;can prove anything&rdquo; by manipulation of model structure
and parameters. The worry is that an anticipated or desired effect
could always be &ldquo;baked in&rdquo;, programmed as an artefact of
the model itself. Production of a simulation would thus demonstrate
not the plausibility of a hypothesis or a fact about the world but
merely the cleverness of the programmer. In a somewhat different
context, Rodney Brooks has written that the problem with simulations
is that they are &ldquo;doomed to succeed&rdquo; (Brooks &amp; Mataric
1993).</p>

<p>
But consider a similar critique of logical argument: that one
&ldquo;can prove anything&rdquo; by careful choice of premises and
rules of inference. The proper response in the case of logical
argument is to concede the fact that a derivation for any proposition
can be produced from carefully chosen premises and rules, but to
emphasize that it may be difficult or impossible to produce a
derivation from agreed rules and clear and plausible premises.</p>

<p>
A similar response is appropriate here. The effectiveness of
simulation as argument depends on the strength of its assumptions and
the soundness of its mechanisms just as the effectiveness of logical
proof depends on the strength of its premises and the validity of its
rules of inference. The legitimate force of the critique, then, is not
that simulation is inherently untrustworthy but simply that the
assumptions of any simulation are always open to further
examination.</p>

<p>
Anyone who has attempted computer simulation can testify that it is
often extremely difficult or impossible to produce an expected effect,
particularly a robust effect across a plausible range of parameters
and with a plausible basic mechanism. Like experiment, simulation can
demonstrate both the surprising fragility of a favored hypothesis and
the surprising robustness of an unexpected effect.</p>

<p>
Far from being &ldquo;doomed to succeed&rdquo;, simulations fail quite
regularly in several important ways (Grim, Rosenberger, Rosenfeld,
Anderson, &amp; Eason 2013). Two standard forms of simulation failure
are failure of verification and failure of validation (Kleijnen 1995;
Windrum, Fabiolo, &amp; Moneta 2007; Sargent 2013). Verification of a
model demands assuring that it accurately reflects design intention.
If a computational model is intended to instantiate a particular
theory of belief change, for example, it fails verification if it does
not accurately represent the dynamics of that theory. Validation is
perhaps the more difficult demand, particularly for philosophical
computation: that the computational model adequately reflects those
aspects of the real world it is intended to capture or explain.</p>

<p>
If its critics are right, a simple example of verification failure is the original Weisberg and
Muldoon model of scientific exploration outlined above (Weisberg &amp;
Muldoon 2009). The model was intended to include two kinds of
epistemic agents&mdash;followers and mavericks&mdash;with distinct
patterns of exploration. Mavericks avoid previously investigated
points in their neighborhood. Followers move to neighboring points
that have been investigated but that have a higher significance. In
contrast to their description in the text, the critics argue, the software
for the model used &ldquo;&gt;=&rdquo; in place of &ldquo;&gt;&rdquo;
at a crucial place, with the result that followers moved to
neighboring points with a higher or equal significance, resulting in
their often getting stuck in a very local oscillation (Alexander, Himmelreich, &amp; Thomson 2015). If so, Weisberg and
Muldoon&rsquo;s original model fails to match its design
intention&mdash;it fails verification&mdash;though some of their
general conclusions regarding epistemic diversity have been vindicated
in further studies.</p>

<p>
Validation is a very different and more difficult demand: that a
simulation model adequately captures relevant aspects of what it is
intended to model. A common critique of specific models is that they
are too simple, leaving out some crucial aspect of the modeled
phenomenon. When properly targeted, this can be an entirely
appropriate critique. But what it calls for is not the abandonment of
modeling but better construction of a better model.</p>

<blockquote>

<p>
In time&hellip;the Cartographers Guilds struck a Map of the Empire
whose size was that of the Empire, and which coincided point for point
with it. The following Generations, saw that that vast Map was
Useless&hellip;. (Jorge Luis Borges, &ldquo;On Exactitude in
Science&rdquo;, 1946 [1998 English translation: 325])</p>
</blockquote>

<p>
Borges&rsquo; story is often quoted in illustration of the fact that
no model&mdash;and no scientific theory&mdash;can include all
characteristics of what it is intended to model (Weisberg 2013).
Models and theories would be useless if they did: the purpose of both
theories and models is to present simpler representations or
mechanisms that capture the <em>relevant</em> features or dynamics of
a phenomenon. What aspects of a phenomenon are in fact the relevant
aspects for understanding that phenomenon calls for evaluative input
outside of the model. But where relevant aspects are omitted,
irrelevant aspects included, or unrealistic or artificial constraints
imposed, what a critique calls for is a better model (Martini &amp;
Pinto 2017; Thicke forthcoming).</p>

<p>
There is one aspect of validation that can sometimes be gauged at the
level of modeling itself and with modeling tools alone. Where the
target is some general phenomenon&mdash;opinion polarization or the
emergence of communication, for example&mdash;a model which produces
that phenomenon within only a tiny range of parameters should be
suspicious. Our estimate of the parameters actually in play in the
actual phenomenon may be merely intuitive or extremely rough, and the
real phenomenon may be ubiquitous in a wide range of settings. In such
a case, it would seem prima facie unlikely that a model which produced
a parallel effect within only a tiny window of parameters could be
capturing the general mechanism of a general phenomenon. In such cases
robustness testing is called for, a test for one aspect of validation
that can still be performed on the computer. To what extent do
conclusions drawn from the modeling effect hold up under a range of
parameter variations?</p>

<p>
The Hong-Page model of the value of diversity in exploration, outlined
above, has been widely appealed to quite generally as support for
cognitive diversity in groups. It has been cited in NASA internal
documents, offered in support of diversity requirements at UCLA, and
appears in an <em>amicus curiae</em> brief before the Supreme Court in
support of promoting diversity in the armed forces (Fisher v. Univ. of
Texas 2016). But the model is not robust across its several parameters
to support sweepingly general claims that have been made on its basis
regarding diversity and ability or expertise (Grim et al. 2019). Is that a problem internal to the model, or an external matter
of its interpretation or application? There is much to be said for the
latter alternative. The model is and remains an interesting
one&mdash;interesting often in the ways in which it <em>does</em> show
sensitivity to different parameters. Thus a failure of one aspect of
validation&mdash;robustness&mdash;with an eye to one type of general
claim can also call for further modelling: modeling intended to
explore different effects in different contexts. Rosenstock, Bruner,
and O&rsquo;Connor (2017) offer a robustness test for the Zollman
model outlined above. Borg, Frey, &Scaron;e&scaron;elja, and
Stra&szlig;er (2018) offer new modeling grounded precisely in a
robustness critique of their predecessors.</p>

<p>
It is noteworthy that the simulation failures mentioned have been
detected and corrected within the literature of simulation itself.
These are effective critiques within disciplines employing simulation,
rather than from outside. An illustration of a such a case with both
verification and validation in play is that of the Bruch and Mare
critique of the Schelling segregation model and the response to it in
van Rooij, Siegel, and Macy (Schelling 1971, 1978; Bruch &amp; Mare
2006; van de Rijt, Siegel, &amp; Macy 2009). Many aspects of that
model are clearly artificial: a limitation to two groups,
spatialization on a cellular automata grid, and
&ldquo;unhappiness&rdquo; or moving in terms of a sharp threshold
cut-off of tolerance for neighbors of the other group. Bruch and Mare
offered clear empirical evidence that residential preferences do not
fit a sharp threshold. More importantly, they built a variation of the
Schelling model in order to show that the Schelling effect disappeared
with more realistic preference profiles. What Bruch and Mare
challenged, in other words, was <em>validation</em>: not merely that
aspects of the target phenomenon of residential segregation were left
out (as they would be in any model), but that relevant aspects were
left out: differences that made an important difference. Van de Rijt,
Siegel, and Macy failed to understand why the smooth preference curves
in Bruch and Mare&rsquo;s data wouldn&rsquo;t support rather than
defeat a Schelling effect. On investigation they found that they
would: Bruch and Mare&rsquo;s validation claim against Schelling was
itself founded in a programming error. De Rijt, Siegel and
Macy&rsquo;s verdict was that Bruch and Mare&rsquo;s attack itself
failed model <em>verification</em>.</p>

<p>
In the case of both Weisberg and Muldoon, and Bruch and Mare, original
code was made freely available to their critics. In both cases, the
original authors recognized the problems revealed, though emphasizing
aspects of their work that survived the criticisms. Here again an
important point is that critiques and responses of this type have
arisen and been addressed within philosophical and scientific
simulation itself, working toward better models and practices.</p>

<h3 id="ProsUndeAspe">4.2 Prospects and Undeveloped Aspects</h3>

<p>
Philosophy at its best has always been in contact with the conceptual
and scientific methodologies of its time. Computational philosophy can
be seen as a contemporary instantiation of that contact, crossing
disciplinary boundaries in order to both influence and benefit from
developments in computer science and artificial intelligence.
Incorporation of new technologies and wider application within
philosophy can be expected and should be hoped for.</p>

<p>
There is one extremely promising area in need of development within
computational philosophy, though that area may also call for changes
in conceptions of philosophy itself. Philosophy has classically been
conceived as abstract rather than concrete, as seeking understanding
at the most general level rather than specific prediction or
retrodiction, often normative, and as operating in terms of logical
argument and analysis rather than empirical data. The last of these
characteristics, and to some extent the first, will have to be
qualified if computational philosophy grows to incorporate a major
batch of contemporary techniques: those related to big data.</p>

<p>
Expansion of computational philosophy in the intersection with big
data seems an exciting prospect for social and political philosophy,
in the analysis of belief change, and in understanding the social and
historical dynamics of philosophy of science (Overton 2013; Pence
&amp; Ramsey 2018). A particular benefit would be better prospects for
validation of a range of simulations and agent-based models, as
emphasized above (M&auml;s 2019; Reijula &amp; Kuorikoski 2019). If
computational philosophy moves in that promising direction, however,
it may take on a more empirical character in some respects. Emphasis
on general and abstract understanding and concern with the normative
will remain marks of a philosophical approach, but the membrane
between some topic areas in philosophy and aspects of computational
science can be expected to become more permeable.</p>

<p>
Dissolving these disciplinary boundaries may itself be a good in some
respects. The examples presented above make it clear that in
incorporating (and contributing to) computational techniques developed
in other areas, computational philosophy has long been
cross-disciplinary. If our gain is a better understanding of the
topics that have long fascinated us, compromise in disciplinary
boundaries and a change in our concept of philosophy seem a small
price to pay.</p>

</div>

<div id="bibliography">

<h2 id="Bib">Bibliography</h2>



<ul class="hanging">

<li>Abe, Jair Minoro, Seiki Akama, and Kazumi Nakamatsu, 2015,
<em>Introduction to Annotated Logics: Foundations for Paracomplete and
Paraconsistent Reasoning</em>, (Intelligent Systems Reference Library
88), Cham: Springer International Publishing.
doi:10.1007/978-3-319-17912-4</li>

<li>Alama, Jesse, Paul E. Oppenheimer, and Edward N. Zalta, 2015,
&ldquo;Automating Leibniz&rsquo;s Theory of Concepts&rdquo;, in
<em>Automated Deduction&mdash;CADE-25: Proceedings of the 25th
International Conference on Automated Deduction, Berlin, Germany,
August 1&ndash;7, 2015</em>, Amy P. Felty and Aart Middeldorp (eds.),
(Lecture Notes in Computer Science 9195), Cham: Springer International
Publishing, 73&ndash;97. doi:10.1007/978-3-319-21401-6_4</li>

<li>Alchourr&oacute;n, Carlos E., Peter G&auml;rdenfors, and David
Makinson, 1985, &ldquo;On the Logic of Theory Change: Partial Meet
Contraction and Revision Functions&rdquo;, <em>Journal of Symbolic
Logic</em>, 50(2): 510&ndash;530. doi:10.2307/2274239</li>

<li>Alexander, J. McKenzie, 2007, <em>The Structural Evolution of
Morality</em>, Cambridge: Cambridge University Press.
doi:10.1017/CBO9780511550997</li>

<li>Alexander, J. McKenzie, Johannes Himmelreich, and Christopher
Thompson, 2015, &ldquo;Epistemic Landscapes, Optimal Search, and the
Division of Cognitive Labor&rdquo;, <em>Philosophy of Science</em>,
82(3): 424&ndash;453. doi:10.1086/681766</li>

<li>Anderson, Elizabeth, 2006, &ldquo;The Epistemology of
Democracy&rdquo;, <em>Episteme</em>, 3(1&ndash;2): 8&ndash;22.
doi:10.3366/epi.2006.3.1-2.8</li>

<li>Andrews, Peter B. and Chad E. Brown, 2006, &ldquo;TPS: A Hybrid
Automatic-Interactive System for Developing Proofs&rdquo;, <em>Journal
of Applied Logic</em>, 4(4): 367&ndash;395.
doi:10.1016/j.jal.2005.10.002</li>

<li>Angere, Staffan and Erik J. Olsson, 2017, &ldquo;Publish Late,
Publish Rarely!: Network Density and Group Performance in Scientific
Communication&rdquo;, in <em>Scientific Collaboration and Collective
Knowledge: New Essays</em>, Thomas Boyer-Kassem, Conor Mayo-Wilson,
and Michael Weisberg (eds.), New York: Oxford University Press, pp. 34-63.
</li>

<li>Axelrod, Robert, 1997, &ldquo;The Dissemination of Culture: A
Model with Local Convergence and Global Polarization&rdquo;,
<em>Journal of Conflict Resolution</em>, 41(2): 203&ndash;226.
doi:10.1177/0022002797041002001</li>

<li>Axelrod, Robert and W. D. Hamilton, 1981, &ldquo;The Evolution of
Cooperation&rdquo;, <em>Science</em>, 211(4489): 1390&ndash;1396.
doi:10.1126/science.7466396</li>

<li>Bala, Venkatesh and Sanjeev Goyal, 1998, &ldquo;Learning from
Neighbours&rdquo;, <em>Review of Economic Studies</em>, 65(3):
595&ndash;621. doi:10.1111/1467-937X.00059</li>

<li>Balbiani, Philippe, Jan Broersen, and Julien Brunel, 2009,
&ldquo;Decision Procedures for a Deontic Logic Modeling Temporal
Inheritance of Obligations&rdquo;, <em>Electronic Notes in Theoretical
Computer Science</em>, 231: 69&ndash;89.
doi:10.1016/j.entcs.2009.02.030</li>

<li>Baltag, Alexandru and Bryan Renne, 2016 [2019], &ldquo;Dynamic
Epistemic Logic&rdquo;, <em>Stanford Encyclopedia of Philosophy</em>,
(Winter 2019), Edward N. Zalta (ed.), URL=
 &lt;<a href="https://plato.stanford.edu/archives/win2016/entries/dynamic-epistemic" target="other">https://plato.stanford.edu/archives/win2016/entries/dynamic-epistemic</a>&gt;</li>
 
<li>Baltag, A., R. Boddy, and S. Smets, 2018, &ldquo;Group Knowledge
in Interrogative Epistemology&rdquo;, in <em>Jaakko Hintikka on
Knowledge and Game-Theoretical Semantics</em>, Hans van Ditmarsch and
Gabriel Sandu (eds.), (Outstanding Contributions to Logic 12), Cham:
Springer International Publishing, 131&ndash;164.
doi:10.1007/978-3-319-62864-6_5</li>

<li>Benzm&uuml;ller, Christoph and Bruno Woltzenlogel Paleo, 2014,
&ldquo;Automating G&ouml;del&rsquo;s Ontological Proof of God&rsquo;s
Existence with Higher-order Automated Theorem Provers&rdquo;, in
<em>ECAI 2014</em>, Torsten Schaub, Gerhard Friedrich, and Barry
O&rsquo;Sullivan (eds.), (Frontiers in Artificial Intelligence and
Applications 263), Amsterdam: IOS Press, pp. 93&ndash;98.
doi:10.3233/978-1-61499-419-0-93</li>

<li>&ndash;&ndash;&ndash;, 2016a, &ldquo;The Inconsistency in
G&#333;del&rsquo;s Ontological Argument: A Success Story for AI in
Metaphysics&rdquo;, in <em>Proceedings of the Twenty-Fifth
International Joint Conference on Artificial Intelligence (IJCAI
2016)</em>, Gerhard Brewka (ed.), New York: AAAI Press, pp.
936&ndash;942.</li>

<li>&ndash;&ndash;&ndash;, 2016b, &ldquo;An Object-Logic Explanation
for the Inconsistency in G&#333;del&rsquo;s Ontological Theory&rdquo;,
in <em>KI 2016: Advances in Artificial Intelligence Proceedings</em>,
Gerhard Friedrich, Malte Helmert, and Franz Wotawa (eds.), Berlin:
Springer, pp. 244&ndash;250.</li>

<li>Benzm&uuml;ller, Christoph, L. Weber, and Bruno Woltzenlogel
Paleo, 2017, &ldquo;Computer-Assisted Analysis of the
Anderson&ndash;H&aacute;jek Ontological Controversy&rdquo;, <em>Logica
Universalis</em>, 11(1): 139&ndash;151.
doi:10.1007/s11787-017-0160-9</li>

<li>Benzm&uuml;ller, Christoph and David Fuenmayor, 2018, &ldquo;Can
Computers Help to Sharpen Our Understanding of Ontological
Arguments?&rdquo; in S. Gosh, R. Uppalari, K. Rao, V. Agarwal, and S.
Sharma (eds.), <em>Mathematics and Reality: Proceedings of the
11<sup>th</sup> All Indian Students&rsquo; Conference on Science and
Spiritual Quest (AISSQ)</em>, Bhudabenswar, Kolkata: The Bhaktiedanta
Institute, pp. 195&ndash;226.</li>

<li>Benzm&uuml;ller, Christoph, Nik Sultana, Lawrence C. Paulson, and
Frank Thei&szlig;, 2015, &ldquo;The Higher-Order Prover Leo-II&rdquo;,
<em>Journal of Automated Reasoning</em>, 55(4): 389&ndash;404.
doi:10.1007/s10817-015-9348-y</li>

<li>Benzm&uuml;ller, Christoph, Xavier Parent, and Leendert van der
Torre, 2018, &ldquo;A Deontic Logic Reasoning Infrastructure&rdquo;,
in <em>Sailing Routes in the World of Computation: 14th Conference on
Computability in Europe, CiE 2018</em>, Florin Manea, Russell G.
Miller, and Dirk Nowotka (eds.), (Lecture Notes in Computer Science
10936), Cham: Springer International Publishing, 60&ndash;69.
doi:10.1007/978-3-319-94418-0_6</li>

<li>Benzm&uuml;ller, Christoph, Ali Farjami, and Xavier Parent, 2018,
&ldquo;A Dyadic Deontic Logic in HOL&rdquo;, in <em>Deontic Logic and
Normative Systems, 14<sup>th</sup> International Conference (DEON
2018)</em>, Jan Broersen, Cleo Condoravdi, Nair Shyam and Gabriella
Pigozzi (eds.), London: College Publications, pp. 33&ndash;50.</li>

<li>Berleman, James E., Jodie Scott, Taliana Chumley, and John R.
Kirby, 2008, &ldquo;Predataxis Behavior in <em>Myxococcus
xanthus</em>&rdquo;, <em>Proceedings of the National Academy of
Sciences</em>, 105(44): 17127&ndash;17132.
doi:10.1073/pnas.0804387105</li>

<li>Betz, Gregor, 2013, <em>Debate Dynamics: How Controversy Improves
Our Beliefs</em>, Dordrecht: Springer Netherlands.
doi:10.1007/978-94-007-4599-5</li>

<li>Beyleveld, Deryck, 1992, <em>The Dialectical Necessity of
Morality: An Analysis and Defense of Alan Gewirth&rsquo;s Argument to
the Principle of Generic Consistency</em>, Chicago: University of
Chicago Press.</li>

<li>&ndash;&ndash;&ndash;, 2012, &ldquo;The Principle of Generic
Consistency as the Supreme Principle of Human Rights&rdquo;, <em>Human
Rights Review</em>, 13(1): 1&ndash;18.
doi:10.1007/s12142-011-0210-2</li>

<li>Black, Max, 1962, <em>Models and Metaphors: Studies in Language
and Philosophy</em>, Ithaca, NY: Cornell University Press.</li>

<li>Bobzien, Susanne, 2006 [2016], &ldquo;Ancient Logic&rdquo;,
<em>The Stanford Encyclopedia of Philosophy</em>, (Winter 2016),
Edward N. Zalta (ed.), URL =
 &lt;<a href="https://plato.stanford.edu/archives/win2016/entries/logic-ancient/" target="other">https://plato.stanford.edu/archives/win2016/entries/logic-ancient/</a>&gt;</li>
 
<li>Boland, Philip J., 1989, &ldquo;Majority Systems and the Condorcet
Jury Theorem&rdquo;, <em>Journal of the Royal Statistical Society:
Series D (The Statistician)</em>, 38(3): 181&ndash;189.
doi:10.2307/2348873</li>

<li>Boland, Philip J., Frank Proschan, and Y. L. Tong, 1989,
&ldquo;Modelling Dependence in Simple and Indirect Majority
Systems&rdquo;, <em>Journal of Applied Probability</em>, 26(1):
81&ndash;88. doi:10.2307/3214318</li>

<li>Borg, AnneMarie, Daniel Frey, Dunja &Scaron;e&scaron;elja, and
Christian Stra&szlig;er, 2018, &ldquo;Epistemic Effects of Scientific
Interaction: Approaching the Question with an Argumentative
Agent-Based Model.&rdquo;, <em>Historical Social Research</em>, 43(1):
285-309.. doi:10.12759/HSR.43.2018.1.285-307</li>

<li>Borges, Jorge Luis [pseud. Suarez Miranda], 1946 [1998],
&ldquo;Del rigor en la ciencia&rdquo;, <em>Los Anales de Buenos
Aires</em>, 1(3). Translated as &ldquo;On Exactitude in
Science&rdquo;, in his <em>Collected Fictions</em>, Andrew Hurley
(trans.), New York: Penguin Books, 1998.</li>

<li>Bramson, Aaron, Patrick Grim, Daniel J. Singer, William J. Berger,
Graham Sack, Steven Fisher, Carissa Flocken, and Bennett Holman, 2017,
&ldquo;Understanding Polarization: Meanings, Measures, and Model
Evaluation&rdquo;, <em>Philosophy of Science</em>, 84(1):
115&ndash;159. doi:10.1086/688938</li>

<li>Bringsjord, Selmer and Naveen Sundar Govindarajulu, 2018 [2019],
&ldquo;Artificial Intelligence&rdquo;, in <em>The Stanford
Encyclopedia of Philosophy</em>, Winter 2019, Edward N. Zalta (ed.),
URL =
 &lt;<a href="https://plato.stanford.edu/archives/win2019/entries/artificial-intelligence/" target="other">https://plato.stanford.edu/archives/win2019/entries/artificial-intelligence/</a>&gt;</li>
 
<li>Brooks, Rodney A. and Maja J. Mataric, 1993, &ldquo;Real Robots,
Real Learning Problems&rdquo;, in <em>Robot Learning</em>, Jonathan H.
Connell and Sridhar Mahadevan (eds.), Dordrecht: Kluwer,
193&ndash;213. doi:10.1007/978-1-4615-3184-5_8</li>

<li>Bruch, Elizabeth E. and Robert D. Mare, 2006, &ldquo;Neighborhood
Choice and Neighborhood Change&rdquo;, <em>American Journal of
Sociology</em>, 112(3): 667&ndash;709. doi:10.1086/507856</li>

<li>Bruner, Justin P., 2017, &ldquo;Minority (Dis)advantage in
Population Games&rdquo;, <em>Synthese,</em> 196 (1)
DOI:10.1007/s11229-017- 1487-8.</li>

<li>&ndash;&ndash;&ndash;, forthcoming, &ldquo;Locke, Nozick and the
State of Nature&rdquo;, <em>Philosophical Studies</em>, first online:
20 November 2018. doi:10.1007/s11098-018-1201-9</li>

<li>Centola, Damon, Juan Carlos Gonz&aacute;lez-Avella, V&iacute;ctor
M. Egu&iacute;luz, and Maxi San Miguel, 2007, &ldquo;Homophily,
Cultural Drift, and the Co-Evolution of Cultural Groups&rdquo;,
<em>Journal of Conflict Resolution</em>, 51(6): 905&ndash;929.
doi:10.1177/0022002707307632</li>

<li>Cheney, Dorothy L. and Robert M. Seyfarth, 1990, <em>How Monkeys
See the World: Inside the Mind of Another Species</em>, Chicago:
University of Chicago Press.</li>

<li>Chung, Hun, 2015, &ldquo;Hobbes&rsquo;s State of Nature: A Modern
Bayesian Game-Theoretic Analysis&rdquo;, <em>Journal of the American
Philosophical Association</em>, 1(3): 485&ndash;508.
doi:10.1017/apa.2015.12</li>

<li>Church, Alonzo, 1936, &ldquo;A Note on the
Entscheidungsproblem&rdquo;, <em>Journal of Symbolic Logic</em>, 1(1):
40&ndash;41. doi:10.2307/2269326</li>

<li>Churchland, Paul M., 1995, <em>The Engine of Reason, the Seat of
the Soul: A Philosophical Journey into the Brain</em>, Cambridge MA:
MIT Press.</li>

<li>Condorcet, Nicolas de, 1785 [1995], &ldquo;An Essay on the
Application of Analysis to the Probability of Decisions Rendered by a
Plurality of Votes (fifth part)&rdquo;, Part translated in
<em>Classics of Social Choice</em>, Iain McLean and Arnold B. Urken
(trans. and eds.), Ann Arbor MI: University of Michigan Press, pp.
91&ndash;112, 1995.</li>

<li>Davis, Martin, 1957 [1983], &ldquo;A Computer Program for
Presburger&rsquo;s Algorithm&rdquo;, presented at the Cornell Summer
Institute for Symbolic Logic. Reprinted in Siekmann and Wrightson
1983: 41&ndash;48.</li>

<li>&ndash;&ndash;&ndash;, 1983, &ldquo;The Prehistory and Early
History of Automated Deduction&rdquo;, in Siekmann and Wrightson 1983:
1&ndash;28.</li>

<li>Dawkins, Richard, 1976, <em>The Selfish Gene</em>, New York:
Oxford University Press.</li>

<li>Deffuant, Guillaume, 2006, &ldquo;Comparing Extremism Propagation
Patterns in Continuous Opinion Models&rdquo;, <em>Journal of
Artificial Societies and Social Simulation</em>, 9(3): 8. URL =
 &lt;<a href="http://jasss.soc.surrey.ac.uk/9/3/8.html" target="other">http://jasss.soc.surrey.ac.uk/9/3/8.html</a>&gt;</li>
 
<li>Deffuant, Guillaume, Fr&eacute;d&eacute;ric Amblard, G&eacute;rard
Weisbuch, and Thierry Faure, 2002, &ldquo;How Can Extremism Prevail? A
Study Based on the Relative Agreement Interaction Model&rdquo;,
<em>Journal of Artificial Societies and Social Simulation</em>, 5(4):
1. URL =
 &lt;<a href="http://jasss.soc.surrey.ac.uk/5/4/1.html" target="other">http://jasss.soc.surrey.ac.uk/5/4/1.html</a>&gt;</li>
 
<li>Dennett, Daniel, 1979, &ldquo;Artificial Intelligence as
Philosophy and as Psychology&rdquo;, in <em>Philosophical Perspectives
in Artificial Intelligence</em>, Martin Ringle (ed.), Atlantic
Highlands, NJ: Humanities Press, pp. 57&ndash;80.</li>

<li>Dietrich, Franz and Kai Spiekermann, 2013, &ldquo;Independent
Opinions? On the Causal Foundations of Belief Formation and Jury
Theorems&rdquo;, <em>Mind</em>, 122(487): 655&ndash;685.
doi:10.1093/mind/fzt074</li>

<li>Douven, Igor and Alexander Riegler, 2010, &ldquo;Extending the
Hegselmann-Krause Model I&rdquo;, <em>Logic Journal of IGPL</em>,
18(2): 323&ndash;335. doi:10.1093/jigpal/jzp059</li>

<li>Dung, Phan Minh, 1995, &ldquo;On the Acceptability of Arguments
and Its Fundamental Role in Nonmonotonic Reasoning, Logic Programming
and <em>n</em>-Person Games&rdquo;, <em>Artificial Intelligence</em>,
77(2): 321&ndash;357. doi:10.1016/0004-3702(94)00041-X</li>

<li>Ernst, Zachary, Branden Fitelson, Kenneth Harris, and Larry Wos,
2002, &ldquo;Shortest Axiomatizations of Implicational S4 and
S5&rdquo;, <em>Notre Dame Journal of Formal Logic</em>, 43(3):
169&ndash;179. doi:10.1305/ndjfl/1074290715</li>

<li>Fagin, Ronald, Joseph Y. Halpern, Yoram Moses and Moshe Vardi,
1995, <em>Reasoning About Knowledge</em>, Cambridge, MA: MIT
Press.</li>

<li>Falkenhainer, Brian, Kenneth D. Forbus, and Dedre Gentner, 1989,
&ldquo;The Structure-Mapping Engine: Algorithm and Examples&rdquo;,
<em>Artificial Intelligence</em>, 41(1): 1&ndash;63.
doi:10.1016/0004-3702(89)90077-5</li>

<li>Fisher, Ronald, 1930, <em>The Genetical Theory of Natural
Selection</em>, Oxford: Clarendon Press.</li>

<li>Fisher v. University of Texas, 2016, Brief for Lt. Gen. Julius W.
Becton, Jr., Gen. John P. Abizaid, Adm. Dennis C. Blair, Gen. Bryan
Doug Brown, Gen. George W. Casey, Lt. Gen Daniel W. Christman, Gen.
Wesley K. Clark, Adm. Archie Clemins, Gen. Ann E. Dunwoody, Gen.
Ronald R. Fogleman, Adm. Edmund P. Giambastiani, Jr., et al., as Amici
Curiae in Support of respondents.
 [<a href="https://www.scotusblog.com/wp-content/uploads/2015/11/LtGenJuliusWBectonJrEtAl.pdf" target="other">Fisher v. University of Texas brief 2016 available online</a>]</li>
 
<li>Fitelson, Branden and Edward N. Zalta, 2007, &ldquo;Steps Toward a
Computational Metaphysics&rdquo;, <em>Journal of Philosophical
Logic</em>, 36(2): 227&ndash;247. doi:10.1007/s10992-006-9038-7</li>

<li>Fuenmayor, David and Christoph Benzm&uuml;ller, 2018,
&ldquo;Formalisation and Evaluation of Alan Gewirth&rsquo;s Proof for
the Principle of Generic Consistency in Isabelle/HOL&rdquo;,
<em>Archive of Formal Proofs</em>, 30 October 2018. URL =
 &lt;<a href="https://isa-afp.org/entries/GewirthPGCProof.html" target="other">https://isa-afp.org/entries/GewirthPGCProof.html</a>&gt;</li>
 
<li>Garbacz, Pawe&#322;, 2012, &ldquo;Prover9&rsquo;s Simplification
Explained Away&rdquo;, <em>Australasian Journal of Philosophy</em>,
90(3): 585&ndash;592. doi:10.1080/00048402.2011.636177</li>

<li>Gentner, Dedre, 1982, &ldquo;Are Scientific Analogies
Metaphors?&rdquo; in <em>Metaphor: Problems and Perspectives</em>,
David S. Miall (ed.), Brighton: Harvester Press, pg.
106&ndash;132.</li>

<li>Gewirth, Alan, 1978, <em>Reason and Morality</em>, Chicago:
University of Chicago Press.</li>

<li>G&ouml;del, Kurt, 1931, &ldquo;&Uuml;ber formal unentscheidbare
S&auml;tze der Principia Mathematica und verwandter Systeme, I&rdquo;,
<em>Monatshefte f&uuml;r Mathematik und Physik</em>, 38(1):
173&ndash;198.</li>

<li>Goldman, Alvin I., 1987, &ldquo;Foundations of Social
Epistemics&rdquo;, <em>Synthese</em>, 73(1): 109&ndash;144.
doi:10.1007/BF00485444</li>

<li>&ndash;&ndash;&ndash;, 1999, <em>Knowledge in a Social World</em>,
Oxford: Oxford University Press. doi:10.1093/0198238207.001.0001</li>

<li>Goldman, Alvin and Cailin O&rsquo;Connor, 2001 [2019],
&ldquo;Social Epistemology&rdquo;, in <em>The Stanford Encyclopedia of
Philosophy</em>, (Fall 2019), Edward N. Zalta (ed.), URL =
 &lt;<a href="https://plato.stanford.edu/archives/fall2019/entries/epistemology-social/" target="other">https://plato.stanford.edu/archives/fall2019/entries/epistemology-social/</a>&gt;</li>
 
<li>Goldman, Alvin and Dennis Whitcomb (eds.), 2011, <em>Social
Epistemology: Essential Readings</em>, New York: Oxford University
Press.</li>

<li>Gordon, Michael J.C. and T.F. Melham (eds.), 1993,
<em>Introduction to HOL: A Theorem Proving Environment for Higher
Order Logic</em>, Cambridge: Cambridge University Press.</li>

<li>Governatori, Guido and Giovanni Sartor (eds.), 2010, <em>Deontic
Logic in Computer Science: 10th International Conference, DEON 2010,
Fiesole, Italy, July 7-9, 2010. Proceedings</em>, (Lecture Notes in
Computer Science 6181), Berlin, Heidelberg: Springer Berlin
Heidelberg. doi:10.1007/978-3-642-14183-6</li>

<li>Gray, Jonathan, 2016, &ldquo;&rsquo;Let us Calculate!&rsquo;:
Leibniz, Lull, and the Computational Imagination&rdquo;, <em>The
Public Domain Review</em>, 10 November 2016. URL =
 &lt;<a href="https://publicdomainreview.org/2016/11/10/let-us-calculate-leibniz-llull-and-computational-imagination/">https://publicdomainreview.org/2016/11/10/let-us-calculate-leibniz-llull-and-computational-imagination/</a>&gt;</li>
 
<li>Grim, Patrick, 1995, &ldquo;The Greater Generosity of the
Spatialized Prisoner&rsquo;s Dilemma&rdquo;, <em>Journal of
Theoretical Biology</em>, 173(4): 353&ndash;359.
doi:10.1006/jtbi.1995.0068</li>

<li>&ndash;&ndash;&ndash;, 1996, &ldquo;Spatialization and Greater
Generosity in the Stochastic Prisoner&rsquo;s Dilemma&rdquo;,
<em>Biosystems</em>, 37(1&ndash;2): 3&ndash;17.
doi:10.1016/0303-2647(95)01541-8</li>

<li>&ndash;&ndash;&ndash;, 2006, &ldquo;Tangled Webs: The
Philosophical Importance of Networks&rdquo;, The Marshall Weinberg
lecture, University of Michigan.</li>

<li>&ndash;&ndash;&ndash;, 2009, &ldquo;Threshold Phenomena in
Epistemic Networks&rdquo;, <em>Proceedings, AAAI Fall Symposium on
Complex Adaptive Systems and the Threshold Effect</em>, FS-09-03, AAAI
Press. </li>

<li>Grim, Patrick, Gary R. Mar, and Paul St. Denis, 1998, <em>The
Philosophical Computer: Exploratory Essays in Philosophical Computer
Modeling</em>, Cambridge MA: MIT Press.</li>

<li>Grim, Patrick, Paul St. Denis and Trina Kokalis, 2002, &ldquo;Learning to Communicate: The Emergence of Signaling in Spatialized Arrays of Neural Nets&rdquo;,
<em>Adaptive Behavior</em>, 10(4): 45&ndash;70. doi:10.1177/10597123020101003</li>

<li>Grim, Patrick, Trina Kokalis, Ali Alai-Tafti, Nicholas Kilb and Paul St. Denis, 2004, &ldquo;Making Meaning Happen&rdquo;,
<em>Journal of Experimental and Theoretical Artificial Intelligence</em>, 16: 209&ndash;243. doi:10.1080/09528130412331294715</li>

<li>Grim, Patrick, Daniel J. Singer, Christopher Reade, and Steven
Fisher, 2015, &ldquo;Germs, Genes, and Memes: Function and Fitness
Dynamics on Information Networks&rdquo;, <em>Philosophy of
Science</em>, 82(2): 219&ndash;243. doi:10.1086/680486</li>

<li>Grim, Patrick, Daniel J. Singer, Steven Fisher, Aaron Bramson,
William J. Berger, Christopher Reade, Carissa Flocken, and Adam Sales,
2013, &ldquo;Scientific Networks on Data Landscapes: Question
Difficulty, Epistemic Success, and Convergence&rdquo;,
<em>Episteme</em>, 10(4): 441&ndash;464. doi:10.1017/epi.2013.36</li>

<li>Grim, Patrick, Daniel J. Singer, Aaron Bramson, Bennett Holman,
Sean McGeehan, and William J. Berger, 2019, &ldquo;Diversity, Ability,
and Expertise in Epistemic Communities&rdquo;, <em>Philosophy of
Science</em>, 86(1): 98&ndash;123. doi:10.1086/701070</li>

<li>Grim, Patrick, Aaron Bramson, Daniel J. Singer, William J. Berger,
Jiin Jung, and Scott E. Page, forthcoming, &ldquo;Representation in
Models of Epistemic Democracy&rdquo;, <em>Episteme</em>, first online:
21 December 2018. doi:10.1017/epi.2018.51</li>

<li>Grim, Patrick, Robert Rosenberger, Adam Rosenfeld, Brian Anderson,
and Robb E. Eason, 2013, &ldquo;How Simulations Fail&rdquo;,
<em>Synthese</em>, 190(12): 2367&ndash;2390.
doi:10.1007/s11229-011-9976-7</li>

<li>Gunn, Paul, 2014, &ldquo;Democracy and Epistocracy&rdquo;,
<em>Critical Review</em>, 26(1&ndash;2): 59&ndash;79.
doi:10.1080/08913811.2014.907041</li>

<li>Habermas, J&uuml;rgen , 1992 [1996], <em>Faktizit&auml;t und
Geltung. Beitr&auml;ge zur Diskurstheorie des Rechts und des
demokratischen Rechtsstaats</em>, Frankfurt Am Main: Suhrkamp Verlag.
Translated as <em>Between Facts and Norms: Contributions to a
Discourse Theory of Law and Democracy</em>, William Rehg (trans.),
Cambridge MA: MIT Press, 1996.</li>

<li>Haldane, J.B.S., 1932, <em>The Causes of Evolution</em>, London:
Longmans, Green &amp; Co.</li>

<li>Halpern, Joseph Y. and Yoram Moses, 1984, &ldquo;Knowledge and
Common Knowledge in a Distributed Environment&rdquo;, in
<em>Proceedings of the Third Annual ACM Symposium on Principles of
Distributed Computing</em>, ACM Press, pp. 50&ndash;61.</li>

<li>Hamilton, W.D., 1964a, &ldquo;The Genetical Evolution of Social
Behaviour. I&rdquo;, <em>Journal of Theoretical Biology</em>, 7(1):
1&ndash;16. doi:10.1016/0022-5193(64)90038-4</li>

<li>&ndash;&ndash;&ndash;, 1964b, &ldquo;The Genetical Evolution of
Social Behaviour. II&rdquo;, <em>Journal of Theoretical Biology</em>,
7(1): 17&ndash;52. doi:10.1016/0022-5193(64)90039-6</li>

<li>Hegselmann, Rainer and Ulrich Krause, 2002, &ldquo;Opinion
Dynamics and Bounded Confidence: Models, Analysis and
Simulation&rdquo;, <em>Journal of Artificial Societies and Social
Simulation</em>, 5(3): 2. URL =
 &lt;<a href="http://jasss.soc.surrey.ac.uk/5/3/2.html" target="other">http://jasss.soc.surrey.ac.uk/5/3/2.html</a>&gt;</li>
 
<li>&ndash;&ndash;&ndash;, 2005, &ldquo;Opinion Dynamics Driven by
Various Ways of Averaging&rdquo;, <em>Computational Economics</em>,
25(4): 381&ndash;405. doi:10.1007/s10614-005-6296-3</li>

<li>&ndash;&ndash;&ndash;, 2006, &ldquo;Truth and Cognitive Division
of Labour: First Steps towards a Computer Aided Social
Epistemology&rdquo;, <em>Journal of Artificial Societies and Social
Simulation</em>, 9(3): 10. URL =
 &lt;<a href="http://jasss.soc.surrey.ac.uk/9/3/10.html" target="other">http://jasss.soc.surrey.ac.uk/9/3/10.html</a>&gt;</li>
 
<li>Hesse, Hermann, 1943 [1969], <em>Das Glasperlenspelel</em>,
Switzerland. Translated as <em>The Glass Bead Game (Magister
Ludi)</em>, Richard &amp; Clara Winston (trans.), New York: Holt,
Rinehart &amp; Winston, 1969.</li>

<li>Hesse, Mary B., 1966, <em>Models and Analogies in Science</em>,
Notre Dame IN: Notre Dame University Press.</li>

<li>Hobbes, Thomas, 1651, <em>Leviathan</em>, London: Crooke, London:
Penguin 1982.</li>

<li>Hofstadter, Douglas, 2008, <em>Fluid Concepts and Creative
Analogies</em>, New York: Basic Books.</li>

<li>Holland, John H., 1975, <em>Adaptation in Natural and Artificial
Systems</em>, Cambridge, MA: MIT Press.</li>

<li>Holyoak, Keith J. and Paul Thagard, 1989, &ldquo;Analogical
Mapping by Constraint Satisfaction&rdquo;, <em>Cognitive Science</em>,

13(3): 295&ndash;355. doi:10.1207/s15516709cog1303_1</li>

<li>&ndash;&ndash;&ndash;, 1995, <em>Mental Leaps: Analogy in Creative

Thought</em>, Cambridge, MA: MIT Press.</li>

<li>Hong, Lu and Scott E. Page, 2004, &ldquo;Groups of Diverse Problem

Solvers Can Outperform Groups of High-Ability Problem Solvers&rdquo;,

<em>Proceedings of the National Academy of Sciences</em>, 101(46):

16385&ndash;16389. doi:10.1073/pnas.0403723101</li>

<li>Horner, Jack K., 2019, &ldquo;A Computationally Assisted

Reconstruction of an Ontological Argument in Spinoza&rsquo;s The

Ethics&rdquo;, <em>Open Philosophy</em>, (special issue on
computational philosophy) 2(1): 211&ndash;229.
doi:10.1515/opphil-2019-0012</li>

<li>Isenberg, Daniel J., 1986, &ldquo;Group Polarization: A Critical
Review and Meta-Analysis.&rdquo;, <em>Journal of Personality and
Social Psychology</em>, 50(6): 1141&ndash;1151.
doi:10.1037/0022-3514.50.6.1141</li>

<li>Kalman, John Arnold, 2001, <em>Automated Reasoning with
Otter</em>, Princeton, NJ: Rinton Press.</li>

<li>Kauffman, Stuart, 1995, <em>At Home in the Universe: The Search
for Laws of Self-Organization and Complexity</em>, New York: Oxford
University Press.</li>

<li>Kendall, Graham, Xin Yao, and Siang Yew Chong, 2007, <em>The
Iterated Prisoner&rsquo;s Dilemma: 20 Years On</em>, Singapore: World
Scientific.</li>

<li>Khald&#363;n, Ibn, 1377 [1958], <em>The Muqaddimah: An
Introduction to History</em>, vol. 3, Franz Rosenthal, Princeton, NJ:
Princeton University Press.</li>

<li>Kirchner, Daniel, Christoph Benzm&uuml;ller, and Edward N. Zalta,
2019, &ldquo;Computer Science and Metaphysics: A
Cross-Fertilization&rdquo;, <em>Open Philosophy</em>, (special issue
on computational philosophy) 2(1): 230&ndash;251.
doi:10.1515/opphil-2019-0015</li>

<li>Kitcher, Philip, 1993, <em>The Advancement of Science: Science
Without Legend, Objectivity Without Illusions</em>, Oxford: Oxford
University Press. doi:10.1093/0195096533.001.0001</li>

<li>Kleijnen, Jack P.C., 1995, &ldquo;Verification and Validation of
Simulation Models&rdquo;, <em>European Journal of Operational
Research</em>, 82(1): 145&ndash;162.
doi:10.1016/0377-2217(94)00016-6</li>

<li>Klein, Dominik, Johannes Marx, and Kai Fischbach, 2018,
&ldquo;Agent-Based Modeling in Social Science, History, and
Philosophy. An Introduction.&rdquo;, <em>Historical Social
Research</em>, 43(1): 7&ndash;27. doi:10.12759/HSR.43.2018.1.7-27</li>

<li>Klemm, Konstantin, V&iacute;ctor M. Egu&iacute;luz, Ra&uacute;l
Toral, and Maxi San Miguel, 2003a, &ldquo;Global Culture: A
Noise-Induced Transition in Finite Systems&rdquo;, <em>Physical ReviewE</em>, 67(4pt2): 045101. doi:10.1103/PhysRevE.67.045101</li>

<li>&ndash;&ndash;&ndash;, 2003b, &ldquo;Nonequilibrium Transitions in Complex Networks: A Model of Social Interaction&rdquo;, <em>Physical Review E</em>, 67 (2): 026120. doi:10.1103/PhysRevE.67.026120</li>

<li>&ndash;&ndash;&ndash;, 2003c, &ldquo;Role of Dimensionality in Axelrod&rsquo;s Model for the Dissemination of Culture&rdquo;, <em>Physica A</em>, 327 (1): 1&ndash;5. doi:10.1016/S0378-4371(03)00428-X</li>

<li>&ndash;&ndash;&ndash;, 2005, &ldquo;Globalization, Polarization
and Cultural Drift&rdquo;, <em>Journal of Economic Dynamics and
Control</em>, 29(1&ndash;2): 321&ndash;334.
doi:10.1016/j.jedc.2003.08.005</li>

<li>Krakauer, David C. (ed.), 2019, <em>Worlds Hidden in Plain Sight:
Thirty Years of Complexity Thinking at the Santa Fe Institute</em>,
Santa Fe, NM: Santa Fe Institute Press.</li>

<li>Kuehn, Daniel, 2017, &ldquo;Diversity, Ability, and Democracy: A
Note on Thompson&rsquo;s Challenge to Hong and Page&rdquo;,
<em>Critical Review</em>, 29(1): 72&ndash;87.
doi:10.1080/08913811.2017.1288455</li>

<li>Kuhn, Steven, 1997 [2019], &ldquo;Prisoner&rsquo;s Dilemma&rdquo;,
in <em>The Stanford Encyclopedia of Philosophy</em>, (Winter 2019),
Edward N. Zalta (ed.), URL =
 &lt;<a href="https://plato.stanford.edu/archives/win2019/entries/prisoner-dilemma/" target="other">https://plato.stanford.edu/archives/win2019/entries/prisoner-dilemma/</a>&gt;</li>
 
<li>Lakoff, George and Mark Johnson, 1980, <em>Metaphors We Live
By</em>, Chicago: University of Chicago Press.</li>

<li>Lakoff, George and Mark Turner, 1989, <em>More Than Cool Reason: A
Field Guide to Poetic Metaphor</em>, Chicago: University of Chicago
Press.</li>

<li>Landemore, H&eacute;l&egrave;ne, 2013, <em>Democratic Reason:
Politics, Collective Intelligence, and the Rules of the Many</em>,
Princeton NJ: Princeton University Press.</li>

<li>Leibniz, Gottfried Wilhelm, 1666 [1923], <em>Dissertatio De Arte Combinatoria
</em>, URL = &lt;<a href="https://archive.org/details/ita-bnc-mag-00000844-001/page/n11/mode/2up" target="other">https://archive.org/details/ita-bnc-mag-00000844-001/page/n11/mode/2up</a>&gt;; <em>S&auml;mtliche Schriften und Briefe</em>, Berlin-Brandenburgische Akademie der Wissenschraften / Akademie der Wissenschraften zu G&ouml;ttingen (eds.), Berlin: Akademie Verlag.</li>

<li>&ndash;&ndash;&ndash;, 1685 [1951], <em>The Art of
Discovery</em>, in <em>Leibniz: Selections</em>, Philip P. Wiener
(ed., trans), New York: Scribner, 1951.</li>

<li>Lehrer, Keith and Carl Wagner, 1981, <em>Rational Consensus in
Science and Society</em>, Dordrecht: Reidel.</li>

<li>Lem, Stanislaw, 1964 [2013], <em>Summa Technologiae</em>, Joanna
Zylinski, Minneapolis, MN: University of Minnesota Press, 2013.</li>

<li>Lewis, David, 1969, <em>Convention: A Philosophical Study</em>,
Cambridge MA: Harvard University Press.</li>

<li>Longino, Helen E., 1990, <em>Science as Social Knowledge:Values
and Objectivity in Scientific Inquiry</em>, Princeton, NJ: Princeton
University Press.</li>

<li>Longino, Helen, 2002 [2019], &ldquo;The Social Dimensions of
Scientific Knowledge&rdquo;, in <em>The Stanford Encyclopedia of
Philosophy</em>, (Summer 2019), Edward N. Zalta (ed.), URL =
 &lt;<a href="https://plato.stanford.edu/archives/sum2019/entries/scientific-knowledge-social/" target="other">https://plato.stanford.edu/archives/sum2019/entries/scientific-knowledge-social/</a>&gt;</li>
 
<li>Lord, Charles G., Lee Ross, and Mark R. Lepper, 1979,
&ldquo;Biased Assimilation and Attitude Polarization: The Effects of
Prior Theories on Subsequently Considered Evidence.&rdquo;,
<em>Journal of Personality and Social Psychology</em>, 37(11):
2098&ndash;2109. doi:10.1037/0022-3514.37.11.2098</li>

<li>Loveland, Donald W., 1984, &ldquo;Automated Theorem Proving: A
Quarter Century Review&rdquo;, <em>Contemporary Mathematics,</em> 29:
1&ndash;45.</li>

<li>Llull, Ramon, 1308 [1986], <em>Ars generalis ultima</em>, in <em>Raimondi Lulli Opera Latina</em> XIV / CCCM 75, 4&ndash;527, Turnholt, Belgium: Brepols</li>

<li>MacKenzie, Donald, 1995, &ldquo;The Automation of Proof: A
Historical and Sociological Exploration&rdquo;, <em>IEEE Annals of the
History of Computing</em>, 17(3): 7&ndash;29.
doi:10.1109/85.397057</li>

<li>Martin, Ernst, 1925 [1992], <em>Die Rechenmaschinen und ihre
Entwicklungsgeschichte</em>, Germany: Pappenheim. Translated as
<em>The Calculating Machines: Their History and Development</em>,
Peggy Aldrich Kidwell and Michael R. Williams (trans.), Cambridge MA:
MIT Press, 1992.</li>

<li>Martini, Carlo and Manuela Fern&aacute;ndez Pinto, 2017,
&ldquo;Modeling the Social Organization of Science: Chasing Complexity
through Simulations&rdquo;, <em>European Journal for Philosophy of
Science</em>, 7(2): 221&ndash;238. doi:10.1007/s13194-016-0153-1</li>

<li>Mar, Gary and Patrick Grim, 1991, &ldquo;Pattern and Chaos: New
Images in the Semantics of Paradox&rdquo;, <em>No&ucirc;s</em>, 25(5):
659&ndash;693. doi:10.2307/2215637</li>

<li>M&auml;s, Michael, 2019, &ldquo;Challenges to Simulation
Validation in the Social Sciences. A Critical Rationalist
Perspective&rdquo;, in <em>Computer Simulation Validation</em>, Claus
Beisbart and Nicole J. Saam (eds.), Cham: Springer International
Publishing, 857&ndash;879. doi:10.1007/978-3-319-70766-2_35</li>

<li>Mccune, William, 1997, &ldquo;Solution of the Robbins
Problem&rdquo;, <em>Journal of Automated Reasoning</em>, 19(3):
263&ndash;276. doi:10.1023/A:1005843212881</li>

<li>McCune, William and Larry Wos, 1997, &ldquo;Otter: The CADE-13
Competition Incarnations&rdquo;, <em>Journal of Automated
Reasoning</em>, 18(2): 211&ndash;220. doi:10.1023/A:1005843632307</li>

<li>McRobbie, Michael A., 1991, &ldquo;Automated Reasoning and
Nonclassical Logics: Introduction&rdquo;, <em>Journal of Automated
Reasoning</em>, 7(4): 447&ndash;451. doi:10.1007/BF01880323</li>

<li>Meadows, Michael and Dave Cliff, 2012, &ldquo;Reexamining the
Relative Agreement Model of Opinion Dynamics&rdquo;, <em>Journal of
Artificial Societies and Social Simulation</em>, 15(4): 4.
doi:10.18564/jasss.2083</li>

<li>Meyer, John-Jules Ch. and Roel Wierenga, 1994, <em>Deontic Logic
in Computer Science: Normative System Specification</em>. Hoboken, NJ:
Wiley.</li>

<li>Miller, George A., Richard Beckwith, Christiane Fellbaum, Derek
Gross, and Katherine J. Miller, 1990, &ldquo;Introduction to WordNet:
An On-Line Lexical Database&rdquo;, <em>International Journal of
Lexicography</em>, 3(4): 235&ndash;244. doi:10.1093/ijl/3.4.235</li>

<li>Mitchell, Melanie, 2011, <em>Complexity: A Guided Tour</em>, New
York: Oxford University Press.</li>

<li>Nowak, Martin A. and Karl Sigmund, 1992, &ldquo;Tit for Tat in
Heterogeneous Populations&rdquo;, <em>Nature</em>, 355(6357):
250&ndash;253. doi:10.1038/355250a0</li>

<li>O&rsquo;Connor, Cailin, 2017, &ldquo;The Cultural Red King
Effect&rdquo;, <em>The Journal of Mathematical Sociology</em>, 41(3):
155&ndash;171. doi:10.1080/0022250X.2017.1335723</li>

<li>O&rsquo;Connor, Cailin and Justin Bruner, 2019, &ldquo;Dynamics
and Diversity in Epistemic Communities&rdquo;, <em>Erkenntnis</em>,
84(1): 101&ndash;119. doi:10.1007/s10670-017-9950-y</li>

<li>O&rsquo;Connor, Cailin, Liam Kofi Bright, and Justin P. Bruner,
2019, &ldquo;The Emergence of Intersectional Disadvantage&rdquo;,
<em>Social Epistemology</em>, 33(1): 23&ndash;41.
doi:10.1080/02691728.2018.1555870</li>

<li>O&rsquo;Connor, Cailin and James Owen Weatherall, 2018,
&ldquo;Scientific Polarization&rdquo;, <em>European Journal for
Philosophy of Science</em>, 8(3): 855&ndash;875.
doi:10.1007/s13194-018-0213-9</li>

<li>O&rsquo;Leary, Daniel J., 1991, &ldquo;Principia Mathematica and
the Development of Automated Theorem Proving&rdquo;, in
<em>Perspectives on the History of Mathematical Logic</em>, Thomas
Drucker (ed.), Boston, MA: Birkh&auml;user Boston, 47&ndash;53.
doi:10.1007/978-0-8176-4769-8_4</li>

<li>Olsson, Erik J., 2011, &ldquo;A Simulation Approach to Veritistic
Social Epistemology&rdquo;, <em>Episteme</em>, 8(2): 127&ndash;143.
doi:10.3366/epi.2011.0012</li>

<li>&ndash;&ndash;&ndash;, 2013, &ldquo;A Bayesian Simulation Model of
Group Deliberation and Polarization&rdquo;, in <em>Bayesian
Argumentation</em>, Frank Zenker (ed.), Dordrecht: Springer
Netherlands, 113&ndash;133. doi:10.1007/978-94-007-5357-0_6</li>

<li>Oppenheimer, Paul E. and Edward N. Zalta, 2011, &ldquo;A
Computationally-Discovered Simplification of the Ontological
Argument&rdquo;, <em>Australasian Journal of Philosophy</em>, 89(2):
333&ndash;349. doi:10.1080/00048401003674482</li>

<li>Overton, James A., 2013, &ldquo;&lsquo;Explain&rsquo; in
Scientific Discourse&rdquo;, <em>Synthese</em>, 190(8):
1383&ndash;1405. doi:10.1007/s11229-012-0109-8</li>

<li>Page, Scott E., 2007, <em>The Difference: How the Power of
Diversity Creates Better Groups, Firms, Schools, and Societies</em>,
Princeton, NJ: Princeton University Press.</li>

<li>Paulson, Lawrence C., 1990, &ldquo;Isabelle: The Next 700 Theorem
Provers&rdquo;, in Piergiorgio Odifreddi (ed.), <em>Logic and Computer
Science</em>, Cambridge, MA: Academic Press, pp. 361-386.</li>

<li>Pearl, Judea, 1988, <em>Probabilistic Reasoning in Intelligent
Systems</em>, San Mateo, CA: Morgan Kaufmann.</li>

<li>&ndash;&ndash;&ndash;, 2000, <em>Causality: Models, Reasoning, and
Inference</em>, Cambridge, MA: Cambridge Univ. Press.</li>

<li>Pearl, Judea and Dana Mackenzie, 2018, <em>The Book of Why: The
New Science of Cause and Effect</em>, New York: Basic Books.</li>

<li>Pence, Charles H. and Grant Ramsey, 2018, &ldquo;How to Do Digital
Philosophy of Science&rdquo;, <em>Philosophy of Science</em>, 85(5):
930&ndash;941. doi:10.1086/699697</li>

<li>Pollock, John L., 1989, <em>How to Build a Person: A
Prolegomenon</em>, Cambridge, MA: MIT Press.</li>

<li>&ndash;&ndash;&ndash;, 1995, <em>Cognitive Carpentry: A Bluepoint
for How to Build a Person</em>, Cambridge, MA: MIT Press.</li>

<li>&ndash;&ndash;&ndash;, 2006, <em>Thinking about Acting: Logical
Foundations for Rational Decision Making</em>, Oxford: Oxford
University Press. doi:10.1093/acprof:oso/9780195304817.001.0001</li>

<li>Portoraro, Frederic, 2001 [2019], &ldquo;Automated
Reasoning&rdquo;, in <em>The Stanford Encyclopedia of Philosophy</em>,
(Spring 2019), Edward N. Zalta (ed.), URL =
 &lt;<a href="https://plato.stanford.edu/archives/spr2019/entries/reasoning-automated/" target="other">https://plato.stanford.edu/archives/spr2019/entries/reasoning-automated/</a>&gt;</li>
 
<li>Reijula, Samuli and Jaakko Kuorikoski, 2019, &ldquo;Modeling
Epistemic Communities&rdquo;, in Miranda Fricker, Peter J. Graham,
David Henderson and Nikolaj J.L.L. Pedersen (eds), <em>The Routledge
Handbook of Social Epistemology</em>, Abingdon-on-Thames: Routledge,
chapter 24.</li>

<li>Rendsvig, Rasmus and John Symons, 2006 [2019], &ldquo;Epistemic
Logic&rdquo;, in <em>The Stanford Encyclopedia of Philosophy</em>,
(Summer 2019), Edward N. Zalta (ed.), URL =
 &lt;<a href="https://plato.stanford.edu/archives/sum2019/entries/logic-epistemic/" target="other">https://plato.stanford.edu/archives/sum2019/entries/logic-epistemic/</a>&gt;</li>
 
<li>Rescher, Nicholas, 2012, <em>Leibniz and Cryptography</em>,
University Library System, University of Pittsburgh.</li>

<li>Riegler, Alexander and Igor Douven, 2009, &ldquo;Extending the
Hegselmann&ndash;Krause Model III: From Single Beliefs to Complex
Belief States&rdquo;, <em>Episteme</em>, 6(2): 145&ndash;163.
doi:10.3366/E1742360009000616</li>

<li>&ndash;&ndash;&ndash;, 2010, &ldquo;Extending the
Hegselmann-Krause Model II&rdquo;, in T. Czarnecki, K. Kijania-Placek,
O. Poller, and J. Wolenski (eds.), <em>The Analytical Way: Proceedings
of the 6<sup>th</sup> European Congress of Analytic Philosophy</em>,
London: College Publications.</li>

<li>Riazanov, Alexandre and Andrei Voronkov, 2002, &ldquo;The Design
and Implementation of VAMPIRE&rdquo;, <em>AI Communications</em>,
15(2&ndash;3): 91&ndash;110.</li>

<li>Robson, Arthur J., 1990, &ldquo;Efficiency in Evolutionary Games:
Darwin, Nash and the Secret Handshake&rdquo;, <em>Journal of
Theoretical Biology</em>, 144(3): 379&ndash;396.
doi:10.1016/S0022-5193(05)80082-7</li>

<li>Rosenstock, Sarita, Justin Bruner, and Cailin O&rsquo;Connor,
2017, &ldquo;In Epistemic Networks, Is Less Really More?&rdquo;,
<em>Philosophy of Science</em>, 84(2): 234&ndash;252.
doi:10.1086/690717</li>

<li>Rubin, Hannah and Cailin O&rsquo;Connor, 2018,
&ldquo;Discrimination and Collaboration in Science&rdquo;,
<em>Philosophy of Science</em>, 85(3): 380&ndash;402.
doi:10.1086/697744</li>

<li>Rushby, John, 2018, &ldquo;A Mechanically Assisted Examination of
Begging the Question in Anselm&rsquo;s Ontological Argument&rdquo;,
<em>Journal of Applied Logics</em>, 5(7): 1473&ndash;1496.</li>

<li>Sargent, R G, 2013, &ldquo;Verification and Validation of
Simulation Models&rdquo;, <em>Journal of Simulation</em>, 7(1):
12&ndash;24. doi:10.1057/jos.2012.20</li>

<li>Schelling, Thomas C., 1971, &ldquo;Dynamic Models of
Segregation&rdquo;, <em>The Journal of Mathematical Sociology</em>,
1(2): 143&ndash;186. doi:10.1080/0022250X.1971.9989794</li>

<li>&ndash;&ndash;&ndash;, 1978, <em>Micromotives and
Macrobehavior</em>, New York: Norton.</li>

<li>Shults, F. LeRon, 2019, &ldquo;Computer Modeling in Philosophy of
Religion&rdquo;, <em>Open Philosophy</em>, (special issue on computer
modeling in philosophy) 2(1): 108&ndash;125.
doi:10.1515/opphil-2019-0011</li>

<li>Sidgwick, Henry, 1886, <em>Outlines of the History of Ethics for
English Readers</em>, London: Macmillan, Indianapolis IN: Hackett
1988.</li>

<li>Siekmann, J&ouml;rg and G. Wrightson (eds.), 1983, <em>Automation
of Reasoning: Classical Papers on Computational Logic,
1957&ndash;1965</em>, volume 1, Berlin: Springer</li>

<li>Singer, Daniel J., 2019, &ldquo;Diversity, Not Randomness, Trumps
Ability&rdquo;, <em>Philosophy of Science</em>, 86(1): 178&ndash;191.
doi:10.1086/701074</li>

<li>Singer, Daniel J., Aaron Bramson, Patrick Grim, Bennett Holman,
Jiin Jung, Karen Kovaka, Anika Ranginani, and William J. Berger, 2019,
&ldquo;Rational Social and Political Polarization&rdquo;,
<em>Philosophical Studies</em>, 176(9): 2243&ndash;2267.
doi:10.1007/s11098-018-1124-5</li>

<li>Singer, Daniel J., Aaron Bramson, Patrick Grim, Bennett Holman,
Karen Kovaka, Jiin Jung, and William J. Berger, forthcoming,
&ldquo;Don&rsquo;t Forget Forgetting: The Social Epistemic Importance
of How We Forget&rdquo;, <em>Synthese</em>, first online: 8 October
2019. doi:10.1007/s11229-019-02409-0</li>

<li>Skyrms, Brian, 1996, <em>Evolution of the Social Contract</em>,
Cambridge: Cambridge University Press.
doi:10.1017/CBO9780511806308</li>

<li>&ndash;&ndash;&ndash;, 2004, <em>The Stag Hunt and the Evolution
of Social Structure</em>, New York: Cambridge University Press.
doi:10.1017/CBO9781139165228</li>

<li>&ndash;&ndash;&ndash;, 2010, <em>Signals: Evolution, Learning and
Information</em>, New York: Oxford University Press.
doi:10.1093/acprof:oso/9780199580828.001.0001</li>

<li>Solomon, Miriam, 1994a, &ldquo;Social Empiricism&rdquo;,
<em>No&ucirc;s</em>, 28(3): 325&ndash;343. doi:10.2307/2216062</li>

<li>&ndash;&ndash;&ndash;, 1994b, &ldquo;A More Social
Epistemology&rdquo;, in Frederick E. Schmitt (ed.), <em>Socializing
Epistemology: The Social Dimensions of Knowledge</em>, Lanham, MD:
Rowman and Littlefield, pp. 217-233.</li>

<li>Spirtes, Peter, Clark Glymour, and Richard Scheines, 1993,
<em>Causation, Prediction, and Search</em>, (Lecture Notes in
Statistics 81), New York: Springer New York.
doi:10.1007/978-1-4612-2748-9</li>

<li>Sprenger, Jan and Stephen Hartmann, 2019, <em>Bayesian Philosophy
of Science</em>, Oxford: Oxford University Press.
doi:10.1093/oso/9780199672110.001.0001</li>

<li>Steen, Alexander and Christoph Benzm&uuml;ller, 2018, &ldquo;The
Higher-Order Prover Leo-III&rdquo;, in <em>KI 2019: Advances in
Artificial Intelligence: 42nd German Conference on AI</em>, Didier
Galmiche, Stephan Schulz, and Roberto Sebastiani (eds.), (Lecture
Notes in Computer Science 10900), Cham: Springer International
Publishing, 108&ndash;116. doi:10.1007/978-3-319-94205-6_8</li>

<li>St. Denis, Paul and Patrick Grim, 1997, &ldquo;Fractal Images of
Formal Systems&rdquo;, <em>Journal of Philosophical Logic</em>, 26(2):
181&ndash;222. doi:10.1023/A:1004280900954</li>

<li>Steinhart, Eric, 1994, &ldquo;NETMET: A Program for Generating and
Interpreting Metaphors&rdquo;, <em>Computers and the Humanities</em>,
28(6): 383&ndash;392. doi:10.1007/BF01829973</li>

<li>Steinhart, Eric and Eva Kittay, 1994, &ldquo;Generating Metaphors
from Networks: A Formal Interpretation of the Semantic Field Theory of
Metaphor&rdquo;, in <em>Aspects of Metaphor</em>, Jaakko Hintikka
(ed.), Dordrecht: Springer Netherlands, 41&ndash;94.
doi:10.1007/978-94-015-8315-2_3</li>

<li>Swift, J., 1726, <em>Gulliver&rsquo;s Travels</em>
URL=
 &lt;<a href="https://www.gutenberg.org/files/829/829-h/829-h.htm" target="other">https://www.gutenberg.org/files/829/829-h/829-h.htm</a>&gt;
</li>
 
<li>Thagard, Paul, 1988, <em>Computational Philosophy of Science</em>,
Cambridge MA: MIT Press.</li>

<li>&ndash;&ndash;&ndash;, 1992, <em>Conceptual Revolutions</em>,
Princeton, NJ: Princeton University Press.</li>

<li>&ndash;&ndash;&ndash;, 2012, <em>The Cognitive Science of Science:
Explanation, Discovery, and Conceptual Change</em>, Cambridge MA: MIT
Press.</li>

<li>Thicke, Michael, forthcoming, &ldquo;Evaluating Formal Models of
Science&rdquo;, <em>Journal for General Philosophy of Science</em>,
First online: 1 February 2019. doi:10.1007/s10838-018-9440-1</li>

<li>Thoma, Johanna, 2015, &ldquo;The Epistemic Division of Labor
Revisited&rdquo;, <em>Philosophy of Science</em>, 82(3):
454&ndash;472. doi:10.1086/681768</li>

<li>Thompson, Abigail, 2014, &ldquo;Does Diversity Trump Ability?: An
Example of the Misuse of Mathematics in the Social Sciences&rdquo;,
<em>Notices of the American Mathematical Society</em>, 61(9):
1024&ndash;1030.</li>

<li>Turing, A. M., 1936&ndash;1937, &ldquo;On Computable Numbers, with
an Application to the <em>Entscheidungsproblem</em>&rdquo;,
<em>Proceedings of the London Mathematical Society</em>, s2-42(1):
230&ndash;265. doi:10.1112/plms/s2-42.1.230</li>

<li>van Benthem, Johan, 2006, &ldquo;Epistemic Logic and Epistemology:
The State of Their Affairs&rdquo;, <em>Philosophical Studies</em>,
128(1): 49&ndash;76. doi:10.1007/s11098-005-4052-0</li>

<li>van de Rijt, Arnout, David Siegel, and Michael Macy, 2009,
&ldquo;Neighborhood Chance and Neighborhood Change: A Comment on Bruch
and Mare&rdquo;, <em>American Journal of Sociology</em>, 114(4):
1166&ndash;1180. doi:10.1086/588795</li>

<li>Van Den Hoven, Jeroen and Gert&#8208;Jan Lokhorst, 2002,
&ldquo;Deontic Logic and Computer&#8208;Supported Computer Ethics&rdquo;,
<em>Metaphilosophy</em>, 33(3): 376&ndash;386.
doi:10.1111/1467-9973.00233</li>

<li>Van Ditmarsch, Hans, Wiebe van der Hoek, and Barteld Kooi, 2008,
<em>Dynamic Epistemic Logic</em>, (Synthese Library 337), Dordrecht:
Springer Netherlands. doi:10.1007/978-1-4020-5839-4</li>

<li>Vanderschraaf, Peter, 2006, &ldquo;War or Peace?: A Dynamical
Analysis of Anarchy&rdquo;, <em>Economics and Philosophy</em>, 22(2):
243&ndash;279. doi:10.1017/S0266267106000897</li>

<li>Wagner, Elliott, 2009, &ldquo;Communication and Structured
Correlation&rdquo;, <em>Erkenntnis</em>, 71(3): 377&ndash;393.
doi:10.1007/s10670-009-9157-y</li>

<li>Waldrop, M. Mitchell, 1992, <em>Complexity: The Emerging Science
at the Edge of Order and Chaos</em>, New York: Simon and
Schuster.</li>

<li>Wang, Hao, 1960, &ldquo;Toward Mechanical Mathematics&rdquo;,
<em>IBM Journal of Research and Development</em>, 4(1): 2&ndash;22.
doi:10.1147/rd.41.0002</li>

<li>Watts, Duncan J. and Steven H. Strogatz, 1998, &ldquo;Collective
Dynamics of &lsquo;Small-World&rsquo; Networks&rdquo;,
<em>Nature</em>, 393(6684): 440&ndash;442. doi:10.1038/30918</li>

<li>Weisberg, Michael, 2013, <em>Simulation and Similarity: Using
Models to Understand the World</em>, Oxford: Oxford University Press.
doi:10.1093/acprof:oso/9780199933662.001.0001</li>

<li>Weisberg, Michael and Ryan Muldoon, 2009, &ldquo;Epistemic
Landscapes and the Division of Cognitive Labor&rdquo;, <em>Philosophy
of Science</em>, 76(2): 225&ndash;252. doi:10.1086/644786</li>

<li>Weymark, John A., 2015, &ldquo;Cognitive Diversity, Binary
Decisions, and Epistemic Democracy&rdquo;, <em>Episteme</em>, 12(4):
497&ndash;511. doi:10.1017/epi.2015.34 </li>

<li>Whitehead, Alfred North and Bertrand Russell, 1910, 1912, 1913, <em>Principia Mathematica</em>, 3 volumes, Cambridge: Cambridge University Press. </li>

<li>Windrum, Paul, Giorgio Fagiolo, and Alessio Moneta, 2007,
&ldquo;Empirical Validation of Agent-Based Models: Alternatives and
Prospects&rdquo;, <em>Journal of Artificial Societies and Social
Simulation</em>, 10(2): 8. URL =
 <a href="http://jasss.soc.surrey.ac.uk/10/2/8.html" target="other">http://jasss.soc.surrey.ac.uk/10/2/8.html</a>&gt;</li>
 
<li>Wiseman, Thomas and Okan Yilankaya, 2001, &ldquo;Cooperation,
Secret Handshakes, and Imitation in the Prisoners&rsquo;
Dilemma&rdquo;, <em>Games and Economic Behavior</em>, 37(1):
216&ndash;242. doi:10.1006/game.2000.0836</li>

<li>Wright, Sewall, 1932, &ldquo;The Roles of Mutation, Inbreeding,
Crossbreeding, and Selection in Evolution&rdquo;, <em>Proceedings of
the Sixth International Congress on Genetics,</em> vol. 1, D. F. Jones
(ed.), pp. 355&ndash;366.</li>

<li>Young, H.P., 1993, &ldquo;An Evolutionary Model of
Bargaining&rdquo;, <em>Journal of Economic Theory</em>, 59(1):
145&ndash;168. doi:10.1006/jeth.1993.1009</li>

<li>Zalta, Edward, 2020, <em>Principia Metaphysica</em>, unpublished manuscript. URL = &lt;<a href="https://mally.stanford.edu/principia.pdf" target="other">https://mally.stanford.edu/principia.pdf</a>&gt;</li>

<li>Zollman, Kevin James Spears, 2005, &ldquo;Talking to Neighbors: The Evolution of Regional Meaning&rdquo;, <em>Philosophy of
Science</em>, 72(1): 69&ndash;85. doi:10.1086/428390</li>

<li>&ndash;&ndash;&ndash;, 2007, &ldquo;The Communication
Structure of Epistemic Communities&rdquo;, <em>Philosophy of
Science</em>, 74(5): 574&ndash;587. doi:10.1086/525605</li>

<li>&ndash;&ndash;&ndash;, 2010a, &ldquo;The Epistemic Benefit of Transient Diversity&rdquo;, <em>Erkenntnis</em>, 72(1): 17&ndash;35. doi:10.1086/525605</li>

<li>&ndash;&ndash;&ndash;, 2010b, &ldquo;Social Structure and the
Effects of Conformity&rdquo;, <em>Synthese</em>, 172(3):
317&ndash;340. doi:10.1007/s11229-008-9393-8</li>
</ul>

</div>

<div id="academic-tools">

<h2 id="Aca">Academic Tools</h2>

<blockquote>

<table class="vert-top">
<tr>
  <td>
<img src="../../symbols/sepman-icon.jpg" alt="sep man icon" />
</td>
 
 <td><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=computational-philosophy" target="other">How to cite this entry</a>.</td>
 </tr>
<tr>
  <td>
<img src="../../symbols/sepman-icon.jpg" alt="sep man icon" />
</td>
 
 <td><a href="https://leibniz.stanford.edu/friends/preview/computational-philosophy/" target="other">Preview the PDF version of this entry</a>
 at the
 <a href="https://leibniz.stanford.edu/friends/" target="other">Friends of the SEP Society</a>.</td>
 </tr>
<tr>
  <td>
<img src="../../symbols/inpho.png" alt="inpho icon" />
</td>
 
 <td><a href="https://www.inphoproject.org/entity?sep=computational-philosophy&amp;redirect=True" target="other">Look up topics and thinkers related to this entry</a>
 at the Internet Philosophy Ontology Project (InPhO).</td> </tr>
<tr>
  <td>
<img src="../../symbols/pp.gif" alt="phil papers icon" />
</td>
 
 <td><a href="https://philpapers.org/sep/computational-philosophy/" target="other">Enhanced bibliography for this entry</a>
 at
 <a href="https://philpapers.org/" target="other">PhilPapers</a>,
 with links to its database.</td> </tr>
</table>
</blockquote>

</div>



<div id="other-internet-resources">

<h2 id="Oth">Other Internet Resources</h2>

<p>
Computational philosophy encompasses many different tools and
techniques. The aim of this section is to highlight a few of the most
commonly used tools.</p>

<p>
A large amount of computational philosophy uses agent-based
simulations. An extremely popular tool for producing and analyzing
agent-based simulations is the free tool
 <a href="https://ccl.northwestern.edu/netlogo/" target="other">NetLogo</a>,
 which was produced and is maintained by Uri Wilensky and The Center
for Connected Learning and Computer-Based Modeling at Northwestern
University. NetLogo is a simple but powerful platform for creating and
running agent-based simulations, used in all of the examples below,
which run using the NetLogo web platform. NetLogo includes a number of
tutorials to help people completely new to programming. It also
includes advanced tools, like BehaviorSpace and BehaviorSearch, which
let the research run large &ldquo;experiments&rdquo; of simulations
and easily implement genetic algorithms and other search techniques to
explore model parameters. NetLogo is a very popular simulation
language among computational philosophers, but there are other
agent-based modelling environments that are similar, such as
 <a href="https://www.swarm.org/wiki/Swarm_main_page" target="other">Swarm</a>,
 as well as tools to help analyze agent-based models, such as
 <a href="https://openmole.org/" target="other">OpenMOLE</a>.
 Computational philosophy simulations may also be written and analyzed
in Python, Java, and C, all of which are general programming languages
but are much less friendly to beginners.</p>

<p>
For analyzing data (from models or elsewhere) and creating graphs and
charts,
 <a href="https://www.r-project.org/" target="other">the statistical environment R</a>
 is popular.
 <a href="https://www.wolfram.com/mathematica/" target="other">Mathematica</a>
 and
 <a href="https://www.mathworks.com/products/matlab.html" target="other">MATLAB</a>
 are also sometimes used to check or prove mathematical claims. All
three of these are advanced tools that are not easily accessible to
beginners. For beginners, Microsoft Excel can be used to analyze and
visualize smaller data sets.</p>

<p id="OIR-vampire">
As mentioned above, common tools used for theorem proving include
 <a href="https://vprover.github.io/" target="other">Vampire</a>
 and
 <a href="https://isabelle.in.tum.de/" target="other">Isabelle/HOL</a>.</p>

 
<p>
Just as philosophical methodology is diverse, so too are the
computational tools used by philosophers. Because it is common to
mention tools used in the course of research, further tools can be
found in the literature of computational philosophy.</p>

<h3 id="CompModeExam">Computational Model Examples</h3>

<p>
Below is a list of the example computational models mentioned above.
Each model can be run on Netlogoweb in your browser. Alternatively,
any of the models can be downloaded and run on Netlogo desktop by
clicking on &ldquo;Export: Netlogo&rdquo; in the top right of the
model screen.</p>

<ul class="jfy">

<li id="OIR-HK"><a href="https://netlogoweb.org/web?https://www.danieljsinger.com/models/Bounded%20Confidence%20from%20Netlogo%20Community.nlogo" target="other">Interactive simulation of the Hegselmann and Krause bounded confidence model</a>.
 To start the model, click &ldquo;setup&rdquo; and then
&ldquo;go&rdquo; (near the top left corner). To restart the model,
click &ldquo;setup&rdquo; again. Near the top right corner, you can
change the display to show the history of the histogram of opinions
over time or show the trajectories through time of individual agents.
For more information about the model, scroll down and click on
&ldquo;Model Info&rdquo;.</li>

<li id="OIR-NetlogoAxelrod"><a href="https://netlogoweb.org/web?https://www.danieljsinger.com/models/Dissemination%20of%20Culture.nlogo" target="other">Interactive simulation of Axelrod&rsquo;s Polarization Model</a>.
 To start the model, click &ldquo;setup&rdquo; and then
&ldquo;go&rdquo; (near the top left corner). To restart the model,
click &ldquo;setup&rdquo; again. Each &ldquo;patch&rdquo; in the
display represents one person. Where there are dark black lines
between people, the people share no traits. The line gets lighter as
they share more traits. This model runs quite slowly in web browsers,
so try speeding it up by manually pulling the &ldquo;model
speed&rdquo; slider to the right. For more information about the
model, scroll down and click on &ldquo;Model Info&rdquo;.</li>

<li id="OIR-NetlogoZollman"><a href="https://netlogoweb.org/web?https://www.danieljsinger.com/models/Zollman%20Bandit%20Model.nlogo" target="other">Interactive simulation of Zollman&rsquo;s Networked-Researchers Model</a>.
 To start the model, click &ldquo;setup&rdquo; and then
&ldquo;go&rdquo; (near the top left corner). To restart the model,
click &ldquo;setup&rdquo; again. In this model (a simplified version
of the model discussed in Zollman 2007), agents play a bandit problem (like a slot machine with two
arms that have different probabilities of paying off). They usually
play the arm they think it most profitable, except that they deviate
with a small chance to make sure they aren&rsquo;t missing something
better on the other arm. The model allows agents to share information
either in a ring or in a complete network. For more information about
the model, scroll down and click on &ldquo;Model Info&rdquo;.</li>

<li id="OIR-NetlogoEpistemicNetworks"><a href="https://netlogoweb.org/web?https://www.danieljsinger.com/models/Grim%20and%20Singer%20Epistemic%20Networks%20Simplified.nlogo" target="other">Interactive simulation of Grim and Singer&rsquo;s networked agents on an epistemic landscape</a>.
 To start the model, click &ldquo;setup&rdquo; and then
&ldquo;go&rdquo;. To restart the model, unclick &ldquo;go&rdquo; if
the model is still running and then click &ldquo;setup&rdquo; again.
Initially, agents are assigned random beliefs (locations on the x-axis
of the epistemic landscape). On each round the imitate their
highest-performing network-neighbor by moving toward their belief with
a certain speed and uncertainty about their neighbor&rsquo;s view. The
model allows simulation of many different kinds of networks and
landscapes. For more information about the model, scroll down and
click on &ldquo;Model Info&rdquo;.</li>

<li id="OIR-NetlogoWeisbergMuldoon"><a href="https://netlogoweb.org/web?https://www.danieljsinger.com/models/Weisberg%20Muldoon%20Landscape.nlogo" target="other">Interactive simulation of Weisberg and Muldoon&rsquo;s model of agents on an epistemic landscape</a>.
 To start the model, click &ldquo;setup&rdquo; and then
&ldquo;go&rdquo;. To restart the model, unclick &ldquo;go&rdquo; if
the model is still running and then click &ldquo;setup&rdquo; again.
Initially, mavericks and followers are dropped on parts of the
landscape that aren&rsquo;t on the &ldquo;hills&rdquo;. Both kinds of
agents then use their own method for hill climbing. As mentioned
above, Alexander et al. (2015) argue that there&rsquo;s a technical problem with
the original model. This simulation includes a toggle between the
original model and a critic&rsquo;s preferred version of it. For more information about
the model, scroll down and click on &ldquo;Model Info&rdquo;.</li>

<li id="OIR-NetlogoHongPageModel"><a href="https://netlogoweb.org/web?https://www.danieljsinger.com/models/Hong%20Page%20Diversity%20Model.nlogo" target="other">Interactive simulation of the Hong and Page model of group deliberation</a>.
 To setup the model, which includes setting up the landscape and the
two groups (random group and group of highest-performers), click
&ldquo;setup&rdquo;. Note: Setup may be slow, since it tests all
possible heuristics (unless quick-setup-experts is activated).
Clicking &ldquo;go&rdquo; then calculates the scores of the two
groups. This simulation extends Hong and Page&rsquo;s original model
to allow for landscape smoothing (instead of the original random
landscape). It also includes a &ldquo;tournament&rdquo; group dynamics
that is different from the group dynamics of the original model. For
more information about the model, scroll down and click on
&ldquo;Model Info&rdquo;.</li>

<li id="OIR-NetlogoPrisonersDilemma"><a href="https://www.netlogoweb.org/web?https://www.danieljsinger.com/models/Prisoner%27s%20Dilemma.nlogo" target="other">Interactive simulation of a Repeated Prisoner&rsquo;s Dilemma Model</a>.
 To start the model, click &ldquo;setup&rdquo; and then
&ldquo;go-once&rdquo; (to have agents play and imitate once) or
&ldquo;go&rdquo; (to have agents repeatedly play and imitate their
neighbors). To restart the model, click &ldquo;setup&rdquo; again.
Each &ldquo;patch&rdquo; in the display represents one agent. Agents
start with a randomly-assigned strategy, play each of their 8
neighbors rounds_to_play times and then imitate their best-performing
neighbors. This model runs slowly in web browsers, but it runs a lot
more quickly in Netlogo Desktop (you can download the model code by
clicking on &ldquo;Export: Netlogo&rdquo; near the top right). For
more information about the model, scroll down and click on
&ldquo;Model Info&rdquo;.</li>

<li id="OIR-NetlogoSegregation"><a href="https://www.netlogoweb.org/web?https://www.netlogoweb.org/assets/modelslib/Sample%20Models/Social%20Science/Segregation.nlogo" target="other">Interactive simulation of residential segregation</a>.
 To start the model, click &ldquo;setup&rdquo; and then
&ldquo;go&rdquo; (near the top left corner). To restart the model,
click &ldquo;setup&rdquo; again. Change the threshold below which
agents move by changing &ldquo;%-similar-wanted&rdquo;, and change how
full the grid is at the beginning by changing &ldquo;density&rdquo;.
For more information about the model, scroll down and click on
&ldquo;Model Info&rdquo;.</li>

<li id="OIR-NetlogoSignalingModel"><a href="https://netlogoweb.org/web?https://www.danieljsinger.com/models/Grim%20et%20al%20Making%20Meaning%20Happen.nlogo" target="other">Interactive simulation of an emergence of signaling model from Grim et al. (2004)</a>.
 In this model, each agent (each patch in the display) starts with a
random communication strategy (a way of responding to and producing
signals). As the model runs, the agents are potentially helped (fed by
the fish) or hurt (by wolves) depending on how they act (in part, in
response to the signals they hear). Each 100 rounds, agents copy the
signaling strategy of their healthiest neighbor. Doing so results in
so-called &ldquo;perfect communication&rdquo; strategies eventually
dominating, though that can take tens of thousands of rounds. For more
information about the model, scroll down and click on &ldquo;Model
Info&rdquo;.</li>
</ul>

<h3 id="AddiInteReso">Additional Internet Resources</h3>

<ul>

<li id="OIR-Laputa"><a href="https://www.luiq.lu.se/software-for-social-epistemology-laputa-1-6-now-available/">Laputa</a>
 </li>

<li id="OIR-NETMET"><a href="http://ericsteinhart.com/ANALOGY/lom-netmet.html" target="other">NETMET (The Logic of Metaphor)</a></li>
 
<li id="OIR-mace4"><a href="https://www.cs.unm.edu/~mccune/prover9/" target="other">Prover9 and Mace4</a></li>
 
<li id="OIR-prover9"><a href="https://www.cs.unm.edu/~mccune/mace4/examples/2009-11A/" target="other">Prover9 (and some Mace4) examples</a></li>
 
 <li><a href="https://www.degruyter.com/view/j/opphil.2019.2.issue-1/issue-files/opphil.2019.2.issue-1.xml" target="other">Topical issue on Computational Modeling in Philosophy in <em>Open Philosophy</em> vol. 2, issue 1 (January 2019)</a></li>
 
 <li><a href="https://isa-afp.org/entries/GewirthPGCProof.html" target="other">Fuenmayor and Benzm&uuml;ller&rsquo;s 2018 Formalisation and Evaluation of Alan Gewirth&rsquo;s Proof for the Principle of Generic Consistency in Isabelle/HOL at the <em>Archive of Formal Proofs</em></a></li>
 
<li id="OIR-mally"><a href="https://mally.stanford.edu/cm/" target="other">&ldquo;Computational Metaphysics&rdquo; pages</a>
 at the Metaphysics Research Lab</li>

<li id="OIR-fischer">Fischer, Eric, 2010,
 <a href="https://flickr.com/photos/24431382@N03/4981441877" target="other">map of Race and Ethnicity, Los Angeles</a>,
 based on the 2000 census data. Licensed under
 <a href="https://creativecommons.org/licenses/by-sa/2.0/" target="other">CC BY-SA 2.0</a></li>
 
<li id="OIR-mohseni">Mohseni, Aydin, Cailin O&rsquo;Connor, and Hannah
Rubin, 2019, &ldquo;On the Emergence of Minority Disadvantage: Testing
the Cultural Red King Hypothesis&rdquo;, unpublished manuscript, URL =
 &lt;<a href="http://philsci-archive.pitt.edu/16352/" target="other">http://philsci-archive.pitt.edu/16352/</a>&gt;</li>
 
<li id="OIR-zalta">Zalta, Edward, 2020, <em>Principia
Logico-Metaphysica</em>, unpublished manuscript. URL =
 &lt;<a href="https://mally.stanford.edu/principia.pdf" target="other">https://mally.stanford.edu/principia.pdf</a>&gt;</li>
 
 </ul>

</div>

<div id="related-entries">

<h2 id="Rel">Related Entries</h2>

<p>

 <a href="../artificial-intelligence/index.html">artificial intelligence</a> |
 <a href="../epistemology-social/index.html">epistemology: social</a> |
 <a href="../logic-ancient/index.html">logic: ancient</a> |
 <a href="../logic-epistemic/index.html">logic: epistemic</a> |
 <a href="../prisoner-dilemma/index.html">prisoner&rsquo;s dilemma</a> |
 <a href="../reasoning-automated/index.html">reasoning: automated</a> |
 <a href="../scientific-knowledge-social/index.html">scientific knowledge: social dimensions of</a> |
 <a href="../social-norms/index.html">social norms</a>

</p>

</div>

<div id="acknowledgments">

<h3>Acknowledgments</h3>

<p>
The authors are grateful to Anthony Beavers, Christoph
Benzm&uuml;ller, Gregor Betz, Selmer Bringsjord, Branden Fitelson,
Ryan Muldoon, Eric Steinhart, Michael Weisberg, and Kevin Zollman for
consultation, contributions, and assistance.</p>
</div>

<script type="text/javascript" src="local.js"></script>
<script type="text/javascript" src="../../MathJax/MathJaxdda6.js?config=TeX-AMS-MML_HTMLorMML"></script>


</div><!-- #aueditable --><!--DO NOT MODIFY THIS LINE AND BELOW-->

<!-- END ARTICLE HTML -->

</div> <!-- End article-content -->

  <div id="article-copyright">
    <p>
 <a href="../../info.html#c">Copyright &copy; 2020</a> by

<br />
Patrick Grim
&lt;<a href="m&#97;ilto:patrick&#37;2egrim&#37;40stonybrook&#37;2eedu"><em>patrick<abbr title=" dot ">&#46;</abbr>grim<abbr title=" at ">&#64;</abbr>stonybrook<abbr title=" dot ">&#46;</abbr>edu</em></a>&gt;<br />
Daniel Singer
&lt;<a href="m&#97;ilto:singerd&#37;40phil&#37;2eupenn&#37;2eedu"><em>singerd<abbr title=" at ">&#64;</abbr>phil<abbr title=" dot ">&#46;</abbr>upenn<abbr title=" dot ">&#46;</abbr>edu</em></a>&gt;
    </p>
  </div>

</div> <!-- End article -->

<!-- NOTE: article banner is outside of the id="article" div. -->
<div id="article-banner" class="scroll-block">
  <div id="article-banner-content">
    <a href="../../fundraising/index.html">
    Open access to the SEP is made possible by a world-wide funding initiative.<br />
    The Encyclopedia Now Needs Your Support<br />
    Please Read How You Can Help Keep the Encyclopedia Free</a>
  </div>
</div> <!-- End article-banner -->

    </div> <!-- End content -->

    <div id="footer">

      <div id="footer-menu">
        <div class="menu-block">
          <h4><i class="icon-book"></i> Browse</h4>
          <ul role="menu">
            <li><a href="../../contents.html">Table of Contents</a></li>
            <li><a href="../../new.html">What's New</a></li>
            <li><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/random">Random Entry</a></li>
            <li><a href="../../published.html">Chronological</a></li>
            <li><a href="../../archives/index.html">Archives</a></li>
          </ul>
        </div>
        <div class="menu-block">
          <h4><i class="icon-info-sign"></i> About</h4>
          <ul role="menu">
            <li><a href="../../info.html">Editorial Information</a></li>
            <li><a href="../../about.html">About the SEP</a></li>
            <li><a href="../../board.html">Editorial Board</a></li>
            <li><a href="../../cite.html">How to Cite the SEP</a></li>
            <li><a href="../../special-characters.html">Special Characters</a></li>
            <li><a href="../../tools/index.html">Advanced Tools</a></li>
            <li><a href="../../contact.html">Contact</a></li>
          </ul>
        </div>
        <div class="menu-block">
          <h4><i class="icon-leaf"></i> Support SEP</h4>
          <ul role="menu">
            <li><a href="../../support/index.html">Support the SEP</a></li>
            <li><a href="../../support/friends.html">PDFs for SEP Friends</a></li>
            <li><a href="../../support/donate.html">Make a Donation</a></li>
            <li><a href="../../support/sepia.html">SEPIA for Libraries</a></li>
          </ul>
        </div>
      </div> <!-- End footer menu -->

      <div id="mirrors">
        <div id="mirror-info">
          <h4><i class="icon-globe"></i> Mirror Sites</h4>
          <p>View this site from another server:</p>
        </div>
        <div class="btn-group open">
          <a class="btn dropdown-toggle" data-toggle="dropdown" href="https://plato.stanford.edu/">
            <span class="flag flag-usa"></span> USA (Main Site) <span class="caret"></span>
            <span class="mirror-source">Philosophy, Stanford University</span>
          </a>
          <ul class="dropdown-menu">
            <li><a href="../../mirrors.html">Info about mirror sites</a></li>
          </ul>
        </div>
      </div> <!-- End mirrors -->
      
      <div id="site-credits">
        <p>The Stanford Encyclopedia of Philosophy is <a href="../../info.html#c">copyright &copy; 2022</a> by <a href="http://mally.stanford.edu/">The Metaphysics Research Lab</a>, Department of Philosophy, Stanford University</p>
        <p>Library of Congress Catalog Data: ISSN 1095-5054</p>
      </div> <!-- End site credits -->

    </div> <!-- End footer -->

  </div> <!-- End container -->

   <!-- NOTE: Script required for drop-down button to work (mirrors). -->
  <script>
    $('.dropdown-toggle').dropdown();
  </script>

</body>

<!-- Mirrored from seop.illc.uva.nl/entries/computational-philosophy/ by HTTrack Website Copier/3.x [XR&CO'2014], Wed, 22 Jun 2022 19:42:57 GMT -->
</html>
