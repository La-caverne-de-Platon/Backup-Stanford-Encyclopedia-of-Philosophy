<!DOCTYPE html>
<!--[if lt IE 7]> <html class="ie6 ie"> <![endif]-->
<!--[if IE 7]>    <html class="ie7 ie"> <![endif]-->
<!--[if IE 8]>    <html class="ie8 ie"> <![endif]-->
<!--[if IE 9]>    <html class="ie9 ie"> <![endif]-->
<!--[if !IE]> --> <html> <!-- <![endif]-->

<!-- Mirrored from seop.illc.uva.nl/entries/content-narrow/ by HTTrack Website Copier/3.x [XR&CO'2014], Wed, 22 Jun 2022 19:52:47 GMT -->
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>
Narrow Mental Content (Stanford Encyclopedia of Philosophy)
</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="robots" content="noarchive, noodp" />
<meta property="citation_title" content="Narrow Mental Content" />
<meta property="citation_author" content="Brown, Curtis" />
<meta property="citation_publication_date" content="2002/11/20" />
<meta name="DC.title" content="Narrow Mental Content" />
<meta name="DC.creator" content="Brown, Curtis" />
<meta name="DCTERMS.issued" content="2002-11-20" />
<meta name="DCTERMS.modified" content="2022-04-27" />

<!-- NOTE: Import webfonts using this link: -->
<link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,300,600,200&amp;subset=latin,latin-ext" rel="stylesheet" type="text/css" />

<link rel="stylesheet" type="text/css" media="screen,handheld" href="../../css/bootstrap.min.css" />
<link rel="stylesheet" type="text/css" media="screen,handheld" href="../../css/bootstrap-responsive.min.css" />
<link rel="stylesheet" type="text/css" href="../../css/font-awesome.min.css" />
<!--[if IE 7]> <link rel="stylesheet" type="text/css" href="../../css/font-awesome-ie7.min.css"> <![endif]-->
<link rel="stylesheet" type="text/css" media="screen,handheld" href="../../css/style.css" />
<link rel="stylesheet" type="text/css" media="print" href="../../css/print.css" />
<link rel="stylesheet" type="text/css" href="../../css/entry.css" />
<!--[if IE]> <link rel="stylesheet" type="text/css" href="../../css/ie.css" /> <![endif]-->
<script type="text/javascript" src="../../js/jquery-1.9.1.min.js"></script>
<script type="text/javascript" src="../../js/bootstrap.min.js"></script>

<!-- NOTE: Javascript for sticky behavior needed on article and ToC pages -->
<script type="text/javascript" src="../../js/jquery-scrolltofixed-min.js"></script>
<script type="text/javascript" src="../../js/entry.js"></script>

<!-- SEP custom script -->
<script type="text/javascript" src="../../js/sep.js"></script>
</head>

<!-- NOTE: The nojs class is removed from the page if javascript is enabled. Otherwise, it drives the display when there is no javascript. -->
<body class="nojs article" id="pagetopright">
<div id="container">
<div id="header-wrapper">
  <div id="header">
    <div id="branding">
      <div id="site-logo"><a href="../../index.html"><img src="../../symbols/sep-man-red.png" alt="SEP home page" /></a></div>
      <div id="site-title"><a href="../../index.html">Stanford Encyclopedia of Philosophy</a></div>
    </div>
    <div id="navigation">
      <div class="navbar">
        <div class="navbar-inner">
          <div class="container">
            <button class="btn btn-navbar collapsed" data-target=".collapse-main-menu" data-toggle="collapse" type="button"> <i class="icon-reorder"></i> Menu </button>
            <div class="nav-collapse collapse-main-menu in collapse">
              <ul class="nav">
                <li class="dropdown open"><a id="drop1" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-book"></i> Browse</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop1">
                    <li><a href="../../contents.html">Table of Contents</a></li>
                    <li><a href="../../new.html">What's New</a></li>
                    <li><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/random">Random Entry</a></li>
                    <li><a href="../../published.html">Chronological</a></li>
                    <li><a href="../../archives/index.html">Archives</a></li>
                  </ul>
                </li>
                <li class="dropdown open"><a id="drop2" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-info-sign"></i> About</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop2">
                    <li><a href="../../info.html">Editorial Information</a></li>
                    <li><a href="../../about.html">About the SEP</a></li>
                    <li><a href="../../board.html">Editorial Board</a></li>
                    <li><a href="../../cite.html">How to Cite the SEP</a></li>
                    <li><a href="../../special-characters.html">Special Characters</a></li>
                    <li><a href="../../tools/index.html">Advanced Tools</a></li>
                    <li><a href="../../contact.html">Contact</a></li>
                  </ul>
                </li>
                <li class="dropdown open"><a id="drop3" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-leaf"></i> Support SEP</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop3">
                    <li><a href="../../support/index.html">Support the SEP</a></li>
                    <li><a href="../../support/friends.html">PDFs for SEP Friends</a></li>
                    <li><a href="../../support/donate.html">Make a Donation</a></li>
                    <li><a href="../../support/sepia.html">SEPIA for Libraries</a></li>
                  </ul>
                </li>
              </ul>
            </div>
          </div>
        </div>
      </div>
    </div>
    <!-- End navigation -->
    
    <div id="search">
      <form id="search-form" method="get" action="https://seop.illc.uva.nl/search/searcher.py">
        <input type="search" name="query" placeholder="Search SEP" />
        <div class="search-btn-wrapper"><button class="btn search-btn" type="submit"><i class="icon-search"></i></button></div>
      </form>
    </div>
    <!-- End search --> 
    
  </div>
  <!-- End header --> 
</div>
<!-- End header wrapper -->

<div id="content">

<!-- Begin article sidebar -->
<div id="article-sidebar" class="sticky">
  <div class="navbar">
    <div class="navbar-inner">
      <div class="container">
        <button class="btn btn-navbar" data-target=".collapse-sidebar" data-toggle="collapse" type="button"> <i class="icon-reorder"></i> Entry Navigation </button>
        <div id="article-nav" class="nav-collapse collapse-sidebar in collapse">
          <ul class="nav">
            <li><a href="#toc">Entry Contents</a></li>
            <li><a href="#Bib">Bibliography</a></li>
            <li><a href="#Aca">Academic Tools</a></li>
            <li><a href="https://leibniz.stanford.edu/friends/preview/content-narrow/">Friends PDF Preview <i class="icon-external-link"></i></a></li>
            <li><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=content-narrow">Author and Citation Info <i class="icon-external-link"></i></a> </li>
            <li><a href="#pagetopright" class="back-to-top">Back to Top <i class="icon-angle-up icon2x"></i></a></li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</div>
<!-- End article sidebar --> 

<!-- NOTE: Article content must have two wrapper divs: id="article" and id="article-content" -->
<div id="article">
<div id="article-content">

<!-- BEGIN ARTICLE HTML -->


<div id="aueditable"><!--DO NOT MODIFY THIS LINE AND ABOVE-->

<h1>Narrow Mental Content</h1><div id="pubinfo"><em>First published Wed Nov 20, 2002; substantive revision Wed Apr 27, 2022</em></div>

<div id="preamble">

<p>
Narrow mental content is a kind of mental content that does not depend
on an individual&rsquo;s environment. Narrow content contrasts with
&ldquo;broad&rdquo; or &ldquo;wide&rdquo; content, which depends on
features of the individual&rsquo;s environment as well as on features
of the individual. It is controversial whether there is any such thing
as narrow content. Assuming that there is, it is also controversial
what sort of content it is, what its relation to ordinary or
&ldquo;broad&rdquo; content is, and how it is determined by the
individual&rsquo;s intrinsic properties.</p>
</div> 

<div id="toc">
<!--Entry Contents-->
<ul>
<li><a href="#Int">1. Introduction</a></li>

<li><a href="#Bro">2. Arguments for Broad Content</a>
 
  <ul>
  <li><a href="#put">2.1 Putnam&rsquo;s Argument: Twin Earth and Natural Kinds</a></li>
  <li><a href="#bur">2.2 Burge&rsquo;s Argument: Semantic Deference</a></li>
  <li><a href="#ass">2.3 Responses to the Arguments</a></li>
  </ul>
  </li>

<li><a href="#Nar">3. Arguments for Narrow Content</a>
 
  <ul>
  <li><a href="#cau">3.1 Causal Arguments</a></li>
  <li><a href="#int">3.2 Arguments from Introspective Access</a></li>
  <li><a href="#rat">3.3 Arguments Concerning Rationality</a></li>
  <li><a href="#phenint">3.4 Argument from Phenomenal Intentionality</a></li>
  </ul>
  </li>

<li><a href="#Con">4. Conceptions of Narrow Content</a>

  <ul>
  <li><a href="#des">4.1 Descriptive Content</a></li>
  <li><a href="#rol">4.2 Conceptual Role</a></li>
  <li><a href="#map">4.3 The Mapping Conception</a></li>
  <li><a href="#dia">4.4 Diagonal Propositions</a></li>
  <li><a href="#cen">4.5 Sets of Maximal Epistemic Possibilities</a></li>
  </ul>
  </li>

<li><a href="#Str">5. Strategies for Determining Narrow Content</a>

  <ul>
  <li><a href="#sdi">5.1 Diagonalization Strategy</a></li>
  <li><a href="#sub">5.2 Subtraction Strategy</a></li>
  <li><a href="#ide">5.3 Ideal Environment Strategy</a></li>
  <li><a href="#epi">5.4 Epistemic Strategy</a></li>
  </ul>
  </li>

<li><a href="#Fur">6. Types and Tokens</a></li>

<li><a href="#CriNarCon">7. A Critique of Narrow Content</a>

  <ul>
  <li><a href="#dnc">7.1 Defining Narrow Content</a></li>
  <li><a href="#ppa">7.2 The Parameter Proliferation Argument</a></li>
  <li><a href="#res">7.3 Responses to the Parameter Proliferation Argument</a></li>
  </ul>
  </li>

<li><a href="#Cnc">8. Conclusion</a></li>

<li><a href="#Bib">Bibliography</a></li>

<li><a href="#Aca">Academic Tools</a></li>

<li><a href="#Oth">Other Internet Resources</a></li>

<li><a href="#Rel">Related Entries</a></li>

</ul>

<!--Entry Contents-->

<hr />

</div>

<div id="main-text">

<h2><a name="Int">1. Introduction</a></h2>

<p>
What is narrow mental content? <em>Mental</em> content simply means
the content of a mental state such as a thought, a belief, a desire, a
fear, an intention, or a wish. <em>Content</em> is a deliberately
vague term; it is a rough synonym of another vague term,
&lsquo;meaning&rsquo;. A state with content is a state that
<em>represents</em> some part or aspect of the world; its content is
the way it represents the world as being. For example, consider my
belief that water is a liquid at room temperature. The content of this
belief is what it says about the world, namely that a certain
substance, water, has a certain property, being a liquid, under
specified conditions, namely being at room temperature. Whether a
belief is true or false depends on its content: it is true if the
world really is the way the belief represents it as being; otherwise
it is false.</p>

<p>
A <em>narrow</em> content of a particular state is a content of that
state that is completely determined by the individual&rsquo;s
intrinsic properties. An <em>intrinsic</em> property of an individual
is a property that does not depend at all on the individual&rsquo;s
environment. For example, having a certain shape is, arguably, an
intrinsic property of a particular penny; being in my pocket is not an
intrinsic property of the penny. This is because the penny&rsquo;s
shape depends only on internal properties of the penny, whereas the
fact that it is in my pocket depends on where it happens to be, which
is an extrinsic property. The shape of the penny could not be
different unless the penny itself were different in some way, but the
penny could be exactly the way it is even if it were not in my pocket.
Again, there could not be an exact duplicate of the penny that did not
share its shape, but there could be an exact duplicate that was not in
my pocket. Similarly, a narrow content of a belief or other mental
state is a content that could not be different unless the subject who
has the state were different in some intrinsic respect: no matter how
different the individual&rsquo;s environment were, the belief would
have the same content it actually does. Again, a narrow content of an
individual&rsquo;s belief is a content that must be shared by any
exact duplicate of the individual. (If some form of dualism is true,
then the intrinsic properties of an individual may include properties
that are not completely determined by the individual&rsquo;s physical
properties. In that case an &ldquo;exact duplicate&rdquo; must be
understood to be an individual who shares all intrinsic nonphysical
properties as well as physical ones.)</p>

<p>
(The notion of an intrinsic property turns out to be surprisingly
difficult to define precisely. A good guide to the various approaches
that have been taken, and their difficulties and refinements, is the
entry on
 <a href="../intrinsic-extrinsic/index.html">intrinsic vs. extrinsic properties</a>.)</p>
 
<p>
On first encounter, it may seem strange that the idea of narrow
content should be controversial, or even that we should need a special
term for it. Most people, if they were ever to explicitly consider the
issue of whether mental content is narrow or broad, would probably
hold that all mental content is narrow, i.e. that all of the contents
of our mental states are entirely determined by our intrinsic
properties. It seems conceivable, for example, as Descartes argued in
his First Meditation, that our perceptual states and beliefs could be
exactly as they are even if the world were nothing like we think it
is. This seems to presuppose that no difference in our environment,
however radical, could make a difference to the contents of our
beliefs so long as our intrinsic properties remained the same.</p>

<p>
Why, then, have philosophers believed they need to define narrow
content and argue for its existence? The reason is that many
philosophers have been convinced by some influential arguments that,
in the most ordinary or typical sense of &lsquo;content&rsquo;, most
or even all of the contents of our mental states are broad rather than
narrow. If this conclusion is correct, if ordinary content is broad,
then it requires some work to define an alternative, narrow conception
of content, and it requires arguments to show that there is any such
thing. To understand the issues about narrow content, then, it is
essential to first understand the arguments that most ordinary content
is broad.</p>

<h2><a name="Bro">2. Arguments for Broad Content</a></h2>

<h3><a name="put">2.1 Putnam&rsquo;s Argument: Twin Earth and Natural Kinds</a></h3>

<p>
Among the earliest and most influential arguments for broad content
were Hilary Putnam&rsquo;s arguments in such essays as &ldquo;The
Meaning of &lsquo;Meaning&rsquo;&rdquo; (1975). Putnam&rsquo;s
arguments were not designed specifically with <em>mental</em> content
in mind. They applied in the first instance to <em>linguistic</em>
content, more specifically to the reference of terms in a natural
language. However, they have been widely applied to mental content. I
will first discuss Putnam&rsquo;s argument concerning linguistic
content, and then note how it can be extended to mental content.</p>

<p>
Putnam&rsquo;s most famous examples involve &ldquo;Twin Earth,&rdquo;
an imaginary planet which is molecule-for-molecule identical to Earth,
including having exact duplicates of Earth&rsquo;s inhabitants,
<em>except</em> for a systematic change in certain parts of the
natural environment. In a particularly well-known version of this
example, we consider Earth as it was around 1750, before the chemical
structure of water was discovered, and we consider an inhabitant of
Earth named &ldquo;Oscar&rdquo; who is a competent user of the term
&lsquo;water&rsquo;. We then imagine a Twin Earth which is exactly
like Earth in every way, including having an exact duplicate of Oscar,
with one exception: for every place on Earth that contains
H<sub>2</sub>O, the Twin Earthly duplicate of that place instead
contains XYZ, a substance with a different microstructure from water
but with similar observable properties. On Twin Earth, it is XYZ, not
H<sub>2</sub>O, that falls from the skies and fills the lakes and
oceans.</p>

<p>
Putnam argues that the stuff that falls from the skies and fills the
lakes on Twin Earth <em>is not water</em>. According to Putnam, when
people used the term &lsquo;water&rsquo;, even in 1750, they intended
to refer to a <em>natural kind</em>, a kind of thing whose instances
share a common nature, not directly observable, which explains the
observable properties of instances of the kind. They identified water
by observable characteristics like colorlessness and odorlessness, but
they also assumed that there was a microstructure which explains these
observable properties. Since 1750, we have learned what this
microstructure is, namely that water consists of molecules of
H<sub>2</sub>O. But water <em>was</em> H<sub>2</sub>O even in 1750,
before we learned this. (Other natural kind terms work in the same
way. For instance, we identify diseases by their symptoms, but we
assume that there is an underlying cause of these symptoms, for
example a particular microorganism, and that even before we know what
this underlying cause is, it makes the disease what it is.)</p>

<p>
Now Twin Oscar, being an exact duplicate of Earth&rsquo;s Oscar, will
have many of the same properties Oscar has. For instance, he will be
disposed to accept a sentence of Twin English that is written and
pronounced exactly like the English sentence &ldquo;Water is
wet.&rdquo; However, Putnam argues, Twin Oscar&rsquo;s word
&lsquo;water&rsquo; does <em>not</em> refer to <em>water</em>. There
is no water on Twin Earth, only XYZ; Twin Oscar has never seen water,
talked about water, or interacted with water in any way. So it seems
that he cannot possibly refer to water.</p>

<p>
(Two points should be made parenthetically about this example. (1) The
observable properties of XYZ do not need to be <em>identical</em> to
those of water; all that is needed is that Oscar and Twin Oscar have
not observed the differences. (2) In some ways it is unfortunate that
the water/XYZ example has become Putnam&rsquo;s best known example,
because it has a failing that many of his other examples lack, namely
that most of the human body consists of water. This has the
consequence that Twin Oscar cannot be an exact duplicate of Oscar
unless Twin Oscar also consists largely of water. Other examples
Putnam considers involve switching aluminum and molybdenum, beeches
and elms, diseases, and so on, and these examples do not suffer from
the same problem.)</p>

<p>
It is important for this example that, although 1750 residents of
Earth did not yet realize this, all water was in fact H<sub>2</sub>O.
Had it turned out instead that some of the stuff called
&ldquo;water&rdquo; was H<sub>2</sub>O while other stuff called
&ldquo;water&rdquo; was XYZ, then water would not have turned out to
be a single &ldquo;natural kind.&rdquo; In that case the English word
&ldquo;water&rdquo; would refer to anything that was either
H<sub>2</sub>O or XYZ, and we could say that the Earthly and
Twin-Earthly &lsquo;water&rsquo;-words referred to the same thing.
Again, if it had turned out that there were a huge number of different
microstructures that produced the observable properties of water, then
water would not have been a natural kind at all. In that case we would
probably say that anything with the right observable properties was
water, and in that case again we could say both
&lsquo;water&rsquo;-words were coreferential. In fact, though, neither
of these possibilities obtains. Water is a natural kind whose
essential nature is that it has the chemical structure H<sub>2</sub>O;
since there is no H<sub>2</sub>O on Twin Earth, there is no water
there. Twin Earthlings never had occasion to give a label to water,
since there is none on their planet, so their word &ldquo;water&rdquo;
does not refer to water.</p>

<p>
Since Oscar and Twin Oscar have exactly the same intrinsic properties,
yet refer to different substances when they use their
&lsquo;water&rsquo;-words, their intrinsic properties cannot suffice
to determine what they refer to. If the meaning of a word suffices to
determine its reference, then meaning cannot be determined by
intrinsic properties either. As Putnam famously puts it,
&ldquo;&lsquo;meanings&rsquo; just ain&rsquo;t in the
<em>head</em>!&rdquo; (1975, p. 227).</p>

<p>
Although the argument as presented so far concerns the reference of
&lsquo;water&rsquo; and other natural kind terms, it is natural to
extend it to mental content as well (McGinn 1977; Burge 1979, note 2).
Not only does Twin Oscar not refer to water when he uses the term
&lsquo;water&rsquo;, he does not have beliefs about water either. To
be sure, he has beliefs that play the same role in his mental life
that Oscar&rsquo;s water-beliefs play in his. But in Twin
Oscar&rsquo;s case, those beliefs are not about water. In particular,
while Oscar believes that water is wet, Twin Oscar does not. Since
Oscar and Twin Oscar have identical intrinsic properties, yet Oscar
believes that water is wet while Twin Oscar does not, mental content
cannot be determined solely by intrinsic properties.</p>

<h3><a name="bur">2.2 Burge&rsquo;s Argument: Semantic Deference</a></h3>

<p>
The second main source of arguments that ordinary mental content is
broad is a series of influential articles by Tyler Burge, including
&ldquo;Individualism and the Mental&rdquo; (1979). Burge has offered
several lines of argument for the externalist view he calls
&ldquo;anti-individualism.&rdquo; These are helpfully distinguished
and described in the Introduction to Burge 2007. One line of argument,
closely related to Putnam&rsquo;s water example, emphasizes the role
of the environment in thought about natural kinds. Another line of
argument defends anti-individualism about perceptual content. I will
consider a third much-discussed line of argument, which relies on the
fact that in many cases we intend what we are thinking or talking
about to depend to some extent on the beliefs of others in our
community, especially those more expert than we.</p>

<p>
Burge&rsquo;s most famous example involves the concept of arthritis.
He considers an individual who is unaware that arthritis is a disease
specifically of the joints. His subject believes that he has arthritis
in his thigh. This belief is false, since one cannot have arthritis in
the thigh. However, Burge argues, in a world in which all the
intrinsic facts about the subject were exactly the same as they
actually are, but in which the term &lsquo;arthritis&rsquo; is
generally used in the subject&rsquo;s community to refer to rheumatoid
ailments in general, the subject&rsquo;s belief would have a different
content. It would be a belief that the subject had a rheumatoid
ailment in the thigh, and this is a belief which could possibly be
true. Burge offers a wide variety of other examples making the same
point, involving beliefs about such things as sofas and contracts.
These latter examples are important because, if successful, they show
that broad content extends far beyond beliefs about natural kinds.</p>

<p>
The idea that mental content is broad is the idea that it is not
determined entirely by an individual&rsquo;s intrinsic properties, but
is determined in part by features of the individual&rsquo;s
environment. But if the content of my beliefs is not determined
entirely by my internal states, what else could determine it? How
could anything other than my intrinsic properties determine what I
think and believe? The examples just discussed point to two different
sorts of environmental factor. Putnam&rsquo;s example of Oscar and his
Twin Earth duplicate focuses on the contribution of the
<em>natural</em> environment. The crucial idea here is that when we
have thoughts or beliefs about natural kinds, we often do not know
what the essential features of those kinds are, even though we assume
that there are such essential features. In such cases, what we are
thinking about depends not only on internally available factors, but
also on facts about the physical, chemical, or biological makeup of
the kinds we are thinking about. Burge&rsquo;s arthritis example, by
contrast, focuses on the contribution of the <em>social</em>
environment. In our thoughts about many kinds of things, including
natural kinds but also including kinds invented by humans, such as
furniture or contracts, we assume that others may have more expertise
than we do about what is and what is not included in the kind in
question. Thus, what we are thinking about depends not only on our
intrinsic properties, but also on expert opinion. We <em>defer</em> to
the experts with regard to what exactly we are thinking about. For
this reason, this sort of contribution of the social environment is
sometimes referred to as &ldquo;semantic deference.&rdquo;</p>

<p>
The phenomenon of semantic deference is closely related to what Putnam
memorably termed &ldquo;the linguistic division of labor.&rdquo;
Putnam&rsquo;s idea was that as long as there are experts on what
certain words refer to, we do not all need to have that specialized
knowledge; we can rely on the knowledge of the experts. In
Burge&rsquo;s treatment, however, the phenomenon is not merely
linguistic: it is not just that we defer to the experts on the meaning
of the <em>word</em> &lsquo;arthritis&rsquo;; we also defer to the
experts on the nature of the <em>disease</em> arthritis. Thus, for
Burge, the phenomenon affects not only what we mean by the words we
use, but also the very contents of our thoughts.</p>

<h3><a name="ass">2.3 Responses to the Arguments</a></h3>

<p>
We can distinguish between three broad categories of response to the
examples of Putnam and Burge. On one extreme, to use the terminology
of Segal (2000), we have the unqualified acceptance of the <em>extreme
externalist</em>. Many philosophers have been persuaded by examples
like those of Putnam and Burge that <em>all</em> or nearly all mental
content is broad. Such philosophers are highly skeptical about the
usefulness of any notion of narrow content. Burge himself is a
noteworthy proponent of extreme externalism; other extreme
externalists include Robert Stalnaker (1989, 1990, 2008) and Robert A.
Wilson (1995).</p>

<p>
A second response takes us to the opposite extreme, <em>extreme
internalism</em>. According to this response, Putnam&rsquo;s and
Burge&rsquo;s examples do not succeed in showing that <em>any</em>
content is broad. This position has been defended by, among others,
Kent Bach (1987), Tim Crane (1991), and Gabriel Segal (2000). These
authors question the externalist interpretation of the examples we
have discussed. For example, in response to Putnam, Segal points out
that we have some <em>empty</em> natural kind concepts &mdash; that
is, we have concepts which we intend to be natural kind concepts, but
which in fact do not succeed in referring to a real kind. Possible
examples include the concepts of witches, ghosts, and phlogiston. In
these examples, the environment cannot make the sort of contribution
discussed by Putnam, because the environment contains no relevant
kind. Nevertheless, people who have them use these concepts in their
reasoning, and their behavior is partly explained by these concepts.
If so, then we can have natural kind concepts that do not have an
environmental component. Now, it seems that with respect to
explanations of our reasoning and action, it does not make a
difference whether the kinds we think we are reasoning about actually
exist: so long as we <em>think</em> they exist, we will make the same
inferences and perform the same actions regardless of whether we are
correct or not. This may lead us to suspect that even in the case of
non-empty natural kind concepts, our reasoning and action are best
explained in terms of concepts whose content is not environmentally
determined &mdash; in short, in terms of concepts whose content is
narrow.</p>

<p>
With respect to Burge&rsquo;s examples, Segal suggests that it is odd
to regard someone who thinks it possible to have arthritis in the
thigh as having the concept of arthritis at all. Arthritis just
<em>is</em> an inflammation of the joints; it seems peculiar to say
that someone who does not realize this has the concept of arthritis.
Instead, we should say that the subject in Burge&rsquo;s example has a
<em>different</em> concept, a concept he mistakenly associates with
the English word &lsquo;arthritis&rsquo;. Thus we might want to deny
that Burge&rsquo;s subject really believes he has arthritis in his
thigh. What he really believes is something it is hard to express in
English, since we do not have a word that applies to all and only the
cases he would regard as cases of arthritis.</p> (For a careful
presentation and critique of this sort of &ldquo;dual concepts&rdquo;
objection to externalism, see Frances 2016.)

<p>
(Segal takes these arguments to undermine the idea that Putnam&rsquo;s
and Burge&rsquo;s examples establish that thoughts and beliefs about
kinds have <em>only</em> broad contents. He does not take them to
refute &ldquo;two-factor&rdquo; theories according to which beliefs
have both broad and narrow contents, although he does offer additional
arguments specifically targeted against two-factor theories.)</p>

<p>
Although extreme internalists advocate narrow content, they also hold
that ordinary content is already narrow, so that we do not need a
special or technical notion of narrow content. Thus, much of the
literature in favor of narrow content is written by those who accept
the third response to Putnam&rsquo;s and Burge&rsquo;s arguments,
<em>moderate internalism</em> (which we could equally well call
&ldquo;moderate externalism,&rdquo; since it is a compromise between
the two extreme views). This is the view that, while Putnam&rsquo;s
and Burge&rsquo;s examples do show that ordinary content is broad,
there are <em>also</em> contents that are narrow. On a moderate
internalist view, many beliefs have both broad and narrow contents.
Since, on this view, ordinary content is often broad, we need a
distinctive, specialized notion of narrow content as different in some
way from ordinary content.</p>

<h2><a name="Nar">3. Arguments for Narrow Content</a></h2>

<p>
Why do moderate internalists believe that, despite the success of
arguments that ordinary content is often or always broad, we
nevertheless need a notion of narrow content? There are four main
kinds of arguments they have found persuasive.</p>

<h3><a name="cau">3.1 Causal Arguments</a></h3>

<p>
One influential argument for narrow content (Fodor 1987; a recent
defense of this kind of argument, with relies to criticisms, is
Gaukroger, 2017) appeals to considerations involving causal
explanation. We might outline the argument like this. A first premise
is that mental states causally explain behavior by virtue of the
content they have. Although this has been denied by some, it certainly
seems to be a central part of commonsense psychology. Our behavior
seems to be a causal consequence of our beliefs and desires; moreover,
the content of those beliefs and desires seems to be centrally
involved in the causation of behavior. We behave the way we do because
of what we want and what we believe, and this seems to be just another
way of saying that we behave as we do because of the contents of our
beliefs and desires. A second premise is that the causal powers of an
entity, its capacity to produce effects, must be intrinsic features of
the entity. Thus twins, who share all their intrinsic properties, must
share their causal powers. This premise seems plausible for at least
two reasons. First, causation is <em>local</em>. It seems that
features of the environment can affect an individual&rsquo;s actions
only by way of effects on the individual&rsquo;s intrinsic properties.
Second, causal powers should be evaluated across contexts. If an
astronaut on the Moon can easily lift a one-hundred-kilogram weight
and I, on Earth, cannot, this does not mean that the astronaut is
stronger; the crucial issue is whether the astronaut can lift more
than I can in the same environments. This appears to show that my Twin
Earth counterpart and I have the same causal powers even though I can
obtain water by turning on the faucet and he cannot, since our
parallel actions will achieve parallel results provided that our
environments are the same. A third and final premise is that broad
content does not characterize intrinsic features, at least not
essentially; thus twins need not share broad contents. According to
the first premise, mental states must have a kind of content that
causally explains behavior. Taken together, the second and third
premises show that broad content cannot fulfill this role. The
conclusion of the argument, then, is that mental states must have
narrow contents, contents that <em>are</em> shared between twins.</p>

<p>
Externalists have attacked this argument at its second premise, the
premise that causal powers must be intrinsic properties. Against the
argument that causal powers must be intrinsic because causation is
local, Burge (1986, 1989) has argued that local <em>causation</em> is
entirely compatible with broad <em>individuation</em>. Against the
argument that the cross-context test for sameness of causal powers
shows that they are intrinsic, Burge (1989) suggests that causal
powers are typically identified relative to a normal environment;
thus, for example, it would be reasonable to distinguish between a
heart and a similar organ whose function is to pump waste even if one
of these organs could be successfully surgically replaced by the
other. Burge (1986) also argues that actual psychological theories,
such as Marr&rsquo;s theory of vision, do not satisfy internalist
constraints. (For criticisms of Burge&rsquo;s interpretation of Marr,
see Segal 1989 and Egan 1991. Burge 2010 is a book-length defense of
the claim that perceptual psychology is anti-individualistic.)</p>

<p>
In a later essay (Fodor 1991), Fodor defends a weaker and more
complicated version of the second premise. He suggests that there are
<em>some</em> extrinsic properties, such as being a planet, that
affect causal powers, and others, like being part of a universe in
which a certain coin toss comes out heads, that are irrelevant to
causal powers. He then offers a criterion for distinguishing between
causally relevant extrinsic properties and causally irrelevant
extrinsic properties: roughly, an extrinsic property is causally
irrelevant to outcomes that it is logically connected to. He then
argues that broad content does not satisfy the criterion for being a
causally relevant extrinsic property. (It should be noted that in
still more recent work (Fodor 1995, Chapter 2), Fodor has abandoned
the idea that narrow content is important for psychology.)</p>

<h3><a name="int">3.2 Arguments from Introspective Access</a></h3>

<p>
A somewhat different motivation for narrow content (Loar 1988) appeals
to the idea that we have introspective access to the contents of our
own thoughts. In particular, it seems that we should be able to
determine introspectively whether two of our thoughts have the same
content or not. But the kind of difference in content that
distinguishes Oscar&rsquo;s thoughts from Twin Oscar&rsquo;s thoughts
seems to be the sort of difference that they could not in principle be
introspectively aware of. From the inside, so to speak, there is no
way for Oscar and Twin Oscar to tell whether they are thinking
XYZ-thoughts or H<sub>2</sub>O-thoughts. (Recall that they are unaware
of what the microstructure of the substance they call
&ldquo;water&rdquo; is, although they assume that it has one.) The
difference in broad content between the beliefs of Oscar and Twin
Oscar seems to be a difference to which they themselves have no
access.</p>

<p>
It is difficult to formulate this point precisely, however. For
instance, Oscar can think that water is wet and then think the
meta-level thought, &ldquo;that thought I just had was about
<em>water</em>!&rdquo;, referring thereby to H<sub>2</sub>O and thus
expressing the very aspect of his original thought which distinguishes
his content from Twin Oscar&rsquo;s. Since neither Oscar nor Twin
Oscar has thoughts about the substance his twin has thoughts about, it
is not clear what it means to say that they cannot introspectively
distinguish between these different thoughts. One way to try to
clarify and reinforce the argument is to consider the phenomenon of
&ldquo;slow switching&rdquo; (introduced in Burge 1988, and used by
Boghossian 1989 to pose difficulties for self-knowledge). Suppose
Oscar moves to Twin Earth. Initially his water-thoughts will continue
to be about water, but it seems that gradually, the longer he
interacts with XYZ and the longer he is out of touch with
H<sub>2</sub>O, his thoughts will come to be about XYZ rather than
H<sub>2</sub>O. If this is correct, then his
&lsquo;water&rsquo;-thoughts will have come over time to have a
different broad content than they previously had. However, this change
in content will be completely invisible to Oscar himself. From his own
subjective point of view, his thoughts appear to have exactly the same
content as before. If there is a kind of mental content to which we
have introspective access, and if introspective access must include
the ability to recognize when contents are the same or different, then
the sort of content to which we have introspective access cannot be
broad content. This suggests that we need a concept of narrow content
to capture the kind of content that we are immediately aware of.</p>

<p>
Burge&rsquo;s response to this sort of argument is to accept that we
have introspective knowledge of the contents of our own thoughts, but
deny that this entails that we can tell introspectively whether two
contents are the same or different (Burge 1988). In response, some
suggest that knowing that my thought is about water requires ruling
out relevant alternative possibilities, and that in slow switching
cases the possibility that my thought is instead about XYZ is in fact
a relevant alternative that we cannot rule out. (For further
dialectical twists and turns, see Ludlow and Martin 1998, and
Nuccetelli 2003.)</p>

<h3><a name="rat">3.3 Arguments Concerning Rationality</a></h3>

<p>
A related issue is that describing a subject&rsquo;s beliefs in terms
of broad content can make them appear irrational even though they are
not: when beliefs are described in terms of broad content, they can be
inconsistent with one another even though the inconsistency is in
principle not discoverable by the subject. A famous example is due to
Saul Kripke (1979). In Kripke&rsquo;s example, Pierre, a Frenchman,
grows up with a belief he expresses by saying &ldquo;Londres est
jolie.&rdquo; This belief has the (broad) content that London is
pretty. Later he moves to England, where he learns English by
immersion rather than by translation. He comes to have a second
belief, which he expresses in English by saying &ldquo;London is not
pretty.&rdquo; This belief has the broad content that London is not
pretty. Pierre never realizes that the city he thinks of as Londres
and the city he thinks of as London are in fact the same city. His two
beliefs directly contradict one another, and yet he is not guilty of
any sort of failure of rationality; it is impossible for him to
ascertain that the two beliefs are contradictory. Kripke himself does
not offer a solution to his puzzle and does not discuss narrow
content. But a natural response to the example is to suppose that,
while the belief Pierre accepts and the one he rejects have the same
broad content, they have different narrow contents. If so, then the
sort of content most relevant to determining whether someone&rsquo;s
beliefs and inferences are rational is not broad content but narrow
content.</p>

<p>
One response to this sort of argument is offered by Stalnaker (1990)
in a critique of Loar (1988). Stalnaker agrees that examples like that
of Pierre require us to distinguish between the world as it is
according to Pierre, on the one hand, and, on the other hand, the
propositions ordinarily expressed by the sentences we use to describe
those beliefs, e.g. the proposition that London is pretty. However, in
his view it does not follow that an accurate description of the world
according to Pierre must be narrow: &ldquo;I don&rsquo;t think the
belief states themselves &mdash; the ways the world is according to
the thinker &mdash; are any less causally and socially infected than
the language in which beliefs are ascribed&rdquo; (p. 203). Jackson
(2003) responds to Stalnaker&rsquo;s reasons for skepticism about
narrow content.</p>

<h3><a name="phenint">3.4 Argument from Phenomenal Intentionality</a></h3>

<p>
A more recent argument for the existence of narrow content is an
argument from phenomenal intentionality (Loar 2003; Horgan and Tienson
2002; Horgan, Tienson and Graham 2004; Kriegel 2013). To understand
this argument, we first need to understand what its proponents mean by
&ldquo;phenomenal intentionality.&rdquo; (For a detailed overview of
the topic of phenomenal intentionality, including connections with
narrow content, see the entry on
 <a href="../phenomenal-intentionality/index.html">phenomenal intentionality</a>.)
 Philosophers of mind have traditionally drawn a sharp distinction
between two sorts of properties of mental states, phenomenal
properties and intentional properties. Phenomenal properties have to
do with the felt character of conscious experience, with &ldquo;what
it&rsquo;s like,&rdquo; in Thomas Nagel&rsquo;s famous phrase (Nagel
1974). Intentional properties have to do with the representational
character of mental states, i.e. with their content. One view of the
relation between phenomenal and intentional properties, called
&ldquo;separatism&rdquo; by Horgan and Tienson (2002), is that they
are independent of one another: any given phenomenal character could
be accompanied by any intentional properties (or none), and vice
versa. According to Lycan (2008 &sect;9), this view was &ldquo;the
standard attitude among philosophers of mind between the 1950s and the
1980s.&rdquo; On another view of the relation between the intentional
and the phenomenal, known as representationalism, the phenomenal
character of experience is completely determined by its intentional
nature. The key thesis of phenomenal intentionality is that, while
representationalism is correct that there is an intimate connection
between phenomenology and intentionality, the determination runs in
the opposite direction: there is a kind of intentional content,
phenomenal intentionality, which is entirely constitutively determined
by the phenomenal character of a mental state. </p>

<p>
This thesis is one premise of the argument from phenomenal
intentionality to narrow content. The other premise is that the
phenomenal character of experience is itself narrow. Putting the two
premises together, we get the following argument for the existence of
narrow content: &ldquo;(1) There is pervasive intentional content that
constitutively depends on phenomenology alone. (2) Phenomenology
constitutively depends only on narrow factors. So, (3) There is
pervasive intentional content that constitutively depends only on
narrow factors&rdquo; (Horgan and Tienson 2002, p. 527; cf. Horgan,
Tienson and Graham 2004, p. 300).</p>

<p>
Both premises of this argument are controversial. The second premise,
that phenomenology is narrow, is rejected by phenomenal externalists
(Lycan 2008, &sect;14), while the controversial character of the first
premise, that there is intentional content that is entirely determined
by phenomenology, can be seen in the fact that its proponents have
advanced it as a departure from orthodoxy. Defenders of phenomenal
intentionality have supported both premises by appeal to brain-in-vat
scenarios. Suppose that alien beings synthesize a structure identical
to your own brain, and connect it to a computer-controlled apparatus
that provides inputs to this brain-like object which maintain its
similarity to your brain over a substantial period of time. (See
Horgan, Tienson and Graham 2004 for further details. This fairly
elaborate brain-in-vat scenario avoids some of Burge&rsquo;s
objections (Burge 2003, pp. 443&ndash;445) to Loar&rsquo;s
less-fully-described version (Loar 2003).) Defenders of phenomenal
intentionality find it intuitively plausible that by virtue of its
physical similarity with your brain, the brain-like object will also
share your phenomenology, supporting the narrowness of phenomenology;
and that the brain-like object will, by virtue of sharing your
phenomenology, also share many of the contents of your mental states,
supporting the existence of phenomenally-determined intentionality.
(For these two uses of the brain-in-vat scenario, see Horgan, Tienson
and Graham 2004, p. 302. For additional arguments for the existence of
phenomenal intentionality, see Kriegel 2013, &sect;2.1. Criticisms of
phenomenal intentionality may be found in Bailey and Richards 2014 and
Werner 2015.)</p>

<p>
The most immediately plausible purported example of phenomenal
intentionality is the content of perceptual experience. If perceptual
experience is a genuine example of phenomenally determined
intentionality, but also the only example, then the argument from
phenomenal intentionality would show the existence of narrow contents
of perceptual states, but would be silent on whether other mental
states such as beliefs and desires have narrow contents. However, some
defenders of phenomenal intentionality (e.g. Horgan, Tienson and
Graham 2004 and several of the contributors to Bayne and Montague
2011) would go further, arguing that there are distinctive
phenomenologies of agency and of propositional attitudes including
beliefs and desires; that the phenomenal properties of these mental
states also constitutively determine intentional properties; and
moreover that <em>all</em> intentionality either is identical with, or
is derived from, phenomenal intentionality. If these bolder theses are
correct, then the argument from phenomenal intentionality would give
reason to think that all of the propositional attitudes have narrow
contents, and that their wide contents, if any, are derived from these
narrow contents.</p>

<h2><a name="Con">4. Conceptions of Narrow Content</a></h2>

<p>
Supposing that there is a sort of content of at least some mental
states that is narrow, how should we conceive of it? What sort of
thing is narrow content? There are many different proposals in the
literature (although in some cases the differences between them may
not be as great as they first appear). We consider several.</p>

<h3><a name="des">4.1 Descriptive Content</a></h3>

<p>
Perhaps the most obvious suggestion is that the narrow content of a
particular belief can be understood as a more detailed description of
what is believed. More specifically, the idea is that the narrow
content of a particular concept is a description of what the concept
expresses or refers to.</p>

<p>
An example will make this idea clearer. Consider Oscar, who believes
that water is wet. This belief involves the concept of water, and
arguments like Putnam&rsquo;s appear to show that the ordinary content
of this concept is broad. The proposal we are considering is that
there is a more detailed description that captures the narrow content,
for Oscar, of the concept of water. This description might be
something like &ldquo;clear, colorless, odorless liquid that falls
from the sky and fills the lakes.&rdquo; Oscar and his Twin may share
this descriptive content even though their
&lsquo;water&rsquo;-concepts do not have the same broad content. The
suggestion, then, is that, when Oscar thinks the thought that he would
express by saying &ldquo;water is wet,&rdquo; and when Twin Oscar
thinks the thought that he would express by saying, in Twin English,
&ldquo;water is wet,&rdquo; both of them are expressing a thought with
the descriptive content &ldquo;the clear, colorless, odorless liquid
that falls from the sky and fills the lakes is wet.&rdquo; This narrow
content, the proposal continues, determines, on Twin Earth, the broad
content that XYZ is wet, while on Earth it determines the broad
content that water (i.e. H<sub>2</sub>O) is wet.</p>

<p>
Notice that if this description is to succeed in determining the
appropriate broad content on Earth and on Twin Earth, then it must
have a subtle &ldquo;indexical&rdquo; component. An indexical is a
term, like &lsquo;I&rsquo; or &lsquo;now&rsquo;, whose referent is
context-relative. The referent of &lsquo;I&rsquo; depends on who
utters or thinks it; the referent of &lsquo;now&rsquo; depends on the
time at which it is uttered or thought. The supposedly narrow content
&ldquo;colorless odorless liquid that falls from the sky and fills the
lakes&rdquo; must have an implicit indexical component: the content in
question is really something like &ldquo;the colorless, odorless
liquid that falls from the sky and fills the lakes <em>around
here</em>&rdquo; (Putnam 1975, p. 234).</p>

<p>
There is an obvious and serious problem with the proposal that narrow
content is descriptive content, however. The problem is simply that
the description which is intended to give the narrow content of a
concept such as Oscar&rsquo;s &lsquo;water&rsquo;-concept may itself
be broad (Lepore and Loewer, 1986; Taylor, 1989). In my example,
several of the concepts involved in the descriptive content arguably
have broad contents. The notion of a liquid has a technical meaning
that need not correspond to the observable properties we associate
with it. And perhaps concepts like those of sky, lake, and color are
also broad.</p>

<p>
This objection need not be entirely crushing, but it certainly makes
the descriptive content approach more difficult to spell out in
detail. If we specify the description that is supposed to capture a
narrow content in ordinary language, then we will need to use only
ordinary-language terms that do not have broad contents. If the moral
of the arguments for broad content is as sweeping as philosophers like
Burge believe, it may be difficult or impossible to find enough
ordinary-language expressions that satisfy this requirement. We could
regard the description we have been discussing as a first step; the
second step would be to replace the expressions &lsquo;liquid&rsquo;,
&lsquo;sky&rsquo;, &lsquo;lake&rsquo;, and so on with their own
descriptive contents. But these descriptions in turn might well
contain expressions with broad contents, which would then need to be
replaced with still further descriptions. It is not clear that we will
be able to find enough purely narrow expressions to do all the
descriptive work we need. (Mendola 2008 is a recent attempt to develop
a detailed version of the descriptive approach that can overcome such
worries.)</p>

<h3><a name="rol">4.2 Conceptual Role</a></h3>

<p>
A second approach to narrow content identifies narrow contents with
&ldquo;conceptual roles.&rdquo; This approach was laid out in a
programmatic way by Ned Block in his essay &ldquo;Advertisement for a
Semantics for Psychology&rdquo; (Block 1986). The general idea is that
the conceptual role of a particular state is a matter of its causal
relations to other states. As Block puts it, conceptual role &ldquo;is
a matter of the causal role of the expression in reasoning and
deliberation and, in general, in the way the expression combines and
interacts with other expressions so as to mediate between sensory
inputs and behavioral outputs&rdquo; (p. 93). However, conceptual role
should not be understood to include <em>all</em> the causal relations
between a given state and other states: &ldquo;Conceptual role
abstracts away from all causal relations except the ones that mediate
inferences, inductive or deductive, decision making, and the
like&rdquo; (p. 94).</p>

<p>
The easiest way to get a feeling for conceptual role semantics is to
consider the kind of example that it seems to fit most naturally.
Suppose that we have a mental representation we will symbolize as
&lsquo;*&rsquo;. Suppose further that &lsquo;*&rsquo; stands in the
following causal relations with other mental representations.</p>

<ol>

<li>If the subject bears the belief relation to sentential mental
representations P and Q, then the subject is likely to also acquire
the belief relation to the compound representation P*Q.</li>

<li>If the subject bears the belief relation to P*Q, then the subject
is likely to also acquire the belief relation to P.</li>

<li>If the subject bears the belief relation to P*Q, then the subject
is likely to also acquire the belief relation to Q.</li>
</ol>

<p>
If the representation &lsquo;*&rsquo; is related in these ways to
other mental representations, it seems reasonable to say that it
expresses the relation of <em>conjunction</em>, i.e. that
&lsquo;*&rsquo; should be interpreted as &lsquo;and&rsquo;. In fact,
we might want to go so far as to say that satisfying the conditions
above <em>constitutes</em> meaning conjunction. It is worth noticing
that these three conditions closely resemble the rules that typically
characterize conjunction in natural deduction systems of propositional
logic. Reflecting on this similarity may suggest some potential
problems for conceptual role semantics.</p>

<p>
These potential problems include the following. (1) Rules of inference
are normative rather than descriptive. They tell us what inferences
are permissible; they do not purport to provide an empirical account
of what inferences people actually make. It is not clear how a
description of the causal interactions between mental states can
capture this normative element (Williams 1990; for a critique of the
idea that mental content is normative, see Gl&uuml;er and Wikforss
2009). (2) One might wonder whether there is something backward about
the view that conceptual role determines meaning. In the case of
propositional logic, a standard view is that the meaning of logical
connectives such as conjunction is given by a <em>truth table</em>,
which shows how the truth or falsity of a compound sentence is
determined by the truth values of its component sentences. The
adequacy of a system of inference rules is then determined by whether
it permits derivations of all and only those arguments that are
semantically valid. Similarly, perhaps the causal roles of mental
states should be explained in part by their semantics, instead of the
other way around. (3) Conceptual role semantics seems more plausible
for logical connectives than for other sorts of representations. It is
one thing to regard the meaning of a mental symbol for conjunction as
determined by the inferences a subject will make between mental
representations that contain the symbol and those that do not. After
all, that is what conjunction is <em>for</em>. It is another and much
bolder thing to regard more empirical mental representations as having
their meanings determined in this way.</p>

<p>
Two additional problems, already identified in Block&rsquo;s essay,
have been much discussed since. First, conceptual role semantics seems
to lead to a very extreme holism. If <em>all</em> or nearly all of the
inferential relations between mental representations are included in
their conceptual role, then it seems that a change in the meaning of
any representation will also change the meanings of all or nearly all
the others, and also that nearly any change in belief will result in a
change in the meaning of one&rsquo;s representations. We ordinarily
think that there is an important difference between changes of belief
and changes of meaning, but it is hard to see how to capture this
difference within conceptual role semantics. Second, conceptual role,
as understood by Block and others, may seem too
&ldquo;syntactic&rdquo; to constitute a conception of content at all.
In particular, conceptual role does not naturally give rise to an
account of truth conditions. As Block puts it, &ldquo;is narrow
content really content?&rdquo; Block himself regards conceptual role
as a <em>determinant</em> of content, and leaves it an open question
whether it is also a <em>kind</em> of content. But if conceptual role
is not actually a kind of content, then it does not satisfy all of the
original motivations for introducing a notion of narrow content.</p>

<h3><a name="map">4.3 The Mapping Conception</a></h3>

<p>
White (1982) and Fodor (1987) have offered a rather different, and
highly influential, way of thinking about narrow content. This
conception focuses on what narrow contents are supposed to accomplish.
A narrow content is supposed to be something that Oscar and Twin Oscar
share, and by virtue of which Oscar believes that water is wet and
Twin Oscar believes that XYZ is wet. Similarly, it should be something
that Art in his actual environment shares with Art in his envisioned
counterfactual environment, and by virtue of which he believes, in his
actual environment, that he has arthritis in his thigh, and believes,
in the counterfactual environment, that he has a different and broader
disease in his thigh. So one approach to narrow content is simply to
declare that a narrow content is something that, given a particular
environment, determines a particular broad content. Block (1991) calls
this the &ldquo;mapping theory,&rdquo; since on this account a narrow
content <em>maps</em> environments into broad contents.</p>

<p>
Some care is required in determining what the relevant environments
are. What matters is not only the environment the subject is currently
in, but rather the environment in which the subject acquired the
relevant beliefs and other mental states. If we zipped Oscar to Twin
Earth and Twin Oscar to Earth, we would not thereby change what their
thoughts are about (at least not immediately). Oscar would still be
thinking about water, and would probably misidentify XYZ as water;
Twin Oscar would still be thinking about XYZ, and would probably
misidentify water as XYZ. What determines the broad content of their
thoughts is not merely the environment they are in at the moment, but
also the environment in which they first acquired their thoughts and
beliefs about watery stuff. Provided we understand
&ldquo;context&rdquo; to include both sorts of facts, we can describe
the mapping conception as a conception on which narrow content is a
function from contexts to broad contents.</p>

<p>
(White (1982) actually distinguishes between &ldquo;contexts of
acquisition&rdquo; and &ldquo;contexts of occurrence&rdquo;, and
defines a notion of &ldquo;partial character&rdquo; as a higher-order
function which takes a context of acquisition as argument and yields
as the resulting value a function from contexts of occurrence to broad
contents. The relation between White&rsquo;s view and Fodor&rsquo;s is
easier to see, however, if we employ a more inclusive conception of
context that includes both one&rsquo;s current environment and
one&rsquo;s history of acquisition of the relevant concept. If we do,
we can collapse both levels of White&rsquo;s higher-order function
into one, yielding a lower-order function like Fodor&rsquo;s. The
broad content determined by a Fodorian narrow content applied to a
particular context is the same as the broad content determined by
applying White&rsquo;s partial character to that context, and then
applying the resulting function to the very same context.)</p>

<p>
The mapping theory faces a number of difficulties. (1) As Fodor notes,
on the mapping view narrow content seems to be ineffable. We would
like to be able to say what the narrow content of a particular thought
or belief is, but on Fodor&rsquo;s view this cannot be done. To
express a narrow content we would presumably need to find an English
expression that is synonymous with it. But the content of English
expressions is broad, not narrow, so this seems to be impossible.</p>

<p>
(Valerie Walker (1990) and Stephen Stich (1991) propose that narrow
contents could be expressed if English were supplemented with a
&ldquo;bracketing&rdquo; notation. For example, an expression of the
form &lsquo;___ has the (narrow) content that [p]&rsquo; is said to
have as its extension &ldquo;in any possible world the class of brain
state tokens whose (broad) content is p, along with physically
identical tokens in all doppelgangers of people who harbor tokens
whose broad content is p&rdquo; (Stich 1991, p. 247). The chief
difficulty with this proposal is that it has the consequence that
every token with a given broad content has the same narrow content.
But mental states with a particular broad content can be very unlike
one another: compare Oscar&rsquo;s belief that water is wet with that
of an expert in chemistry, or the very different ways in which Pierre
is related to the proposition that London is pretty. If narrow content
is to be useful in explaining behavior and rational inference, it must
be the case not only that Twins share their narrow contents despite
their different broad contents, but also that individuals with the
same broad content may have different narrow contents (Brown
1993).)</p>

<p>
(2) A second difficulty noted by Fodor is that, like conceptual role
semantics, the mapping conception may not deserve to be called
&ldquo;content,&rdquo; because the narrow contents it yields do not
suffice to determine truth conditions. A central characteristic of
broad content is that a thought or belief with broad content thereby
has truth conditions: in some possible circumstances it is true, and
in others it is false. On the mapping conception, narrow content does
not suffice to determine truth conditions in this sense. To determine
truth conditions, one needs to fix not only a narrow content but also
a context. For instance, given the narrow content shared by Oscar and
Twin Oscar when they think, &ldquo;Lake Superior is full of
water,&rdquo; we do not have enough information to say whether that
thought is true or false in a particular situation. Suppose Lake
Superior is full of XYZ. Then Twin Oscar&rsquo;s thought is true but
Oscar&rsquo;s thought is false, even though both thoughts have the
same narrow content. So it seems that narrow content by itself is not
enough to determine what truth conditions a thought has. (However, see
the following section on &ldquo;Diagonal Propositions.&rdquo;)</p>

<p>
(3) Finally, although the mapping conception gives us an abstract,
formal conception of narrow content, it does not give us an algorithm
for <em>finding</em> the narrow content of a particular state.
Although apparently any function from contexts to contents would count
as a &ldquo;narrow content&rdquo; in Fodor&rsquo;s sense, some of
these functions could not really be the content of a mental state. To
use a computational analogy, we are really interested only in
&ldquo;computable&rdquo; functions from context to content, functions
that can be implemented somehow in a human mind, and this suggests
that it is not the function itself that is of interest but rather the
algorithm by means of which it is computed.</p>

<h3><a name="dia">4.4 Diagonal Propositions</a></h3>

<p>
The complaint that on the mapping conception, narrow contents are not
truth conditional, and hence perhaps should not be called
&ldquo;contents&rdquo; at all, can be met by an interesting twist on
the mapping conception. Instead of considering a function from
contexts of acquisition to broad contents in its full generality, we
can focus our attention on a narrower function, the &ldquo;diagonal
proposition&rdquo; determined by a Fodorian narrow content. The idea,
and the term &ldquo;diagonal proposition,&rdquo; were originally
introduced by Robert Stalnaker in a different context (Stalnaker 1999,
especially papers 4, 6, and 7), but it turns out to be useful here. It
is not clear that anyone has actually proposed this idea as an account
of narrow content, but Stalnaker has suggested it as an interpretation
of Loar&rsquo;s view (Stalnaker 1990, discussing Loar 1988), and the
view of Chalmers (1996) has sometimes been understood in this way
(e.g. by Block and Stalnaker 1999).</p>

<p>
Recall that on the mapping conception, a narrow content is a function
from environments or contexts of acquisition to broad contents. Broad
contents in turn are thought of as determining truth conditions; that
is, a broad content will be true in some situations and false in
others. How should we think of the environments or contexts that
determine broad content, and the situations in which broad contents
are true or false? One reasonably natural suggestion is the following.
Oscar and Twin Oscar both actually exist (in Putnam&rsquo;s fantasy),
but they have different environments, different contexts of
acquisition. We can think of their contexts as including <em>all</em>
the objective or nonperspectival facts about the actual world,
<em>plus</em> a bit more, namely information about their locations in
that world. This may be more information than we need, but it gives us
a simple way to characterize contexts, and it is guaranteed to include
everything relevant to the contribution of the natural and social
environment to the contents of their beliefs. And of course, in
addition to the actual contexts of Oscar and Twin Oscar, we can
consider other possible contexts, other environments that they might
have inhabited. In general, we can say that a context of an individual
at a time is a <em>centered world</em>, a possible world that we
regard as centered on the relevant individual and time.</p>

<p>
With this background, we can consider a way to visualize the mapping
conception. We will consider how the account applies to an example
similar to that of Oscar and Twin Oscar. To keep things simple, we
will change the example slightly. Instead of regarding Earth and Twin
Earth as two different planets both of which exist in the actual
world, we will consider them as different ways things could have
turned out to be on our actual planet. In the actual world, the watery
stuff on Earth is H<sub>2</sub>O; in a possible counterfactual world,
it is XYZ instead. We will envision Oscar looking at a beaker full of
a colorless, odorless liquid and thinking a thought that he would
express by saying &ldquo;that beaker contains water.&rdquo;</p>

<p>
Now, we consider three possible environments or contexts, which we are
thinking of as centered worlds. These are:</p>

<ul>

<li>context 1: Oscar&rsquo;s &lsquo;water&rsquo;-thoughts have been
acquired in an environment in which the colorless, odorless liquid
that falls from the sky and fills the lakes is XYZ. For short, let us
say that Oscar&rsquo;s &lsquo;water&rsquo;-thoughts are
<em>anchored</em> in XYZ. Moreover, the substance in the beaker in
front of him is in fact XYZ.</li>

<li>context 2: Oscar&rsquo;s &lsquo;water&rsquo;-thoughts are anchored
in H<sub>2</sub>O. Moreover, the substance in the beaker in front of
him is in fact H<sub>2</sub>O.</li>

<li>context 3: As in context 2, Oscar&rsquo;s
&lsquo;water&rsquo;-thoughts are anchored in H<sub>2</sub>O. However,
in context 3, the substance in the beaker is neither H<sub>2</sub>O
nor XYZ, but sulfuric acid, H<sub>2</sub>SO<sub>4</sub>.</li>
</ul>

<p>
In context 2 and context 3, Oscar&rsquo;s &lsquo;water&rsquo;-thoughts
are about water, i.e. H<sub>2</sub>O, while in context 1 they are
about XYZ. Whether Oscar&rsquo;s thought about the substance in the
beaker is true or not depends on two things: what his thought means,
i.e. its broad content, and a certain fact about the world, namely
what substance is in the beaker. Since a context includes all the
objective facts about a world plus additional information about the
&ldquo;center&rdquo; of the world, each context determines a unique
possible world. For example, if we take context 1 and subtract the
information about the time and individual on which the context is
centered, we obtain a possible world we could call w(context 1).</p>

<p>
We can summarize the situation in the following table:</p>

<table class="centered all-rules avoid-break cellpad-med-dense cell-center">
<tr>
  <td></td>
  <td></td>
  <td><strong>w(context 1)
<br />
substance:
<br />
XYZ</strong></td>
  <td><strong>w(context 2)
<br />
substance:
<br />
H<sub>2</sub>O</strong></td>
  <td><strong>w(context 3)
<br />
substance:
<br />
H<sub>2</sub>SO<sub>4</sub></strong></td> </tr>
<tr>
  <td>1</td>
  <td> anchor: XYZ;
<br />
substance: XYZ</td>
  <td>T</td>
  <td>F</td>
  <td>F</td> </tr>
<tr>
  <td>2</td>
  <td> anchor: H<sub>2</sub>0;
<br />
substance: H<sub>2</sub>O</td>
  <td>F</td>
  <td>T</td>
  <td>F</td> </tr>
<tr>
  <td>3</td>
  <td> anchor: H<sub>2</sub>O;
<br />
substance: H<sub>2</sub>SO<sub>4</sub></td>
  <td>F</td>
  <td>T</td>
  <td>F</td> </tr>
</table>

<p>
The items in the left-hand column of our table are contexts. The
horizontal row to the right of each context represents the truth
conditions or broad content Oscar&rsquo;s thought has if it originated
in the indicated context. For instance, in context 1, Oscar&rsquo;s
thought has the broad content that there is XYZ in the beaker. This
thought is true in the world of context 1, false in the world of
context 2 (since the beaker contains H<sub>2</sub>O in that world),
and false in the world of context 3. A suitably extended version of
our table, then, could be regarded as visually representing the narrow
content of Oscar&rsquo;s thought about the substance in the beaker, on
the mapping conception of narrow content, since it would illustrate,
for each context, the broad content associated with Oscar&rsquo;s
thought by that context.</p>

<p>
Now we can say what the &ldquo;diagonal proposition&rdquo; is. It is
simply the proposition represented by the diagonal from the upper left
to the lower right of the above table. This represents the truth value
Oscar&rsquo;s belief has, for any context, in the world <em>of that
context</em>. The truth conditions this gives us are different from
any of the three broad contents Oscar&rsquo;s belief might have
depending on his context. But arguably they also give a better account
of his narrow content than any of the horizontal propositions does.
Unaware as he is of the chemical structure of water, Oscar has no
direct access to which possible context is his actual context, and
thus in a sense does not know what broad content his thoughts have. He
also does not know for certain what liquid the beaker contains. What
he <em>does</em> know is that <em>if</em> his
&lsquo;water&rsquo;-thoughts are anchored in XYZ and the substance in
the glass is also XYZ, then his belief is true; and <em>if</em> his
&lsquo;water&rsquo;-thoughts are anchored in H<sub>2</sub>O and the
substance in the glass is also H<sub>2</sub>O, then his belief is
true; and <em>if</em> his &lsquo;water&rsquo;-thoughts are anchored in
H<sub>2</sub>O and the substance in the glass is
H<sub>2</sub>SO<sub>4</sub>, then his belief is false; and so on. In
short, although his internal state does not suffice to determine any
of the horizontal propositions, it does suffice to determine the
diagonal proposition, which therefore seems to do a better job of
capturing Oscar&rsquo;s state of mind than the horizontal propositions
do.</p>

<p>
The diagonal proposition view seems to avoid many of the difficulties
of other approaches to narrow content. In particular, it does provide
truth conditions, and hence seems clearly to be a kind of content.
(However, Kriegel (2008) points out that, while two-dimensional
accounts like this one and the epistemic account to be discussed next
can provide truth conditions for &ldquo;the mental analog of a
sentence&rdquo; and thus explain how it &ldquo;puts us in cognitive
contact with a state of affairs that constitutes its potential truth
maker&rdquo; (305), it is not so clear how the account can associate
the mental analogs of subsentential expressions with worldly things
and properties. Kriegel offers an account according to which concepts,
the mental analogs of predicate terms, denote response-dependent
properties.)</p>

<p>
The main difficulties for the diagonal proposition account concern (1)
how to apply it in order to determine the narrow content of a given
mental state, and (2) the fact that it gives a way of defining the
truth conditions of a mental state only in centered worlds in which
the state actually exists. In the example above, for instance, Oscar
is presumed to be in the same mental state in each context, although
differences in how he came to be in that state affect its content. But
this raises the problem of what we need to &ldquo;hold constant&rdquo;
in considering various counterfactual contexts in order to be
considering a context in which Oscar is in the relevant state. These
issues are considered briefly in section 5.1.</p>

<h3><a name="cen">4.5 Sets of Maximal Epistemic Possibilities</a></h3>

<p>
A final view about the nature of narrow content has some striking
structural resemblances to the idea of a diagonal proposition, but is
motivated very differently. This is the view of David Chalmers (1996,
2002); a related view has been defended by David Lewis (1979, 1994).
In a nutshell, the view construes narrow contents as sets of maximal
epistemic possibilities, or <em>scenarios</em>. (Scenarios closely
resemble the centered worlds used to define diagonal propositions.
Whether there is a centered world for every scenario, and vice versa,
are debated issues: see Chalmers 2006, section 3.4.) The motivation
for this view requires some development.</p>

<p>
Narrow content is intended to capture a subject&rsquo;s perspective on
the world, the way the world is according to the subject. A very
natural way to think of this is to consider the narrow content of a
belief or other thought to be a way of dividing up the ways things
could conceivably be into those that are compatible with the thought
and those that are ruled out by it.</p>

<p>
Of course, <em>broad</em> contents also produce a kind of partitioning
of possibilities. <em>Any</em> sort of content that determines truth
conditions will rule in some possibilities and rule out others. But
broad content does not provide the kind of partitioning needed for
narrow content. Twin Earth is ruled out by the broad content of my
belief that the lakes are full of water, since the lakes on Twin Earth
do not contain water. But narrow content was introduced precisely in
order to have a kind of content that my Twin and I share, so the
narrow content of my thought that the lakes contain water should come
out true in a Twin Earth environment centered on my Twin, just as my
Twin&rsquo;s parallel thought comes out true there. A related way to
see why Twin Earth is not ruled out by the narrow content of my
thought is to notice that I can imagine finding out that all the
watery stuff in my <em>actual</em> environment is XYZ. In that case I
would not conclude that the lakes do not contain water; instead I
would conclude that water is XYZ. So the narrow content of my thought
that the lakes contain water does not rule out Twin Earth, even though
its broad content does.</p>

<p>
Chalmers develops this line of thought with the help of the following
apparatus. A thought is said to be <em>epistemically possible</em> if
it cannot be ruled out a priori, i.e. if its negation cannot be
conclusively established without any appeal to experience. Such a
thought corresponds to an epistemic possibility, a way the world could
be for all one can tell a priori. A <em>scenario</em> is then defined
to be a maximally specific epistemic possibility, an epistemic
possibility with no detail left unspecified. <em>Epistemic space</em>
is the set of all such scenarios. Any thought carves out a particular
region of epistemic space by <em>endorsing</em> some scenarios and
<em>excluding</em> others. A thought endorses a scenario when, if we
accept that the scenario is actual, we should accept the thought as
true. For instance, if we accept as actual a scenario in which the
liquid that falls from the skies and fills the lakes is XYZ, we should
accept as true the thought that water is XYZ. We can then think of the
narrow content of a thought as constituted by the way the thought
divides epistemic space into those scenarios it endorses and those it
excludes. More specifically, we can think of the narrow content of a
thought as a function from scenarios to truth values, or (equivalently
if we have only two truth values) simply as a set of scenarios, namely
those endorsed by the thought. (This paragraph closely follows
Chalmers 2002, p. 610. Chalmers gives related but somewhat more
detailed expositions in Chalmers 2003, especially pp. 47, 54, and in
Chalmers 2006, especially pp. 76ff. Note that a thought endorses a
scenario iff the scenario verifies the thought: Chalmers 2006 uses the
latter terminology but not the former.)</p>

<p>
Scenarios clearly have much in common with centered worlds. Indeed, it
may be possible to simply identify scenarios with centered worlds.
(Chalmers is cautious about this, noting reasons that some might
reject this identification, but makes use of it for some purposes.) If
scenarios are thought of as centered worlds, then the idea that narrow
content is a function from scenarios to truth values is obviously a
close cousin of the idea that narrow contents are diagonal
propositions, which can also be thought of as functions from centered
worlds to truth values. The differences between the two accounts
should not be underestimated, however. An immediate formal difference
is that narrow contents on Chalmers&rsquo; approach are defined over a
larger class of centered worlds than are diagonal propositions. On the
diagonal approach, the centered worlds with respect to which a thought
is evaluated must include a token of that very thought at the center,
while this is not the case on the approach we are now considering.
Another substantive difference between the two views is that they lead
to very different strategies for determining narrow contents, as will
emerge in sections 5.1 and 5.4.</p>

<h2><a name="Str">5. Strategies for Determining Narrow Content</a></h2>

<p>
We have seen that there are various sorts of thing a narrow content
could be: a description, a conceptual role, a function from contexts
to broad contents, a diagonal proposition, or a set of maximal
epistemic possibilities. It is a further question which items of the
relevant sort (which diagonal propositions or epistemic possibilities,
for example) constitute the narrow content of a particular state of a
particular subject.</p>

<p>
How can we <em>find out</em> what the narrow content of a mental state
is? Even more centrally, what is it about a mental state that makes it
appropriate to describe it as having a particular narrow content? In
the remainder of this section, I consider several strategies for
determining narrow content. I do not address the issue of whether
these strategies should be regarded as giving the essential nature of
narrow content, or merely as heuristic devices for approximating it in
practice.</p>

<p>
Arguably, it is these differences over the appropriate strategy for
determining narrow contents that are the most important differences
between rival views of narrow content. Although we have considered
several different views about the sort of semantic entities narrow
contents might be, all these views, with the exception of conceptual
role semantics, are close cousins of the view that narrow contents are
sets of centered worlds. The most substantive differences between
rival views concern how to determine which centered worlds are
included in the narrow content of a particular state of a particular
subject.</p>

<h3><a name="sdi">5.1 Diagonalization Strategy</a></h3>

<p>
A first strategy fits neatly with the view of narrow content as a
diagonal proposition. If we want to know the narrow content of a
particular mental state, we simply construct the diagonal proposition.
That is, we first envision a variety of situations or environments in
which the mental state could be embedded, i.e. a set of contexts or
centered worlds that contain, at the center, the very mental state
whose content we are interested in. For each of these contexts, we use
our knowledge of broad content and how it is determined to discover
the broad content that the mental state would have in that context.
And then we determine whether, in the world of that context, a belief
with that broad content would be true.</p>

<p>
There are three main problems with this strategy. First, it treats
broad content as fundamental, and narrow content as derivative.
However, for many advocates of narrow content (e.g. Chalmers 2002),
narrow content is at least as fundamental as broad content. In fact,
it is tempting to regard broad content as determined by narrow content
in conjunction with facts about context. But the strategy we are
considering can only be applied to determine narrow content if we
already have an independent way of determining broad content.</p>

<p>
A second problem for the diagonalization strategy is a problem of
scope (Chalmers, 2002). Although the diagonalization strategy yields a
truth-conditional notion of content, the only centered worlds at which
the diagonal proposition is evaluated will be worlds that contain at
their center the mental state we are interested in. In effect this
means that every mental state represents itself as existing. But it is
puzzling why I could not have mental states whose content has nothing
to do with their own existence. Chalmers offers these examples
(Chalmers 2002, p. 625): it seems that my thought that I am a
philosopher should be true in worlds centered on a philosopher even if
he is not currently thinking that he is a philosopher. Again, it seems
that the thought that someone is thinking should be false, not
undefined, at centered worlds that do not contain a thinking
person.</p>

<p>
Third, there is the problem of what to &ldquo;hold constant&rdquo; in
determining which possible contexts to consider (Block and Stalnaker
1999). The strategy requires us to consider contexts that include the
mental state whose content we are interested in. But exactly what
counts as a context that includes a particular mental state? And how
closely, and in which respects, must the version of the state in the
other worlds resemble the version in the actual world?</p>

<p>
Block and Stalnaker argue in some detail that the likely candidates
for what to hold constant all give the wrong results. Consider how we
might find the diagonal proposition associated with Oscar&rsquo;s
belief that water is wet. Suppose that a belief is, or is associated
with, a mental analog of a sentence. We will suppose that, like a
sentence, a mental token can be identified separately from its
meaning. Then Oscar&rsquo;s mental token, like the sentence
&ldquo;Water is wet,&rdquo; could, in some possible mental language,
mean that dogs have fur. Now if in diagonalizing we consider all
possible worlds centered on someone who possesses the same mental
sentence as Oscar&rsquo;s water-sentence, regardless of its meaning,
we get a diagonal proposition that is much too unconstrained to serve
as a narrow content. We surely do not want to say that the narrow
content of Oscar&rsquo;s belief that water is wet has the value True
in a world that contains no remotely watery substance, but in which
dogs are furry and the mental token in question means that dogs are
furry.</p>

<p>
So it is not sufficient to hold a syntactically identified mental
token constant in deciding which worlds to include in the diagonal
proposition. We must somehow consider worlds in which the token
carries the same meaning it carries in the actual world. However, if
we consider only worlds in which the token has the <em>broad</em>
meaning that water is wet, the diagonal proposition will be too
constrained to play the role of narrow content: it will be false, not
true, in a world centered on Twin Oscar.</p>

<p>
Still another possibility is to hold constant, not the broad content
of the mental token, but its narrow content. This will give the
results we want, but at the cost of making the account completely
circular; diagonalizing cannot be a useful strategy for discovering
narrow contents if we must already know the narrow content of a mental
token in order to apply the strategy.</p>

<h3><a name="sub">5.2 Subtraction Strategy</a></h3>

<p>
The subtraction strategy (Brown 1992) is an attempt to identify the
narrow contents of a subject&rsquo;s beliefs by considering all of the
contents of the subject&rsquo;s belief and subtracting those that are
<em>not</em> narrow. The contents that remain must be narrow. More
precisely, if a content of my belief is something I believe, then a
<em>narrow</em> content of my belief is something that I believe
<em>and</em> that is believed by every possible duplicate of me
(possibly within some restricted class of worlds). I say
&ldquo;ordinary content&rdquo; instead of &ldquo;broad content&rdquo;
here, since the subtraction strategy presupposes that not all ordinary
contents are broad.</p>

<p>
To see why this strategy might be appealing, we can consider an
analogy with perception. (A similar analogy with action is also
possible.) Consider the perceptual state of someone looking at an
apple. We can characterize this state in terms of what the person
sees, just as we can characterize Oscar&rsquo;s belief state in terms
of what he believes. In this case, our subject sees an apple, so one
way to characterize her perceptual state is as &ldquo;seeing an
apple,&rdquo; just as one way to describe Oscar&rsquo;s belief state
is as &ldquo;believing that water is wet.&rdquo; However, we can
easily construct scenarios in which our perceiver is in exactly the
same narrow state, but does not see an apple &mdash; perhaps because
everything except the apple&rsquo;s facing surface has been cut away.
We can easily find a content of the subject&rsquo;s perception that is
a content of the very same perceptual state but which characterizes it
more narrowly: the subject sees the facing surface of the apple, and
it is by virtue of seeing the facing surface that she sees the apple
as a whole. Characterizing the perceptual state as &ldquo;seeing the
facing surface of an apple&rdquo; is a narrower characterization in a
very simple sense: if we consider alternative situations in which the
subject is intrinsically exactly the same, but her environment is
different, we will observe that in every situation in which she sees
an apple, she also sees its facing surface, but that there are
additional situations in which she sees the facing surface but does
not thereby see an entire apple. Similarly, if we consider
Oscar&rsquo;s belief that water is wet, we notice that a Twin
Earth-like scenario provides a situation in which he is in the very
same cognitive state but does not believe that water is wet. So we
look for other contents of his belief, other things he believes, that
characterize his state more narrowly. In this case we notice that in
every situation in which he is in exactly the same intrinsic state and
believes that water is wet, he also believes that the colorless,
odorless liquid called &lsquo;water&rsquo; is wet, but not conversely.
So this latter belief seems to characterize his intrinsic state more
narrowly than does the content &ldquo;water is wet.&rdquo;</p>

<p>
It is important to notice that neither the perceptual content of
seeing the facing surface of an apple, nor the belief content of
believing that the colorless, odorless liquid called
&lsquo;water&rsquo; is wet, is completely narrow. We can find still
more remote possibilities in which the subject&rsquo;s perceptual or
belief state is exactly the same, but he or she does not have this
perceptual or belief content. (The &ldquo;apple&rdquo; could be a wax
imitation or a holographic projection; Oscar&rsquo;s Twin could live
in an environment in which the word &lsquo;liquid&rsquo; refers to
very finely granulated solids.) To find truly narrow contents we will
need to press our subtraction strategy still further, and appeal to
objects that are very different from the ordinary objects of
perception or belief &mdash; perhaps colored shapes or sense-data in
the case of perception; perhaps beliefs about the subject&rsquo;s
perceptual inputs and behavioral outputs in the case of belief (cf.
McDermott 1986).</p>

<p>
This suggests an important point which is rarely mentioned (but see
Recanati 1994 for a related observation). Narrowness need not be
construed as an all-or-nothing property. We can understand it instead
as a matter of degree: one content of a mental state is narrower than
another the further away from the actual world we need to go in
logical space in order to find a world in which the subject&rsquo;s
intrinsic properties are the same but the state does not have that
content. (Alternatively, we could relativize the notion of narrow
content to a set of possibilities; the more possibilities the set
includes, the fewer contents will count as narrow. For many purposes
we never consider Twin-Earth possibilities; for such purposes the
proposition that water is wet may count as a narrow content of a
subject&rsquo;s belief.) On this way of thinking of things, narrowness
as it is usually defined is a limiting case: narrowness relative to
the set of all metaphysically possible worlds. The concept of
narrowness may be useful even if the limiting case never occurs, just
as the concept of flatness is useful even though in this world the
limiting case of absolute flatness never occurs.</p>

<p>
Possible problems for the subtraction strategy include the following.
(1) The strategy presupposes that all the narrow contents of our
beliefs are included in the ordinary contents of belief, so that once
we have subtracted the non-narrow contents away the narrow contents
will remain. On many conceptions of narrow content, however, narrow
content is a more specialized and technical notion than this, and we
cannot suppose that the ordinary contents of belief will include
narrow contents. (2) The conception of narrow content with which the
subtraction strategy fits most naturally is the descriptive content
conception discussed in section 2.1. It inherits the principal
objection to that view, namely that it is not clear that ordinary
language can offer a narrow vocabulary sufficient to describe the
narrow contents of our thoughts. Two points should be made in response
to this worry. First, while the subtraction strategy assumes that the
narrow contents of belief are a subset of the ordinary contents of
belief, it need not be committed to the view that all of these
ordinary contents are describable in natural language. Second, as
noted above, we can think of completely narrow content as a limiting
ideal case. The subtraction strategy offers a way of relating broad
beliefs to the narrower beliefs on which they depend. This may be
useful even if the process does not terminate in beliefs which are
absolutely narrow. (3) Although the subtraction strategy offers a way
of determining one&rsquo;s total narrow content, it is not clear
whether or how it could be applied to more specific belief states. (4)
The subtraction strategy also shares with the diagonalization strategy
the problem that it gives us a method of identifying narrow contents
only if we already have an independent method of identifying contents
in general.</p>

<h3><a name="ide">5.3 Ideal Environment Strategy</a></h3>

<p>
This strategy is proposed by Dennett (1982). The idea is that a
(centered) world is included in one&rsquo;s narrow content if and only
if it is a world to which one is ideally suited. Place a subject in
some environments, and everything will work out extremely well: the
subject&rsquo;s attempts to satisfy his or her desires will succeed
every time. Other environments will be much less friendly; somehow the
subject&rsquo;s actions will never turn out to have quite the desired
effects. Dennett&rsquo;s thought is roughly that we can capture the
way the world is from the subject&rsquo;s point of view by taking the
set of centered worlds to which the subject is ideally adapted. One
attraction of this strategy is that it does not make narrow content
parasitic on broad content; another is that it does not require the
subject to be able to answer questions or reflect on the content of
the subject&rsquo;s thoughts, so that it could easily be applied to
cats and dogs as well as to humans.</p>

<p>
A possible problem for the ideal environment strategy is that, while
it may give us a way to determine a subject&rsquo;s total view of the
world, it does not provide a way of parceling out narrow contents to
more specific states.</p>

<p>
A second problem is that the strategy does not seem to properly
discriminate cognitive content from other sorts of information a
subject&rsquo;s body may carry. A baby is better adapted to worlds in
which extreme heat can damage its body than to worlds in which it
cannot. When the baby touches something hot it automatically jerks
away. This action has a useful purpose in a world in which heat is
damaging, but would be pointless in a world in which it was not. But
it does not follow that the baby <em>believes</em> that extreme heat
is damaging. (See Stalnaker 1989, White 1991.)</p>

<p>
A third problem is that, in some cases in which an individual&rsquo;s
states do seem contentful, the ideal environment strategy, as stated
above, seems to yield the wrong content. In the most obvious sense, I
am better suited to worlds that do not contain a homicidal maniac who
wants to kill me than I am to worlds that do contain such a maniac,
even if I believe that such a maniac exists. So it seems that the
ideal environment strategy will not correctly include the content of
this belief among those it attributes to me. (Related examples are
offered by Stalnaker 1989, White 1991, and Chalmers 2002.) As
Stalnaker notes (1999: 182&ndash;183), Dennett is better understood to
mean, not that the worlds I am best suited to are those in which I
would do best, but rather that they are those with which I am best
prepared to cope. But refining this account is a challenging task.
(For instance, martial arts training might prepare me to cope with
dangers that I do not believe to exist, raising the worry that the
ideal environment strategy on this interpretation will attribute to me
beliefs I do not in fact have.)</p>

<h3><a name="epi">5.4 Epistemic Strategy</a></h3>

<p>
The epistemic strategy is recommended by Chalmers (2002, 2003, 2006).
The framework that gives rise to this strategy was presented in
section 3.5. Narrow contents are to be thought of as effecting a
partition of scenarios, which are similar to the centered worlds
employed by the diagonalization strategy, into those endorsed by the
thought and those excluded by it. But how exactly are we to determine
which scenarios are which? On the diagonalization strategy, we make
use of our preexisting grasp of ordinary content to determine what
ordinary content the thought would express if it were located at the
center of a particular centered world, and then determine whether that
ordinary content is true at that centered world. The epistemic
strategy is radically different, and treats narrow content as at least
as fundamental as ordinary content.</p>

<p>
So, what function from scenarios to truth values constitutes the
narrow content of my thought that the lakes contain water? Put
slightly differently, which scenarios does this narrow content include
and which does it exclude? To find out whether the narrow content of
the thought that the lakes contain water includes a given scenario, I
consider the hypothesis that the scenario is actual. For example, if I
consider the hypothesis that a scenario in which the oceans and lakes
around me contain H<sub>2</sub>O is actual, then I will be led by a
priori reasoning to the conclusion that the lakes contain water;
hence, the narrow content of my thought that the lakes contain water
includes this Twin Earthly scenario. Similarly, if I consider the
hypothesis that a scenario in which the oceans and lakes contain XYZ
is actual, I will still conclude that the lakes contain water, since
in Twin Earth scenarios my water-thoughts are about XYZ. So the Twin
Earthly scenario is also included in the narrow content of my thought
that the lakes contain water. By contrast, the narrow content of my
thought that water is H<sub>2</sub>O will separate these two
scenarios. If I consider the hypothesis that an Earthly scenario is
actual, I will conclude that water is H<sub>2</sub>O, so the narrow
content of the thought that water is H<sub>2</sub>O includes Earthly
scenarios. However, if I consider the hypothesis that a Twin Earthly
scenario is actual, I will conclude that water is not H<sub>2</sub>O
(rather, it is XYZ), so the narrow content of my thought that water is
H<sub>2</sub>O excludes Twin Earthly scenarios.</p>

<p>
It is crucial that when I consider the hypothesis that the
Twin-Earthly (or any other) scenario is actual, and ask whether, in
that case, my thought that lakes contain water is true, I am
<em>not</em> asking whether, had a Twin-Earthly world obtained, lakes
would have contained water. The answer to <em>that</em> question is
&ldquo;no,&rdquo; but it is a different question. When I ask this
latter question, I am considering the Twin-Earthly world as
counterfactual. Presupposing that the world is not actually that way,
I ask what would be true if it were that way. Such questions, in which
we consider alternative worlds as counterfactual, are the appropriate
way to determine issues of <em>metaphysical</em> possibility. The sort
of question relevant to <em>epistemic</em> possibility is different.
It involves considering scenarios <em>as actual</em>, not as
counterfactual: seeing what <em>is</em> the case if the world
<em>is</em> that way, not seeing what <em>would be</em> the case if
the world <em>were</em> that way. Questions about epistemic
possibility, in which we consider scenarios as actual, are naturally
posed in indicative conditionals: if the substance in the lakes
<em>is</em> XYZ, is it water?</p>

<p>
A full account must say much more than this about precisely what it is
to consider a scenario as actual, and what it is for a scenario to be
endorsed by a particular belief. In order to consider a scenario, we
must have a complete description of some sort. On the other hand,
there must be restrictions on the vocabulary in which the description
is expressed. In particular, it cannot contain expressions like
&lsquo;water&rsquo;, for which Twin Earth examples can be constructed.
Chalmers offers a detailed account that addresses such questions.
(This is presented briefly in Chalmers 2002 and Chalmers 2003, and in
much more detail in Chalmers 2006.) Here is the short version
(Chalmers 2002, p. 611):</p>

<blockquote>
To consider a scenario W as actual is to consider the hypothesis that
D is the case, where D is a <em>canonical description</em> of W. When
scenarios are understood as centered worlds, a canonical description
will conjoin an <em>objective</em> description of the character of W
(including its mental and physical character, for example), with an
<em>indexical</em> description of the center&rsquo;s location within
W. The objective description will be restricted to <em>semantically
neutral terms</em>: roughly, terms that are not themselves vulnerable
to Twin Earth thought experiments (thus excluding most names, natural
kind terms, indexicals, and terms used with semantic deference). The
indexical description will allow in addition indexical terms such as
&lsquo;I&rsquo; and &lsquo;now&rsquo;, to specify the center&rsquo;s
location. We can then say that W verifies a thought T when a
hypothesis that D is the case implies T. Or equivalently, where S is a
linguistic expression of T, W verifies T when a material conditional
&lsquo;if D, then S&rsquo; is a priori.
</blockquote>

<p>
Unlike the diagonalization strategy, the epistemic strategy does not
depend on a prior determination of the broad content of the expression
or state. Moreover, it does not require that narrow contents be
evaluated only in scenarios that contain a token of the mental state
at their center.</p>

<p>
Potential problems for the epistemic strategy include: (1) whether it
can be applied to nonhuman animals, many of whom presumably also have
contentful mental states; (2) whether a canonical language that
satisfies the necessary constraints is possible (see e.g. Schroeter
2004; Soames 2005, pp. 216&ndash;218; Sawyer 2007); and (3) whether a
version of the &ldquo;what is held constant&rdquo; problem for the
diagonalization strategy also poses problems for the epistemic
strategy. (This last point is discussed a bit further in section
6.2.)</p>

<h2><a name="Fur">6. Types and Tokens</a></h2>

<p>
We have frequently considered the narrow content of Oscar&rsquo;s
beliefs about water, for instance his belief that water is wet. Is the
mental state we are concerned with here a type or a token? That is,
are we concerned with a particular instance of a mental state, which
occurs at a particular place and time, namely Oscar&rsquo;s belief on
this particular occasion that water is wet, or are we concerned with a
general kind of belief, the belief that water is wet, which many
different people could have on many different occasions?</p>

<p>
It seems that it cannot be the general type of belief that we are
interested in here, at least not if the type in question is
&ldquo;belief that water is wet,&rdquo; since different people (or
even the same person on different occasions) could have beliefs of
this type which had different narrow contents. Oscar is ignorant of
the molecular structure of water; he identifies water as a clear,
odorless, colorless substance that falls from the skies and fills the
lakes. As we have already seen, Twin Oscar shares Oscar&rsquo;s narrow
content, but in his environment this narrow content determines that he
believes that XYZ is wet, not that water is wet. However, an earthly
expert chemist who has done years of laboratory research on water, and
is well aware of its molecular structure, will have a different
water-concept than Oscar does, and his belief that water is wet will
have a different narrow content than Oscar&rsquo;s does. The
chemist&rsquo;s Twin Earth duplicate does not believe that XYZ is wet,
since he is aware of the chemical composition of water and his beliefs
explicitly concern H<sub>2</sub>O. He believes that water is wet
(though he also believes, falsely, that the substance that fills the
lakes and emerges from the taps is water).</p>

<p>
Although Oscar and the chemist share the (broad) belief that water is
wet, they have different narrow contents associated with this belief.
So when we say that it is a belief that has a particular narrow
content, we cannot be speaking of a general type of belief, at least
not if the type is determined by the broad content of the belief.
Rather, we must be speaking of a particular token belief, in this case
Oscar&rsquo;s belief on a particular occasion that water is wet.</p>

<p>
We cannot completely evade issues about the nature of the token mental
states we are considering, however. Even if the object of our concern
is a particular token, we need to know how to identify the particular
token we are interested in. Compare: suppose we decided we wanted to
know the weight of a certain animal. A first question would be whether
we are talking about a type of animal or a token animal. In this case
we almost certainly intend to refer to the token rather than the type.
(If the token belongs to a type of animal all or most of whose tokens
have weights that fall in a fairly narrow range, we may later decide
that we can also assign a weight to the type, but it is the weight of
the tokens that is primary.) In this case there seems to be no
problem: we can easily determine the weight of this animal, and even
determine what its weight would be in other environments, without
deciding whether the relevant type might be Pomeranians, or dogs, or
canines, for example.</p>

<p>
However, our ability to determine the weight of a token animal depends
on the fact that we already know what <em>animals</em> are and how to
identify them. If someone told us to find the weight of that
<em>thing</em> over there, we would need a further specification of
the thing in question before we could find its weight. Which thing?
The dog? The dog&rsquo;s front leg? The dog&rsquo;s fur? The cat over
there next to the dog? Or possibly even the disjoint thing consisting
of both the cat and the dog? It is not clear that asking about the
narrow content of Oscar&rsquo;s belief that water is wet is a much
more clearly defined task than asking about the weight of that thing
over there. Do we really have a means of picking out the mental state
in question in a way that distinguishes it from other beliefs in the
vicinity? What properties does it have? For example, does it have a
syntactic structure? Is it an intrinsic state? Does it have a
particular location in the brain? Is it entirely distinct from
Oscar&rsquo;s beliefs that water is a liquid, that water can form
droplets, and that water feels a certain way to the touch?</p>

<p>
The problem of identifying the bearer of narrow content is obviously
closely related to the problem of what to hold constant when employing
the diagonalization strategy. But the problem may also affect views on
which we do not need to require that a token state be present in a
counterfactual situation in order to determine whether its narrow
content would be true in that situation. It still seems that in order
to know exactly what question we are asking, we need to know what it
is whose content we are evaluating in the counterfactual situations.
We need to know what the token state is in the actual world whether or
not we insist on its presence in the counterfactual one.</p>

<h2><a name="CriNarCon">7. A Critique of Narrow Content</a></h2>

<p>
Since the first introduction of the term &ldquo;narrow content,&rdquo;
some authors have doubted that there is any useful concept for it to
capture (see e.g. Stalnaker 1990; Burge 2007, pp. 11&ndash;13). The
most sustained critique of narrow content is a relatively recent book,
<em>Narrow Content</em>, by Juhani Yli-Vakkuri and John Hawthorne
(Yli-Vakkuri and Hawthorne 2018).</p>

<h3><a name="dnc">7.1 Defining Narrow Content</a></h3>

<p>
Yli-Vakkuri and Hawthorne (hereafter YVH) begin by offering a rigorous
definition of narrow content intended to capture mainstream ideas in a
more precise way. For YVH, &ldquo;thoughts&rdquo; are token
representational mental states &ldquo;which occur in an agent at a
time&rdquo; (18). A &ldquo;content assignment&rdquo; is a systematic
assignment of contents to thoughts, i.e a function from thoughts to
contents. Narrowness is a property of content assignments: roughly, a
content assignment is narrow if, for any thought, the content assigned
to it is completely determined by the purely qualitative properties of
the thought and the purely qualitative relations it stands in to other
things going on in the agent (see YVH 2018, Chapter 2, for a more
careful and detailed account). A consequence of the definition is
that, given a narrow content assignment, if two agents are exact
duplicates (like Oscar and Twin Oscar), then any thought of one of
them will be assigned the same content as the corresponding thought of
the other.</p>

<p>
YVH do not deny that narrow content assignments are possible, but they
do argue that there is unlikely to be any narrow content assignment
that plays a theoretically useful role. A plausible minimal
requirement for a narrow content assignment to be useful is that it be
&ldquo;truth conditional,&rdquo; in the following sense: for any
thought, the content assigned to that thought should determine,
relative to the circumstances in which the thought actually occurs,
the truth value that the thought actually has. One of their central
arguments, the &ldquo;parameter proliferation argument,&rdquo;
attempts to show that the only way for a narrow content assignment to
be truth conditional is for it to employ a problematic notion of
content (specifically, a notion of content with inappropriate
&ldquo;parameters,&rdquo; in a sense to be explained next).</p>

<p>
By &ldquo;content,&rdquo; YVH mean a function from indices to truth
values, where an &ldquo;index&rdquo; is a sequence of parameters. In
the simplest case, an index will consist of a single parameter, namely
a possible world. In that case, a content will be a function from
possible worlds to truth values. In the table used to illustrate the
diagonal proposition conception of narrow content in
 <a href="#dia">section 4.4</a>
 of this entry, the rows of the table represent contents of this
sort.</p>

<h3><a name="ppa">7.2 The Parameter Proliferation Argument</a></h3>

<p>
It seems plausible that narrow contents must be more discriminating
than this. YVH introduce several examples to show that indices for
narrow contents must include an agent parameter as well as a world
parameter (pp. 69&ndash;71). To take a slight variant of the simplest
one, suppose that Varnsen and Twin Varnsen are sitting in identical
offices, and each is thinking &ldquo;I am in room 250.&rdquo; Varnsen
is in room 250, but Twin Varnsen is in room 251, so their thoughts
have different truth values. The thoughts occur in the same possible
world and have (since the two are duplicates) the same (narrow)
content. This is not possible if indices contain only a world
parameter, but if there is also an agent parameter, then the differing
truth values are not a problem, since the thoughts occur in, and are
therefore evaluated at, different indices. Similar considerations show
the need for a time parameter in addition to world and agent
parameters.</p>

<p>
If we modify the conception of content by letting indices contain, in
addition to a possible world parameter, parameters for an agent and a
time, we get a conception of content on which a content is a function
from triples of a world, an agent, and a time to truth values. This
conception is one way of capturing the kind of content represented by
the diagonal proposition in
 <a href="#dia">section 4.4</a>.
 The diagonal proposition was a function from centered worlds to truth
values, and a centered world can be thought of as a triple of a world,
an agent, and a time (with the agent and time fixing the
&ldquo;center&rdquo; of the centered world). On this conception,
Oscar&rsquo;s and Twin Oscar&rsquo;s thoughts can have different truth
values even though they have the same content, since, although the
world and time parameters of the index in which their thoughts occur
are the same, the agent parameter is different.</p>

<p>
Many writers have thought that this conception of content, or
something very similar, is well suited to capture the notion of narrow
content. Both the diagonal proposition conception, and the view of
narrow contents as sets of maximal epistemic possibilities, can be
understood in this way. The parameter proliferation argument gives
reasons to think that, unless we add still more parameters, content
assignments will still not be able to determine the correct truth
values for all thoughts.</p>

<p>
To show that worlds, agents, and times do not suffice, YVH employ the
much-discussed case of Mirror Man (YVH 2018, pp. 76&ndash;77). Mirror Man
has a completely symmetrical brain: his left hemisphere is a mirror
image of his right hemisphere. Mirror Man is thinking two
qualitatively identical thoughts, one in his left hemisphere and one
in his right hemisphere. Both thoughts would be expressed by
&ldquo;Kit is human,&rdquo; but in the first thought the mental analog
of the name &lsquo;Kit&rsquo; is related to a person on Mirror
Man&rsquo;s left in such a way that it refers to that person, while in
the second thought the distinct but qualitatively identical name
&lsquo;Kit&rsquo; refers to a visually exact wax replica located on
Mirror Man&rsquo;s right. Mirror Man is of course qualitatively
exactly like himself, and both thoughts stand in all the same
qualitative relations to the rest of Mirror Man. So a narrow content
assignment must assign both thoughts the same content. Yet the first
thought is true and the second thought is false. If content is a
function from world, agent, time triples to truth values, then a
narrow content assignment must assign one of the two thoughts the
wrong truth value, since both occur in the same world, are thoughts of
the same agent, and occur at the same time.</p>

<p>
This is not the end of the argument: further examples are introduced
to show that adding further parameters (for example, for location)
still results in conceptions of content that are vulnerable to
counterexamples. In the end, YVH suggest that the only parameters
whose addition is capable of avoiding all the counterexamples (for
example, a parameter for thoughts) will result in an extreme and
unattractive form of relativism.</p>

<h3><a name="res">7.3 Responses to the Parameter Proliferation Argument</a></h3>

<p>
How much wiggle room have YVH left the narrow content advocate? A
number of responses have been attempted (many of them already
anticipated in YVH 2018).</p>

<p>
First, some critics focus on the Mirror Man example. One approach is
to suggest that mirrored duplicates are not in fact qualitatively
identical (Chalmers 2018, Jerzak 2021). Another is to suggest that the
two hemispheres of Mirror Man&rsquo;s brain are in effect two separate
agents, so that the agent parameter is enough to give the two thoughts
different truth values (Hattiangadi 2019). One problem with this kind
of response is that YVH have alternative examples that pose similar
problems but cannot be rejected in these ways (YVH 2018, pp.
78&ndash;79, 93&ndash;94).</p>

<p>
Second, one can question the idea that a content assignment should
assign contents to individual thoughts. An alternative approach is to
assign contents not to individual thoughts, but to an agent. YVH call
this a &ldquo;coarse&rdquo; content assignment, and argue that such an
assignment cannot serve the explanatory purposes of narrow content
advocates. Jerzak (2021) notes that assigning contents to thoughts
assumes that thoughts are atomistic, and argues that on a more
holistic view like that of Stalnaker (1990), coarse content
assignments would be more appropriate. Byrne (2021) also defends
coarse content assignments, and criticizes YVH&rsquo;s objections to
them (though Byrne thinks that coarse assignments will only make
things worse for the defender of narrow content). In their reply to
Byrne (YVH 2021a), YVH concede that some of their criticisms of coarse
assignments are not decisive, and go on to make some interesting
suggestions about how a narrow content advocate might try to construct
a suitable notion of narrow content for coarse content assignments.
They show that on one way of doing so, &ldquo;Mirror Man would not
pose a threat&rdquo; (YVH 2021a, p. 3051). (Of course, they think that
other threats remain.)</p>

<p>
Third, one can question YVH&rsquo;s definition of narrow content in a
different way. For YVH, a narrow content assignment must supervene on
the total qualitative state of an agent. As Chalmers points out, one
can be an internalist about mental content without requiring a content
assignment to be this restrictive. Instead of requiring that content
supervene on the agent&rsquo;s qualitative properties, one could
simply require that it supervene on internal properties, where these
might include the agent&rsquo;s identity and the identities of
particular thoughts or experiences. As Chalmers puts it, the resulting
view of content, although it would not have the consequence that exact
duplicates must share all their mental contents, might still be
&ldquo;internalist enough to be interesting&rdquo; (Chalmers 2018).
YVH call such views &ldquo;quasi-internalist,&rdquo; and this notion
of content &ldquo;quasi-narrow&rdquo; (YVH 2018, Chapter 5).</p>

<p>
Fourth, one might bite the bullet and embrace one of the two radical
forms of relativism discussed by YVH. The simpler one is to add
thoughts as parameters, resulting in the view that YVH call
&ldquo;thought-relativism&rdquo; (pp. 80&ndash;81). (The other one is
&ldquo;extension-assignment relativism.&rdquo;) YVH give detailed
arguments against such views, but Chalmers suggests that they might
still have promise (Chalmers 2018). As Chalmers notes, it seems that
we can have thoughts like &ldquo;the thinker of this very thought is
human,&rdquo; where the truth or falsity of the thought depends on the
identity of the thought token being evaluated. Speaks (2021) explores
some ways of developing thought-relativism, but argues that the view,
if developed in such a way that it gives the right results about a
priori knowledge, will &ldquo;collapse into quasi-internalism&rdquo;
(Speaks 2021, p. 3044).</p>

<h2><a name="Cnc">8. Conclusion</a></h2>

<p>
It should be evident that the idea of narrow content is highly
controversial. Some thinkers reject the very idea of narrow content,
while to others it seems an attractive way to think about the kind or
aspect of mental content that most closely captures the
subject&rsquo;s perspective on the world, the nature of rational
belief and inference, and the nature and extent of a priori knowledge.
Even among its advocates, however, there has been substantial
disagreement on the precise form a theory of narrow content should
take. In their detailed and thorough critique of narrow content,
Yli-Vakkuri and Hawthorne (2018) have substantially clarified the
issues and the possible forms a theory of narrow content might take.
It will be interesting to see whether their book will mark the end of
discussions of narrow content, or whether it will instead reinvigorate
the discussion.</p>
</div>

<div id="bibliography">

<h2><a name="Bib">Bibliography</a></h2>

<ul class="hanging">

<li>Bach, Kent, 1987, <em>Thought and Reference</em>, Oxford: Oxford
University Press.</li>

<li>&ndash;&ndash;&ndash;, 1998, &ldquo;Content: Wide and
Narrow,&rdquo;<em>Routledge Encyclopedia of Philosophy</em> (Version
1.0), London: Routledge.</li>

<li>Bailey, Andrew and Bradley Richards, 2014, &ldquo;Horgan and
Tienson on phenomenology and intentionality,&rdquo; <em> Philosophical
Studies</em> 167: 313&ndash;326.</li>

<li>Bayne, Tim and Michelle Montague (eds.), 2011, <em>Cognitive
Phenomenology</em>, Oxford: Oxford University Press.</li>

<li>Block, Ned, 1986, &ldquo;Advertisement for a Semantics for
Psychology,&rdquo; <em>Midwest Studies in Philosophy</em>, 10:
615&ndash;678. Reprinted in Stephen P. Stich and Ted A. Warfield,
eds., <em>Mental Representation: A Reader</em>, Oxford: Blackwell,
1994.</li>

<li>&ndash;&ndash;&ndash;, 1991, &ldquo;What Narrow Content is
Not,&rdquo; In Loewer and Rey (eds.) 1991.</li>

<li>Block, Ned, and Stalnaker, Robert, 1999, &ldquo;Conceptual
Analysis, Dualism, and the Explanatory Gap,&rdquo; <em>Philosophical
Review</em>, 108: 1&ndash;46.</li>

<li>Boghossian, Paul, 1989, &ldquo;Content and self-knowledge,&rdquo;
<em>Philosophical Topics</em>, 17: 5&ndash;26.</li>

<li>Braddon-Mitchell, David, and Jackson, Frank, 1996, <em>Philosophy
of Mind and Cognition</em>, Oxford: Blackwell.</li>

<li>Brown, Curtis, 1992, &ldquo;Direct and Indirect Belief,&rdquo;
<em>Philosophy and Phenomenological Research</em>, 52:
289&ndash;316.</li>

<li>&ndash;&ndash;&ndash;, 1993, &ldquo;Belief States and Narrow
Content,&rdquo; <em>Mind and Language</em>, 8: 343&ndash;67.</li>

<li>Burge, Tyler, 1979, &ldquo;Individualism and the Mental,&rdquo;
<em>Midwest Studies in Philosophy</em>, 4: 73&ndash;121; reprinted in
Burge 2007.</li>

<li>&ndash;&ndash;&ndash;, 1986, &ldquo;Individualism and
Psychology,&rdquo; <em>Philosophical Review</em>, 95: 3&ndash;45;
reprinted in Burge 2007.</li>

<li>&ndash;&ndash;&ndash;, 1988, &ldquo;Individualism and
Self-Knowledge,&rdquo; <em>Journal of Philosophy</em>, 85:
649&ndash;65.</li>

<li>&ndash;&ndash;&ndash;, 1989, &ldquo;Individuation and Causation in
Psychology,&rdquo; <em>Pacific Philosophical Quarterly</em>, 70:
303&ndash;322; reprinted in Burge 2007.</li>

<li>&ndash;&ndash;&ndash;, 2003, &ldquo;Phenomenality and Reference:
Reply to Loar,&rdquo; in Martin Hahn and Bj&oslash;rn Ramberg (eds.),
<em>Reflections and Replies: Essays on the Philosophy of Tyler
Burge</em>, Cambridge, MA: MIT Press.</li>

<li>&ndash;&ndash;&ndash;, 2007, <em>Foundations of Mind:
Philosophical Essays, Volume 2</em>, Oxford: Oxford University
Press.</li>

<li>&ndash;&ndash;&ndash;, 2010, <em>Origins of Objectivity</em>,
Oxford: Oxford University Press.</li>

<li>Byrne, Alex, 2021, &ldquo;Comment on Yli-Vakkuri and Hawthorne,
Narrow Content,&rdquo; <em>Philosophical Studies</em>, 178:
3017&ndash;3026.</li>

<li>Chalmers, David J., 1996, <em>The Conscious Mind</em>, Oxford:
Oxford University Press.</li>

<li>&ndash;&ndash;&ndash;, 2002, &ldquo;The Components of
Content,&rdquo; in D. Chalmers (ed.), <em>Philosophy of Mind:
Classical and Contemporary Readings</em>, Oxford: Oxford University
Press.</li>

<li>&ndash;&ndash;&ndash;, 2003, &ldquo;The Nature of Narrow
Content,&rdquo; <em>Philosophical Issues</em>, 13: 46&ndash;66.</li>

<li>&ndash;&ndash;&ndash;, 2006, &ldquo;The Foundations of
Two-Dimensional Semantics,&rdquo; in Garcia-Carpintero and Macia
(eds.), <em>Two-Dimensional Semantics</em>, Oxford: Oxford University
Press.</li>

<li>&ndash;&ndash;&ndash;, 2010, &ldquo;The Representational Character
of Experience,&rdquo; in D. Chalmers, <em>The Character of
Consciousness</em>, Oxford: Oxford University Press.</li>

<li>&ndash;&ndash;&ndash;, 2018, &ldquo;Review of Juhani Yli-Vakkuri
and John Hawthorne, <em>Narrow Content</em>,&rdquo; <em>Notre Dame
Philosophical Reviews</em>, published 01 December 2018
 [<a href="https://ndpr.nd.edu/reviews/narrow-content/" target="other">Chalmers 2018 available online</a>].</li>
 
<li>Clark, Andy, and David Chalmers, 1998, &ldquo;The Extended
Mind,&rdquo; <em>Analysis</em>, 58: 7&ndash;19.</li>

<li>Crane, Tim, 1991, &ldquo;All the Difference in the World,&rdquo;
<em>Philosophical Quarterly</em>, 41: 1&ndash;25.</li>

<li>Dennett, Daniel, 1982, &ldquo;Beyond Belief,&rdquo; in Andrew
Woodfield (ed.), <em>Thought and Object: Essays on
Intentionality</em>, Oxford: Oxford University Press, 1982; reprinted
in D. Dennett, <em>The Intentional Stance</em>, Cambridge: MIT Press,
1987.</li>

<li>Egan, Frances, 1991, &ldquo;Must Psychology Be
Individualistic?&rdquo; <em>Philosophical Review</em>, 100:
179&ndash;203.</li>

<li>Fodor, Jerry, 1987, <em>Psychosemantics</em>, Cambridge, MA: MIT
Press.</li>

<li>&ndash;&ndash;&ndash;, 1991a, &ldquo;A Modal Argument for Narrow
Content,&rdquo; <em>Journal of Philosophy</em>, 88: 5&ndash;26.</li>

<li>&ndash;&ndash;&ndash;, 1991b, &ldquo;Replies,&rdquo; in Loewer and
Rey (eds.) 1991.</li>

<li>&ndash;&ndash;&ndash;, 1995, <em>The Elm and the Expert: Mentalese
and its Semantics</em>, Cambridge, MA: MIT Press.</li>

<li>Frances, Bryan, 2016, &ldquo;The Dual Concepts Objection to
Content Externalism,&rdquo; <em>American Philosophical Quarterly</em>,
53: 123&ndash;138.</li>

<li>Gaukroger, Cressida, 2017, &ldquo;Why Broad Content Can&rsquo;t
Influence Behavior,&rdquo; <em>Synthese</em>, 194:
3005&ndash;3020.</li>

<li>Gl&uuml;er, Kathrin and &Aring;sa Wikforss, 2009, &ldquo;Against
Content Normativity,&rdquo; <em>Mind</em>, 118: 31&ndash;70.</li>

<li>Hattiangadi, Anandi, 2019, &ldquo;In Defence of <em>Narrow
Content</em>,&rdquo;, <em>Analysis</em>, 79 (3): 539&ndash;550.</li>

<li>Horgan, Terence, and John Tienson, 2002, &ldquo;The Intentionality
of Phenomenology and the Phenomenology of Intentionality,&rdquo; in D.
Chalmers (ed.), <em>Philosophy of Mind: Classical and Contemporary
Readings</em>, Oxford: Oxford University Press.</li>

<li>Horgan, Terence, John Tienson, and George Graham, 2004,
&ldquo;Phenomenal Intentionality and the Brain in a Vat,&rdquo; in
Richard Schanz (ed.), <em>The Externalist Challenge</em>, Berlin:
Walter de Gruyter.</li>

<li>Jackson, Frank, 1996, &ldquo;Mental Causation,&rdquo;
<em>Mind</em>, 105:: 377&ndash;413.</li>

<li>&ndash;&ndash;&ndash;, 2003, &ldquo;Representation and Narrow
Belief,&rdquo; <em>Philosophical Issues</em>, 13: 99&ndash;112.</li>

<li>&ndash;&ndash;&ndash;, 2003, &ldquo;Narrow Content and
Representation, or Twin Earth Revisited,&rdquo; <em>Proceedings and
Addresses of the American Philosophical Association</em>, 77 (2):
55&ndash;70.</li>

<li>Jerzak, Ethan, 2021, &ldquo;Review of Yli-Vakkuri and
Hawthorne&rsquo; s<em>Narrow Content</em>,&rdquo; <em>The
Philosophical Review</em>, 130 (3): 475&ndash;480.</li>

<li>Kriegel, Uriah, 2008, &ldquo;Real Narrow Content,&rdquo; <em>Mind
and Language</em>, 23: 305&ndash;328.</li>

<li>&ndash;&ndash;&ndash;, 2013, &ldquo;The Phenomenal Intentionality
Research Program,&rdquo; in Uriah Kriegel (ed.), <em>Phenomenal
Intentionality</em>, Oxford: Oxford University Press.</li>

<li>Kripke, Saul, 1979, &ldquo;A Puzzle About Belief,&rdquo; in A.
Margalit (ed.), <em>Meaning and Use</em>, Dordrecht: D. Reidel,
239&ndash;283.</li>

<li>Lepore, Ernest, and Barry Loewer, 1986, &ldquo;Solipsist
Semantics,&rdquo; <em>Midwest Studies in Philosophy</em>, 10:
595&ndash;614.</li>

<li>Lewis, David, 1979, &ldquo;Attitudes <em>De Dicto</em> and <em>De
Se</em>,&rdquo; <em>Philosophical Review</em>, 88: 513&ndash;543;
reprinted in D. Lewis, <em>Philosophical Papers</em> (Volume 1),
Oxford: Oxford University Press, 1983.</li>

<li>&ndash;&ndash;&ndash;, 1994, &ldquo;Reduction of Mind,&rdquo; in
Samuel Guttenplan (ed.), <em>A Companion to the Philosophy of
Mind</em>, Oxford: Blackwell.</li>

<li>Loar, Brian, 1988, &ldquo;Social Content and Psychological
Content,&rdquo; in R. Grimm and D. Merrill (eds.), <em>Contents of
Thought</em>, Tucson: University of Arizona Press.</li>

<li>&ndash;&ndash;&ndash;, 2003, &ldquo;Phenomenal Intentionality as
the Basis of Mental Content,&rdquo; in Martin Hahn and Bj&oslash;rn
Ramberg (eds.), <em>Reflections and Replies: Essays on the Philosophy
of Tyler Burge</em>, Cambridge, MA: MIT Press.</li>

<li>Loewer, Barry and Georges Rey (eds.), 1991, <em>Meaning in Mind:
Fodor and his Critics</em>, Oxford: Blackwell.</li>

<li>Ludlow, Peter and Norah Martin (eds.), 1998, <em>Externalism and
Self-Knowledge</em>, Stanford: CSLI Publications.</li>

<li>Lycan, William G., 2008, &ldquo;Phenomenal
Intentionalities,&rdquo; <em>American Philosophical Quarterly</em>,
45: 233&ndash;252.</li>

<li>McDermott, Michael, 1986, &ldquo;Narrow Content,&rdquo;
<em>Australasian Journal of Philosophy</em>, 64: 277&ndash;288.</li>

<li>McGinn, Colin, 1977, &ldquo;Charity, Interpretation, and
Belief,&rdquo; <em>Journal of Philosophy</em>, 74: 521&ndash;535.</li>

<li>Mendola, Joseph, 2008, <em>Anti-Externalism</em>, Oxford: Oxford
University Press.</li>

<li>Nagel, Thomas, 1974, &ldquo;What Is It Like to Be a Bat?&rdquo;
<em>Philosophical Review</em>, 4: 435&ndash;450.</li>

<li>Nuccetelli, Susana (ed.), 2003, <em>New Essays on Semantic
Externalism and Self-Knowledge</em>, Cambridge, MA: MIT Press.</li>

<li>Putnam, Hilary, 1975, &ldquo;The Meaning of
&lsquo;Meaning&rsquo;,&rdquo; in Keith Gunderson (ed.), <em>Language,
Mind and Knowledge</em> (Minnesota Studies in the Philosophy of
Science, Volumes VII), Minneapolis: University of Minnesota Press,
1975; reprinted in H. Putnam, <em>Mind, Language and Reality</em>
(Philosophical Papers, Volume 2), Cambridge: Cambridge University
Press, 1975.</li>

<li>Recanati, Francois, 1994, &ldquo;How Narrow is Narrow
Content?&rdquo; <em>Dialectica</em>, 48: 209&ndash;229.</li>

<li>Sawyer, Sarah, 2007, &ldquo;There Is No Viable Notion of Narrow
Content,&rdquo; in Brian P. McLaughlin and Jonathan Cohen (eds.),
<em>Contemporary Debates in Philosophy of Mind</em>, Oxford:
Blackwell.</li>

<li>Schroeter, Laura, 2004, &ldquo;The Rationalist Foundations of
Chalmers&rsquo;s 2D Semantics,&rdquo; <em>Philosophical Studies</em>,
118: 227&ndash;255.</li>

<li>Segal, Gabriel, 1989, &ldquo;Seeing What Is Not There,&rdquo;
<em>Philosophical Review</em>, 98: 189&ndash;214.</li>

<li>Segal, Gabriel, 2000, <em>A Slim Book about Narrow Content</em>,
Cambridge: MIT Press.</li>

<li>&ndash;&ndash;&ndash;, 2003, &ldquo;Ignorance of Meaning,&rdquo;
in A. Barber (ed.), <em>Epistemology of Language</em>, Oxford: Oxford
University Press.</li>

<li>Soames, Scott, 2005, <em>Reference and Description: The Case
Against Two-Dimensionalism</em>, Princeton: Princeton University
Press.</li>

<li>Speaks, Jeff, 2021, &ldquo;Galacticism, Thought-Relativism,
Quasi-Internalism,&rdquo; <em>Philosophical Studies</em>, 178:
3037&ndash;3047.</li>

<li>Stalnaker, Robert C., 1990, &ldquo;Narrow Content,&rdquo; In C.
Anthony Anderson and Joseph Owens (eds.), <em>Propositional Attitudes:
The Role of Content in Logic, Language, and Mind</em>, Stanford: CSLI
Publications; reprinted in Stalnaker 1999.</li>

<li>&ndash;&ndash;&ndash;, 1989, &ldquo;On What&rsquo;s in the
Head,&rdquo; <em>Philosophical Perspectives</em>, 3: 287&ndash;316;
reprinted in Stalnaker 1999.</li>

<li>&ndash;&ndash;&ndash;, 1999, <em>Context and Content</em>, Oxford:
Oxford University Press.</li>

<li>&ndash;&ndash;&ndash;, 2006, &ldquo;Assertion Revisited,&rdquo; in
Garcia-Carpintero and Macia (eds.), <em>Two-Dimensional
Semantics</em>, Oxford: Oxford University Press.</li>

<li>&ndash;&ndash;&ndash;, 2008, <em>Our Knowledge of the Internal
World</em>, Oxford: Oxford University Press.</li>

<li>Stich, Stephen P., 1991, &ldquo;Narrow Content Meets Fat
Syntax,&rdquo; in Loewer and Rey (eds.) 1991.</li>

<li>Taylor, Kenneth A., 1989, &ldquo;Narrow Content Functionalism and
the Mind-Body Problem,&rdquo; <em>No&ucirc;s</em>, 23: 355&ndash;372.</li>

<li>Walker, Valerie, 1990, &ldquo;In Defense of a Different Taxonomy:
A Reply to Owens,&rdquo; <em>Philosophical Review</em>, 99:
425&ndash;431.</li>

<li>Werner, Preston J., 2015, &ldquo;Character (alone) doesn&rsquo;t
count: phenomenal character and narrow intentional content,&rdquo;
<em> American Philosophical Quarterly</em> 52: 261&ndash;271.</li>

<li>White, Stephen, 1982, &ldquo;Partial Character and the Language of
Thought,&rdquo; <em>Pacific Philosophical Quarterly</em>, 63:
347&ndash;365.</li>

<li>&ndash;&ndash;&ndash;, 1991, &ldquo;Narrow Content and Narrow
Interpretation,&rdquo; in S. White, <em>The Unity of the Self</em>,
Cambridge, MA: MIT Press, 1991.</li>

<li>Williams, Meredith, 1990, &ldquo;Social Norms and Narrow
Content,&rdquo; <em>Midwest Studies in Philosophy</em>, 15:
425&ndash;462.</li>

<li>Wilson, Robert A., 1995, <em>Cartesian Psychology and Physical
Minds: Individualism and the Sciences of Mind</em>, New York:
Cambridge University Press.</li>

<li>Yli-Vakkuri, Juhani, and John Hawthorne, 2018, <em>Narrow
Content</em>, Oxford: Oxford University Press.</li>

<li>&ndash;&ndash;&ndash;, 2021a, &ldquo;Reply to Byrne,&rdquo;
<em>Philosophical Studies</em>, 178: 3049&ndash;3054.</li>

<li>&ndash;&ndash;&ndash;, 2021b, &ldquo;Reply to Speaks,&rdquo;
<em>Philosophical Studies</em>, 178: 3061&ndash;3065.</li>
</ul>
</div> 

<div id="academic-tools">
<h2 id="Aca">Academic Tools</h2>

<blockquote>
<table class="vert-top">
<tr>
<td><img src="../../symbols/sepman-icon.jpg" alt="sep man icon" /></td>
<td><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=content-narrow" target="other">How to cite this entry</a>.</td>
</tr>

<tr>
<td><img src="../../symbols/sepman-icon.jpg" alt="sep man icon" /></td>
<td><a href="https://leibniz.stanford.edu/friends/preview/content-narrow/" target="other">Preview the PDF version of this entry</a> at the
 <a href="https://leibniz.stanford.edu/friends/" target="other">Friends of the SEP Society</a>.</td>
</tr>

<tr>
<td><img src="../../symbols/inpho.png" alt="inpho icon" /></td>
<td><a href="https://www.inphoproject.org/entity?sep=content-narrow&amp;redirect=True" target="other">Look up topics and thinkers related to this entry</a>
 at the Internet Philosophy Ontology Project (InPhO).</td>
</tr>

<tr>
<td><img src="../../symbols/pp.gif" alt="phil papers icon" /></td>
<td><a href="https://philpapers.org/sep/content-narrow/" target="other">Enhanced bibliography for this entry</a>
at <a href="https://philpapers.org/" target="other">PhilPapers</a>, with links to its database.</td>
</tr>

</table>
</blockquote>
</div>

<div id="other-internet-resources">

<h2><a name="Oth">Other Internet Resources</a></h2>

<ul>

 <li><a href="http://philpapers.org/browse/narrow-content" target="other">Papers on Narrow Content</a>,
 at philpapers.org.</li>
</ul>
</div>

<div id="related-entries">

<h2><a name="Rel">Related Entries</a></h2>

<p>

 <a href="../content-externalism/index.html">externalism about the mind</a> |
 <a href="../indexicals/index.html">indexicals</a> |
 <a href="../phenomenal-intentionality/index.html">intentionality: phenomenal</a> |
 <a href="../intrinsic-extrinsic/index.html">intrinsic vs. extrinsic properties</a> |
 <a href="../content-causal/index.html">mental content: causal theories of</a> |
 <a href="../content-teleological/index.html">mental content: teleological theories of</a> |
 <a href="../mental-representation/index.html">mental representation</a>

</p>

</div> 
</div><!-- #aueditable --><!--DO NOT MODIFY THIS LINE AND BELOW-->

<!-- END ARTICLE HTML -->

</div> <!-- End article-content -->

  <div id="article-copyright">
    <p>
 <a href="../../info.html#c">Copyright &copy; 2022</a> by

<br />
<a href="http://www.trinity.edu/cbrown/" target="other">Curtis Brown</a>
&lt;<a href="m&#97;ilto:cbrown&#37;40trinity&#37;2eedu"><em>cbrown<abbr title=" at ">&#64;</abbr>trinity<abbr title=" dot ">&#46;</abbr>edu</em></a>&gt;
    </p>
  </div>

</div> <!-- End article -->

<!-- NOTE: article banner is outside of the id="article" div. -->
<div id="article-banner" class="scroll-block">
  <div id="article-banner-content">
    <a href="../../fundraising/index.html">
    Open access to the SEP is made possible by a world-wide funding initiative.<br />
    The Encyclopedia Now Needs Your Support<br />
    Please Read How You Can Help Keep the Encyclopedia Free</a>
  </div>
</div> <!-- End article-banner -->

    </div> <!-- End content -->

    <div id="footer">

      <div id="footer-menu">
        <div class="menu-block">
          <h4><i class="icon-book"></i> Browse</h4>
          <ul role="menu">
            <li><a href="../../contents.html">Table of Contents</a></li>
            <li><a href="../../new.html">What's New</a></li>
            <li><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/random">Random Entry</a></li>
            <li><a href="../../published.html">Chronological</a></li>
            <li><a href="../../archives/index.html">Archives</a></li>
          </ul>
        </div>
        <div class="menu-block">
          <h4><i class="icon-info-sign"></i> About</h4>
          <ul role="menu">
            <li><a href="../../info.html">Editorial Information</a></li>
            <li><a href="../../about.html">About the SEP</a></li>
            <li><a href="../../board.html">Editorial Board</a></li>
            <li><a href="../../cite.html">How to Cite the SEP</a></li>
            <li><a href="../../special-characters.html">Special Characters</a></li>
            <li><a href="../../tools/index.html">Advanced Tools</a></li>
            <li><a href="../../contact.html">Contact</a></li>
          </ul>
        </div>
        <div class="menu-block">
          <h4><i class="icon-leaf"></i> Support SEP</h4>
          <ul role="menu">
            <li><a href="../../support/index.html">Support the SEP</a></li>
            <li><a href="../../support/friends.html">PDFs for SEP Friends</a></li>
            <li><a href="../../support/donate.html">Make a Donation</a></li>
            <li><a href="../../support/sepia.html">SEPIA for Libraries</a></li>
          </ul>
        </div>
      </div> <!-- End footer menu -->

      <div id="mirrors">
        <div id="mirror-info">
          <h4><i class="icon-globe"></i> Mirror Sites</h4>
          <p>View this site from another server:</p>
        </div>
        <div class="btn-group open">
          <a class="btn dropdown-toggle" data-toggle="dropdown" href="https://plato.stanford.edu/">
            <span class="flag flag-usa"></span> USA (Main Site) <span class="caret"></span>
            <span class="mirror-source">Philosophy, Stanford University</span>
          </a>
          <ul class="dropdown-menu">
            <li><a href="../../mirrors.html">Info about mirror sites</a></li>
          </ul>
        </div>
      </div> <!-- End mirrors -->
      
      <div id="site-credits">
        <p>The Stanford Encyclopedia of Philosophy is <a href="../../info.html#c">copyright &copy; 2022</a> by <a href="http://mally.stanford.edu/">The Metaphysics Research Lab</a>, Department of Philosophy, Stanford University</p>
        <p>Library of Congress Catalog Data: ISSN 1095-5054</p>
      </div> <!-- End site credits -->

    </div> <!-- End footer -->

  </div> <!-- End container -->

   <!-- NOTE: Script required for drop-down button to work (mirrors). -->
  <script>
    $('.dropdown-toggle').dropdown();
  </script>

</body>

<!-- Mirrored from seop.illc.uva.nl/entries/content-narrow/ by HTTrack Website Copier/3.x [XR&CO'2014], Wed, 22 Jun 2022 19:52:47 GMT -->
</html>
