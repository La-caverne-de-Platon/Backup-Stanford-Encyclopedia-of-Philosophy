<!DOCTYPE html>
<!--[if lt IE 7]> <html class="ie6 ie"> <![endif]-->
<!--[if IE 7]>    <html class="ie7 ie"> <![endif]-->
<!--[if IE 8]>    <html class="ie8 ie"> <![endif]-->
<!--[if IE 9]>    <html class="ie9 ie"> <![endif]-->
<!--[if !IE]> --> <html> <!-- <![endif]-->

<!-- Mirrored from seop.illc.uva.nl/entries/experimental-moral/ by HTTrack Website Copier/3.x [XR&CO'2014], Wed, 22 Jun 2022 19:47:17 GMT -->
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>
Experimental Moral Philosophy (Stanford Encyclopedia of Philosophy)
</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="robots" content="noarchive, noodp" />
<meta property="citation_title" content="Experimental Moral Philosophy" />
<meta property="citation_author" content="Alfano, Mark" />
<meta property="citation_author" content="Loeb, Don" />
<meta property="citation_author" content="Plakias, Alexandra" />
<meta property="citation_publication_date" content="2014/03/19" />
<meta name="DC.title" content="Experimental Moral Philosophy" />
<meta name="DC.creator" content="Alfano, Mark" />
<meta name="DC.creator" content="Loeb, Don" />
<meta name="DC.creator" content="Plakias, Alexandra" />
<meta name="DCTERMS.issued" content="2014-03-19" />
<meta name="DCTERMS.modified" content="2018-08-09" />

<!-- NOTE: Import webfonts using this link: -->
<link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,300,600,200&amp;subset=latin,latin-ext" rel="stylesheet" type="text/css" />

<link rel="stylesheet" type="text/css" media="screen,handheld" href="../../css/bootstrap.min.css" />
<link rel="stylesheet" type="text/css" media="screen,handheld" href="../../css/bootstrap-responsive.min.css" />
<link rel="stylesheet" type="text/css" href="../../css/font-awesome.min.css" />
<!--[if IE 7]> <link rel="stylesheet" type="text/css" href="../../css/font-awesome-ie7.min.css"> <![endif]-->
<link rel="stylesheet" type="text/css" media="screen,handheld" href="../../css/style.css" />
<link rel="stylesheet" type="text/css" media="print" href="../../css/print.css" />
<link rel="stylesheet" type="text/css" href="../../css/entry.css" />
<!--[if IE]> <link rel="stylesheet" type="text/css" href="../../css/ie.css" /> <![endif]-->
<script type="text/javascript" src="../../js/jquery-1.9.1.min.js"></script>
<script type="text/javascript" src="../../js/bootstrap.min.js"></script>

<!-- NOTE: Javascript for sticky behavior needed on article and ToC pages -->
<script type="text/javascript" src="../../js/jquery-scrolltofixed-min.js"></script>
<script type="text/javascript" src="../../js/entry.js"></script>

<!-- SEP custom script -->
<script type="text/javascript" src="../../js/sep.js"></script>
</head>

<!-- NOTE: The nojs class is removed from the page if javascript is enabled. Otherwise, it drives the display when there is no javascript. -->
<body class="nojs article" id="pagetopright">
<div id="container">
<div id="header-wrapper">
  <div id="header">
    <div id="branding">
      <div id="site-logo"><a href="../../index.html"><img src="../../symbols/sep-man-red.png" alt="SEP logo" /></a></div>
      <div id="site-title"><a href="../../index.html">Stanford Encyclopedia of Philosophy</a></div>
    </div>
    <div id="navigation">
      <div class="navbar">
        <div class="navbar-inner">
          <div class="container">
            <button class="btn btn-navbar collapsed" data-target=".collapse-main-menu" data-toggle="collapse" type="button"> <i class="icon-reorder"></i> Menu </button>
            <div class="nav-collapse collapse-main-menu in collapse">
              <ul class="nav">
                <li class="dropdown open"><a id="drop1" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-book"></i> Browse</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop1">
                    <li><a href="../../contents.html">Table of Contents</a></li>
                    <li><a href="../../new.html">What's New</a></li>
                    <li><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/random">Random Entry</a></li>
                    <li><a href="../../published.html">Chronological</a></li>
                    <li><a href="../../archives/index.html">Archives</a></li>
                  </ul>
                </li>
                <li class="dropdown open"><a id="drop2" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-info-sign"></i> About</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop2">
                    <li><a href="../../info.html">Editorial Information</a></li>
                    <li><a href="../../about.html">About the SEP</a></li>
                    <li><a href="../../board.html">Editorial Board</a></li>
                    <li><a href="../../cite.html">How to Cite the SEP</a></li>
                    <li><a href="../../special-characters.html">Special Characters</a></li>
                    <li><a href="../../tools/index.html">Advanced Tools</a></li>
                    <li><a href="../../contact.html">Contact</a></li>
                  </ul>
                </li>
                <li class="dropdown open"><a id="drop3" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-leaf"></i> Support SEP</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop3">
                    <li><a href="../../support/index.html">Support the SEP</a></li>
                    <li><a href="../../support/friends.html">PDFs for SEP Friends</a></li>
                    <li><a href="../../support/donate.html">Make a Donation</a></li>
                    <li><a href="../../support/sepia.html">SEPIA for Libraries</a></li>
                  </ul>
                </li>
              </ul>
            </div>
          </div>
        </div>
      </div>
    </div>
    <!-- End navigation -->
    
    <div id="search">
      <form id="search-form" method="get" action="https://seop.illc.uva.nl/search/searcher.py">
        <input type="search" name="query" placeholder="Search SEP" />
        <div class="search-btn-wrapper"><button class="btn search-btn" type="submit"><i class="icon-search"></i></button></div>
      </form>
    </div>
    <!-- End search --> 
    
  </div>
  <!-- End header --> 
</div>
<!-- End header wrapper -->

<div id="content">

<!-- Begin article sidebar -->
<div id="article-sidebar" class="sticky">
  <div class="navbar">
    <div class="navbar-inner">
      <div class="container">
        <button class="btn btn-navbar" data-target=".collapse-sidebar" data-toggle="collapse" type="button"> <i class="icon-reorder"></i> Entry Navigation </button>
        <div id="article-nav" class="nav-collapse collapse-sidebar in collapse">
          <ul class="nav">
            <li><a href="#toc">Entry Contents</a></li>
            <li><a href="#Bib">Bibliography</a></li>
            <li><a href="#Aca">Academic Tools</a></li>
            <li><a href="https://leibniz.stanford.edu/friends/preview/experimental-moral/">Friends PDF Preview <i class="icon-external-link"></i></a></li>
            <li><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=experimental-moral">Author and Citation Info <i class="icon-external-link"></i></a> </li>
            <li><a href="#pagetopright" class="back-to-top">Back to Top <i class="icon-angle-up icon2x"></i></a></li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</div>
<!-- End article sidebar --> 

<!-- NOTE: Article content must have two wrapper divs: id="article" and id="article-content" -->
<div id="article">
<div id="article-content">

<!-- BEGIN ARTICLE HTML -->


<div id="aueditable"><!--DO NOT MODIFY THIS LINE AND ABOVE-->

<h1>Experimental Moral Philosophy</h1><div id="pubinfo"><em>First published Wed Mar 19, 2014; substantive revision Thu Aug 9, 2018</em></div>

<div id="preamble">

<p>

Experimental moral philosophy emerged as a methodology in the last
decade of the twentieth century, as a branch of the larger experimental
philosophy (X-Phi) approach.  Experimental moral philosophy is the empirical study of moral intuitions, judgments, and behaviors.  Like other forms of experimental philosophy, it involves gathering data using experimental methods and using these data to substantiate, undermine, or revise philosophical theories.  In this case, the theories in question concern the nature of moral reasoning and judgment; the extent and sources of moral obligations; the nature of a good person and a good life; even the scope and nature of moral theory itself.  This entry begins with a brief look at the historical uses of empirical data in moral theory and goes on to ask what, if anything, is distinctive about <em>experimental</em> moral philosophy&mdash;how should we distinguish it from related work in empirical moral psychology?  After discussing some strategies for answering this question, the entry examines two of the main projects within experimental moral philosophy, and then discusses some of the most prominent areas of reseatch within the field.  As we will see, in some cases experimental moral philosophy has opened up new avenues of investigation, while in other cases it has influenced longstanding debates within moral theory. </p>

</div>
<div id="toc">
<!--Entry Contents-->
<ul>
<li><a href="#Int">1. Introduction and History</a>
 <ul>
 <li><a href="#WhaCouExp">1.1 What are Experiments?</a></li>
 <li><a href="#WhoConExpInv">1.2 What Types of Questions and Data?</a></li>
 </ul></li>
<li><a href="#MorJudInt">2. Moral Intuitions and Conceptual Analysis</a>
 <ul>
 <li><a href="#TwoNegPro">2.1 The Negative Program in Experimental Moral Philosophy</a></li>
 <li><a href="#ThrPosPro">2.2 The Positive Program in Experimental Moral Philosophy</a></li>
 <li><a href="#ExaIntRes">2.3 An Example: Intentionality and Responsibility</a></li>
 <li><a href="#AnoExaLinAna">2.4 Another Example: The Linguistic Analogy</a></li>
 </ul></li>
<li><a href="#ChaWelEmo">3. Character, Wellbeing, and Emotion</a>
 <ul>
 <li><a href="#ChaVir">3.1 Character and Virtue</a></li>
 <li><a href="#Wel">3.2 Wellbeing, Happiness, and the Good Life</a></li>
 <li><a href="#EmoAff">3.3 Emotion and Affect</a></li>
 </ul></li>
<li><a href="#SomMetIss">4. Metaethics and Experimental Moral Philosophy</a>
 <ul>
 <li><a href="#MorRea">4.1 Folk Metaethics and Moral Realism</a></li>
<li><a href="#MorDis">4.2 Moral Disagreement</a></li>
 <li><a href="#MorLan">4.3 Moral Language</a></li>
 </ul></li>
<li><a href="#CriExpMor">5. Criticisms of Experimental Moral Philosophy</a>
 <ul>
 <li><a href="#ProExpDesInt">5.1 Problems with Experimental Design and Interpretation</a></li>
 <li><a href="#PhiPro">5.2 Philosophical Problems</a></li>
 </ul></li>
<li><a href="#Bib">Bibliography</a></li>
<li><a href="#Aca">Academic Tools</a></li>
<li><a href="#Oth">Other Internet Resources</a></li>
<li><a href="#Rel">Related Entries</a></li>
</ul>

<!--Entry Contents-->

<hr />

</div>

<div id="main-text">

<h2><a id="Int">1. Introduction and History</a></h2>

<p>
The idea that our actual moral judgments are an important source of
information about the origins and justification of moral norms goes
back to ancient Greece, if not further. Herodotus recounts a story in
which the Persian emperor Darius invited Greek members of his court
&ldquo;and asked them what price would persuade them to eat the dead
bodies of their fathers. They answered that there was no price for
which they would do it.&rdquo; Darius then summoned members of a
different group, &ldquo;and asked them&hellip; what would make them
willing to burn their fathers at death. The Indians cried aloud, that
he should not speak of so horrid an act.&rdquo; Herodotus concludes
that stories like these prove that, as the poet Pindar writes,
&ldquo;custom is king of all,&rdquo; thereby providing an instance of
the argument from moral disagreement for relativism. Likewise, in
the <em>Outlines of Skepticism</em>, Sextus Empiricus stresses that
empirical discoveries can destabilize our confidence in universal
moral agreement:


</p>

<blockquote>

even if in some cases we cannot see an anomaly, we should say that
possibly there is dispute about these matters too&hellip; Just as, if
we had not, for example, known about the Egyptian custom of marrying
their sisters, we should have affirmed, wrongly, that it is agreed by
all that you must not marry your sister. (Sextus
Empiricus, <em>Outlines of Skepticism</em>) </blockquote>

<p>
While the use of empirical observation in moral theory has a long
history, the contemporary movement known as experimental philosophy
goes back only a few decades. The current experimental philosophy
movement owes its beginnings to the work of Stephen Stich and Jonathan
Weinberg (2001) and Joshua Knobe (2003), but the earliest instance of
experimental philosophy may be <em>Truth as Conceived by Those Who Are
Not Professional Philosophers</em> (Naess 1938), which surveyed
ordinary speakers for their intuitions about the nature of
truth. Contemporary philosophers have not been uniformly accepting of
the movement, but as we will see, there are reasons to think that
experimental evidence might have a distinctive role, significance, and
importance in moral philosophy and theorizing.</p>

<p>
The relationship between more traditional philosophy and experimental
work is instructive and brings out some tensions within moral
philosophy and theory: namely, morality is at once practical and
normative, and these two aspects inform and constrain the extent to
which it is accountable to human psychology.

</p>

<p>

Insofar as morality is practical, it should be accessible to and
attainable by agents like us: if a theory is too demanding, or relies
on intuitions, judgments, motivations, or capacities that people do
not (or, worse, cannot) possess, we might on those grounds dismiss
it. On the other hand, morality is also normative: it aims not just to
describe what we actually do or think, but to guide our practice. For
this reason, some philosophers have responded to experimental results
claiming to show that attaining and reliably expressing virtues in a
wide variety of situations is difficult (see section 3.1 below for a
discussion of this literature) by pointing out that the fact that
people do not always make the right judgment, or perform actions for
the right reasons, does not falsify a theory&mdash;it simply shows
that people often act in ways that are morally deficient. We will
return to these issues when we discuss criticisms of experimental
moral philosophy at the end of this entry; for now, we mention them to
illustrate that the extent to which experimental moral philosophy
challenges traditional philosophical approaches is itself a
controversial issue. Some moral philosophers see themselves as
deriving moral principles a priori, without appeal to contingent facts
about human psychology. Others see themselves as working within a
tradition, going back at least as far as Aristotle, that conceives of
ethics as the study of human flourishing. These philosophers have not
necessarily embraced experimental moral philosophy, but many
practitioners envision their projects as outgrowths of the
naturalistic moral theories developed by Aristotle, Hume, and others.

</p>

<h3><a id="WhaCouExp">1.1 What Are Experiments?</a></h3>

<p>

As the examples discussed above reveal, a variety of types of
empirical evidence are useful to moral theorizing (see also the
entries on empirical moral psychology, empirical distributive justice,
and empirical psychology and character). Anthropological observation
and data have long played a role in moral philosophy. The
twentieth-century moral philosophers John Ladd and Richard Brandt
investigated moral relativism in part by conducting their own
ethnographies in Native American communities. Brandt writes, &ldquo;We
have&hellip; a question affecting the truth of ethical relativism
which, conceivably, anthropology can help us settle. Does ethnological
evidence support the view that &ldquo;qualified persons&rdquo; can
disagree in ethical attitude?&rdquo; But, he notes, &ldquo;some kinds
of anthropological material will not help us&mdash;in particular, bare
information about intercultural differences in ethical opinion or
attitude.&rdquo; (1952: 238). This is a caveat frequently cited by
philosophers engaged in empirical research: it is important to have
philosophers participate in experimental design and the gathering of
empirical data, because there are certain questions that must be
addressed for the data to have philosophical applications&mdash;in
this case, whether moral disagreements involve different factual
beliefs or other non-moral differences. Barry Hallen (1986, 2000)
conducted a series of interviews and ethnographies among the Yoruba,
investigating central evaluative concepts and language relating to
epistemology, aesthetics, and moral value. Hallen was motivated by
questions about the indeterminacy of translation, but his work
provides an example of how in-depth interviews can inform
investigations of philosophical concepts. </p>

<p>

These examples show that ethnography has a valuable role to play in
philosophical theory, but the remainder of this entry will focus
primarily on experiments. Paradigmatic experiments involve randomized
assignment to varying conditions of objects or people from a
representative sample, followed by statistical comparison of the
outcomes for each condition. The variation in conditions is sometimes
called a manipulation. For example, an experimenter might try to
select a representative sample of people, randomly assign them either
to find or not to find a dime in the coin return of a pay phone, and
then measure the degree to which they subsequently help someone they
take to be in need (Isen and Levin 1972). Finding or not finding the
dime is the condition; degree of helpfulness is the outcome variable.

</p>

<p>

While true experiments follow this procedure, other types of studies
allow non-random assignment to conditions. Astronomers, for example,
sometimes speak of natural experiments. Although we are in no position
to affect the motions of heavenly bodies, we can observe them under a
variety of conditions, over long periods of time, and with a variety
of instruments. Likewise, anthropological investigation of different
cultures&rsquo; moral beliefs and practices is unlikely to involve
manipulating variables in the lives of the members of the culture, but
such studies are valuable and empirically respectable. Still, such
studies can at best demonstrate correlation, not causation, so their
evidential value of studies is less than that of experiments; most
published research in experimental philosophy involves true
experiments.

</p>

<p>

Even within the category of experiments, we find a lot of diversity
with respect to inputs, methods of measurement, and outputs. The
experiment just described uses a behavioral measure and
manipulation&mdash;finding the dime is the input, helping is the
outcome measured. Other experiments measure not behavior but judgment
or intuition, and this can be done using a survey or other form of
self&ndash;report or informant&ndash;report where subjects respond
explicitly to some question, situation, or dilemma. Studies measuring
judgments might use either manipulations of the condition in which the
subject makes the judgment, or they might look for correlations
between judgments and some other factor, such as brain activity,
emotional response, reaction time, visual attention, and so on
(Strohminger et al. 2014).

</p>

<p>

The experimental methods available have also changed over
time. Surveys have been the dominant method of experimental philosophy
for the past few decades, but technology may change this: advances in
virtual and augmented reality mean that philosophers can now immerse
people in moral dilemmas such as Thompson&rsquo;s (1971) violinist
thought experiment and different versions of the trolley
problem. Philosophers interested in the neural correlates of moral
judgment can use transcranial magnetic stimulation (TMS) to
investigate the effects of enhancing or lessening activity in certain
areas of the brain. Even survey methods have seen advances thanks to
technology; the ubiquity of smartphones allows researchers to ping
people in real time, asking for reports on mood (see section 3.2 below
for a discussion of surveys relating to happiness and mood).

</p>

<p>

Whether experimental moral philosophy has to use true experiments or
can include studies and even ethnographies and other forms of
qualitative data is partly a terminological question about how to
define the field and whether we distinguish it from empirical moral
psychology, a closely related research program. As we will see below,
though, a diversity of both methods and subjects is important in
helping experimental moral philosophy respond to its critics.

</p>

<h3><a id="WhoConExpInv">1.2 What Types of Questions and Data?</a></h3>

<p>

Like experimental philosophy more generally, experimental moral
philosophy is interested in our intuitions and judgments about
philosophical thought experiments and moral dilemmas. But research in
this area also concerns the cognitive architecture underlying our
moral judgments; the developmental processes that give rise to moral
judgments; the neuroscience of moral judgment; and other related
fields.

</p>

<p>

<em>Direct</em> experiments investigate whether a claim held (or
denied) by philosophers is corroborated or falsified. This might mean
investigating an intuition and whether it is as widely shared as
philosophers claim, or it might mean investigating the claim that a
certain behavior or trait is widespread or that two factors
covary. For example, we find philosophers claiming that it is wrong to
imprison an innocent person to prevent rioting; that a good life must
be authentic; and that moral judgments are intrinsically
motivating. Experimental research can be (and has been, as we will see
below) brought to bear on each of these claims.

</p>

<p>

<em>Indirect</em> experiments look at the nature of some capacity or
judgment: for example, whether certain types of moral dilemmas engage
particular areas of the brain; how early children develop a capacity
to empathize; and whether the moral/conventional distinction is
universal across cultures. These claims have philosophical relevance
insofar as they help us understand the nature of moral judgment.

</p>

<p>

In addition to distinctions involving the type of data and how
directly it bears on the question, we can also distinguish among
experimental applied ethics, experimental normative ethics, and
experimental metaethics. The first involves the variables that
influence judgments about particular practical problems, such as how a
self-driving car should respond to sacrificial dilemmas (Bonnefon,
Sharriff, and Rahwan 2016). The second involves investigations of how
we ought to behave, act, and judge, as well as our intuitions about
moral responsibility, character, and what constitutes a good life. The
third involves debates over moral realism and antirealism. In this
entry we focus on the latter two.

</p>

<p>

In many of these cases, the line between experimental moral philosophy
and its neighbors is difficult to draw: what distinguishes
experimental moral philosophy from empirical moral psychology? What is
the difference between experimental moral philosophy and psychology or
neuroscience that investigates morality? What is the difference
between experimental moral philosophy and metaethics? We might try to
answer these questions by pointing to the training of the
experimenters&mdash;as philosophers or as scientists&mdash;but much of
the work in these areas is done by collaborative teams involving both
philosophers and social scientists or neuroscientists. In addition,
some philosophers work in law and psychology departments, and graduate
programs increasingly offer cross-disciplinary training. Another
approach would be to look at the literature with which the work
engages: many psychologists (e.g., Haidt, Greene) investigating moral
judgment situate their arguments within the debate between Kantians
and Humeans, so engagement with the philosophical tradition might be
used as a criterion to distinguish experimental moral philosophy from
experimental moral psychology. All this said, an inability to sharply
distinguish experimental moral philosophy from adjoining areas of
investigation may not be particularly important. Experimental
philosophers often point out that the disciplinary divide between
philosophy and psychology is a relatively recent phenomenon; early
twentieth-century writers such as William James situated themselves in
both disciplines, making vital contributions to each. If there is a
problem here, it is not unique to experimental moral philosophy. For
example, is work on semantics that uses both linguistics and analytic
philosophy best understood as linguistics or philosophy of language?
These debates arise, and may be largely moot, for many research
programs that cut across disciplinary boundaries.

</p>

<p>

The rest of this entry proceeds as follows. Section 2 canvasses
experimental research on moral judgments and intuitions, describing
various programmatic uses to which experimental results have been put,
then turning to examples of experimental research on moral judgment
and intuition, including intuitions about intentionality and
responsibility, as well as the so-called linguistic analogy. Section 3
discusses experimental results on thick (i.e., simultaneously
descriptive and normative) topics, including character and virtue,
wellbeing, and emotion and affect. Section 4 discusses questions about
moral disagreement and moral language, both important sources of
evidence in the longstanding debate over moral objectivity. Section 5
considers some objections to experimental moral philosophy.

</p>

<h2><a id="MorJudInt">2. Moral Intuitions and Conceptual Analysis</a></h2>

<p>

One role for experiments in moral philosophy, as indicated above, is
to investigate our moral intuitions about cases, and to use the
results gleaned from such investigations to guide or constrain our
moral metaphysics, semantics, or epistemology. Philosophers often rely
on such judgments&mdash;in the form of claims to the effect that
&ldquo;we would judge x&rdquo; or, &ldquo;intuitively,
x&rdquo;&mdash;as data or evidence for a theory (though see Cappelen
2012 and Deutsch 2016 for critical discussion of this point). Claims
about what we would judge or about the intuitive response to a case
are empirically testable, and one project in experimental moral
philosophy (perhaps the dominant original project) has been to test
such claims via an investigation of our intuitions and related moral
judgments. In doing so, experimental moral philosophers can accomplish
one of two things: first, they can test the claims of traditional
philosophers about what is or is not intuitive; second, they can
investigate the sources of our intuitions and judgments. These tasks
can be undertaken as part of a positive program, which uses our
intuitions and judgments as inputs and constructs theories that
accommodate and explain them. Alternatively, these tasks can figure in
a negative program, which uses experimental research to undermine
traditional appeals to intuition as evidence in moral philosophy and
conceptual analysis more broadly. The negative program can proceed
directly or indirectly: either via testing and refuting claims about
intuitions themselves, or by discrediting the sources of those
intuitions by discovering that they are influenced by factors widely
regarded as not evidential or unreliable. We discuss both the negative
program and the positive program below.

</p>

<h3><a id="TwoNegPro">2.1 The Negative Program in Experimental Moral Philosophy</a></h3>

<p>

Early work in experimental philosophy suggested cross-cultural
differences in semantic, epistemic, and moral intuitions. For example,
Machery, Mallon, and Stich (2004) argued that East Asian subjects were
more likely to hold descriptivist intuitions than their Western
counterparts, who tended to embrace causal theories of
reference. Haidt (2006) argued that the extent to which people judged
harmless violations such as eating a deceased pet, or engaging in
consensual sibling incest, to be wrong depended on socioeconomic
status. Since, presumably, moral wrongness doesn&rsquo;t itself depend
on socioeconomic status, gender, or culture of the person making the
moral judgment, these results have been marshaled to argue either
against the evidential value of intuitions or against the existence of
moral facts altogether.

</p>

<p>

Negative experimental moral philosophy generates results that are then
used to discount the evidential value of appeals to intuition. For
example, Walter Sinnott-Armstrong (2008d), Eric Schwitzgebel, Fiery
Cushman (2012), and Peter Singer (2005) have recently followed this
train of thought, arguing that moral intuitions are subject to
normatively irrelevant situational influences (e.g., order effects),
while Feltz &amp; Cokely (2009) and Knobe (2011) have documented
correlations between moral intuitions and (presumably) normatively
irrelevant individual differences (e.g., extroversion). Such results
might warrant skepticism about moral intuitions, or at least about
some classes of intuitions or
intuiters.<sup>[<a href="notes.html#note-1" id="ref-1">1</a>]</sup>

</p>

<p>

The studies just mentioned involve results that suggest that the
content of intuitions varies along some normatively irrelevant
dimension. Another source of evidence for the negative program draws
on results regarding the cognitive mechanisms underlying or generating
intuitions themselves. For example, studies that suggest that
deontological intuitions are driven by emotional aversions to harming
others have been used to argue that we ought to discount our
deontological intuitions in favor of consequentialist
principles&mdash;an idea discussed in more detail below (see Singer
2005, Weigman 2017).

</p>

<p>

The distinction between negative and positive experimental moral
philosophy is difficult to draw, partly because the negative program
often discounts particular classes or types of intuitions in favor of
others that are supposed to be more reliable. For example, Singer
offers an anti-deontological argument as part of the negative program
insofar as his argument uses the emotional origins of deontological
intuitions to discount them. But because he then argues for the
superiority of consequentialist intuitions, his position also fits
within the positive program. So the difference between the two
programs is not in the data or the kinds of questions investigated,
but in how the data are put to use&mdash;whether they are seen as
debunking traditional philosophical appeals to intuition or as an
addition to traditional philosophical appeals to intuition, by helping
philosophers distinguish between reliable and unreliable intuitions
and their sources. In the next section, we look at positive uses of
intuitions as evidence.

</p>

<h3><a id="ThrPosPro">2.2 The Positive Program in Experimental Moral Philosophy</a></h3>

<p>

Other philosophers are more sanguine about the upshot of experimental
investigations of moral judgment and intuition. Knobe, for example,
uses experimental investigations of the determinants of moral
judgments to identify the contours of philosophically resonant
concepts and the mechanisms or processes that underlie moral
judgment. He has argued for the pervasive influence of moral
considerations throughout folk psychological concepts (2009, 2010; see
also Pettit &amp; Knobe 2009), claiming, among other things, that the
concept of an intentional action is sensitive to the foreseeable
evaluative valence of the consequences of that action (2003, 2004b,
2006).<sup>[<a href="notes.html#note-2" id="ref-2">2</a>]</sup> In a
recent paper, Knobe (2016) shows that only ten percent of experimental
philosophy aims to support or undercut a proposed conceptual analysis;
instead, most published papers aim to shed light on the cognitive and
affective processes underlying the relevant phenomenon. </p>

<p>

Another line of research is due to Joshua Greene and his colleagues
(Greene et al. 2001, 2004, 2008; Greene 2008), who investigate the
neural bases of consequentialist and deontological moral
judgments. Greene and his colleagues elicited the intuitions of
subjects about a variety of trolley problems&mdash;cases that present
a dilemma in which a trolley is racing towards five individuals, all
of whom will be killed unless the trolley is instead diverted towards
one individual&mdash;while inside an fMRI scanner. The researchers
found that, when given cases in which the trolley is diverted by
pulling a switch, most subjects agreed that diverting the trolley away
from the five and towards the one person was the right action. When,
instead, the case involved pushing a person off a bridge to land in
front of and halt the trolley, subjects were less likely to judge that
sacrificing the one person as morally permissible. In addition, Greene
found that subjects who did judge it permissible to push the person
took longer to arrive at their judgment, suggesting that they had to
overcome conflicting intuitions to do so&mdash;a finding bolstered by
the fact that when subjects considered pushing the person off the
bridge, their brains revealed increased activity in areas associated
with the aggregation and modulation of value signals (e.g.,
ventromedial prefrontal cortex and dorsolateral prefrontal
cortex). Greene concludes that our aversion to pushing the person is
due to an emotional response to the thought of causing physical harm
to someone, while our willingness to pull the switch is due to the
rational calculation that saving five people is preferable to letting
five people die to spare one life. Greene and Singer use these
findings as a basis for a debunking of deontological intuitions and a
vindication of consequentialism, since the latter rests on intuitions
which stem from a source we consider both generally reliable and
appropriately used as the basis for moral reasoning. It should be
noted, though, that this argument presupposes that emotional reactions
are (at least in these cases) necessarily irrational or arational;
philosophers who are unsympathetic to such a view of emotions need not
follow Greene and Singer to their ultimate conclusions (Railton 2014).

</p>

<p>

A related approach aims to identify the features to which intuitions
about philosophically important concepts are sensitive. Sripada (2011)
thinks that the proper role of experimental investigations of moral
intuitions is not to identify the mechanisms underlying moral
intuitions. Such knowledge, it is claimed, contributes little of
relevance to philosophical theorizing. It is rather to investigate, on
a case by case basis, the features to which people are responding when
they have such intuitions. On this view, people (philosophers
included) can readily identify whether they have a given intuition,
but not why they have it. An example from the debate over determinism
and free will: manipulation cases have been thought to undermine
compatibilist intuitions&mdash;intuition supporting the notion that
determinism is compatible with &ldquo;the sort of free will required
for moral responsibility&rdquo; (Pereboom 2001). In such cases, an
unwitting victim is described as having been surreptitiously
manipulated into having and reflectively endorsing a motivation to
perform some action. Critics of compatibilism say that such cases
satisfy compatibilist criteria for moral responsibility, and yet,
intuitively, the actors are not morally responsible (Pereboom
2001). Sripada (2011) makes a strong case, however, through both
mediation analysis and structural equation modeling, that to the
extent that people feel the manipulee not to be morally responsible,
they do so because they judge him in fact not to satisfy the
compatibilist criteria.<sup>[<a href="notes.html#note-3" id="ref-3">3</a>]</sup> Thus, by determining which aspects of the case
philosophical intuitions are responding to, it might be possible to
resolve otherwise intractable questions. </p>

<h3><a id="ExaIntRes">2.3 An Example: Intentionality and Responsibility</a></h3>

<p>

Since Knobe&rsquo;s seminal (2003) paper, experimental philosophers
have investigated the complex patterns in people&rsquo;s dispositions
to make judgments about moral notions (praiseworthiness,
blameworthiness, responsibility), cognitive attitudes (belief,
knowledge, remembering), motivational attitudes (desire, favor,
advocacy), and character traits (compassion, callousness) in the
context of violations of and conformity to various norms (moral,
prudential, aesthetic, legal, conventional,
descriptive).<sup>[<a href="notes.html#note-4" id="ref-4">4</a>]</sup>
In Knobe&rsquo;s original experiment, participants first read a
description of a choice scenario: the protagonist is presented with a
potential policy (aimed at increasing profits) that would result in a
side effect (either harming or helping the environment). Next, the
protagonist explicitly disavows caring about the side effect, and
chooses to go ahead with the policy. The policy results as advertised:
both the primary and the side effect occur. Participants are asked to
attribute intentionality or an attitude (or, in the case of later work
by Robinson et al. 2013, a character trait) to the protagonist. What
Knobe found was that participants were significantly more inclined to
indicate that the protagonist had intentionally brought about the side
effect when it was perceived to be bad (harming the environment) than
when it was perceived to be good (helping the environment). This
effect has been replicated dozens of times, and its scope has been
greatly expanded from intentionality attributions after violations of
a moral norm to attributions of diverse properties after violations of
a wide variety of norms.</p>

<p>

The first-order aim of interpreters of this body of evidence is to
create a model that predicts when the attribution asymmetry will crop
up. The second-order aims are to explain as systematically as possible
why the effect occurs, and to determine the extent to which the
attribution asymmetry can be considered rational. Figure 1, presented
here for the first time, models how participants&rsquo; responses to
this sort of vignette are produced:</p>

<div class="figure">
<img src="fig1.png" width="550" alt="diagram of participant response" />
<p><span class="figlabel">Figure 1.</span>  Model of Participant
Response to Experimental Philosophy Vignettes</p>
</div>

<p>

In this model, the boxes represent constructs, the arrows represent
causal or functional influences, and the area in grey represents the
mind of the participant, which is not directly observable but is the
target of investigation. In broad strokes, the idea is that a
participant first reads the text of the vignette and forms a mental
model of what happens in the story. On the basis of this model (and
almost certainly while the vignette is still being read), the
participant begins to interpret, i.e., to make both descriptive and
normative judgments about the scenario, especially about the mental
states and character traits of the people in it. The participant then
reads the experimenter&rsquo;s question, forms a mental model of what
is being asked, and&mdash;based on her judgments about the
scenario&mdash;forms an answer to that question. That answer may then
be pragmatically revised (to avoid unwanted implications, to bring it
more into accord with what the participant thinks the experimenter
wants to hear, etc.) and is finally recorded as an explicit response
to a statement about the protagonist&rsquo;s attitudes (e.g.,
&ldquo;he brought about the side effect intentionally,&rdquo; graded
on a Likert scale.)<sup>[<a href="notes.html#note-5" id="ref-5">5</a>]</sup></p>

<p>

A result that has been replicated repeatedly is that, when the
vignette describes a norm violation, subjects indicate that they agree
more strongly that the action violating the norm was performed
intentionally. While this finding could be used by proponents of the
negative program to undermine the conceptual coherence of our notion
of moral responsibility, experimental moral philosophers working in
the positive program have taken up the task of explaining the
asymmetry by postulating models of unobservable entities that mediate,
explain, and perhaps even rationalize the asymmetry. A discussion of
several attempts to do so follows; each offers a different explanation
of the asymmetry, but all represent vindications or at least
rehabilitations of our intuitions about intention.

</p>

<p><em>The Conceptual Competence Model</em></p>

<p>
Perhaps the best known is Knobe&rsquo;s conceptual competence model,
according to which the asymmetry arises at the judgment stage. On this
view, normative judgments about the action influence otherwise
descriptive judgments about whether it was intentional (or desired, or
expected, etc.). Moreover, this influence is taken to be part of the
very conception of intentionality (desire, belief, etc.). Thus, on the
conceptual competence model, the asymmetry in attributions is a
rational expression of the ordinary conception of intentionality
(desire, belief, etc.), which turns out to have a normative
component.<sup>[<a href="notes.html#note-6" id="ref-6">6</a>]</sup></p>

<p><em>The Motivational Bias Model</em></p>

<p>

The motivational bias model (Alicke 2008; Nadelhoffer 2004, 2006)
agrees that the asymmetry originates in the judgment stage, and that
normative judgments influence descriptive judgments. However, unlike
the conceptual competence model, it takes this to be a bias rather
than an expression of conceptual competence. Thus, on this model, the
asymmetry in attributions is a distortion of the correct conception of
intentionality (desire, belief, etc.).</p>

<p><em>The Deep Self Model</em></p>

<p>

The <em>deep self concordance model</em> (Sripada 2010, 2012; Sripada
&amp; Konrath 2011) also locates the source of the asymmetry in the
judgment stage, but does not recognize an influence (licit or illicit)
of normative judgments on descriptive judgments. Instead, proponents
of this model claim that when assessing intentional action, people not
only attend to their representation of a person&rsquo;s
&ldquo;surface&rdquo; self&mdash;her expectations, means-end beliefs,
moment-to-moment intentions, and conditional desires&mdash;but also to
their representation of the person&rsquo;s &ldquo;deep&rdquo; self,
which harbors her sentiments, values, and core principles. According
to this model, when assessing whether someone intentionally brings
about some state of affairs, people determine (typically
unconsciously) whether there exists sufficient concordance between
their representation of the outcome the agent brings about and what
they take to be her deep self. For instance, when the chairman says he
does not care at all about either harming or helping the environment,
people attribute to him a deeply anti-environment stance. When he
harms the environment, this is concordant with his anti-environment
deep self; in contrast, when the chairman helps the environment, this
is discordant with his anti-environment deep self. According to the
deep self concordance model, then, the asymmetry in attributions is a
reasonable expression of the folk psychological distinction between
the deep and shallow self.</p>

<p><em>The Conversational Pragmatics Model</em></p>

<p>

Unlike the models discussed so far, the conversational pragmatics
model (Adams &amp; Steadman 2004, 2007) locates the source of the
asymmetry in the pragmatic revision stage. According to this model,
participants judge the protagonist not to have acted intentionally in
both norm-conforming and norm-violating cases. However, when it comes
time to tell the experimenter what they think, participants do not
want to be taken as suggesting that the harm-causing protagonist is
blameless, so they report that he acted intentionally. This is a
reasonable goal, so according to the pragmatic revision model, the
attribution asymmetry is rational, though misleading.</p>

<p><em>The Deliberation Model</em></p>

<p>

According to the deliberation model (Alfano, Beebe, &amp; Robinson
2012; Robinson, Stey, &amp; Alfano 2013; Scaife &amp; Webber 2013),
the best explanation of the complex patterns of evidence is that the
very first mental stage, the formation of a mental model of the
scenario, differs between norm-violation and norm-conformity
vignettes. When the protagonist is told that a policy he would
ordinarily want to pursue violates a norm, he acquires a reason to
deliberate further about what to do; in contrast, when the protagonist
is told that the policy conforms to some norm, he acquires no such
reason. Participants tend to think of the protagonist as deliberating
about what to do when and only when a norm would be violated. Since
deliberation leads to the formation of other mental states such as
beliefs, desires, and intentions, this basal difference between
participants&rsquo; models of what happens in the story flows through
the rest of their interpretation and leads to the attribution
asymmetry. On the deliberation model, then, the attribution asymmetry
originates earlier than other experimental philosophers suppose, and
is due to rational processes.</p>

<h3><a id="AnoExaLinAna">2.4 Another Example: The Linguistic Analogy</a></h3>

<p>

Another positive program investigates the structure and form of moral
intuitions, in addition to their content, with the aim of using these
features to inform a theory of the cognitive structures underlying
moral judgment and their etiology. </p>


<p>

Rawls (1971), drawing on Chomsky&rsquo;s (1965) theory of generative
linguistics, suggested that moral cognition might be usefully modeled
on our language faculty, a parallel endorsed by Chomsky himself:

</p>

<blockquote>

I don&rsquo;t doubt that we have a natural moral sense&hellip;.That is, just as people somehow can construct an extraordinarily rich system of knowledge of language on the basis of rather limited and degenerate experience, similarly, people develop implicit systems of moral evaluation, which are more or less uniform from person to person. There are differences, and the differences are interesting, but over quite a substantial range we tend to make comparable judgments, and we do it, it would appear, in quite intricate and delicate ways involving new cases and agreement often about new cases&hellip; and we do this on the basis of a very limited environmental context available to us. The child or the adult doesn&rsquo;t have much information that enables the mature person to construct a moral system that will in fact apply to a rich range of cases, and yet that happens.&hellip;whenever we see a very rich, intricate system developing in a more or less uniform way on the basis of rather restricted stimulus conditions, we have to assume that there is a very powerful, very rich, highly structured innate component that is operating in such a way as to create that highly specific system on the basis of the limited data available to it. (Chomsky, quoted in Mikhail 2005).

</blockquote>

<p>Here Chomsky points to three similarities between the development
of linguistic knowledge and the development of moral knowledge: </p>

<blockquote>
<p>

L1: A child raised in a particular linguistic community almost
inevitably ends up speaking an idiolect of the local language despite
lack of sufficient explicit instruction, lack of extensive negative
feedback for mistakes, and grammatical mistakes by caretakers.</p>

<p>M1: A child raised in a particular moral community almost
inevitably ends up judging in accordance with an idiolect of the local
moral code despite lack of sufficient explicit instruction, lack of
sufficient negative feedback for moral mistakes, and moral mistakes by
caretakers.</p>

<p>

L2: While there is great diversity among natural languages, there are
systematic constraints on possible natural languages.</p>

<p>

M2: While there is great diversity among natural moralities, there are
systematic constraints on possible natural moralities.</p>

<p>

L3: Language-speakers obey many esoteric rules that they themselves
typically cannot articulate or explain, and which some would not even
recognize.</p>

<p>

M3: Moral agents judge according to esoteric rules (such as the
doctrine of double effect) that they themselves typically cannot
articulate or explain, and which some would not even recognize.</p>

<p>

L4: Drawing on a limited vocabulary, a speaker can both produce and
comprehend a potential infinity of linguistic expressions.</p>

<p>

M4: Drawing on a limited moral vocabulary, an agent can produce and
evaluate a very large (though perhaps not infinite) class of
action-plans, which are ripe for moral judgment.</p>
</blockquote>

<p>

We will now explain and evaluate each of these pairs of claims in
turn.

</p>

<p>

L1/M1 refer to Chomsky&rsquo;s <em>poverty of the stimulus</em>
argument: despite receiving little explicit linguistic and grammatical
instruction, children develop language rapidly and at a young age, and
quickly come to display competence applying complex grammatical
rules. Similarly, Mikhail and other proponents of the analogy argue
that children acquire moral knowledge at a young age based on
relatively little explicit instruction. However, critics of the
analogy point out several points of difference. First, children
actually receive quite a bit of explicit moral instruction and
correction, and in contrast with the linguistic case, this often takes
the form of explicit statements of moral rules: &lsquo;don&rsquo;t
hit,&rsquo; &lsquo;share,&rsquo; and so on. Secondly, there is debate
over the age at which children actually display moral competence. Paul
Bloom (2013; see also Blake, McAuliffe, and Warneken 2014) has argued
that babies display moral tendencies as early as 3&ndash;6 months, but
others (most famously Kohlberg (1969) and Piaget (1970); see also
Turiel (1983) and Nucci (2002)) have argued that children are not
fully competent with moral judgment until as late as 8&ndash;12 years,
by which time they have received quite a bit of moral instruction,
both implicit and explicit. A related point concerns the ability to
receive instructions: in the case of language, a child requires some
linguistic knowledge or understanding in order even to receive
instruction: a child who has no understanding of language will not
understand instructions given to her. But in the moral case, a child
need not understand moral rules in order to be instructed in them, so
there is less need to posit some innate knowledge or
understanding. Nichols et al. (2016) have conducted a series of
experiments using statistical learning and Bayesian modeling to show
how children might learn complex rules with scant input. Finally,
while children may initially acquire the moral values present in their
environment, they sometimes change their values or develop their own
values later in life in ways that present spontaneously and with
little conscious effort. This is in marked contrast with language; as
any second-language learner will recognize, acquiring a new language
later in life is effortful and, even if one succeeds in achieving
fluency, the first language is rarely lost. Lastly, as Prinz (2008)
points out, children are punished for moral violations, which may
explain why they are quicker to learn moral than grammatical
rules. </p>

<p>

L2/M2 refer to the existence of so-called <em>linguistic
universals</em>: structures present in all known languages. Whether
this is true in the moral case is controversial, for reasons
we&rsquo;ll discuss further below. Prinz (2008) and Sripada (2004)
have argued that there are no <em>exceptionless</em> moral universals,
unless one phrases or describes the norms in question in such a way as
to render them vacuous. Sripada uses the example &lsquo;murder is
wrong&rsquo; as a vacuous rule: while this might seem like a plausible
candidate for a moral universal, when we consider that
&lsquo;murder&rsquo; refers to a wrongful act of killing, we can see
that the norm is not informative. But Mikhail might respond by
claiming that the fact that all cultures recognize a subset of
intentional killings as morally wrong, even if they differ in how they
circumscribe this subset, is itself significant, and the relevant
analogy here would be with the existence of categories like
&lsquo;subject&rsquo;, &lsquo;verb&rsquo;, and &lsquo;object&rsquo; in
all languages, or with features like recursion, which are present in
the grammars of all natural languages.

</p>

<p>

L3/M3 refer to the patterns displayed by grammatical and moral
intuitions. In the case of language, native speakers can recognize
grammatical and ungrammatical constructions relatively easily, but
typically cannot articulate the rules underlying these intuitions. In
the case of moral grammar, the analogy claims, the same is true: we
produce moral intuitions effortlessly without being able to explain
the rules underlying them. Indeed, in both cases, the rules underlying
the judgments might be quite esoteric and difficult for native
speakers to learn and understand&mdash;as anyone who has taught the
doctrine of double effect to introductory students can likely
attest. </p>

<p>

L4/M4 refer to the fact that we can embed linguistic phrases within
other linguistic phrases to create novel and increasingly complex
phrases and sentences. This property is known as <em>recursion</em>,
and is present in all known natural languages (indeed, in a 2002
paper, Chomsky suggests that perhaps recursion is the only linguistic
universal; see Hauser, Chomsky, and Fitch 2002). For instance, just as
phrases can be embedded in other phrases to form more complex
phrases:</p>

<blockquote>

the calico cat \(\rightarrow\) the calico cat (that the dog chased)
\(\rightarrow\) the calico cat (that the dog [that the breeding
conglomerate wanted] chased) \(\rightarrow\) the calico cat (that the
dog [that the breeding conglomerate{that was bankrupt} wanted] chased)
</blockquote>

<p>

so moral judgments can be embedded in other moral judgments to produce
novel moral judgments (Harman 2008, 346). For example:</p>

<blockquote>

It&rsquo;s wrong to \(x \rightarrow\) It&rsquo;s wrong to
coerce someone to \(x \rightarrow\) It&rsquo;s wrong to
persuade someone to coerce someone to \(x\)
</blockquote>

<p>

The point is twofold: first, we can create complex action
descriptions; second, we can evaluate novel and complex actions and
respond with relatively automatic intuitions of grammatical or moral
permissibility. Mikhail (2011: 43&ndash;48) uses experimental evidence
of judgments about trolley problems to argue that our moral judgments
are generated by imposing a deontic structure on our representation of
the causal and evaluative features of the action under
consideration. Mikhail points to a variation on the poverty of the
stimulus argument, which he calls the <em>poverty of the perceptual
stimulus </em> (Mikhail 2009: 37): when faced with a particular moral
situation, we draw complex inferences about both act and actor based
on relatively little data. Mikhail (2010) uses this argument against
models of moral judgment as affect-driven intuitions: </p>

<blockquote>

Although each of these rapid, intuitive, and highly automatic moral judgments is occasioned by an identifiable stimulus, how the brain goes about interpreting these complex action descriptions
and assigning a deontic status to each of them is not something revealed in any obvious way by the surface structure of the stimulus itself. Instead, an intervening step must be postulated: an intuitive appraisal of some sort that is imposed on the stimulus prior to any deontic response to it. Hence, a simple perceptual model, such as the one implicit in Haidt&rsquo;s (2001) influential model of moral judgment, appears inadequate for explaining these intuitions, a point that can be illustrated by calling attention to the unanalyzed link between eliciting situation and intuitive response in Haidt&rsquo;s model

</blockquote>

<p>Unlike the traditional poverty of the stimulus argument, this
version does not rely on developmental evidence but on our ability to
quickly and effortlessly appraise complicated scenarios, such as
variations on trolley problems, and then issue normative
judgments. The postulated intervening step is like the unconscious
appeal to rules of grammar, and the evidence for such a step must come
from experiments showing that we do, in fact, have such intuitions,
and that they conform to predictable patterns.</p>

<p>

The linguistic analogy relies on experimental evidence about the
nature and pattern of our moral intuitions, and it outlines an
important role for experiments in moral theory. If the analogy holds,
then an adequate moral theory must be based on the judgments of
competent moral judges, just as grammatical rules are constructed
based on the judgments of competent speakers. A pressing task will be
the systematic collection of such judgments. The analogy also suggests
a kind of rationalism about moral judgment, since it posits that our
judgments result from the unconscious application of rules to
cases. Finally, the analogy has metaethical implications. Just as we
can only evaluate grammaticality of utterances relative to a language,
it may be that we can only evaluate the morality of an action relative
to a specific moral system. How to individuate moralities, and how
many (assuming there are multiple ones) there are, is a question for
further empirical investigation, and here again experimental evidence
will play a crucial role.</p>

<h2><a id="ChaWelEmo">3. Character, Wellbeing, and Emotion</a></h2>

<p>

Until the 1950s, modern moral philosophy had largely focused on either
consequentialism or deontology. The revitalization of virtue ethics
led to a renewed interest in virtues and vices (e.g., honesty,
generosity, fairness, dishonesty, stinginess, unfairness), in
<em>eudaimonia</em> (often translated as &lsquo;happiness&rsquo; or
&lsquo;flourishing&rsquo;), and in the emotions. In recent
decades, experimental work in psychology, sociology, and neuroscience
has been brought to bear on the empirical grounding of philosophical
views in these areas.</p>

<h3><a id="ChaVir">3.1 Character and Virtue</a></h3>

<p>

A virtue is a complex disposition comprising sub-dispositions to
notice, construe, think, desire, and act in characteristic ways.  To
be generous, for instance, is (among other things) to be disposed to
notice occasions for giving, to construe ambiguous social cues
charitably, to desire to give people things they want, need, or would
appreciate, to deliberate well about what they want, need, or would
appreciate, and to act on the basis of such deliberation.
Manifestations of such a disposition are observable and hence ripe for
empirical investigation. Virtue ethicists of the last several decades
have sometimes been optimistic about the distribution of virtue in the
population. Alasdair MacIntyre claims, for example, that
&ldquo;without allusion to the place that justice and injustice,
courage and cowardice play in human life very little will be genuinely
explicable&rdquo; (1984, 199). Julia Annas (2011, 8&ndash;10) claims
that &ldquo;by the time we reflect about virtues, we already have
some.&rdquo; Linda Zagzebski (2010) provides an
&ldquo;exemplarist&rdquo; semantics for virtue terms that only gets
off the ground if there are in fact many virtuous people.</p>

<p>

Starting with Owen Flanagan&rsquo;s <em>Varieties of Moral
Personality</em> (1993), philosophers began to worry that empirical
results from social psychology were inconsistent with the structure of
human agency presupposed by virtue theory. In this framework, people
are conceived as having more or less fixed traits of character that
systematically order their perception, cognition, emotion, reasoning,
decision-making, and behavior. For example, a generous person is
inclined to notice and seek out opportunities to give supererogatorily
to others. The generous person is also inclined to think about what
would (and wouldn&rsquo;t) be appreciated by potential recipients, to
feel the urge to give and the glow of satisfaction after giving, to
deliberate effectively about when, where, and how to give to whom, to
come to firm decisions based on such deliberation, and to follow
through on those decisions once they&rsquo;ve been made. Other traits
are meant to fit the same pattern, structuring perception, cognition,
motivation, and action of their bearers. Famous results in social
psychology, such as Darley and Batson&rsquo;s (1973) Good Samaritan
experiment, seem to tell against this view of human moral
conduct. When someone helps another in need, they may do so simply
because they are not in a rush, rather than because they are
expressing a fixed trait like generosity or compassion.</p>

<p>
In the virtue theoretic framework, people are not necessarily assumed
to already be virtuous. However, they are assumed to be at least
potentially responsive to the considerations that a virtuous person
would ordinarily notice and take into account. Flanagan (1993),
followed by Doris (1998, 2002), Harman (1999, 2000), and Alfano
(2013), made trouble for this framework by pointing to social
psychological evidence suggesting that much of people&rsquo;s
thinking, feeling, and acting is instead predicted by (and hence
responsive to) situational factors that don&rsquo;t seem to count as
reasons at all&mdash;not even bad reasons or temptations to
vice. These include influences such as ambient sensibilia (sounds,
smells, light levels, etc.), seemingly trivial and normatively
irrelevant inducers of positive and negative moods, order of
presentation of stimuli, and a variety of framing and priming effects,
many of which are reviewed in Alfano (2013:
40&ndash;50).<sup>[<a href="notes.html#note-7" id="ref-7">7</a>]</sup>
It&rsquo;s worth emphasizing the depth of the problem these studies
pose. It&rsquo;s not that they suggest that most people aren&rsquo;t
virtuous (although they do suggest that as well). It&rsquo;s that they
suggest that they undermine the entire framework in which people are
conceived as cognitively sensitive and motivationally responsive to
reasons. Someone whose failure to act virtuously because they gave in
to temptation can be understood in the virtue theoretic
framework. Someone whose failure to act virtuously because
they&rsquo;d just been subliminally primed with physical coldness,
which in turn is metaphorically associated with social coldness, finds
no place in the virtue theoretic framework. These sorts of effects
push us to revamp our whole notion of agency and personhood (Doris
2009).
</p>

<p>
Early estimates suggested that individual difference variables
typically explain less than 10% of the variance in people&rsquo;s
behavior (Mischel 1968)&mdash;though, as Funder &amp; Ozer (1983)
pointed out, situational factors may explain less than
16%.<sup>[<a href="notes.html#note-8" id="ref-8">8</a>]</sup> More
recent aggregated evidence indicates that situational factors explain
approximately twice as much of the variance in human behavior as the
five main trait factors (Rauthmann et al. 2014). Convergent evidence
from both lexicographical and survey studies indicates that there are
at least five dimensions of situations that reliably predict thought,
feeling, and behavior: (1) negative valence, (2) adversity, (3) duty,
(4) complexity, and (5) positive valence (Rauthmann and Sherman 2018).
</p>

<p>

According to Doris (2002), the best explanation of this lack of
cross-situational consistency is that the great majority of people
have local rather than global, traits: they are not honest,
courageous, or greedy, but they may be honest-while-in-a-good-mood,
courageous-while-sailing-in-rough-weather-with-friends, and
greedy-unless-watched-by-fellow-parishioners. In contrast, Christian
Miller (2013, 2014) thinks the evidence is best explained by a theory
of mixed global traits, such as the disposition to (among other
things) help because it improves one&rsquo;s mood. Such traits are
global, in the sense that they explain and predict behavior across
situations (someone with such a disposition will, other things being
equal, typically help so long as it will maintain her mood), but
normatively mixed, in the sense that they are neither virtues nor
vices. Mark Alfano (2013) goes in a third direction, arguing that
virtue and vice attributions tend to function as self-fulfilling
prophecies. People tend to act in accordance with the traits that are
attributed to them, whether the traits are minor virtues such as
tidiness (Miller, Brickman, &amp; Bolen 1975) and ecology-mindedness
(Cornelissen et al. 2006, 2007), major virtues such as charity (Jensen
&amp; Moore 1977), cooperativeness (Grusec, Kuczynski, Simutis &amp;
Rushton 1978), and generosity (Grusec &amp; Redler 1980), or vices
such as cutthroat competitiveness (Grusec, Kuczynski, Simutis &amp;
Rushton 1978). On Alfano&rsquo;s view, when people act in accordance
with a virtue, they often do so not because they possess the trait in
question, but because they think they do or because they know that
other people think they do. He calls such simulations of moral
character <em>factitious virtues</em>, and even suggests that the
notion of a virtue should be revised to include reflexive and social
expectations.<sup>[<a href="notes.html#note-9" id="ref-9">9</a>]</sup></p>

<p>

It might seem that the criticisms that motivate these novel approaches
to virtue miss their mark. After all, virtue ethicists needn&rsquo;t
(and often don&rsquo;t) commit themselves to the claim that almost
everyone <em>is</em> virtuous. Instead, many argue that virtue is the
normative goal of moral development, and that people mostly fail in
various ways to reach that goal. The argument from the fact that most
people&rsquo;s dispositions are not virtues to a rejection of orthodox
virtue ethics, then, might be thought a <em>non sequitur,</em> at
least for such views. But empirically-minded critics of virtue ethics
do not stop there. They all have positive views about what sorts of
dispositions people have <em>instead</em> of virtues. These
dispositions are alleged to be so structurally dissimilar from virtues
(as traditionally understood) that it may be psychologically
unrealistic to treat (traditional) virtue as a regulative ideal.  What
matters, then, is the width of the gap between the descriptive and the
normative, between the (structure of the) dispositions most people
have and the (structure of the) dispositions that count as
virtues.</p>

<p>

Three leading defenses against this criticism have been offered. Some
virtue ethicists (Kupperman 2009) have conceded that virtue is
extremely rare, but argued that it may still be a useful regulative
ideal. Others (Hurka 2006, Merritt 2000) have attempted to weaken the
concept of virtue in such a way as to enable more people, or at least
more behaviors, to count as virtuous. Still others (Kamtekar 2004,
Russell 2009, Snow 2010, Sreenivasan 2002) have challenged the
situationist evidence or its interpretation. While it remains unclear
whether these defenses succeed, grappling with the situationist
challenge has led both defenders and challengers of virtue ethics to
develop more nuanced and empirically informed
views.<sup>[<a href="notes.html#note-10" id="ref-10">10</a>]</sup></p>

<h3><a id="Wel">3.2 Wellbeing, Happiness, and the Good Life</a></h3>

<p>

Philosophers have always been interested in what makes a human life go
well, but recent decades have seen a dramatic increase in both
psychological and philosophical research into happiness, well-being,
and what makes for a good life. It is important to distinguish here
between &lsquo;good life&rsquo; in the sense of a life that goes well
for the one who lives it, and a <em>morally</em> good life, since
philosophers have long debated whether a morally bad person could
enjoy a good life. The empirical study of wellbeing focuses primarily
on lives that are good in the former sense: good for the person whose
life it is. Second, we need to distinguish between a hedonically good
life and an overall good life. A life that is hedonically good is one
that the subject experiences as pleasant; an overall good life might
not contain much pleasure but might be good for other reasons, such as
what it accomplishes. We might decide, after investigation, that an
overall good life must be a hedonically good life, but the two
concepts are distinct.</p>

<p>

With these distinctions in mind, we can see the relevance of
experimental evidence to investigations in this area. First and
perhaps most obviously, experiments can investigate our intuitions
about what constitutes a good life, thereby giving us insight into the
ordinary concepts of happiness, well-being, and flourishing. To this
end, Phillips, Nyholm, &amp; Liao (2014) investigated intuitions about
the relationship between morality and happiness. Their results suggest
that the ordinary conception of happiness involves both descriptive
and normative components: specifically, we judge that people are happy
if they are experiencing positive feelings that they ought to
experience. So, to use their examples, a Nazi doctor who gets positive
feelings from conducting his experiments is not happy. By contrast, a
nurse who gets positive feelings from helping sick children is happy,
though a nurse who is made miserable by the same actions is not happy.

</p>

<p>

Another set of experimental findings bearing on this question involves
Nozick&rsquo;s (1974: 44&ndash;45) experience machine thought
experiment. In response to the hedonist&rsquo;s claim that pleasure is
the only intrinsic good, Nozick asks us to consider the following:

</p>

<blockquote>

Suppose there was an experience machine that would give you any
experience you desired. Super-duper neuropsychologists could stimulate
your brain so that you would think and feel you were writing a great novel,
or making a friend, or reading an interesting book. All the time you would
be floating in a tank, with electrodes attached to your brain. Should you
plug into this machine for life, preprogramming your life experiences? [&hellip;]
Of course, while in the tank you won&rsquo;t know that you&rsquo;re there; you&rsquo;ll think
that it&rsquo;s all actually happening [&hellip;] Would you plug in? 

</blockquote>

<p>

Nozick argues that our response to the experience machine reveals that
well-being is not purely subjective: &ldquo;We learn that something
matters to us in addition to experience by imagining an experience
machine and then realizing that we would not use it.&rdquo; DeBrigard
(2010) reports finding that subjects&rsquo; intuitions about the
experience were different if they were told they were already in such
a machine, in which case they would not choose to unplug; he explains
this in terms of the status quo bias. Weijers (2014) goes further,
asking subjects about Nozick&rsquo;s original scenario while also
asking them to justify their response; he found that many of the
justifications implied a kind of imaginative resistance to the
scenario or cited irrelevant factors. He also found that respondents
were more likely to say that a &lsquo;plugged in life&rsquo; would be
better when they were choosing for someone else, rather than for
themselves.


</p>

<p>

A second type of study involves investigating the causes and
correlates of happiness, well-being, and life-satisfaction. These
experiments look at the conditions under which people report positive
affect or life-satisfaction, as well as the conditions under which
they judge that their lives are going well. This is distinct from the
first type of research, since the fact that someone reports an
experience as being pleasurable does not necessarily tell us whether
they would judge that experience to be pleasurable for someone else;
there may be asymmetries in first- and third-person
evaluations. Furthermore, this type of research can tell us how
various candidates contribute to well-being from a first-person
perspective, but that doesn&rsquo;t settle the question of the concept
of a good life. I might judge that my life is going well, yet fail to
notice that I am doing so because I am in a very good mood, and that
in fact I am not accomplishing any of my goals; if confronted with
another person in a similar situation, I might not make the same
judgment. Which of these judgments best represents our concept of
well-being is a tricky question, and a normative one since
experimental evidence alone may not settle it. As it turns out,
experiments have uncovered a number of factors that influence our own
reports and assessments of pleasure and well-being. We will discuss
two areas of research in particular: reports of pleasures and pains,
and judgments of life satisfaction.

</p>

<p>

First, in the realm of hedonic evaluation, there are marked
divergences between the aggregate sums of in-the-moment pleasures and
pains and ex post memories of pleasures and pains. For example, the
remembered level of pain of a colonoscopy is well-predicted by the
average of the worst momentary level of pain and the final level of
pain; furthermore, the duration of the procedure has no measurable
effect on ex post pain ratings (Redelmeier &amp; Kahneman 1996). What
this means is that people&rsquo;s after-the-fact summaries of their
hedonic experiences are not simple integrals with respect to time of
momentary hedonic tone. If the colonoscopy were functionally completed
after minute 5, but arbitrarily prolonged for another 5 minutes so
that the final level of pain was less at the end of minute 10 than at
the end of minute 5, the patient would retrospectively evaluate the
experience as less painful. This complicates accounts of wellbeing in
terms of pleasure (for example, Bentham&rsquo;s 1789/1961 hedonism)
insofar as it raises the question whether the pleasure being measured
is pleasure as experienced in the moment, or retrospectively: if, in
the very act of aggregating pleasure, we change the way we evaluate
it, this is a complication for hedonism and for some versions of
utilitarianism. Since well-being is supposed to be a normative notion
capable of guiding both individual actions and social policy, findings
like these also call into question what, exactly, we ought to be
seeking to maximize: pleasurable moments, or the overall retrospective
evaluation of pleasure.

</p>




<p>

Such findings have led some philosophers to seek out alternatives to
hedonism in hopes of establishing a more empirically stable
underpinning for well-being: in particular, the idea that well-being
consists in life satisfaction. The most prominent psychologist in
this field is Ed 
  Diener<sup>[<a href="notes.html#note-11" id="ref-11">11</a>]</sup> 
 whose Satisfaction with Life Scale asks participants to agree or
disagree with statements such as, &ldquo;I am satisfied with my
life&rdquo; and &ldquo;If I could live my life over, I would change
almost nothing.&rdquo; These questions seem to get at more stable and
significant features of life than hedonic assessments in terms of
pleasure and pain, and one might expect the responses to be more
consistent and robust. However, two problems arise. The first is that
participants&rsquo; responses to life satisfaction questionnaires may
not be accurate reports of standing attitudes. Fox &amp; Kahneman
(1992), for instance, showed that, especially in personal domains
people seem to value (friends and love life), what predicts
participants&rsquo; responses is not recent intrapersonal factors but
social comparison. Someone who has just lost a friend but still thinks
of herself as having more friends than her peers will tend to report
higher life satisfaction than someone who has just gained a friend but
who still thinks of himself as having fewer friends than his peers.
</p>

<p>
Life satisfaction surveys also seem to be subject to order
 effects. For instance, if a participant is asked a global life
 satisfaction question and then asked about his romantic life, the
 correlation between these questions tends to be near zero, but if the
 participant is asked the dating question first, the correlation tends
 to be high and positive (Strack, Martin, &amp; Schwarz
 1988).<sup>[<a href="notes.html#note-12" id="ref-12">12</a>]</sup>
 This suggests that life-satisfaction judgments might be unduly
 influenced by the topics and questions considered just before making
 a life-satisfaction judgment. Another example is Schwarz and Clore&rsquo;s oft-cited 1983 study, in which the authors reported a correlation between weather and life-satisfaction when subjects were asked about weather first, but not when the weather question followed the life-satisfaction query.  We note, however, that there is
 significant controversy about this oft-cited example. Some
 recent papers claim to find a correlation between the two (e.g. Connolly 2013) while others claim there is no
 evidence for an effect of weather on life-satisfaction judgments
 (e.g. Lucas &amp; Lawless 2013).</p>

<p>

Findings like the above have led some researchers (e.g., Haybron 2008)
to argue that life-satisfaction judgments are too arbitrary to ever
satisfy the requirements of a theory of well-being. In response,
Tiberius and Plakias (2011) argue for an idealized life-satisfaction
theory they call <em>value based life satisfaction</em>, suggesting
that by asking subjects to consider their life-satisfaction while
attending to the domains they most value much of the instability
plaguing the studies described above is removed, a claim they support
with research showing that judgments made after priming subjects to
think about their values demonstrate higher levels of retest stability
(Schimmack &amp; Oishi 2005).

</p>


<h3><a id="EmoAff">3.3 Emotion and Affect</a></h3>

<p>

As much of the previous discussion reveals, the relationship between
emotion and moral judgment is one of the central concerns of both
traditional and experimental moral philosophy. Our discussion of this
topic will focus on two types of research: the role of emotion in
moral reasoning generally, and the role of one specific
emotion&mdash;disgust&mdash;in moral judgments.

</p>

<p>

One debate concerns whether hot, emotion-driven reasoning is
necessarily better or worse than reasoning based only on cooler, more
reflective thinking&mdash;a distinction sometimes referred to using
Kahneman&rsquo;s terminology of system 1/system 2 thinking. The
terminology is not perfect, though, because Kahneman&rsquo;s terms map
onto a quick, automatic, unconscious system of judgments (system 1)
and a slow, effortful, deliberative decision-making process (system
2), and as we saw above, this is not a distinction between emotion and
reason, since rule-based judgments can be automatic and unconscious
while emotional judgments might be effortful and conscious. The debate
between Mikhail and Haidt is a debate over the extent to which
emotions rather than rules explain our moral judgments; Singer and
Greene&rsquo;s arguments against deontology rest on the claim that
emotion-backed judgments are less justified than their utilitarian
counterparts.

</p>

<p>

One reason for thinking that moral judgments essentially involve some
emotional component is that they tend to motivate us. <i>Internalism</i> is the view that there is a necessary connection between moral judgment and motivation. This contrasts
with <i>externalism,</i> which doesn&rsquo;t deny that moral
judgments are usually motivating, but does deny that they are
necessarily so, as the link between judgment and motivation is only
contingent. Since emotions are intrinsically motivational, showing
that moral judgments consist, even in part, of emotions would
vindicate internalism. One route to this conclusion has involved
surveying people&rsquo;s intuitions about moral judgment. Nichols
(2002: 289) asked subjects whether an agent who &ldquo;had no
emotional reaction to hurting other people&rdquo; but claims to know
that hurting others is wrong really understands that hurting others is
wrong. He found that most subjects did attribute knowledge in such
cases, suggesting that the ordinary concept of moral judgment is
externalist, a claim that is further supported by Strandberg and
Bj&ouml;rklund (2013). An additional source of evidence comes from
psychopaths and patients with traumatic brain injuries, both of whom
show evidence of impaired moral functioning&mdash;though how one
regards this evidence depends on which perspective one begins with:
while externalists (Nichols 2002, Roskies 2003) claim that the
existence of psychopaths provides a counterexample to the claim that
moral judgment is motivating (since psychopaths lack empathy and an
aversion to harming others), internalists (Smith 1994, Maibom 2005,
Kennett and Fine 2008) argue that psychopaths don&rsquo;t actually
make full-fledged moral judgments. Psychologist Robert Hare (1993:
129) quotes a researcher as saying that, they &ldquo;know the words
but not the music.&rdquo; Psychopaths also display other cognitive and
affective deficiencies, as evidenced by their poor decision-making
skills in other areas. This may mean that they should not be taken as
evidence against internalism.

</p>

<p>

A reason for thinking that moral judgments ought not involve emotion
is that emotions sometimes seem to lead to judgments that are
distorted or off-track, or that seem otherwise unjustified. One
emotion in particular is often mentioned in this context:
disgust. This emotion, which seems to be unique to human animals and
emerges relatively late in development (from the ages of about
5&ndash;8), involves a characteristic gaping facial expression, a
tendency to withdraw from the object of disgust, a slight reduction in
body temperature and heart rate, and a sense of nausea and the need to
cleanse oneself. In addition, the disgusted subject is typically
motivated to avoid and even expunge the offending object, experiences
it as contaminating and repugnant, becomes more attuned to other
disgusting objects in the immediate environment, and is inclined to
treat anything that the object comes in contact with (whether
physically or symbolically) as also disgusting. This last
characteristic is often referred to as &lsquo;contamination
potency&rsquo; and it is one of the features that makes disgust so
potent and, according to its critics, so problematic. The disgust
reaction can be difficult to repress, is easily recognized, and
empathically induces disgust in those who do recognize
it.<sup>[<a href="notes.html#note-13" id="ref-13">13</a>]</sup> There
are certain objects that almost all normal adults are disgusted by
(feces, decaying corpses, rotting food, spiders, maggots, gross
physical deformities). But there is also considerable intercultural
and interpersonal variation beyond these core objects of disgust,
where the emotion extends into food choices, sexual behaviors,
out-group members, and violations of social norms. Many studies have
claimed to show that disgust is implicated in harsher moral judgments
(Schnall, Haidt, &amp; Clore 2008), citing experiments in which
subjects filling out questionnaires in smelly or dirty rooms evaluated
moral transgressions more harshly. Others have gone further and argued
that disgust might itself cause or comprise a part of moral judgment
(Haidt 2001; Wheatley &amp; Haidt 2005). If this is true, critics
argue, we ought to be wary of those judgments, because disgust has a
checkered past in multiple senses. First, it&rsquo;s historically (and
currently) associated with racism, sexism, homophobia and xenophobia;
the language of disgust is often used in campaigns of discrimination
and even genocide. Secondly, disgust&rsquo;s evolutionary history
gives us reason to doubt it. Kelly (2011) argues that the universal
bodily manifestations of disgust evolved to help humans avoid
ingesting toxins and other harmful substances, while the more
cognitive or symbolic sense of offensiveness and contamination
associated with disgust evolved to help humans avoid diseases and
parasites. This system is later recruited for an entirely distinct
purpose: to help mark the boundaries between in-group and out-group,
and thus to motivate cooperation with in-group members, punishment of
in-group defectors, and exclusion of out-group members. </p>

<p>

If Kelly&rsquo;s account of disgust is on the right track, it seems to
have a number of important moral upshots. One consequence, he argues,
is &ldquo;disgust skepticism&rdquo; (139), according to which the
combination of disgust&rsquo;s hair trigger and its ballistic
trajectory mean that it is especially prone to incorrigible false
positives that involve unwarranted feelings of contamination and even
dehumanization. Hence, &ldquo;the fact that something is disgusting is
not even remotely a reliable indicator of moral foul play&rdquo; but
is instead &ldquo;irrelevant to moral justification&rdquo; (148).

</p>

<p>

It is important to note that the skeptical considerations Kelly raises
are specific to disgust and its particular evolutionary history, so
they aren&rsquo;t intended to undermine the role of all emotions in
moral judgment. Still, if Kelly is correct, and if disgust is
implicated in lots of moral judgments, we may have a reason to be
skeptical of many of our judgments. Plakias (2011, 2017) argues
against the first half of this antecedent, claiming that Kelly and
other &lsquo;disgust skeptics&rsquo; are wrong to claim that the
purposes of moral and physical disgust are totally distinct; she
suggests that disgust is sometimes a fitting response to moral
violations that protects against social contagion. May (2014) argues
against the second half, claiming that disgust&rsquo;s role in moral
judgment has been significantly overblown; at most, we have evidence
that disgust can, in certain cases, slightly amplify moral judgments
that are already in place. However, more recent empirical work
indicates that incidental disgust has little effect on the harshness
of moral judgments, though dispositional disgust-sensitivity does
(Landy and Goodwin 2015).

</p>


<h2><a id="SomMetIss">4. Metaethics and Experimental Moral Philosophy</a></h2>

<p>

Metaethics steps back from moral theorizing to ask about the nature
and function of morality. While first-order ethics seeks to explain
what we should do, metaethics seeks to explain the status of those
theories themselves: what are their metaphysical commitments, and what
evidence do we have for or against them? Which epistemology best
characterizes our moral practices? What is the correct semantics for
moral language? These questions might not seem obviously empirical,
but insofar as it attempts to give an account of moral semantics, epistemology, and ontology, metaethics aims, in part, to capture or explain what we do when
we engage in moral talk, judgment, and evaluation. To the extent that
metaethics sees itself as characterizing our ordinary practice of
morality, it is therefore answerable to empirical data about that
practice. To the extent that a theory claims that we are mistaken or in widespread error about the meaning of moral language, or that we lack justification for our core moral beliefs, this is taken to be a strike against that theory.  For example, relativism is often criticized on the grounds that it requires us to give up the (putatively) widespread belief that moral claims concern objective matters of fact and are true or false independently of our beliefs or attitudes.  We have already seen several ways that experimental data
bears on theories about moral reasons (the debate between internalists
and externalists) and the epistemology of moral judgment (the debate
over the role of intuitions). In this section we will examine
experimental contributions to the debate over moral realism, arguments
about moral disagreement, and moral language.

</p>

<h3><a id="MorRea">4.1 Folk Metaethics and Moral Realism</a></h3>

<p>

Much contemporary metaethics relies on assumptions about the nature of
ordinary moral thought, discourse, and practice; metaethicists tend to
see their project as essentially conservative. For example, Michael
Smith writes that the first step in metaethical theorizing is to
&ldquo;identify features that are manifest in ordinary moral
practice&rdquo; and the second step is to &ldquo;make sense of a
practice having these features.&rdquo; (1994) This assumption has had
a major impact on the debate between realists and anti-realists, with
realists claiming to best capture the nature of ordinary moral
discourse: &ldquo;We begin as (tacit) cognitivists and realists about
ethics,&rdquo; says Brink (1989), and then &ldquo;we are led to some
form of antirealism (if we are) only because we come to regard the
moral realist&rsquo;s commitments as untenable&hellip; Moral realism
should be our metaethical starting point, and we should give it up
only if it does involve unacceptable metaphysical and epistemological
commitments.&rdquo;

</p>

<p>

But experimental work has cast doubt on this claim, beginning with
Darley and Goodwin (2008), and continued by James Beebe (2014) and
others (Wright et al. 2013; Campbell and Kumar 2012; Goodwin and
Darley 2010; and Sarkissian et al. 2011). Goodwin and Darley asked
subjects to rate their agreement with statements drawn from the moral,
ethical, and aesthetic domain, and asked subjects whether they agreed
with the statement (for example, &ldquo;before the 3rd month of
pregnancy, abortion for any reason (of the mother&rsquo;s) is morally
permissible,&rdquo;), whether they thought it represented
a <em>fact</em> or an <em>opinion or attitude</em>, and whether, if
someone were to disagree with them about the statement, at least one
of the disputants would have to be mistaken. (We will say more about
the authors&rsquo; use of disagreement as a proxy for realism in the
following section.) In general, subjects rated moral statements as
less factual than obviously factual statements (e.g. &ldquo;the earth
is at the center of the universe,&rdquo;) but more factual than
statements about matters of taste or etiquette. What is striking about
these findings is not just that people are not straightforwardly
realist, but that they seem to treat moral questions variably: some
are treated as matters of fact, others as matters of opinion. This
pattern has been replicated in several studies, and persists even when
subjects are allowed to determine for themselves which issues to
assign to the moral domain, suggesting that subjects do not think
moral claims are uniformly objective

</p>

A question that remains is how to explain this variation: are people being inconsistent? Are they tracking something besides the moral question&mdash;perhaps the degree of consensus that exists about a question? Further research may help shed some light on these issues, but even if the questions are answered in the affirmative, the realist&rsquo;s claim to capture folk morality is called into question, since these experiments suggest that folk intuitions are either not uniformly realist, or they are confused (and hence poorly suited for a role in metaethical theorizing). Another response to these findings is that they reveal a kind of folk metaethical pluralism. For example, Michael Gill (2008, 2009) and Walter Sinnott-Armstrong (2009) have suggested a noncognitivist treatment of some areas of morality and cognitivism about others. This response is under-motivated by empirical data, however, since such data shows at most that our judgments about the extent to which moral claims describe mind-independent facts is variable, and not that their semantics itself varies. Nor does such data settle the question whether our moral judgments are beliefs or another conative state: while experimental data can reveal a role for emotion in moral judgment, as discussed above, it does not show that in such cases belief is absent. We will discuss limitations on experimental moral philosophy in more detail in Section 5 below. For now, it seems that data about folk realism are best viewed as undermining one of the most commonly-cited sources of evidence for moral realism, namely, that it captures our ordinary moral discourse and practice better than its competitors.  A further question, open to exploration, is whether an anti-realist view might do better at capturing and explaining our folk intuitions than realist competitors.

<h3><a id="MorDis">4.2 Moral Disagreement</a></h3>

<p>

As we saw at the beginning of this entry, some of the earliest
thinking in empirically-informed moral philosophy concerns moral
disagreement. Brandt and Ladd conducted in-depth investigations into
the moral codes of other groups, and some contemporary moral
philosophers have argued for continuing attention to the empirical
details of moral disagreement. This is partly due to the influence of
Mackie&rsquo;s (1977: 36&ndash;37) formulation of what he dubbed
&lsquo;the argument from relativity&rsquo; in terms of an inference to
the best explanation: the best explanation of the nature and
persistence of moral diversity, Mackie argues, is that our moral
judgments represent &ldquo;ways of life,&rdquo; rather than
&ldquo;perceptions, most of them seriously inadequate and badly
distorted, of objective moral values.&rdquo; Realists have tended to
respond to the argument by pointing to other possible explanations of
disagreement that are consistent with objectivity, such as mistakes
about the non-moral facts, irrationality, and failures of impartiality
and imagination (see for example Brink 1984, Sturgeon 1988, Smith 1994, and
Shafer-Landau 2003; for an overview and analysis of realist responses, see Loeb 1998).
</p>

<p>

Here it is useful to recall Brandt&rsquo;s admonition that &ldquo;bare
information about intercultural differences&rdquo; will not suffice to
settle the debate. Because the argument from disagreement turns, in
part, on both the existence of moral disagreement and the best
explanation for it, evaluating the prospects for the argument requires
attention to the empirical details of actual moral disagreements,
rather than conjecture about the outcomes of possible moral
disagreements. For example, Doris and Plakias (2008) discuss several
instances of cross-cultural moral disagreement, and assess the
prospects for applying what they call &lsquo;defusing
explanations&rsquo; to these cases. A defusing explanation is one that
accounts for the disagreement in terms of a non-moral difference or an
epistemic shortcoming on the part of one or more disputant, thereby
showing that it is not, in fact, a moral disagreement. Their argument
and the experiments they cite are discussed in detail in the entry on
empirical moral psychology, so we will not discuss them in detail
here; for now, we will note that such explanations are difficult to
assess via survey methods alone. This is why it is especially helpful
to look to the anthropological record, as Oliver Curry et al. (forthcoming)
do in a recent landmark publication. Curry hypothesizes that morality
comprises stable, cooperative solutions to recurrent problems that can
be modeled as non-zero-sum games. There are a variety of such
recurrent problems, and game theory has established a suite of
analytical tools for diagnosing and solving them. Curry and his
colleagues show that such solutions are <em>always</em> seen as either
morally good or morally neutral in societies at various stages of
development, from small-band hunter gatherers to industrialized
democracies. This research suggests that philosophers may have greatly
exaggerated the extent of moral disagreement that actually exists.

</p>

<h3><a id="MorLan">4.3 Moral Language</a></h3>

<p>

One reason disagreement is a useful measure of objectivity is that the
impossibility of faultless disagreement is taken to be characteristic
of questions concerning objective matters of fact. That is, while we
might concede the possibility of faultless disagreements about matters
concerning the deliciousness of foods or the merits of a sports team,
when we disagree over moral issues, we think that there is a correct
answer and that therefore at least one disputant is getting things
wrong (for a discussion of the analogy between food and morality, see Loeb (2003)). To the extent that people judge a disagreement to be faultless,
we might think that they are evincing a kind of anti-realism about the
issue under dispute. This is yet another way disagreement can bear on
the realism/antirealism debate. Can experimental evidence involving
disagreement tell us anything about the semantics of moral language?

</p>

<p>

One reason to think it can is that the very idea of faultless
disagreement strikes some as incoherent. In cases where one individual
thinks (or says) that pistachio ice cream is delicious and another
thinks (or says) that it is disgusting, we understand the two parties
as expressing their own personal preference. To explain the apparent
faultlessness of the dispute, we reinterpret their thoughts or
utterances as expressing something like, &ldquo;pistachio ice cream is
delicious [disgusting] <em>to me</em>.&ldquo; Because the two parties
do not genuinely contradict one another, we need not say that one of
them is mistaken. Faultlessness is therefore supposed to be a point in
favor of the moral anti-realist, since it seems to imply that there is
no single content about which the parties disagree (and about which
one might be mistaken).

</p>

<p>

By contrast, realists claim that their view is better able to capture
our intuition that there is a genuine disagreement at stake when one
person says that stealing is wrong and another says that stealing is
not wrong. In these cases, realists argue, we have the intuition that
there really is a conflict, and only a theory on which moral language
involves attributing properties to acts and things, rather than
reporting or expressing speakers&rsquo; attitudes, can capture this
intuition.

</p>

<p>

We have already seen some data bearing on this issue in our discussion
of folk realism above. The claim here is not about realism per se, but
about whether experimental evidence can give us insight into the
semantics of moral language, since our intuitions about whether there
is genuine faultlessness can tell us about whether there is a single
shared content between two utterances&mdash;a single proposition that
one party asserts and another denies&mdash;or whether the two
parties&rsquo; utterances contain implicit relativizations. This has,
at least, been the assumption guiding much of the debate over
disagreement and its implication for moral semantics. In recent work,
however, John Khoo and Joshua Knobe (2016) have cast doubt on this
assumption; their experiments indicate that subjects do not see
disagreement as requiring exclusionary content&mdash;a single
proposition that one party accepts and the other rejects. This
research suggests that intuitions about disagreement may not be as
straightforwardly tied to moral semantics as philosophers have
thought: judgments that two individuals genuinely disagree about some
claim do not necessarily imply a single shared content between the two
speakers. This work is still in early stages, but it reveals the
complications involved in reading semantics off disagreement.

</p>

<p>

A further challenge for attempts to experimentally investigate moral
semantics is the debate within antirealism between cognitivism and
noncognitivism. According to the cognitivist, ordinary moral sentences
are best understood as factual assertions, expressing propositions
that attribute moral properties (such as rightness or goodness) to
things (such as actions or characters). Noncognitivists (including
their contemporary representatives, the expressivists) hold that moral
language has a fundamentally different function, to express attitudes
or to issue commands, for example. While this debate seems ripe for
experimental investigation, the noncognitivist typically acknowledges
that their view is a reforming one. Furthermore, the semantics of our
terms may be opaque to ordinary users, to the extent that we cannot
read off semantics from intuitions but must investigate them
indirectly. Lastly, the cognitivist and noncognitivist can agree on a
number of empirical features of moral judgment and discourse; the
challenge for experimentalists is to find predictions that confirm one
view while disconfirming the other. This is a relatively new area of
investigation and, while not without challenges, ripe for exploration.

</p>

<h2><a id="CriExpMor">5. Criticisms of Experimental Moral Philosophy</a></h2>

<p>

Experimental moral philosophy far outstrips what we have been able to
cover here, and many issues and areas of productive research have
barely been touched upon. For example, experimental evidence is
relevant to moral questions in bioethics, such as euthanasia,
abortion, genetic screening, and placebogenic interventions.
Likewise, experiments in behavioral economics and cognitive psychology
are being employed in asking moral questions about public policy
(Bicchieri and Chavez 2010; Bicchieri and Xiao 2009).  We neglect
these issues only because of lack of space. In the few words
remaining, we explore some potential criticisms of experimental
philosophy.</p>

<h3><a id="ProExpDesInt">5.1 Problems with Experimental Design and Interpretation</a></h3>

<p>

As a young field, experimental philosophy suffers from various
problems with experimental design and interpretation. These are not
insurmountable problems, and they are problems faced by related
fields, such as social psychology, cognitive psychology, and
behavioral economics.</p>

<p>

One issue that has recently come to the fore is the problem of
 <em>replication</em>.<sup>[<a href="notes.html#note-14" id="ref-14">14</a>]</sup> 
Statistical analysis is not deductive inference, and the mere fact that
statistical analysis yields a positive result does not guarantee that
anything has been discovered. Typically, an experimental result is
treated as &ldquo;real&rdquo; if its \(p\)-value is at most .05,
but such a value just indicates the probability that the observation in
question would have been made if the null hypothesis were true. 
It is not the probability that the null hypothesis is false given
the
 observation.<sup>[<a href="notes.html#note-15" id="ref-15">15</a>]</sup> 
So, even
when statistical analysis indicates that the null hypothesis is to be
rejected, that indication can be fallacious. Moreover, when
multiple hypotheses are tested, the chance of fallaciously rejecting
the null hypothesis at least once rises exponentially.</p>

<p>

We should expect other failures of replication because of a bias built
into the system of funding experimentation and publishing results. The
proportion of published false-positives is much higher for unexpected
and unpredicted results than for expected and predicted results. Since
experimentalists are reluctant to report (and even discouraged by
journal editors and referees from reporting) null results (i.e.,
results where the \(p\)-value is more than .05), for every published,
unexpected result there may be any number of unpublished, unexpected
non-results. Thus, unexpected, published results are more likely to be
false positives than they might appear.</p>

<p>

The best way to tell whether such a result carries any evidential
value is for the experiment to be replicated&mdash;preferably by
another research group. If a result cannot be replicated, it is
probably a mirage. Such mirages have turned up to a disturbing extent
recently, as Daniel Kahneman has famously pointed out (Yong 2012; see
also Wagenmakers et al. 2012). Kahneman proposed a &ldquo;daisy
chain&rdquo; of replication, where no result in psychology would be
published until it had been successfully replicated by another
prominent lab. This proposal has not yet been (and may never be)
instituted, but it has raised the problem of replication to salience,
and a related project has taken off. The reproducibility project in
psychology aims to establish the extent to which prominent, published
results can be replicated.<sup>[<a href="notes.html#note-16"
id="ref-16">16</a>]</sup> Experimental philosophers have followed suit
with their own replication project (see the Other Internet
Resources). This work has recently yielded encouraging fruit: a large
collaborative replication effort suggests that approximately 7 out of
10 experimental philosophy results can be reproduced, whereas similar
efforts show that less than half of the results in biomedicine,
economics, and psychology are replicable (Cova et al. 2018, Other Internet
Resources).</p>

<p>

A related issue with experimental design and interpretation has to do
with &ldquo;fishing expeditions.&rdquo; An experiment is sometimes
pejoratively referred to as a fishing expedition if no specific
predictions are advanced prior to data collection, especially when
multiple hypotheses are tested. Likewise, critics argue that
researchers such as Weinberg, Nichols, &amp; Stich (2008) have put
forward hypotheses that are formulated so vaguely as to make them
nearly unfalsifiable. This problem is exacerbated when no guiding
positive heuristic is offered to explain observed patterns.</p>

<p>

Another worry is that simultaneously testing many intuition-probes can
lead unwary experimenters on snipe hunts. Suppose an experimental
philosopher conducts an experiment with two conditions: in the
experimental condition, participants are primed with deterministic
ideas, while in the control condition they are not primed one way or
another. She asks participants twenty different questions about their
moral intuitions, for instance, whether there is free will, whether
malefactors deserve to be punished, whether virtue deserves to be
rewarded, and so on. She then makes pairwise comparisons of their
responses to each of the questions in an attempt to figure out whether
deterministic priming induces changes in moral intuitions. She thus
makes twenty independent comparisons, each at the industry-standard 5%
level. Suppose now for the sake of argument that there is no
effect&mdash;that all null hypotheses are true. In that case, the
probability that at least one of these tests will result in a Type I
error (rejecting the null hypothesis even though it is true) is
64%. More generally, when an experimenter performs \(n\) independent
comparisons at the 5% level, the probability of at least one Type I
error is \(1-.95^n\). This problem can be addressed by various
procedures, most notably the Tukey method and the Bonferroni
method.<sup>[<a href="notes.html#note-17" id="ref-17">17</a>]</sup>
</p>

<p>

One way to establish that a result is real is to see whether the
experiment has a respectable effect size. The most common measure of
effect size is Cohen&rsquo;s \(d\), which is the ratio of the
difference in means between conditions to the standard deviation of
the relevant variable. So, for example, a \(d\) of 1.0 would indicate
that a manipulation moved the mean of the experimental condition an
entire standard deviation away from the mean of the control condition,
a huge effect. Unfortunately, effect sizes have, until recently,
rarely been reported in experimental philosophy, though that appears
to be changing.</p>

<h3><a id="PhiPro">5.2 Philosophical Problems</a></h3>

<p>

One might object that the real problem with experimental moral
philosophy is not with science, but with its relevance (or more
precisely, its irrelevance) to moral philosophy. The objection is that
moral philosophy is concerned not with how we are and what we do, but
with how we ought to be and what we ought to do. As such, it is a
normative enterprise, and is unaffected by empirical results. Science
is hard, but so is morality; if we fail to understand and live up to
the demands of the latter, that doesn&rsquo;t show a problem with our
moral theory but with our moral natures. </p>

<p>

Experimental philosophers can agree with this objection, up to a
point. No one is suggesting that we read morality directly off survey
results. But, to return to the point with which we began, while
morality is normative, it is also essentially practical. Moral theory
is a theory about what we ought to do: a theory about how creatures
like us ought to conduct ourselves and interact with one another. A
morality completely divorced from our natures, that demanded acts
impossible from us, would surely be unacceptable. This is not just a
point about experimental philosophy; utilitarianism is sometimes
critiqued as making unrealistic demands of impartiality. Alongside the
famous proscription against deriving an <em>ought</em> from
an <em>is,</em> we also find the dictum that <em>ought implies
can</em>. The exact extent to which morality can be demanding without
being unrealistic is itself a philosophical question, and so
experimental moral philosophy works in conjunction with philosophical
analysis; it does not aim to eliminate it. Exactly how the two relate
to each other, and how empirical evidence will bear on and influence
debates in moral theory in the future, is a contested issue, but
surely traditional moral theory and experimental moral philosophy have
much to learn from one another.

</p>

<p>

We need to proceed cautiously here. No one doubts that what we ought
to do depends on how things are non-morally. For example, the moral
claim that a given man deserves to be punished presupposes the
non-moral fact that he committed the crime. It should come as no
surprise, then, that experimental evidence might be relevant in this
way to morality. Whether experimental evidence is relevant to
discovering the fundamental moral principles&mdash;those meant to be
put into action one way or another depending on how the world is
non-morally&mdash;is still subject to debate.</p>

<p>

Another version of this argument says that fundamental moral
philosophical principles are, if true at all, necessarily true, and
that empirical research can establish at best only contingent
truths.<sup>[<a href="notes.html#note-18" id="ref-18">18</a>]</sup>
But if fundamental moral theories are necessary, then they are
necessary
<em>for creatures like us</em>. And one thing that empirical
investigation can do is to help establish what sorts of creatures we
are. Imagination needs material to work with. When one sits
in one&rsquo;s armchair, imagining a hypothetical scenario, one makes a
whole host of assumptions about what people are like, how psychological
processes work, and so on. These assumptions can be empirically
well or poorly informed. It&rsquo;s hard to see why anyone could
doubt that being well informed is to be preferred. Likewise
it&rsquo;s hard to see how anyone could doubt the relevance of
experimental evidence to better grounding our empirical assumptions, in
this case our assumptions relevant to moral philosophy. Exactly
how experimental&mdash;or more broadly, empirical&mdash;evidence is
relevant, and how relevant it is, are at present hotly contested
matters.</p>

</div>

<div id="bibliography">

<h2><a id="Bib">Bibliography</a></h2>

<ul class="hanging">

<li>Abelson, R., 1997. &ldquo;On the surprising longevity of flogged
horses: Why there is a case for the significance test&rdquo;,
<em>Psychological Science</em>, 8(1):  12&ndash;15.</li>

<li>Adams, F., &amp; Steadman, A., 2004. &ldquo;Intentional action in
ordinary language: Core concept or pragmatic understanding?&rdquo;
<em>Analysis</em>, 64: 173&ndash;181.</li>

<li>Adams, F., &amp; Steadman, A., 2007. &ldquo;Folk concepts, surveys,
and intentional action&rdquo;, in C. Lumer (ed.), <em>Intentionality,
deliberation, and autonomy: The action-theoretic basis of practical
philosophy</em>, Aldershot: Ashgate, 17&ndash;33.</li>

<li>Alfano, M., 2013. <em>Character as Moral Fiction</em>, Cambridge:
Cambridge University Press.</li>

<li>&ndash;&ndash;&ndash;, 2016. <em>Moral Psychology: An
Introduction</em>, London: Polity.</li>

<li>Alfano, M., Beebe, J., &amp; Robinson, B., 2012. &ldquo;The
centrality of belief and reflection in Knobe-effect
cases&rdquo;, <em>The Monist</em>, 95(2): 264&ndash;289.</li>

<li>Alicke, M., 2008. &ldquo;Blaming badly&rdquo;, <em>Journal of Cognition and
Culture</em>, 8: 179&ndash;186.</li>

<li>Annas, J., 2011. <em>Intelligent Virtue</em>, Oxford: Oxford
University Press.</li>

<li>Apsler, R., 1975. &ldquo;Effects of embarrassment on behavior toward
others&rdquo;, <em>Journal of Personality and Social Psychology</em>,
32: 145&ndash;153.</li>

<li>Austin, P., Mamdani, M., Juurlink, D., Hux, J., 2006. &ldquo;Testing
multiple statistical hypotheses resulted in spurious associations: A
study of astrological signs and health&rdquo;, <em>Journal of Clinical
Epidemiology</em>, 59(9): 964&ndash;969.</li>

<li>Ayer, A.J., 1936. <em>Language Truth, and Logic</em>, London:
Gollancz.</li>

<li>Banerjee, K., Huebner, B., &amp; Hauser, M., 2010. &ldquo;Intuitive
moral judgments are robust across demographic variation in gender,
education, politics, and religion: A large-scale web-based
study&rdquo;, <em>Journal of Cognition and Culture</em>, 10(1/2):
253&ndash;281.</li>

<li>Baron, R., 1997. &ldquo;The sweet smell of &hellip; helping: Effects
of pleasant ambient fragrance on prosocial behavior in shopping
malls&rdquo;, <em>Personality and Social Psychology Bulletin</em>, 23:
498&ndash;503.</li>

<li>Baron, R., &amp; Kenny, D., 1986. &ldquo;The moderator-mediator
variable distinction in social psychological research: Conceptual,
strategic, and statistical considerations&rdquo;, <em>Journal of
Personality and Social Psychology</em>, 51: 1173&ndash;82.</li>

<li>Baron, R.A., &amp; Thomley, J., 1994. &ldquo;A whiff of reality:
Positive affect as a potential mediator of the effects of pleasant
fragrances on task performance and helping&rdquo;, <em>Environment and
Behavior</em>, 26: 766&ndash;784.</li>

<li>Beebe, J.R., 2013. &ldquo;A Knobe effect for belief
ascriptions&rdquo;, <em>Review of Philosophy and Psychology</em>,
4(2): 235&ndash;258.</li>

<li>&ndash;&ndash;&ndash;, 2014. &ldquo;How different kinds of disagreement
impact folk metaethical judgments&rdquo;, in J.C. Wright &amp;
H. Sarkissian (2014), <em>Advances in Experimental Moral
Psychology: Affect, Character, and Commitment</em>, 167&ndash;187 (London:
Continuum).</li>

<li>Beebe, J.R., &amp; Buckwalter, W., 2010. &ldquo;The epistemic
side-effect effect&rdquo;, <em>Mind &amp; Language</em>, 25:
474&ndash;498.</li>

<li>Beebe, J.R., &amp; Jensen, M., 2012. &ldquo;Surprising
connections between knowledge and action: The robustness of the
epistemic side-effect effect&rdquo;, <em>Philosophical
Psychology</em>, 25(5): 689&ndash;715.</li>

<li>Bentham, J., 1789 [1961]. <em>An Introduction to the Principles of
Morals and Legislation</em>, Garden City: Doubleday. Originally
published in 1789.</li>

<li>Bicchieri, C. and Chavez, A., 2010. &ldquo;Behaving as expected:
Public information and fairness norms&rdquo;, <em>Journal of
Behavioral Decision Making</em>, 23(2): 161&ndash;178.</li>

<li>Bicchieri, C. and Xiao, E., 2009. &ldquo;Do the right thing, but
only if others do so&rdquo;, <em>Journal of Behavioral Decision
Making</em>, 22: 191&ndash;209.</li>

<li>Blake, P., McAuliffe, K., and Warneken, F., 2014. &ldquo;The
developmental origins of fairness: The knowledge-behavior
gap&rdquo;, <em>Trends in Cognitive Sciences</em>, 18(11):
559&ndash;561.</li>

<li>Bloom, P., 2013. <em>Just Babies: The Origins of Good and
Evil</em>, New York: Crown.</li>

<li>Bonnefon, J.-F., Sharriff, A., and Rahwan, I., 2016. &ldquo;The
social dilemma of autonomous vehicles&rdquo;, <em>Science</em>,
352(6293): 1573&ndash;1576.</li>

<li>Brandt, R., 1954. <em>Hopi Ethics: A Theoretical Analysis</em>,
Chicago: University of Chicago Press.</li>

<li>&ndash;&ndash;&ndash;, 1998. <em>A Theory of the Right and the
Good</em>,  Prometheus Books.</li>

<li>Brink, D., 1984. &ldquo;Moral realism and the sceptical arguments
from disagreement and queerness&rdquo;, <em>Australasian Journal of
Philosophy</em>, 62(2): 111&ndash;125.</li>

<li>Buckwalter, W. &amp; Stich, S., 2014. &ldquo;Gender and
philosophical intuition&rdquo;, in Knobe &amp; Nichols (eds.),
<em>Experimental Philosophy</em> (Volume 2), Oxford: Oxford University
Press.</li>

<li>Campbell, R. &amp; Kumar, V., 2012. &ldquo;Moral reasoning on the
ground&rdquo;, <em>Ethics</em>, 122(2): 273&ndash;312.</li>

<li>Cappelen, H., 2012. <em>Philosophy Without Intuitions</em>, 
Oxford: Oxford University Press.</li>

<li>Case, T., Repacholi, B., &amp; Stevenson, R., 2006. &ldquo;My baby
doesn&rsquo;t smell as bad as yours: The plasticity of disgust&rdquo;,
<em>Evolution and Human Behavior</em>, 27(5): 357&ndash;365.</li>

<li>Chomsky, N., 1965. <em>Aspects of the Theory of Syntax</em>,
Cambridge, MA: MIT Press.</li>

<li>Cohen, J., 1994. &ldquo;The Earth is round \((p \lt
.05)\)&rdquo;, <em>American Psychologist</em>, 49(12):
997&ndash;1003.</li>


<li>Cornelissen, G., Dewitte, S., Warlop, L., Liegeois, A., Yzerbyt, V.,
Corneille, O., 2006. &ldquo;Free bumper stickers for a better future: The
long term effect of the labeling technique&rdquo;, <em>Advances in
Consumer Research</em>, 33: 284&ndash;285.</li>

<li>Curry, O., Mullins, D., and Whitehouse, H., forthcoming. &ldquo;Is it
good to cooperate? Testing the theory of morality-as-cooperation in 60
societies&rdquo;, <em>Current Anthropology</em>,</li>

<li>Cushman, F. &amp; Greene, J., 2012. &ldquo;Finding faults: How
moral dilemmas illuminate cognitive structure&rdquo;, <em>Social
Neuroscience</em>, 7(3): 269&ndash;279.</li>

<li>Cushman, F. &amp; Young, L., 2009. &ldquo;The psychology of dilemmas
and the philosophy of morality&rdquo;, <em>Ethical Theory and Moral
Practice</em>, 12(1): 9&ndash;24.</li>

<li>&ndash;&ndash;&ndash;, 2011. &ldquo;Patterns of judgment derive
from nonmoral psychological representations&rdquo;, <em>Cognitive
Science</em>, 35(6): 1052&ndash;1075.</li>

<li>Darley, J. and Batson, C. D., 1973. &ldquo;From Jerusalem to
Jericho: A study of situational and dispositional variables in helping
behavior&rdquo;, <em>Journal of Personality and Social
Psychology</em>, 27: 100&ndash;108.</li>

<li>De Brigard, F., 2010. &ldquo;If you like it, does it matter if
it&rsquo;s real?&rdquo; <em>Philosophical Psychology</em>, 23(1):
43&ndash;57</li>

<li>Deutsch, M., 2016. &ldquo;Arguments, intuitions, and
philosophical cases: A note on a metaphilosophical
dialectic&rdquo;, <em>Philosophical Forum</em>, 47(3&ndash;4):
297&ndash;307.</li>

<li>Diener, E., Scollon, C., &amp; Lucas, R., 2003. &ldquo;The
evolving concept of subjective wellbeing: The multifaceted nature of
happiness&rdquo;, <em>Advances in Cell Aging and Gerontology</em>, 15:
187&ndash;219.</li>

<li>Diener, E., Emmons, R., Larsen, R., &amp; Griffin, S., 2010.
&ldquo;The satisfaction with life scale&rdquo;, <em>Journal of Personality
Assessment</em>, 49(1): 71&ndash;5.</li>

<li>Doris, J., 1998. &ldquo;Persons, situations, and virtue
ethics&rdquo;, <em>No&ucirc;s</em>, 32(4): 504&ndash;540.</li>

<li>&ndash;&ndash;&ndash;, 2002. <em>Lack of Character: Personality and Moral
Behavior</em>, Cambridge: Cambridge University Press.</li>

<li>Doris, J. &amp; Plakias, A., 2008a. &ldquo;How to argue about
disagreement: Evaluative diversity and moral realism&rdquo;, in
Sinnott-Armstrong (2008b), 303&ndash;332.</li>

<li>&ndash;&ndash;&ndash;, 2008b. &ldquo;How to Find a
Disagreement: Philosophical Diversity and Moral Realism&rdquo;, in
Sinnott-Armstrong (2008b), 345&ndash;54.</li>

<li>Doris, John and Stich, Stephen, 2012. &ldquo;Moral Psychology: Empirical 
Approaches&rdquo;, <em>The Stanford Encyclopedia of Philosophy</em>
(Winter 2012 Edition), Edward N. Zalta&nbsp;(ed.), URL = 
&lt;<a href="https://plato.stanford.edu/archives/win2012/entries/moral-psych-emp/">https://plato.stanford.edu/archives/win2012/entries/moral-psych-emp/</a>&gt;.</li>

<li>Dwyer, S., 1999. &ldquo;Moral competence&rdquo;, in K. Murasugi
&amp; R. Stainton (eds.), <em>Philosophy and Linguistics</em>,
Boulder, CO: Westview Press, 169&ndash;190.</li>

<li>&ndash;&ndash;&ndash;, 2009. &ldquo;Moral dumbfounding and the
linguistic analogy: Implications for the study of moral
judgment&rdquo;, <em>Mind and Language</em>, 24: 274&ndash;96.</li>

<li>Flanagan, O., 1983. <em>Varieties of Moral Personality: Ethics
and Psychological Realism</em>, Cambridge: Harvard University
Press.</li>

<li>Foot, P., 1978. <em>Virtues and Vices and Other Essays in Moral
Philosophy</em>, Berkeley, CA: University of California Press; Oxford:
Blackwell.</li>

<li>Fox, C. &amp; Kahneman, D., 1992. &ldquo;Correlations, causes and
heuristics in surveys of life satisfaction&rdquo;, <em>Social Indicators
Research</em>, 27: 221&ndash;34.</li>

<li>Funder, D. &amp; Ozer, D., 1983. &ldquo;Behavior as a function
of the situation&rdquo;, <em>Journal of Personality and Social
Psychology</em>, 44: 107&ndash;112.</li>

<li>Gill, M., 2008. &ldquo;Metaethical Variability, Incoherence, and
Error&rdquo;, in Sinnott-Armstrong (2008b), 387&ndash;402. </li>

<li>&ndash;&ndash;&ndash;, 2009. &ldquo;Indeterminacy and variability
in meta-ethics&rdquo;, <em>Philosophical Studies</em>, 145(2):
215&ndash;234. </li>

<li>Goodwin, G. and Darley, M., 2008. &ldquo;The psychology of
metaethics: Exploring objectivism&rdquo;, <em>Cognition</em>, 106(3):
1339&ndash;1366.</li>

<li>Goodwin, G. &amp; Darley, J., 2010. &ldquo;The perceived
objectivity of ethical beliefs: Psychological findings and
implications for public policy&rdquo;, <em>Review of Philosophy and
Psychology</em>, 1(2): 161&ndash;188.</li>

<li>Greene, J., 2008. &ldquo;The secret joke of Kant&rsquo;s soul&rdquo;, in
Sinnott-Armstrong (2008c), 35&ndash;80.</li>

<li>&ndash;&ndash;&ndash;, 2012. &ldquo;Reflection and reasoning in moral
judgment&rdquo;, <em>Cognitive Science</em>, 36(1): 163&ndash;177.</li>

<li>Greene, J., Morelli, S., Lowenberg, K., Nystrom, L., &amp; Cohen,
J., 2008. &ldquo;Cognitive load selectively interferes with
utilitarian moral judgment&rdquo;, <em>Cognition</em>, 107(3):
1144&ndash;1154.</li>

<li>Greene, J., Nystrom, L., Engell, A., Darley, J., &amp; Cohen, J.,
2004. &ldquo;The neural bases of cognitive conflict and control in moral
judgment&rdquo;, <em>Neuron</em>, 44: 389&ndash;400.</li>

<li>Greene, J., Sommerveille, R., Nystrom, L., Darley, J., &amp;
Cohen, J., 2001. &ldquo;An fMRI investigation of emotional engagement in
moral judgment&rdquo;, <em>Science</em>, 293: 2105&ndash;8.</li>

<li>Grusec, J. &amp; Redler, E., 1980. &ldquo;Attribution, reinforcement,
and altruism: A developmental analysis&rdquo;, <em>Developmental
Psychology</em>, 16(5): 525&ndash;534.</li>

<li>Grusec, J., Kuczynski, L., Rushton, J., &amp; Simutis, Z.,
1978. &ldquo;Modeling, direct instruction, and attributions: Effects on
altruism&rdquo;, <em>Developmental Psychology</em>, 14: 51&ndash;57.</li>

<li>Haidt, J., 2001. &ldquo;The emotional dog and its rational tail:
A social intuitionist approach to moral
judgment&rdquo;, <em>Psychological Review</em>, 108(4):
814&ndash;834.</li>

<li>&ndash;&ndash;&ndash;, 2012. <em>The Righteous Mind: Why Good People are
Divided by Politics and Religion</em>, New York: Pantheon.</li>

<li>Haidt, J. &amp; Bj&ouml;rklund, F., 2008. &ldquo;Social intuitionists
answer six questions about moral psychology&rdquo;, in
Sinnott-Armstrong (2008b), 181&ndash;218.</li>

<li>Hallen, B., 1986. <em>Knowledge, Belief, and Witchcraft: Analytic
Experiments in African Philosophy</em>, Oxford: Oxford University Press.</li>

<li>&ndash;&ndash;&ndash;, 2000. <em>The Good, the Bad, and the
Beautiful: Discourse about Values in Yoruba Culture</em>, Bloomington:
Indiana University Press.</li>

<li>Hare, R., 1993. <em>Without Conscience: The Disturbing World of
the Psychopaths Among Us</em>, New York: Guilford Press.</li>

<li>Harman, G., 1999. &ldquo;Moral philosophy meets social psychology:
Virtue ethics and the fundamental attribution error. &rdquo;
<em>Proceedings of the Aristotelian Society</em> (New Series),  119:
316&ndash;331.</li>

<li>&ndash;&ndash;&ndash;, 2000a. &ldquo;The nonexistence of character traits&rdquo;,
<em>Proceedings of the Aristotelian Society</em>, 100: 223&ndash;226.</li>

<li>&ndash;&ndash;&ndash;, 2000b. <em>Explaining Value and Other Essays in Moral
Philosophy</em>, New York: Oxford University Press.</li>

<li>&ndash;&ndash;&ndash;, 2003. No character or personality. <em>Business
Ethics Quarterly</em>, 13(1): 87&ndash;94.</li>

<li>&ndash;&ndash;&ndash;, 2008. &ldquo;Using a linguistic analogy to study
morality&rdquo;, in W. Sinnott-Armstrong (2008a), 345&ndash;352.</li>

<li>Hauser, M., 2006. <em>Moral Minds: How Nature Designed a Universal
Sense of Right and Wrong</em>, New York: Ecco Press/Harper Collins.</li>

<li>Hauser, M., Chomsky, N., and Fitch, W., 2002. &ldquo;The faculty
of language: What is it, who has it, and how does it
evolve&rdquo;, <em>Science</em>, 298: 1569&ndash;1579.</li>

<li>Hauser, M., Young, L., &amp; Cushman, F., 2008. &ldquo;Reviving
Rawls&rsquo;s linguistic analogy: Operative principles and the causal
structure of moral actions&rdquo;, in W. Sinnott-Armstrong (2008b),
107&ndash;144.</li>

<li>Haybron, D., 2008. <em>The Pursuit of Unhappiness</em>, Oxford:
Oxford University Press.</li>

<li>Heathwood, C., 2005. &ldquo;The problem of defective desires&rdquo;,
<em>Australasian Journal of Philosophy</em>, 83(4): 487&ndash;504.</li>

<li>Hurka, T., 2006. &ldquo;Virtuous act, virtuous dispositions&rdquo;,
<em>Analysis</em>, 66(289):  69&ndash;76.</li>

<li>Inbar, Y., Pizarro, Knobe, J. &amp; Bloom, P., 2009. &ldquo;Disgust
sensitivity predicts intuitive disapproval of
gays&rdquo;, <em>Emotion</em>, 9(3): 435&ndash;443.</li>

<li>Isen, A. &amp; Levin, P., 1972. &ldquo;The effect of feeling good on
helping: Cookies and kindness&rdquo;, <em>Journal of Personality and
Social Psychology</em>, 21: 384&ndash;88.</li>

<li>Jackson, F., 1998. <em>From Metaphysics to Ethics</em>, Oxford:
Oxford University Press.</li>

<li>Jensen, A. &amp; Moore, S., 1977. &ldquo;The effect of attribute
statements on cooperativeness and competitiveness in school-age
boys&rdquo;, <em>Child Development</em>, 48: 305&ndash;307.</li>

<li>Kahneman, D., Diener, E., &amp; Schwartz, N. (eds), (2003).
<em>Wellbeing: The Foundations of Hedonic Psychology</em>, New York:
Russell Sage.</li>

<li>Kahneman, D., 2011. <em>Thinking, Fast and Slow</em>, New York:
Farrar, Straus, &amp; Giroux.</li>

<li>Kamtekar, R., 2004. &ldquo;Situationism and virtue ethics on the content
of our character&rdquo;, <em>Ethics</em>, 114(3): 458&ndash;491.</li>

<li>Kelly, D., 2011. <em>Yuck! The Nature and Moral Significance of
Disgust</em>, Cambridge: MIT Press.</li>

<li>Kennett, J., 2006. &ldquo;Do psychopaths really threaten moral
rationalism?&rdquo; <em>Philosophical Explorations</em>, 9(1):
69&ndash;82.</li>

<li>Khoo, J. and Knobe, J., 2018. &ldquo;Moral disagreement and moral
semantics,&rdquo; <em>No&ucirc;s</em>, 52(1): 109&ndash;143.</li>

<li>Kline, R. B., 2005. <em>Principles and Practice of Structural
Equation Modeling</em>, New York: Guilford Press.</li>

<li>Kluckhohn, C., 1959. <em>Mirror for Man</em>, New York: McGraw
Hill.</li>

<li>Knobe, J., 2003. &ldquo;Intentional action and side effects in ordinary
language&rdquo;, <em>Analysis</em>, 63(3): 190&ndash;194.</li>

<li>&ndash;&ndash;&ndash;, 2004a. &ldquo;Folk psychology and folk morality: Response to
critics&rdquo;, <em>Journal of Theoretical and Philosophical Psychology</em>,
24: 270&ndash;279.</li>

<li>&ndash;&ndash;&ndash;, 2004b. &ldquo;Intention, intentional action and moral
considerations&rdquo;, <em>Analysis</em>, 2: 181&ndash;187.</li>

<li>&ndash;&ndash;&ndash;, 2006. &ldquo;The concept of intentional action: A case study in
the uses of folk psychology&rdquo;, <em>Philosophical Studies</em>, 130(2):
203&ndash;231.</li>

<li>&ndash;&ndash;&ndash;, 2007. &ldquo;Reason explanation in folk
psychology&rdquo;, <em>Midwest Studies in Philosophy</em>, 31:
90&ndash;107.</li>

<li>&ndash;&ndash;&ndash;, 2009. &ldquo;Cause and norm&rdquo;, <em>Journal of
Philosophy</em>, 106(11): 587&ndash;612.</li>

<li>&ndash;&ndash;&ndash;, 2010. &ldquo;Person as scientist, person as morality&rdquo;,
<em>Behavioral and Brain Sciences</em>, 33: 315&ndash;329.</li>

<li>&ndash;&ndash;&ndash;, 2011. &ldquo;Is morality relative? Depends on your
personality&rdquo;, <em>The Philosopher&rsquo;s Magazine</em>, 52:
66&ndash;71.</li>

<li>&ndash;&ndash;&ndash;, 2016. &ldquo;Experimental philosophy is
cognitive science&rdquo;, in J. Sytsma and W. Buckwalter (eds.), <em>A
Companion to Experimental Philosophy</em>, Oxford: Blackwell.</li>

<li>Knobe, J., &amp; Mendlow, G., 2004. &ldquo;The good, the bad and the
blameworthy: Understanding the role of evaluative reasoning in folk
psychology&rdquo;, <em>Journal of Theoretical and Philosophical</em>
<em>Psychology</em>, 24: 252&ndash;258.</li>

<li>Kohlberg, L., 1984. <em>The Psychology of Moral Development: The
Nature and Validity of Moral Stages</em>, San Francisco: Harper and
Row.</li>

<li>Kupperman, J., 2009. Virtue in virtue ethics. <em>Journal of
Ethics</em>, 13(2&ndash;3): 243&ndash;255.</li>

<li>Ladd, J., 1957. <em>The Structure of a Moral Code: A Philosophical
Analysis of Ethical Discourse Applied to the Ethics of the Navaho
Indians</em>, Cambridge, MA: Harvard University Press.</li>

<li>Landy, J. and Goodwin, G., 2015. &ldquo;Does incidental disgust
amplify moral judgment? A meta-analytic review of experimental
evidence&rdquo;, <em>Perspectives on Psychological Science</em>, 10(4):
518&ndash;536.</li>

<li>Lam, B., 2010. &ldquo;Are Cantonese speakers really descriptivists? 
Revisiting cross-cultural semantics&rdquo;, <em>Cognition</em>, 115:
320&ndash;332.</li>

<li>Latan&eacute;, B., &amp; Darley, J., 1968. &ldquo;Group
inhibition of bystander intervention in emergencies&rdquo;, <em>Journal
of Personality and Social Psychology</em>, 10: 215&ndash;221.</li>

<li>&ndash;&ndash;&ndash;, 1970. <em>The
Unresponsive Bystander: Why Doesn&rsquo;t He Help?</em> New
York: Appleton-Century-Crofts.</li>

<li>Latan&eacute;, B., &amp; Nida, S., 1981. &ldquo;Ten years of
research on group size and helping&rdquo;, <em>Psychological
Bulletin</em>, 89: 308&ndash;324.</li>

<li>Latan&eacute;, B., &amp; Rodin, J., 1969. &ldquo;A lady in distress:
inhibiting effects of friends and strangers on bystander
intervention&rdquo;, <em>Journal of Experimental Psychology</em>, 5:
189&ndash;202.</li>

<li>Likert, R., 1932. &ldquo;A technique for the measurement of
attitudes&rdquo;,
<em>Archives of Psychology</em>, 140: 1&ndash;55.</li>

<li>Loeb, D., 1998. &ldquo;Moral realism and the argument from
disagreement&rdquo;, <em>Philosophical Studies</em>, 90(3):
281&ndash;303.</li>

<li>&ndash;&ndash;&ndash;, 2003.  &ldquo;Gastronomic value realism: A
cautionary tale&rdquo;, <em>Journal of Theoretical and Philosophical
Psychology</em>, 21(1): 30&ndash;49.</li>

<li>Lucas, R., 2007. &ldquo;Adaptation and the set-point model of subjective
wellbeing: Does happiness change after major life events?&rdquo; <em>Current
Directions in Psychological Science</em>, 16(2): 75&ndash;9.</li>

<li>Lucas, R., Clark, C., Georgellis, Y., &amp; Diener, E., 2003.
&ldquo;Reexamining adaptation and the set point model of happiness: Reactions
to changes in marital status&rdquo;, <em>Journal of Personality and Social
Psychology</em>, 84(3): 527&ndash;539.</li>

<li>Luetge, C., Rusch, H., and Uhl, M. (eds.), 2014. <em>Experimental
Ethics: Towards an Empirical Moral Philosophy</em>, London:
Palgrave.</li>

<li>Machery, E., Mallon, R., Nichols, S., &amp; Stich, S., 2004.
&ldquo;Semantics, cross-cultural style&rdquo;, <em>Cognition</em>,
92(3): B1&ndash;B12.</li>

<li>MacIntyre, A., 1998. <em>A Short History of Ethics: A History of
Moral Philosophy from the Homeric Age to the Twentieth Century</em>,
South Bend, IN: University of Notre Dame Press</li>

<li>&ndash;&ndash;&ndash;, 1984. <em>After Virtue: A Study in Moral
Theory</em>, South Bend, IN: University of Notre Dame Press.</li>

<li>Mackie, J. L., 1977. <em>Ethics: Inventing Right and Wrong</em>,
New York: Penguin.</li>

<li>Maibom, H. L., 2005. &ldquo;Moral unreason: The case of
psychopathy.&ldquo; <em>Mind and Language</em>, 20(2):
237&ndash;57.</li>

<li>Matthews, K. E., &amp; Cannon, L. K., 1975. &ldquo;Environmental
noise level as a determinant of helping behavior&rdquo;, <em>Journal of
Personality and Social Psychology</em>, 32: 571&ndash;577.</li>

<li>May, J., 2014. &ldquo;Does disgust influence moral judgment?&rdquo;
<em>Australasian Journal of Philosophy</em>,
92(1): 125&ndash;141.</li>

<li>McGilvray, J., 2005. <em>The Cambridge Companion to Chomsky.</em>
Cambridge: Cambridge University Press.</li>

<li>Merritt, M., 2000. &ldquo;Virtue ethics and situationist personality
psychology&rdquo;, <em>Ethical Theory and Moral Practice</em>, 3(4):
365&ndash;383.</li>

<li>Mikhail, J., 2005. &ldquo;Chomsky and moral philosophy&rdquo;, in J.
McGilvray (2005), 235&ndash;53.</li>

<li>&ndash;&ndash;&ndash;, 2007. &ldquo;Universal moral grammar:
Theory, evidence, and the future&rdquo;, <em>Trends in Cognitive
Sciences</em>, 11: 143&ndash;152.</li>

<li>&ndash;&ndash;&ndash;, 2008. &ldquo;The poverty of the moral
stimulus&rdquo;, in W.  Sinnott-Armstrong (2008a), 353&ndash;360.</li>

<li>&ndash;&ndash;&ndash;, 2009. &ldquo;Moral grammar and intuitive
jurisprudence: A formal model of unconscious moral and legal
language&rdquo;, in B. H. Ross, D. M., Bartels, C. W., Bauman,
L. J. Skitka, and D. L. Medin (eds.), <em>Psychology of Learning and
Motivation</em> (Volume 50: Moral Judgment and Decision
Making). New York: Academic Press.</li>

<li>&ndash;&ndash;&ndash;, 2011. <em>Elements of Moral Cognition: Rawls&rsquo;s
Linguistic Analogy and the Cognitive Science of Moral and Legal
Judgment</em>, Cambridge: Cambridge University Press.</li>

<li>Miller, C., 2013. <em>Moral Character: An Empirical Theory</em>,
Oxford: Oxford University Press.</li>

<li>&ndash;&ndash;&ndash;, 2014. <em>Character and Moral Psychology</em>,
Oxford: Oxford University Press.</li>

<li>Miller, R., Brickman, P., &amp; Bolen, D., 1975. &ldquo;Attribution
versus persuasion as a means for modifying behavior&rdquo;, <em>Journal
of Personality and Social Psychology</em>, 31(3): 430&ndash;441.</li>

<li>Mischel, W., 1968. <em>Personality and Assessment</em>, 
New York: Wiley.</li>

<li>Moody-Adams, M. M., 1997. <em>Fieldwork in Familiar Places:Morality,
Culture, and Philosophy</em>, Cambridge, MA: Harvard University
Press.</li>

<li>Nadelhoffer, T., 2004. &ldquo;On praise, side effects, and folk
ascriptions of intentionality&rdquo;, <em>Journal of Theoretical and
Philosophical Psychology</em>, 24: 196&ndash;213.</li>

<li>&ndash;&ndash;&ndash;, 2006. &ldquo;Bad acts, blameworthy agents, and
intentional actions: Some problems for jury impartiality&rdquo;,
<em>Philosophical Explorations</em>, 9: 203&ndash;220.</li>

<li>Naess, A., 1938. <em>Truth as Conceived by Those Who are Not
Professional Philosophers</em>, Oslo: Jacob Dybwad</li>

<li>Nichols, S., 2002. &ldquo;On the genealogy of norms: A case for the role
of emotion in cultural evolution&rdquo;, <em>Philosophy of Science</em>, 69:
234&ndash;255.</li>

<li>&ndash;&ndash;&ndash;, 2004. <em>Sentimental Rules</em>, Oxford:
Oxford University Press.</li>

<li>Nichols, S., Kumar, S., Lopez, T., Ayars, A., and Chan,
H.-Y., 2016. &ldquo;Rational learners and moral
rules&rdquo;, <em>Mind and Language</em>, 31(5): 530&ndash;554.</li>

<li>Nozick, R., 1974. <em>Anarchy, State, and Utopia</em>, Basic Books.</li>

<li>Nussbaum, M., 2001. <em>The Fragility of Goodness: Luck and Ethics in
Greek Tragedy and Philosophy</em>, Cambridge: Cambridge University
Press.</li>

<li>Pereboom, D., 2001. <em>Living Without Free Will</em>, New York:
Cambridge University Press.</li>

<li>Pettit, D. &amp; Knobe, J., 2009. &ldquo;The pervasive impact of moral
judgment&rdquo;, <em>Mind and Language</em>, 24(5): 586&ndash;604.</li>

<li>Phelan, M., &amp; Sarkissian, H., 2009. &ldquo;Is the
&lsquo;trade-off hypothesis&rsquo; worth trading for?&rdquo; <em>Mind
and Language</em>, 24: 164&ndash;180.</li>

<li>Phillips, J., Misenheimer, L., &amp; Knobe, J., 2011. &ldquo;The
ordinary concept of happiness (and others like it)&rdquo;, <em>Emotion
Review</em>, 71: 929&ndash;937.</li>

<li>Phillips, J., Nyholm, S., &amp; Liao, S., forthcoming. &ldquo;The
good in happiness&rdquo;, <em>Oxford Studies in Experimental
Philosophy</em> (Volume 1), Oxford: Oxford University Press.</li>

<li>Piaget, J., 1965. <em>The Moral Judgment of the Child</em>,
New York: Free Press.</li>

<li>Plakias, A., 2017. &ldquo;The response model of moral
disgust&rdquo;, <em>Synthese</em>, first online 3 June 2017. 
doi:10.1007/s11229-017-1455-3</li>

<li>&ndash;&ndash;&ndash;, 2013. &ldquo;The good and the
gross&rdquo;, <em>Ethical Theory and Moral Practice</em>, 16(2):
261&ndash;78</li>

<li>Prinz, J., 2007. <em>The Emotional Construction of Morals</em>,
Oxford, Oxford University Press.</li>

<li>&ndash;&ndash;&ndash;, 2008. &ldquo;Resisting the linguistic analogy: A
commentary on Hauser, Young, and Cushman&rdquo;, in
W. Sinnott-Armstrong (2008b), 157&ndash;170.</li>

<li>Railton, P., 2014. &ldquo;The affective dog and its rational
tale: Intuition and attunement&rdquo;, <em>Ethics</em>, 124(4):
813&ndash;859.</li>

<li>Rauthmann, J. and Sherman, R., 2018. &ldquo;The description of
situations: Towards replicable domains of psychological situation
characteristics&rdquo;, <em>Journal of Personality and Social
Psychology</em>, 114(3): 482&ndash;488.</li>

<li>Rawls, J., 1971. <em>A Theory of Justice</em>, Cambridge, MA:
Harvard University Press.</li>

<li>Redelmeier, D. &amp; Kahneman, D., 1996. &ldquo;Patients&rsquo;
memories of painful medical treatments: Real-time and retrospective
evaluations of two minimally invasive
procedures&rdquo;, <em>Pain</em>, 1: 3&ndash;8.</li>

<li>Regan, J., 1971. &ldquo;Guilt, perceived injustice, and altruistic
behavior&rdquo;, <em>Journal of Personality and Social Psychology</em>,
18: 124&ndash;132.</li>

<li>Robinson, B., Stey, P., &amp; Alfano, M., 2013. &ldquo;Virtue and vice
attributions in the business context: An experimental investigation&rdquo;,
<em>Journal of Business Ethics</em>, 113(4): 649&ndash;661.</li>

<li>Roedder, E. &amp; Harman, G., 2010. &ldquo;Linguistics and moral
theory&rdquo;, in J. Doris (ed.), <em>The Moral Psychology
Handbook</em>, 273&ndash;296. Oxford University Press.</li>

<li>R&ouml;nnow-Rasumussen, T., 2011. <em>Personal Value</em>, Oxford:
Oxford University Press.</li>

<li>Roskies, A., 2003. &ldquo;Are ethical judgments intrinsically
motivational? Lessons from &lsquo;acquired sociopathy.&rsquo; &rdquo;
<em>Philosophical Psychology</em>, 16(1): 51&ndash;66.</li>

<li>Russell, D., 2009. <em>Practical Intelligence and the Virtues</em>,
Oxford: Oxford University Press.</li>

<li>Sarkissian, H., Park, J., Tien, D., Wright, J. C., &amp; Knobe,
J., 2011. &ldquo;Folk moral relativism&rdquo;, <em>Mind and
Language</em>, 26(4): 482&ndash;505.</li>

<li>Sayre-McCord, Geoffrey (ed.), 1988. <em>Essays on Moral
Realism</em>, Ithaca: Cornell University Press.</li>

<li>Sayre-McCord, Geoffrey,, 2008. &ldquo;Moral Semantics and Empirical
Inquiry&rdquo;, in Sinnott-Armstrong (2008b), 403&ndash;412.</li>

<li>Scaife, R. &amp; Webber, J., 2013. &ldquo;Intentional
side-effects of action&rdquo;, <em>Journal of Moral
Philosophy</em>, 10: 179&ndash;203.</li>

<li>Schimmack, U. &amp; Oishi, S., 2005. &ldquo;The influence of
chronically and temporarily accessible information on life
satisfaction judgments&rdquo;, <em>Journal of Personality and Social
Psychology</em>, 89(3): 395&ndash;406.</li>

<li>Schnall, S., Haidt, J., and Clore, 2008. &ldquo;Disgust as
embodied moral judgment&rdquo;, <em>Personality and Social Psychology
Bulletin</em>, 34(8): 1096&ndash;1109.</li>

<li>Schwartz, S. &amp; Gottlieb, A., 1991. &ldquo;Bystander anonymity and
reactions to emergencies&rdquo;, <em>Journal of Personality and Social
Psychology</em>, 39: 418&ndash;430.</li>

<li>Schwitzgebel, E., 2009. &ldquo;Do ethicists steal more books?&rdquo;
<em>Philosophical Psychology</em>, 22(6): 711&ndash;725</li>

<li>Schwitzgebel, E. &amp; Cushman, F., 2012. &ldquo;Expertise in moral
reasoning? Order effects on moral judgment in professional
philosophers and non-philosophers&rdquo;, <em>Mind and Language</em>,
27(2): 135&ndash;153.</li>

<li>Schwitzgebel, E. &amp; Rust, J., 2010. &ldquo;Do ethicists and
political philosophers vote more often than other professors?&rdquo;
<em>Review of Philosophy and Psychology</em>, 1(2): 189&ndash;199.</li>

<li>Schwitzgebel, E., Rust, J., Huang, L., Moore, A., &amp; Coates,
J., 2011. &ldquo;Ethicists&rsquo; courtesy at philosophy conferences&rdquo;,
<em>Philosophical Psychology</em>, 25(3): 331&ndash;340.</li>

<li>Shafer&ndash;Landau, R., 2003. <em>Moral Realism: A
Defence</em>, Oxford: Oxford University Press.</li>

<li>Singer, P., 2005.&ldquo;Ethics and Intuitions&rdquo;, <em>The Journal of
Ethics</em>, 9(3&ndash;4): 331&ndash;352. </li>

<li>Singer, P. &amp; de Lazari-Radak, K., forthcoming. <em>From the
Point of View of the Universe: Sidgwick and Contemporary
Ethics</em>, Oxford: Oxford University Press</li>

<li>Sinnott-Armstrong, W., 2009. &ldquo;Mixed-up
meta-ethics&rdquo;, <em>Philosophical Issues</em>, 19(1):
235&ndash;56</li>

<li>&ndash;&ndash;&ndash; (ed.), 2008a. <em>Moral Psychology: The
Evolution of Morality: Adaptations and Innateness</em> (Volume 1),
Cambridge, MA: MIT Press.</li>

<li>&ndash;&ndash;&ndash; (ed.), 2008b. <em>Moral Psychology:
 The Cognitive Science of Morality: Intuition and Diversity</em>
(Volume 2), Cambridge, MA: MIT Press.</li>

<li>&ndash;&ndash;&ndash; (ed.), 2008c. <em>Moral Psychology: The
Neuroscience of Morality: Emotion, Brain Disorders, and
Development</em> (Volume 3), Cambridge, MA: MIT Press.</li>

<li>&ndash;&ndash;&ndash;, 2008d. &ldquo;Framing moral intuitions&rdquo;,
In Sinnott-Armstrong (2008b), 47&ndash;76.</li>

<li>Sinnott-Armstrong, W., Mallon, R., McCoy, T., &amp; Hull, J.,
2008. &ldquo;Intention, temporal order, and moral
judgments&rdquo;, <em>Mind and Language</em>, 23(1): 90&ndash;106.</li>

<li>Smith, M., 1994. <em>The Moral Problem</em>,  Oxford: Blackwell.</li>

<li>Snow, N., 2010. <em>Virtue as Social Intelligence: An Empirically
Grounded Theory</em>, New York: Routledge.</li>

<li>Sreenivasan, G., 2002. &ldquo;Errors about errors: Virtue theory and
trait attribution&rdquo;, <em>Mind</em>, 111(441): 47&ndash;66.</li>

<li>Sripada, C., 2005. &ldquo;Punishment and the strategic structure
of moral systems&rdquo;, <em>Biology and Philosophy</em>, 20(4):
767&ndash;789.</li>

<li>&ndash;&ndash;&ndash;, 2010. &ldquo;The deep self model and
asymmetries in folk judgments about intentional
action&rdquo;, <em>Philosophical Studies</em>, 151(2):
159&ndash;176.</li>

<li>&ndash;&ndash;&ndash;, 2011. &ldquo;What makes a manipulated agent unfree?&rdquo;
<em>Philosophy and Phenomenological Research</em>, 85(3): 563&ndash;593.
doi:10.1111/j.1933-1592.2011.00527.x</li>

<li>&ndash;&ndash;&ndash;, 2012. &ldquo;Mental state attributions and the
side-effect effect&rdquo;, <em>Journal of Experimental
Psychology</em>, 48(1): 232&ndash;238.</li>

<li>Sripada, C. &amp; Konrath, S., 2011. &ldquo;Telling more than we can know
about intentional action&rdquo;, <em>Mind and Language</em>, 26(3):
353&ndash;380.</li>

<li>Stich, S. &amp; Weinberg, J., 2001. &ldquo;Jackson&rsquo;s empirical
assumptions&rdquo;, <em>Philosophy and Phenomenological Research</em>, 62(3):
637&ndash;643.</li>

<li>Strack, F., Martin, L., &amp; Schwartz, N., 1988. &ldquo;Priming and
communication: Social determinants of information use in judgments of
life satisfaction&rdquo;, <em>European Journal of Social Psychology</em>, 18:
429&ndash;442.</li>

<li>Strandberg, C. &amp; Bj&ouml;rklund, F., 2013. &ldquo;Is moral
internalism supported by folk intuitions?&rdquo; <em>Philosophical
Psychology</em>, 26(3): 319&ndash;335.
</li>

<li>Strawson, P. F., 1962. &ldquo;Freedom and
resentment&rdquo;, <em>Proceedings of the British Academy</em>, 48:
1&ndash;25.</li>

<li>Strohminger, N., Caldwell, B., Cameron, D., Schaich Borg, J., and
Sinnott-Armstrong, W., 2014. &ldquo;Implicit morality: A
methodological survey,&rdquo; in C. Luetge, H. Rusch, and M. Uhl 2014:
133&ndash;156.</li>

<li>Sturgeon, N., 1988. &ldquo;Moral Explanations,&rdquo; in
Sayre-McCord 1988: 229&ndash;255.</li>

<li>Sytsma, J. &amp; Livengood, J., 2011. &ldquo;A new perspective
concerning experiments on semantic intuitions&rdquo;, <em>Australasian
Journal of Philosophy</em>, 89(2): 315&ndash;332.</li>

<li>Thomson, J. J., 1971. &ldquo;A defense of
abortion&rdquo;, <em>Philosophy and Public Affairs</em>, 1(1):
47&ndash;66.</li>

<li>Trivers, R. L., 1971. &ldquo;The evolution of reciprocal altruism&rdquo;,
<em>Quarterly Review of Biology</em>, 46: 35&ndash;57.</li>

<li>Turiel, E., 1983. <em>The Development of Social Knowledge: Moral
and Social Convention</em>, Cambridge: Cambridge University Press.</li>

<li>Wagenmakers, E.-J., Wetzels, R., Borsboom, D., van der Maas, H.,
&amp; Kievit, R., 2012. &ldquo;An agenda for purely confirmatory
research&rdquo;, <em>Perspectives on Psychological Science</em>, 7(6):
632&ndash;638.</li>

<li>Weijers, D., 2014. &ldquo;Nozick&rsquo;s experience machine is
dead, long live the experience machine!&rdquo; <em>Philosophical
Psychology</em>, 27(4): 513&ndash;535.</li>

<li>Weinberg, J., Nichols, S., &amp; Stich, S., 2008. &ldquo;Normativity
and epistemic intuitions&rdquo;, in Knobe &amp; Nichols (eds.)
<em>Experimental Philosophy</em>, Cambridge: Cambridge
University Press, 17&ndash;46.</li>

<li>Weyant, J., 1978. &ldquo;Effects of mood states, costs, and
benefits on helping&rdquo;, <em>Journal of Personality and Social
Psychology</em>, 36: 1169&ndash;1176.</li>

<li>Wheatley, T. and Haidt, J., 2005. &ldquo;Hypnotically induced
disgust makes moral judgments more severe&rdquo;, <em>Psychological
Science</em>, 16(10): 780&ndash;784.</li>

<li>Wiegman, I., 2017. &ldquo;The evolution of retribution: Intuition
undermined&rdquo;, <em>Pacific Philosophical Quarterly</em>, 98(2):
490&ndash;510.</li>

<li>Wright, J. C., Grandjean, P., &amp; McWhite, C., 2013. &ldquo;The
meta-ethical grounding of our moral beliefs: Evidence for meta-ethical
pluralism&rdquo;, <em>Philosophical Psychology</em>, 26(3):
336&ndash;361.</li>

<li>Wright, J. C. &amp; H Sarkissian (eds.), 2014. <em>Advances in
Experimental Moral Psychology: Affect, Character, and Commitment</em>,
London: Continuum.</li>

<li>Yong, E., 2012. &ldquo;Nobel laureate challenges psychologists to clean up
their act: Social-priming research needs &lsquo;daisy chain&rsquo; of
replication&rdquo;, <em>Nature News</em>, 
<a href="https://www.nature.com/news/nobel-laureate-challenges-psychologists-to-clean-up-their-act-1.11535" target="other">available online</a>, 
doi:10.1038/nature.2012.11535</li>

<li>Zagzebski, L., 2010. &ldquo;Exemplarist virtue theory&rdquo;,
<em>Metaphilosophy</em>, 41(1): 41&ndash;57.</li>

<li>Zhong, C.-B., Bohns, V., &amp; Gino, F., 2010. &ldquo;Good lamps are the
best police: Darkness increases dishonesty and self-interested
behavior&rdquo;, <em>Psychological Science</em>, 21(3): 311&ndash;314.</li>

</ul>

</div>

<div id="academic-tools">

<h2><a id="Aca">Academic Tools</a></h2>

<blockquote>
<table class="vert-top">
<tr>
<td><img src="../../symbols/sepman-icon.jpg" alt="sep man icon" /></td>
<td><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=experimental-moral" target="other">How to cite this entry</a>.</td>
</tr>

<tr>
<td><img src="../../symbols/sepman-icon.jpg" alt="sep man icon" /></td>
<td><a href="https://leibniz.stanford.edu/friends/preview/experimental-moral/" target="other">Preview the PDF version of this entry</a> at the
 <a href="https://leibniz.stanford.edu/friends/" target="other">Friends of the SEP Society</a>.</td>
</tr>

<tr>
<td><img src="../../symbols/inpho.png" alt="inpho icon" /></td>
<td><a href="https://www.inphoproject.org/entity?sep=experimental-moral&amp;redirect=True" target="other">Look up topics and thinkers related to this entry</a>
 at the Internet Philosophy Ontology Project (InPhO).</td>
</tr>

<tr>
<td><img src="../../symbols/pp.gif" alt="phil papers icon" /></td>
<td><a href="http://philpapers.org/sep/experimental-moral/" target="other">Enhanced bibliography for this entry</a>
at <a href="http://philpapers.org/" target="other">PhilPapers</a>, with links to its database.</td>
</tr>

</table>
</blockquote>

</div>

<div id="other-internet-resources">

<h2><a id="Oth">Other Internet Resources</a></h2>

<ul>

<li>Cova, F., Strickland, B., Abatista, A. G. F., Allard, A., Andow,
J., Attie, M., &hellip; Zhou, X., 2018,
 <a href="http://doi.org/10.17605/OSF.IO/DVKPR" target="other">Estimating the Reproducibility of Experimental Philosophy</a>, 21 April 2018, Open Science Framework.</li>

<li><a href="http://www.moralpsychology.net/group/" target="other">Moral Psychology Research Group</a></li>

<li><a href="http://philosophycommons.typepad.com/xphi/" target="other">Experimental Philosophy Blog</a></li>

<li><a href="http://experimental-philosophy.yale.edu/xphipage/Experimental Philosophy-Replications.html" target="other">Replications in Experimental Philosophy</a></li>

<li><a href="http://bloggingheads.tv/programs/mind-report" target="other">Blogging Heads TV: Mind Report</a></li>

<li><a href="http://www.ppc.sas.upenn.edu/" target="other">Positive Psychology Center</a></li>

<li><a href="http://www.philosophyexperiments.com/" target="other">Online Experiments</a></li>

<li><a href="http://muepl.wordpress.com/" target="other">University of Missouri Experimental Philosophy Lab</a></li>

<li><a href="http://pantheon.yale.edu/~jk762/lab/Lab.html" target="other">Yale Experimental Philosophy Lab</a></li>

<li><a href="http://portoxphilab.wordpress.com/" target="other">Porto Experimental Philosophy Lab</a></li>

<li><a href="http://www.moralfoundations.org/" target="other">Moral Foundations</a></li>

<li><a href="http://sites.sas.upenn.edu/behav-ethics/" target="other">UPenn Behavioral Ethics Lab</a></li>

</ul>

</div>

<div id="related-entries">

<h2><a id="Rel">Related Entries</a></h2>

<p>

 <a href="../moral-character/index.html">character, moral</a> |
 <a href="../moral-character-empirical/index.html">character, moral: empirical approaches</a> |
 <a href="../moral-cognitivism/index.html">cognitivism vs. non-cognitivism, moral</a> |
 <a href="../emotion/index.html">emotion</a> |
 <a href="../ethics-virtue/index.html">ethics: virtue</a> |
 <a href="../intuition/index.html">intuition</a> |
 <a href="../moral-anti-realism/index.html">moral anti-realism</a> |
 <a href="../moral-epistemology/index.html">moral epistemology</a> |
 <a href="../morality-biology/index.html">morality: and evolutionary biology</a> |
 <a href="../moral-psych-emp/index.html">moral psychology: empirical approaches</a> |
 <a href="../moral-realism/index.html">moral realism</a> |
 <a href="../moral-relativism/index.html">moral relativism</a> |
 <a href="../well-being/index.html">well-being</a>

</p>

</div>

<div id="acknowledgments">

<h3>Acknowledgments</h3>

<p>

The authors thank James Beebe, Gunnar Bj&ouml;rnsson, Wesley
Buckwalter, Roxanne DesForges, John Doris, Gilbert Harman, Dan
Haybron, Chris Heathwood, Antti Kauppinen, Daniel Kelly, Joshua Knobe,
Clayton Littlejohn, Edouard Machery, Josh May, John Mikhail, Sven
Nyholm, Brian Robinson, Chandra Sripada, Carissa Veliz, several
anonymous referees, and the editors of this encyclopedia for helpful
comments and suggestions.</p>

</div>

<script type="text/javascript" src="local.js"></script>
<script type="text/javascript" src="../../MathJax/MathJaxdda6.js?config=TeX-AMS-MML_HTMLorMML"></script>

</div><!-- #aueditable --><!--DO NOT MODIFY THIS LINE AND BELOW-->

<!-- END ARTICLE HTML -->

</div> <!-- End article-content -->

  <div id="article-copyright">
    <p>
 <a href="../../info.html#c">Copyright &copy; 2018</a> by

<br />
<a href="http://www.tbm.tudelft.nl/en/about-faculty/departments/values-technology-and-innovation/sections/ethicsphilosophy-of-technology/staff/mark-alfano/" target="other">Mark Alfano</a>
&lt;<a href="m&#97;ilto:mark&#37;2ealfano&#37;40gmail&#37;2ecom"><em>mark<abbr title=" dot ">&#46;</abbr>alfano<abbr title=" at ">&#64;</abbr>gmail<abbr title=" dot ">&#46;</abbr>com</em></a>&gt;<br />
Don Loeb
<br />
Alexandra Plakias
&lt;<a href="m&#97;ilto:aplakias&#37;40hamilton&#37;2eedu"><em>aplakias<abbr title=" at ">&#64;</abbr>hamilton<abbr title=" dot ">&#46;</abbr>edu</em></a>&gt;
    </p>
  </div>

</div> <!-- End article -->

<!-- NOTE: article banner is outside of the id="article" div. -->
<div id="article-banner" class="scroll-block">
  <div id="article-banner-content">
    <a href="../../fundraising/index.html">
    Open access to the SEP is made possible by a world-wide funding initiative.<br />
    The Encyclopedia Now Needs Your Support<br />
    Please Read How You Can Help Keep the Encyclopedia Free</a>
  </div>
</div> <!-- End article-banner -->

    </div> <!-- End content -->

    <div id="footer">

      <div id="footer-menu">
        <div class="menu-block">
          <h4><i class="icon-book"></i> Browse</h4>
          <ul role="menu">
            <li><a href="../../contents.html">Table of Contents</a></li>
            <li><a href="../../new.html">What's New</a></li>
            <li><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/random">Random Entry</a></li>
            <li><a href="../../published.html">Chronological</a></li>
            <li><a href="../../archives/index.html">Archives</a></li>
          </ul>
        </div>
        <div class="menu-block">
          <h4><i class="icon-info-sign"></i> About</h4>
          <ul role="menu">
            <li><a href="../../info.html">Editorial Information</a></li>
            <li><a href="../../about.html">About the SEP</a></li>
            <li><a href="../../board.html">Editorial Board</a></li>
            <li><a href="../../cite.html">How to Cite the SEP</a></li>
            <li><a href="../../special-characters.html">Special Characters</a></li>
            <li><a href="../../tools/index.html">Advanced Tools</a></li>
            <li><a href="../../contact.html">Contact</a></li>
          </ul>
        </div>
        <div class="menu-block">
          <h4><i class="icon-leaf"></i> Support SEP</h4>
          <ul role="menu">
            <li><a href="../../support/index.html">Support the SEP</a></li>
            <li><a href="../../support/friends.html">PDFs for SEP Friends</a></li>
            <li><a href="../../support/donate.html">Make a Donation</a></li>
            <li><a href="../../support/sepia.html">SEPIA for Libraries</a></li>
          </ul>
        </div>
      </div> <!-- End footer menu -->

      <div id="mirrors">
        <div id="mirror-info">
          <h4><i class="icon-globe"></i> Mirror Sites</h4>
          <p>View this site from another server:</p>
        </div>
        <div class="btn-group open">
          <a class="btn dropdown-toggle" data-toggle="dropdown" href="https://plato.stanford.edu/">
            <span class="flag flag-usa"></span> USA (Main Site) <span class="caret"></span>
            <span class="mirror-source">Philosophy, Stanford University</span>
          </a>
          <ul class="dropdown-menu">
            <li><a href="../../mirrors.html">Info about mirror sites</a></li>
          </ul>
        </div>
      </div> <!-- End mirrors -->
      
      <div id="site-credits">
        <p>The Stanford Encyclopedia of Philosophy is <a href="../../info.html#c">copyright &copy; 2021</a> by <a href="http://mally.stanford.edu/">The Metaphysics Research Lab</a>, Department of Philosophy, Stanford University</p>
        <p>Library of Congress Catalog Data: ISSN 1095-5054</p>
      </div> <!-- End site credits -->

    </div> <!-- End footer -->

  </div> <!-- End container -->

   <!-- NOTE: Script required for drop-down button to work (mirrors). -->
  <script>
    $('.dropdown-toggle').dropdown();
  </script>

</body>

<!-- Mirrored from seop.illc.uva.nl/entries/experimental-moral/ by HTTrack Website Copier/3.x [XR&CO'2014], Wed, 22 Jun 2022 19:47:17 GMT -->
</html>
