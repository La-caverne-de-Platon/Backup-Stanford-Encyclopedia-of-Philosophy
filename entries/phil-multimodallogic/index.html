<!DOCTYPE html>
<!--[if lt IE 7]> <html class="ie6 ie"> <![endif]-->
<!--[if IE 7]>    <html class="ie7 ie"> <![endif]-->
<!--[if IE 8]>    <html class="ie8 ie"> <![endif]-->
<!--[if IE 9]>    <html class="ie9 ie"> <![endif]-->
<!--[if !IE]> --> <html> <!-- <![endif]-->

<!-- Mirrored from seop.illc.uva.nl/entries/phil-multimodallogic/ by HTTrack Website Copier/3.x [XR&CO'2014], Wed, 22 Jun 2022 19:52:59 GMT -->
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>
Philosophical Aspects of Multi-Modal Logic (Stanford Encyclopedia of Philosophy)
</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="robots" content="noarchive, noodp" />
<meta property="citation_title" content="Philosophical Aspects of Multi-Modal Logic" />
<meta property="citation_author" content="Smets, Sonja" />
<meta property="citation_author" content="Vel&aacute;zquez-Quesada, Fernando" />
<meta property="citation_publication_date" content="2019/06/03" />
<meta name="DC.title" content="Philosophical Aspects of Multi-Modal Logic" />
<meta name="DC.creator" content="Smets, Sonja" />
<meta name="DC.creator" content="Vel&aacute;zquez-Quesada, Fernando" />
<meta name="DCTERMS.issued" content="2019-06-03" />
<meta name="DCTERMS.modified" content="2019-06-03" />

<!-- NOTE: Import webfonts using this link: -->
<link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,300,600,200&amp;subset=latin,latin-ext" rel="stylesheet" type="text/css" />

<link rel="stylesheet" type="text/css" media="screen,handheld" href="../../css/bootstrap.min.css" />
<link rel="stylesheet" type="text/css" media="screen,handheld" href="../../css/bootstrap-responsive.min.css" />
<link rel="stylesheet" type="text/css" href="../../css/font-awesome.min.css" />
<!--[if IE 7]> <link rel="stylesheet" type="text/css" href="../../css/font-awesome-ie7.min.css"> <![endif]-->
<link rel="stylesheet" type="text/css" media="screen,handheld" href="../../css/style.css" />
<link rel="stylesheet" type="text/css" media="print" href="../../css/print.css" />
<link rel="stylesheet" type="text/css" href="../../css/entry.css" />
<!--[if IE]> <link rel="stylesheet" type="text/css" href="../../css/ie.css" /> <![endif]-->
<script type="text/javascript" src="../../js/jquery-1.9.1.min.js"></script>
<script type="text/javascript" src="../../js/bootstrap.min.js"></script>

<!-- NOTE: Javascript for sticky behavior needed on article and ToC pages -->
<script type="text/javascript" src="../../js/jquery-scrolltofixed-min.js"></script>
<script type="text/javascript" src="../../js/entry.js"></script>

<!-- SEP custom script -->
<script type="text/javascript" src="../../js/sep.js"></script>
</head>

<!-- NOTE: The nojs class is removed from the page if javascript is enabled. Otherwise, it drives the display when there is no javascript. -->
<body class="nojs article" id="pagetopright">
<div id="container">
<div id="header-wrapper">
  <div id="header">
    <div id="branding">
      <div id="site-logo"><a href="../../index.html"><img src="../../symbols/sep-man-red.png" alt="SEP logo" /></a></div>
      <div id="site-title"><a href="../../index.html">Stanford Encyclopedia of Philosophy</a></div>
    </div>
    <div id="navigation">
      <div class="navbar">
        <div class="navbar-inner">
          <div class="container">
            <button class="btn btn-navbar collapsed" data-target=".collapse-main-menu" data-toggle="collapse" type="button"> <i class="icon-reorder"></i> Menu </button>
            <div class="nav-collapse collapse-main-menu in collapse">
              <ul class="nav">
                <li class="dropdown open"><a id="drop1" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-book"></i> Browse</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop1">
                    <li><a href="../../contents.html">Table of Contents</a></li>
                    <li><a href="../../new.html">What's New</a></li>
                    <li><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/random">Random Entry</a></li>
                    <li><a href="../../published.html">Chronological</a></li>
                    <li><a href="../../archives/index.html">Archives</a></li>
                  </ul>
                </li>
                <li class="dropdown open"><a id="drop2" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-info-sign"></i> About</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop2">
                    <li><a href="../../info.html">Editorial Information</a></li>
                    <li><a href="../../about.html">About the SEP</a></li>
                    <li><a href="../../board.html">Editorial Board</a></li>
                    <li><a href="../../cite.html">How to Cite the SEP</a></li>
                    <li><a href="../../special-characters.html">Special Characters</a></li>
                    <li><a href="../../tools/index.html">Advanced Tools</a></li>
                    <li><a href="../../contact.html">Contact</a></li>
                  </ul>
                </li>
                <li class="dropdown open"><a id="drop3" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-leaf"></i> Support SEP</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop3">
                    <li><a href="../../support/index.html">Support the SEP</a></li>
                    <li><a href="../../support/friends.html">PDFs for SEP Friends</a></li>
                    <li><a href="../../support/donate.html">Make a Donation</a></li>
                    <li><a href="../../support/sepia.html">SEPIA for Libraries</a></li>
                  </ul>
                </li>
              </ul>
            </div>
          </div>
        </div>
      </div>
    </div>
    <!-- End navigation -->
    
    <div id="search">
      <form id="search-form" method="get" action="https://seop.illc.uva.nl/search/searcher.py">
        <input type="search" name="query" placeholder="Search SEP" />
        <div class="search-btn-wrapper"><button class="btn search-btn" type="submit"><i class="icon-search"></i></button></div>
      </form>
    </div>
    <!-- End search --> 
    
  </div>
  <!-- End header --> 
</div>
<!-- End header wrapper -->

<div id="content">

<!-- Begin article sidebar -->
<div id="article-sidebar" class="sticky">
  <div class="navbar">
    <div class="navbar-inner">
      <div class="container">
        <button class="btn btn-navbar" data-target=".collapse-sidebar" data-toggle="collapse" type="button"> <i class="icon-reorder"></i> Entry Navigation </button>
        <div id="article-nav" class="nav-collapse collapse-sidebar in collapse">
          <ul class="nav">
            <li><a href="#toc">Entry Contents</a></li>
            <li><a href="#Bib">Bibliography</a></li>
            <li><a href="#Aca">Academic Tools</a></li>
            <li><a href="https://leibniz.stanford.edu/friends/preview/phil-multimodallogic/">Friends PDF Preview <i class="icon-external-link"></i></a></li>
            <li><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=phil-multimodallogic">Author and Citation Info <i class="icon-external-link"></i></a> </li>
            <li><a href="#pagetopright" class="back-to-top">Back to Top <i class="icon-angle-up icon2x"></i></a></li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</div>
<!-- End article sidebar --> 

<!-- NOTE: Article content must have two wrapper divs: id="article" and id="article-content" -->
<div id="article">
<div id="article-content">

<!-- BEGIN ARTICLE HTML -->


<div id="aueditable"><!--DO NOT MODIFY THIS LINE AND ABOVE-->

<h1>Philosophical Aspects of Multi-Modal Logic</h1><div id="pubinfo"><em>First published Mon Jun 3, 2019</em></div>

<div id="preamble">

<blockquote class="bigindent">

<p>
Here is what I consider one of the biggest mistakes of all in modal
logic: concentration on a system with just one modal operator. The
only way to have any philosophically significant results in deontic
logic or epistemic logic is to combine these operators with: tense
operators (otherwise how can you formulate principles of change?); the
logical operators (otherwise how can you compare the relative with the
absolute?); the operators like <em>historical</em> or
<em>physical</em> necessity (otherwise how can you relate the agent to
his environment?); and so on and so on. <span class="blockright">&mdash;Scott
(1970: 161)</span></p>
</blockquote>

<p>
Consider the following seemingly possible situation: </p>

<blockquote>

<p class="left">
<em>Ann believes that Bob assumes that \(\underbrace{\textit{Ann
believes that Bob&rsquo;s assumption is wrong.}}_{\varphi}\) </em>
</p>
</blockquote>

<p>
Now, here is a tricky question: is \(\varphi\) (<em>&ldquo;Ann
believes that Bob&rsquo;s assumption is wrong&rdquo;</em>) true or
false? Paraphrasing Pacuit and Roy (2017:
 <a href="../epistemic-game/index.html#ParSelRefGamMod">Section 6</a>),
 suppose \(\varphi\) is true. So, what \(\varphi\) represents is true,
that is, Ann believes that Bob&rsquo;s assumption is wrong. Moreover,
by belief introspection, she believes that <em>&ldquo;she believes
Bob&rsquo;s assumption is wrong&rdquo;</em>, that is, she believes
Bob&rsquo;s assumption. But the description of the situation tells us
that Ann believes that Bob assumes \(\varphi\); then, in fact, Ann
believes that Bob&rsquo;s assumption is correct. Thus, \(\varphi\),
<em>&ldquo;Ann believes that Bob&rsquo;s assumption is
wrong&rdquo;</em>, is false.</p>

<p>
Hence, \(\varphi\) must be false. Then, following Pacuit and Roy
(2017:
 <a href="../epistemic-game/index.html#ParSelRefGamMod">Section 6</a>)
 again, Ann believes that Bob&rsquo;s assumption is correct, that is,
Ann believes \(\varphi\) is correct. Furthermore, the description of
the situation states that <em>&ldquo;Ann believes that Bob assumes
that Ann believes that Bob&rsquo;s assumption is wrong&rdquo;</em>,
which, given that \(\varphi\) is Bob&rsquo;s assumption, can be
rewritten as <em>&ldquo;Ann believes that Bob assumes that Ann
believes that \(\varphi\) is wrong&rdquo;</em>. But then, not only Ann
believes that she believes that \(\varphi\) is correct; she also
believes that Bob assumption is that she believes that \(\varphi\) is
wrong. Thus, it is the case that she believes Bob&rsquo;s assumption
is wrong (Ann believes that Bob&rsquo;s assumption is that she
believes that \(\varphi\) is wrong, but she believes that is wrong:
she believes that \(\varphi\) is correct). So, \(\varphi\) is
true.</p>

<p>
Some readers may wonder, <em>why do I need to know whether Ann
believes that Bob&rsquo;s assumption is wrong?</em> One of the reasons
is that, just as
 <a href="../russell-paradox/index.html">Russell&rsquo;s paradox</a>
 suggests that not every collection can constitute a set, this
situation, known as the <em>Brandenburger-Keisler Paradox</em>
(Brandenburger &amp; Keisler 2006), suggests that not every
description of beliefs can be &lsquo;represented&rsquo;. Now, with a
better motivation, one may wonder again: is \(\varphi\) true or false?
Or, maybe better, is there a formal setting that gives an answer?</p>

<p>
It becomes immediately clear that no system involving a single
modality can deal with this situation, as the description includes not
only two agents (so, at least two modalities would be required), but
also two different concepts: <em>beliefs</em> and
<em>assumptions</em>. Thus, to make formal sense of this situation,
one requires a system that allows us to deal not only with different
attitudes, but also with the complex relationship between them. To
make formal sense of this (and other similar) situation(s), one
requires a <em>multi-modal</em> system.</p>



</div>

<div id="toc">
<!--Entry Contents-->
<ul>
<li><a href="#BriePres">1. A Brief Presentation</a></li>
<li><a href="#DefiConcTermOthe">2. <em>Defining</em> Concepts in Terms of Others</a>
   <ul>
   <li><a href="#NecePoss">2.1 Necessity and Possibility</a></li>
   <li><a href="#KnowBeliGrou">2.2 Knowledge and Beliefs of Groups</a></li>
   <li><a href="#SimpAtteRelaKnowBeli">2.3 A Simple Attempt at Relating Knowledge and Belief</a></li>
   <li><a href="#DistCommKnow">2.4 Distributed and Common Knowledge</a></li>
   <li><a href="#BeliTermEvid">2.5 Beliefs in Terms of Evidence</a></li>
   <li><a href="#PlauMode">2.6 Plausibility Models</a></li>
   <li><a href="#InfiModaViaSyntCons">2.7 Infinite Modalities via Syntactic Constructors</a></li>
   <li><a href="#DynaEpisLogiAppr">2.8 The <em>Dynamic Epistemic Logic</em> Approach</a></li>
   </ul></li>
<li><a href="#GeneStraForCombModaSyst">3. General Strategies for <em>Combining</em> Modal Systems</a>
   <ul>
   <li><a href="#Fusi">3.1 Fusion</a></li>
   <li><a href="#Prod">3.2 Product</a></li>
   <li><a href="#ModaFibr">3.3 Modal Fibring</a></li>
   <li><a href="#CompIssu">3.4 Complexity Issues</a></li>
   </ul></li>
<li><a href="#SignInteBetwModa">4. Significant Interactions Between Modalities</a>
   <ul>
   <li><a href="#RelaBetwKnowBeli">4.1 The Relationship Between Knowledge and Beliefs</a></li>
   <li><a href="#TimeKnow">4.2 Time and Knowledge</a></li>
   <li><a href="#KnowQues">4.3 Knowledge and Questions</a></li>
   <li><a href="#Agen">4.4 Agents</a></li>
   <li><a href="#ModaFirsOrdeLogi">4.5 Modal First-Order Logic</a></li>
   <li><a href="#DynaInte">4.6 Dynamics of Intentions</a></li>
   <li><a href="#ObliTime">4.7 Obligations and Time</a></li>
   <li><a href="#KnowObli">4.8 Knowledge and Obligations</a></li>
   </ul></li>
<li><a href="#MultModaSystPhilDisc">5. Multi-Modal Systems in Philosophical Discussions</a>
   <ul>
   <li><a href="#AbduReas">5.1 Abductive Reasoning</a></li>
   <li><a href="#FitcKnowPara">5.2 Fitch Knowability Paradox</a></li>
   <li><a href="#ParaPerfBeli">5.3 The paradox of the perfect believer</a></li>
   <li><a href="#TrutModaPers">5.4 Truthmakers from a modal perspective</a></li>
   <li><a href="#BranKeisPara">5.5 The Brandenburger-Keisler Paradox</a></li>
   </ul></li>
<li><a href="#Bib">Bibliography</a></li>
<li><a href="#Aca">Academic Tools</a></li>
<li><a href="#Oth">Other Internet Resources</a></li>
<li><a href="#Rel">Related Entries</a></li>
</ul>
<!--Entry Contents-->





<hr />

</div>

<div id="main-text">



<h2 id="BriePres">1. A Brief Presentation</h2>

<p>
Modal logics are particularly well suited to study a wide range of
philosophical concepts, including rational beliefs, obligations,
knowledge, intentions, desires, evidence and preferences, among many
others. Such an analysis provides us with the key insights of the
basic building blocks and principles that regulate different
behaviors, which is important in a wide range of academic disciplines
including Artificial Intelligence, Psychology, Social Science and even
Physics. The concepts we look at have specific context-dependent
features, which indicates that they can be best studied using models
that can express different modes of truth (e.g., both global and local
truth). But as Scott&rsquo;s (1970) quote above suggests, there is
something missing when such philosophical concepts are studied in
isolation. A big part of what defines a concept lies in the way it
interacts with others. For instance, <em>rational beliefs</em> are
expected to rely on proper <em>arguments</em>, <em>justifications</em>
or <em>evidence</em>; <em>disjunctions</em> may not behave as they do
in natural language in the context of <em>obligations</em>;
<em>knowledge</em> is better understood when looking for the
<em>actions</em> that modify it; <em>intentions</em> may be understood
as derived from <em>desires</em> and <em>beliefs</em>. What is
required for this study are logical systems with more than one modal
operator, commonly known as multi-modal logics, describing not only
the isolated properties of the individual concepts, but also the way
they relate to one another. Indeed, multi-modal logics have been
designed for a wide range of applications, including reasoning about
time, space, knowledge, beliefs, intentions, desires, obligations,
actions such as public and private communication, observations,
measurements, moves in a game and others.</p>

<p>
The present text intends to give a brief (but broad) overview of the
interaction between many different philosophical concepts, and to show
how the use of multi-modal logical systems can shed some light on
these concepts&rsquo; interaction. We start in
 <a href="#NecePoss">section 2</a>
 (<em>Defining</em> concepts in terms of others) by discussing basic
scenarios that, starting from existing systems, use a combination of
&lsquo;syntactic&rsquo; and &lsquo;semantic&rsquo; strategies for
defining further concepts. These cases are based on the idea that some
notions can be defined in terms of others, with the famous
understanding of knowledge as justified true belief being one of the
most notable examples. An alternative to this idea is to consider that
the involved concepts emerge independently, but are still somehow
related, as the case of the relationship between knowledge and time.
From a formal perspective, this amounts to looking at the different
modes in which two (or more) existing systems can be combined.
 <a href="#GeneStraForCombModaSyst">Section 3</a>
 on General strategies for <em>combining</em> modal systems presents
an overview of some of the most relevant strategies. After this
slightly technical excursion, the discussion takes a philosophical
perspective, describing first combinations of multiple modalities
 (<a href="#SignInteBetwModa">section 4</a>
 on <em>Significant interactions between modalities</em>), and
finishing with examples of cases where the interaction between
modalities sheds light on philosophical issues
 (<a href="#MultModaSystPhilDisc">section 5</a>
 on Multi-modal systems in philosophical discussions).</p>

<p>
<span class="bold">A note on notation and the level of
technicality</span> To discuss aspects of multi-modal logic, this
entry assumes basic knowledge of
 <a href="../logic-modal/index.html">modal logic</a>,
 specifically about its language and its relational
 &lsquo;<a href="../logic-modal/index.html#PosWorSem">possible worlds</a>&rsquo;
 semantics (though other semantic models will be mentioned too). In
particular, a relational model is understood as a tuple containing a
set of possible worlds, one or more (typically binary) relations
between them, and a valuation indicating what each possible
world actually represents. Such structures can be described by
different modal languages. We will use \(\cL\) to denote the standard
<em>propositional language</em>, and \(\cL_{\left\{ O_1, \ldots, O_n
\right\}}\) to denote its extension with modalities \(O_1\), &hellip;,
\(O_n\). Given a relational model <i>M</i> and a formula \(\varphi\),
we will use \(\llbracket \varphi \rrbracket^{M}\) to denote the set of
worlds in <i>M</i> where \(\varphi\) holds. Readers can find more
details about the basics of modal logic not only in the referred SEP
entries, but also in the initial chapters of Blackburn, Rijke, &amp;
Venema (2001) and van Benthem (2010), and also in Blackburn &amp; van
Benthem (2006).</p>

<p>
Still, the goal of this text is not to provide a comprehensive study
of the topic, but rather to highlight the most interesting and
intriguing aspects. Thus, although some level of formal discussion
will be used, most technical details will be restricted to the
 <a href="appendix.html">appendix</a>.</p>
 

<h2 id="DefiConcTermOthe">2. <em>Defining</em> Concepts in Terms of Others</h2>

<p>
In order to use systems with multiple modalities, the question is how
to build such settings. One of the most important points is to decide
whether one of the concepts to be studied is &lsquo;more
fundamental&rsquo; than the other, in the sense that the latter can be
defined in terms of the former. As mentioned, the famous understanding
of knowledge as justified true belief is one of the most notable
examples. Others are equally relevant, as a definition of beliefs in
terms of the available arguments/evidence/justifications, or a
definition of epistemic notions for a group in terms of the epistemic
notions of its members. Yet, the basic <em>alethic</em> modal logic of
necessity and possibility already provides a paradigmatic example of
how to define the relationship between two concepts.</p>

<h3 id="NecePoss">2.1 Necessity and Possibility</h3>

<p>
The basic alethic modal logic contains both a <em>possibility</em>
\((\Diamond)\) and a <em>necessity</em> \((\Box)\) modality. Most
formal presentations of this system take one of these modalities as
the primitive syntactic operator (say, \(\Diamond)\), and then define
the other as its <em>modal</em> dual \((\oBox\varphi := \lnot
\oDiamond \lnot \varphi)\). This is a seemingly harmless
<em>syntactic</em> interdefinability, and comes from the fact that
\(\Diamond\) and \(\Box\) are semantically interpreted in terms of the
existential and universal
 <a href="../quantification/index.html">quantifiers</a>,
 respectively. It is, in some sense, similar to
the interdefinability of Boolean operators in classic propositional
logic. Nevertheless, it already reflects important underlying
assumptions. From a <em>classic</em> point of view, something is
necessary if and only if it is not the case that its negation is
possible \((\oBox\varphi \leftrightarrow \lnot \oDiamond \lnot
\varphi)\), and something is possible if and only if it is not the
case that its negation is necessary \((\oDiamond \varphi
\leftrightarrow \lnot \oBox\lnot \varphi)\). However, this may not be
the case in all settings. For example, while \(\oDiamond \varphi
\rightarrow \lnot \Box \lnot\varphi\) is
 <a href="../quantification/index.html#AxiForIntQuaLog">intuitionistically acceptable</a>
 (the existence of a possibility where \(\varphi\) holds implies that
not every possibility makes \(\varphi\) false), its converse \(\lnot
\oBox \lnot\varphi \rightarrow \oDiamond \varphi\)
 <a href="../quantification/index.html#AxiForIntQuaLog">is not</a>
 (the fact that not every possibility makes \(\varphi\) false is not
enough to guarantee the <em>existence</em> of a possibility where
\(\varphi\) is true). Thus, one should always be careful when defining
a modality in terms of another.</p>

<h3 id="KnowBeliGrou">2.2 Knowledge and Beliefs of Groups</h3>

<p>
Where the above examples started from a uni-modal logic, we provide
now an example in which we start from a homogeneous multi-modal logic.
Our setting is a logic consisting of a number of basic modalities of
the same type, all being semantically interpreted via the same type of
relation. Our example is the basic <em>multi-agent</em> epistemic
logic. This setting is already multi-modal, as its language
\(\cL_{\left\{ \oK{1}, \ldots,\oK{n} \right\}}\) has a knowledge
modality \(K_i\) for each agent \(i \in \ttA\). (In fact, this basic
multi-agent epistemic logic is the fusion
 (<a href="#GeneStraForCombModaSyst">section 3.1</a>)
 of several single-agent epistemic logic systems, one for each agent
\(i \in \ttA\).) Still, when the set of agents is finite (say,
\(\left| \ttA\right| = n)\), one can define a brand new modality for
the group epistemic notion of <em>everybody knows</em>:</p>

\[
{E\varphi} := {\oK{1}\varphi} \land \cdots \land {\oK{n} \varphi}
\]

<p>
In a similar way we can define a modality for <em>everybody
believes</em> in the logic with language \(\cL_{\left\{ \oB{1},
\ldots, \oB{n} \right\}}\) as</p> 

\[
\mathit{EB}\varphi := \oB{1}\varphi \land \cdots \land \oB{n}\varphi
\]

<p>
These definitions assume that the knowledge/beliefs of a group of
agents corresponds to the conjunction of the agent&rsquo;s individual
knowledge/beliefs. However, in the context of
 <a href="../epistemology-social/index.html">social epistemology</a>,
 the reduction of group attitudes to the mere sum of those of the
individuals is contentious, especially when one focuses on group
 beliefs.<sup>[<a href="notes.html#note-1" id="ref-1">1</a>]</sup></p>
 
<h3 id="SimpAtteRelaKnowBeli">2.3 A Simple Attempt at Relating Knowledge and Belief</h3>

<p>
Another example of the interdefinability of modal concepts deals with
the relationship between <em>knowledge</em> and <em>belief</em>. In
 <a href="../epistemology/index.html">epistemology</a>,
 researchers are searching for the correct characterization of
knowledge, and a common trend has been to view knowledge as a form of
 <a href="../knowledge-analysis/index.html#KnowJustTrueBeli">justified true belief</a>
 (an idea that can be traced back to Plato&rsquo;s dialogue
<em>Theaetetus</em>). Gettier&rsquo;s
 <a href="../knowledge-analysis/index.html#GettProb">famous counterexamples</a>
 showed that such a simple characterization of knowledge is not
sufficient: a further condition is required, such as safety,
sensitivity, robustness or stability. In spite of this, a
characterization of knowledge as justified true belief is an important
first step. Classic
 <a href="../logic-epistemic/index.html">epistemic logic</a>
 does not explicitly deal with the notion of
 <em>justification</em>,<sup>[<a href="notes.html#note-2" id="ref-2">2</a>]</sup>
 so a starting point is a simpler understanding of knowledge as true
belief.</p>

<p>
One can take a <em>doxastic</em> relational model with its relation
\(R_B\) being serial, transitive and Euclidean (a <em>KD45</em>
setting), and use a modality <i>B</i> semantically interpreted with
respect to \(R_B\) in the standard way. In this setting, two options
arise. The first one is <em>syntactic</em>, as in the examples that
have been discussed so far, and consists in defining a modality for
knowledge as &lsquo;true belief&rsquo;: \(K'\varphi := B\varphi
\land \varphi\). The second is <em>semantic</em>, and consists in
defining an epistemic equivalence relation \(R_K\) as the reflexive
and symmetric closure of the doxastic relation, then using it in the
standard way to give the semantic interpretation of a modality
<i>K</i>.</p>

<p>
It should be noted that the two approaches are not equivalent.
Consider the following doxastic model (from Halpern, Samet, &amp;
Segev 2009a), with the serial, transitive and Euclidean
<em>doxastic</em> relation \(R_B\) represented by dashed arrows, and
its derived reflexive, transitive and symmetric (i.e., equivalence)
<em>epistemic</em> relation \(R_K\) represented by solid ones.</p>

<div class="figure" id="figure1">
<img src="figure1.svg" alt="a diagram: link to extended description below" />

<p class="center">
<span class="figlabel">Figure 1</span> [An
 <a href="figdesc.html#figure1">extended description of figure 1</a>
 is in the supplement.]</p>
</div>

<p>
Note how the agent believes <i>p</i> on every world in the model,
\(\llbracket \oB{}p \rrbracket^{M} = \left\{ {w_1, w_2, w_3}
\right\}\); then, as the syntactic approach states that
\({K'\varphi}\) holds in those worlds in which \(B\varphi \land
\varphi\) is the case, we have</p> 

\[\llbracket K'p \rrbracket^{M} = \llbracket {\oB{}p} \land p \rrbracket^{M} = \left\{ {w_1, w_2} \right\}.\]

<p>
However, according to the semantic approach, \(K\varphi\) holds in
those worlds from which all epistemically accessible situations
satisfy \(\varphi\), so \(\llbracket K p \rrbracket^{M} = \left\{ w_1
\right\}\). Thus, \({K'}\) and <i>K</i> are not equivalent. One of
the reasons for this mismatch is that the two options do not enforce
the same properties on the derived notion of knowledge. For example,
while the semantic approach enforces negative introspection (by making
\(R_K\) an equivalence relation), the syntactic one does not. In fact,
this property fails at \(w_3\), as \(\lnot {K'p}\) is true \(({B
p} \land p\) fails, as <i>p</i> fails) but still
\(K'\lnot{K'p}\) (unfolded as \({B (\lnot {B p} \lor \lnot p)}
\land (\lnot B p \lor \lnot p))\) is
 false.<sup>[<a href="notes.html#note-3" id="ref-3">3</a>]</sup></p>
 
<p>

 <a href="#RelaBetwKnowBeli">Section 4.1</a>
 comes back on the relationship between these two concepts, recalling
alternative multi-modal accounts that relate knowledge and belief
while doing justice to the involved epistemological subtleties.</p>

<h3 id="DistCommKnow">2.4 Distributed and Common Knowledge</h3>

<p>
The second option in the previous case is, as described, semantic: it
takes the semantic counterpart of an existing modality(ies), and then
extracts from it (them) a further semantic component in terms of which
a new modality can be defined. Here are two further examples of this
strategy.</p>

<p>
Consider again the basic multi-agent epistemic logic with language
\(\cL_{\left\{ \oK{1}, \ldots, \oK{n} \right\}}\). As mentioned above,
this setting is multi-modal, as its language contains, for each agent
\(i \in \ttA\), a knowledge modality \(K_i\) that is semantically
interpreted in the standard way with respect to a matching epistemic
relation \(R_i\). While a modality for the concept of <em>everybody
knows</em> (<i>E</i>) is syntactically definable (provided the set of
agents is finite), other group epistemic notions, such as distributed
knowledge and common knowledge are
 not.<sup>[<a href="notes.html#note-4" id="ref-4">4</a>]</sup></p>
 
<p>
Consider first the notion of <em>distributed knowledge</em>,
understood as describing what the agents would know if they shared all
their information. From this intuitive definition, it is clear that
this concept can be defined semantically in terms of the agent&rsquo;s
individual epistemic relations. More precisely, a relation describing
the distributed knowledge modality should correspond to the
intersection of the individual epistemic relations, \(R_D :=
\bigcap_{i \in \ttA} R_i\). Thus, given an evaluation point <i>w</i>,
a world <i>u</i> will be considered possible after the agents share
all they know if and only if all of them considered it possible before
the communication (or, in other words, <i>u</i> will be considered
possible if and only if <em>no one can discard it</em>). One simply
extends the language with a modality <i>D</i>, semantically
interpreted with respect to this new relation:</p> 

\[ (M, w) \Vdash D\varphi \quad\iffdef\quad \text{for all } u \in W,
 \text{ if } R_Dwu \text{ then } (M, u) \Vdash \varphi.  \]

<p>
Another important notion, crucial in the study of social interaction,
is
 <a href="../common-knowledge/index.html">common knowledge</a>.
 This concept can be described as what everybody knows, everybody
knows that everybody knows, everybody knows that everybody knows that
everybody knows, and so on. Just as with distributed knowledge, this
notion does not require the addition of further semantic components:
the individual epistemic indistinguishability relations already
provide everything that is needed to make the definition explicit. If
one defines an epistemic relation for the <em>&ldquo;everybody
knows&rdquo;</em> modality in the natural way \((R_E := \bigcup_{i \in
\ttA} R_i)\), and then define \(R_C\) as the transitive closure of
\(R_E\),</p> 

\[
R_C := (R_E)^+,
\]

<p>
one can simply extend the language with a modality <i>C</i>,
semantically interpreted in terms of \(R_C\):</p> 

\[ (M, w) \Vdash {C\varphi} \quad\iffdef\quad \text{for all } u \in W,
    \text{ if } R_Cwu \text{ then } (M, u) \Vdash \varphi.  \]

<p>
At world <i>w</i> a formula \(\varphi\) is commonly known among the
agents if and only if \(\varphi\) is the case in <em>every</em> world
(the <em>&ldquo;for all&rdquo;</em> in <i>C</i>&rsquo;s semantic
interpretation) that can be reached by <em>any</em> finite non-zero
sequence of transitions in \(R_E\) (the fact that \(R_C\) is the
transitive closure of \(R_E)\). In other words, \(\varphi\) is
commonly known among the agents if and only if everybody knows
\(\varphi\) (any sequence of length 1), everybody knows that everybody
knows \(\varphi\) (any sequence of length 2), and so
 on.<sup>[<a href="notes.html#note-5" id="ref-5">5</a>]</sup></p>
 
<h3 id="BeliTermEvid">2.5 Beliefs in Terms of Evidence</h3>

<p>
There are more elaborated examples of frameworks extending a given
setting with modalities that &lsquo;extract&rsquo; further information
from the semantic model. One of them is <em>evidence logic</em>,
introduced in van Benthem &amp; Pacuit (2011), and further developed
in van Benthem, Fern&aacute;ndez-Duque, &amp; Pacuit (2014) and
Baltag, Bezhanishvili, et al. (2016). It follows the idea of
representing the evidence the agent has collected, and looks at how
this evidence gives support to further epistemic notions (e.g.,
knowledge and beliefs).  The semantics is given by a basic
neighborhood model (Montague 1970; Scott 1970): a tuple of the form
\(M = {\langle W, N, V \rangle}\) where <i>W</i> and <i>V</i> are a
non-empty set of possible worlds and an atomic valuation, respectively
(as in standard relational models), and \(N:W \to {\wp(\wp(W))}\) is a
neighborhood function assigning, to every possible world, a set of
<em>sets</em> of possible worlds (so \(N(w) \subseteq {\wp(W)}\) is
<em><i>w</i>&rsquo;s neighborhood</em>). In evidence logic, the
neighborhood function is assumed to be constant (i.e., \(N(w) = N(u)\)
for any \(w,u \in W)\), and thus the model can be simply understood as
a tuple \({\langle W, E, V \rangle}\), with \(E \subseteq {\wp(W)}\)
the (constant) neighborhood. This neighborhood, intuitively containing
the basic pieces of evidence the agent has collected, is required to
satisfy two additional properties: evidence <em>per se</em> is never
contradictory \((\emptyset \not\in E)\), and the agent knows her
&lsquo;space&rsquo; \((W \in E)\).</p>

<p>
Syntactically, a neighborhood model can be described by a modal
language \(\cL_{\left\{ \oBox \right\}}\), as is typically done in
standard neighborhood models. There are at least two possibilities for
the semantic interpretation of the \({\oBox}\) modality (Areces &amp;
Figueira 2009), and the one chosen in evidence logic is the
following:</p> 

\[ (M, w) \Vdash {\oBox\varphi} \quad\iffdef\quad \text{there is } U
    \in E\text{ such that } U \subseteq {\llbracket \varphi
    \rrbracket^{M}}.  \]

<p>
Thus, in this setting, \({\oBox\varphi}\) expresses that <em>&ldquo;the agent has evidence
supporting \(\varphi\)&rdquo;</em>.</p>

<p>
What is the epistemic state of the agent that such a model entails? In
other words, given such a model, how can we define epistemic notions
such as knowledge and belief?</p>

<p>
In the case of knowledge, one can follow the traditional single-agent
idea: all worlds in the model play a role in the agent&rsquo;s
epistemic state, and thus one can say that the agent <em>knows</em> a
given formula \(\varphi\) if and only if \(\varphi\) is true in every
world of the model. For this, evidence logic uses a <em>global</em>
modality <i>A</i>:</p> 

\[ (M, w) \Vdash {A\varphi} \quad\iffdef\quad {\llbracket \varphi
    \rrbracket^{M}} = W \]

<p>
In the case of beliefs, there are more alternatives. A straightforward
idea says that the agent believes \(\varphi\) if and only if she has
evidence supporting \(\varphi\) (a syntactic definition of the form
\(B\varphi := \oBox\varphi)\). However, this would allow the agent to
have contradictory beliefs, as two pieces of evidence might contradict
themselves (there may be \(X, Y \in E\) such that \(X \cap Y =
\emptyset\), and thus \(Bp \land B{\lnot p}\) could be satisfiable).
More importantly, this would be a &lsquo;lazy&rsquo; approach, as the
agent would be able to collect evidence (thus defining <i>E</i>), but
nevertheless she would not be doing any &lsquo;reasoning&rsquo; with
it.</p>

<p>
A more interesting idea is to define (semantically) a notion of belief
in terms of <em>combinations</em> of pieces of evidence. In van
Benthem and Pacuit (2011), the authors propose (roughly speaking) that
beliefs should be given by the <em>maximal consistent</em> ways in
which evidence can be combined, stating that the agent believes
\(\varphi\) if and only if <em>all</em> maximally consistent
combination of pieces of evidence support \(\varphi\). More
precisely,</p>

<table class="centered cellpad-med vert-top left">
<tr>
  <td>\((M, w) \Vdash B\varphi\)</td>
  <td>\(\iffdef\)</td>
  <td> \(\bigcap \sX \subseteq {\llbracket \varphi \rrbracket^{M}}\)
(support) for every \(\sX \subseteq E\) satisfying:

<ol type="i">

<li> \(\bigcap \sX \neq \emptyset\) (consistency) </li>

<li> \(\sX \subset \sY \subseteq E\) implies \(\bigcap \sY =
\emptyset\)

<!--pdf include <br/>
pdf include--> (maximality) </li>
</ol> </td> </tr>
</table>

<p>
Given these definitions, it is clear that knowledge implies both
belief and evidence (i.e., both \(A\varphi \rightarrow B\varphi\) and
\(A\varphi \rightarrow \oBox\varphi\) are valid). Still, it is
interesting to note not only that the agent might believe a given
\(\varphi\) without having a basic piece of evidence supporting it
\((B \varphi \rightarrow \oBox\varphi\) is <em>NOT</em> valid, as
beliefs are defined in terms of <em>combined</em> pieces of evidence),
but also that she might have a basic piece of evidence supporting
\(\varphi\) without believing \(\varphi\) \((\oBox\varphi \rightarrow
B\varphi\) is <em>NOT</em> valid, as the basic evidence supporting
\(\varphi\) not be part of all maximally consistent combinations).</p>

<p>
In this setting, at least when <i>E</i> is finite (and in many other
cases), beliefs are consistent (i.e., \(\neg B \bot)\); still, the
setting also allows &lsquo;bad&rsquo; models in which beliefs can turn
out to be inconsistent. In Baltag, Bezhanishvili, et al. (2016), the
authors provide an example of such a model, and then solve the problem
by extending the setting to a topological approach. Indeed, the
authors use the <em>topology</em> generated by <i>E</i>, which
intuitively describes the different ways in which the available pieces
of evidence can be
 combined.<sup>[<a href="notes.html#note-6" id="ref-6">6</a>]</sup>
 This is reasonable as, while <i>E</i> can be understood as containing
the pieces of evidence the agent has received from external sources
(observations, communication), the topology \(\tau_{E}\) can be
understood as the different ways in which she can
&lsquo;extract&rsquo; further information from them (i.e., the result
of her own reasoning processes). Given the topology, it is possible to
define (semantically) further epistemic notions, such as arguments,
justifications, consistent beliefs, consistent conditional beliefs,
and different forms of knowledge. For more on this, we refer to
Baltag, Bezhanishvili, et al. (2016: Section 2).</p>

<h3 id="PlauMode">2.6 Plausibility Models</h3>

<p>
As we have seen, a new modality can be introduced in syntactic terms
(using the language to provide a formula defining the new concept),
but also in a semantic way (using the semantic counterparts of the
existing modalities to define a further semantic notion, which in turn
is used to interpret the new modality). Our examples so far have been
restricted to the use of one of these two strategies, but their
interplay is also possible. The case to be discussed here concerns the
 <a href="../dynamic-epistemic/index.html#PlauModeBeliChan">plausibility models</a>
 of Board (2004); Baltag and Smets (2006, 2008); van Benthem (2007);
here, the presentation of Baltag and Smets (2008) is used.</p>

<p>
A plausibility model is a relational model \(M = {\langle W, \leq, V
\rangle}\) in which the binary relation \(\leq\) is interpreted as
describing the <em>plausibility</em> ordering the agent assigns to her
epistemic possibilities \((w \leq u\) indicates that, for the agent,
world <i>w</i> is at least as plausible as world <i>u</i>). In the
<em>single-agent</em> case, the plausibility relation \(\leq\) is
required to be a <em>well-preorder</em>: a total relation which is
both reflexive and transitive, and such that every non-empty subset of the
domain has \(\leq\)-minimal elements. These minimal elements in <i>W</i> are
then understood as the agent&rsquo;s <em>most plausible</em> worlds.
We see below that what is true in all the most plausible worlds
characterizes what an agent believes.</p>

<p>
To start, take a modality \([\leq]\) semantically interpreted via the
plausibility relation \(\leq\),</p> 

\[ (M, w) \Vdash {[\leq]\varphi} \quad\iffdef\quad \text{for all } u
    \in W, \text{ if } u \leq w \text{ then } (M, u) \Vdash \varphi,
    \]

<p>
This modality has the properties of an S4 modal operator; hence, it is
factive, positively introspective but not negatively introspective. In
Baltag and Smets (2008), it is argued that this modality is well
suited to express a version of Lehrer&rsquo;s <em>indefeasible
(&ldquo;weak&rdquo;, non-negatively-introspective) type of
knowledge</em> (Lehrer 1990; Lehrer &amp; Paxson 1969), and the
authors explain how it can be understood as belief that is persistent
under revision with any <em>true</em> piece of information. Using this
modality (also read as <em>safe belief</em> in Baltag &amp; Smets
2008), it is possible to define syntactically a notion of simple
<em>belief</em> as <em>truth in the most plausible worlds</em>: </p>

\[
B\varphi := \langle{\leq}\rangle [{\leq}]\varphi.
\]

<p>
As simple as a plausibility model is, it is powerful enough to encode
a wide range of different epistemic concepts, all of which can be
brought to light by the proper semantic definitions. First, we define
a relation of <em>epistemic</em> possibility (or indistinguishability)
\(\sim\) by taking it to be the universal relation,</p> 

\[
{\sim} := W \times W,
\]

<p>
thus understanding that two worlds are epistemically indistinguishable
if and only if they can be compared via
 \(\leq\).<sup>[<a href="notes.html#note-7" id="ref-7">7</a>]</sup>
 Then, a notion of S5-knowledge can be expressed by introducing a
modality <i>K</i> semantically interpreted via \(\sim\):</p>

\[ (M, w) \Vdash K\varphi \quad\iffdef\quad \text{for all } u \in W,
    \text{ if } w \sim u \text{ then } (M, u) \Vdash \varphi \]

<p>
With this new modality <i>K</i> it is possible to define,
syntactically, the finer notion of <em>conditional belief</em>
\(B^{\psi}\), intuitively describing what the agent would have
believed was true had she learnt that a certain condition \(\psi\) is
the case. Indeed,</p> 

\[ B^{\psi}\varphi := \hK \psi \rightarrow \hK (\psi \rightarrow
[{\leq}] (\psi \rightarrow\varphi)) \]

<p>
for \({\hK}\) the modal dual of <i>K</i> (i.e., \(\hK\psi := \lnot
K\lnot \psi)\). This extended language \(\cL_{\left\{ [{\leq}], K
\right\}}\) can also express a notion of <em>strong belief</em>, \(Sb
\varphi\), semantically understood as true whenever all
\(\varphi\)-worlds are strictly more plausible than all
\(\lnot\varphi\)-worlds, and syntactically defined as </p> 

\[
 Sb\varphi := \langle{\leq}\rangle [{\leq}] \varphi \land K(\varphi \rightarrow [{\leq}] \varphi)
\]

<p>
Finally, note how a plausibility relation defines, semantically,
layers or spheres of equally-plausible worlds, with the spheres
themselves ordered according to their plausibility so that every
strong belief characterizes one of the spheres. This will turn every
plausibility model into a sphere model (Grove 1988; Spohn 1988),
making it perfectly fit to model
 <a href="../logic-belief-revision/index.html">belief revision</a>.
 Still, even though in \(\cL_{\left\{ [{\leq}], K \right\}}\) there
are formulas expressing that \(\varphi\) holds in <em>the most
plausible</em> sphere (the mentioned \(B\varphi\), given by
\(\langle{\leq}\rangle[{\leq}]\varphi)\), no formula can express,
e.g., that \(\varphi\) holds in the <em>next to</em> most plausible
worlds. One way to fix this &lsquo;problem&rsquo; is to define (now
semantically) the <em>strict</em> plausibility relation \({&lt;} :=
{\leq} \cup {\not\geq}\) (with \(\geq\) the <em>converse</em> of
\(\leq\), defined in the standard way, \({\geq} := \left\{ (u,w) \in W
\times W \mid w \leq u \right\})\), and then introduce a standard
modality for it:</p> 

\[ (M, w) \Vdash [{&lt;}]\varphi \quad\iffdef\quad \text{for all } u
    \in W, \text{ if } u &lt; w \text{ then } (M, u) \Vdash \varphi \]

<p>
With this new modality, one can provide syntactic definitions for the
concepts described above. Indeed, while the formula \(\lambda_0 :=
[&lt;]\bot\) characterizes the most plausible worlds (so \(K
(\lambda_0 \rightarrow\varphi)\) expresses that the most plausible
worlds satisfy \(\varphi\), just as \(B\varphi\) does), the formula
\(\lambda_1 := \lnot \lambda_0 \land [&lt;]\lambda_0\) characterizes
the next to most plausible worlds (so \(K(\lambda_1
\rightarrow\varphi)\) expresses that the next to most plausible worlds
satisfy \(\varphi)\). This procedure can be repeated, producing
formulas \(\lambda_i\) characterizing each layer, and thus it is
possible to deal syntactically with a qualitative <em>degree of
beliefs</em> (Grove 1988; Spohn 1988), looking for what holds
&lsquo;from some level up&rsquo; (see also Vel&aacute;zquez-Quesada
2017).</p> <!-- bib check so far -->

<p>
This new modality \([&lt;]\) allows us to define even more
epistemic notions. For example, a formula \(\varphi\) is <em>weakly
safely believed</em> (a belief which might be lost but is never
reversed when revising with true information) if and only if \(\varphi
\land [{&lt;}] \varphi\) holds. More details can be found in Baltag
and Smets (2008: Subsection 2.4).</p>

<h3 id="InfiModaViaSyntCons">2.7 Infinite Modalities via Syntactic Constructors</h3>

<p>
Just as some multi-modal systems are created by extending existing
ones, some others are born with multiple modalities in mind. Among
them,
 <a href="../logic-dynamic/index.html">propositional dynamic logic</a>
 (Harel, Kozen, &amp; Tiuryn 2000) and <em>Boolean modal logic</em>
(Gargov &amp; Passy 1990; Gargov, Passy, &amp; Tinchev 1987) deserve a
special mention. The reason is that they both define, within the
language, operators for building new modalities from a collection of
basic ones. As a consequence, both systems contain an
<em>infinite</em> number of modalities.</p>

<p>
Following earlier approaches to reason about programs in Engeler
(1967) and Hoare (1969), Propositional dynamic logic (<em>PDL</em>), the logic of
programs (Harel, Kozen, &amp; Tiuryn 2000), intends to describe what
programs can achieve. Semantically, programs are interpreted in
standard relational models, with one binary relation \(R_a\) for every
<em>basic program</em> <i>a</i>; syntactically, the language contains
a modality \([a]\) for each such <i>a</i>.</p>

<p>
So far, <em>PDL</em> is technically similar to a multi-agent epistemic
logic (the difference being, besides the symbols used for the
modalities, the fact that there are no restrictions on the relations
for the basic
 programs).<sup>[<a href="notes.html#note-8" id="ref-8">8</a>]</sup>
 The crucial insight is, however, that basic programs can be
<em>composed</em> in order to create more complex ones: one can think
of executing one program after another, or repeating some of them a
number of times. Thus, these basic modalities are not enough. For
this, a new syntactic entity is created: besides formulas, the
language of <em>PDL</em> contains a set of <em>basic programs</em>
together with <em>program constructors</em> representing those for
<em>regular expressions</em> (Kleene 1956). Formally, <em>formulas
\(\varphi\)</em> and <em>programs \(\alpha\)</em> of the
<em>PDL</em>-language \(\cL_{\textit{PDL}}\) are defined
simultaneously via mutual recursion as</p> 

\[ \begin{align} \varphi &amp; ::= p \mid \lnot \varphi \mid \varphi
\land \varphi \mid [\alpha]\varphi\\ \alpha &amp; ::= a \mid \varphi
\qbin \mid \alpha \scbin \alpha \mid \alpha \bcup \alpha \mid
\alpha^{\ast} \end{align} \]

<p>
with <i>p</i> an atomic proposition coming from a given set, and
<i>a</i> a basic program coming from a given set. For formulas, the
intended reading of the Boolean operators is standard, and formulas of
the form \([\alpha]\varphi\) express that <em>&ldquo;every execution
of program \(\alpha\) from the current state leads to a state
satisfying \(\varphi\)&rdquo;</em>. For programs, while the basic
programs simply represent themselves, &ldquo;\(\varphi \qbin\)&rdquo;
is a program that &lsquo;does nothing&rsquo; when \(\varphi\) is the
case but &lsquo;fails&rsquo; otherwise (essentially, a <em>test</em>
for \(\varphi)\), &ldquo;\(\alpha \scbin \beta\)&rdquo; represents the
program that results from executing \(\alpha\) and then executing
\(\beta\) (their <em>sequential composition</em>), &ldquo;\(\alpha
\bcup \beta\)&rdquo; represents the program that results from
executing either \(\alpha\) or else \(\beta\) (their
<em>non-deterministic choice</em>), and
&ldquo;\({\alpha^{\ast}}\)&rdquo; represents the program that results
from repeating \(\alpha\) a finite number of times \((\alpha\)&rsquo;s
<em>iteration</em>).</p>

<p>
With these program constructors it is possible to build more complex
programs. Famous examples are</p>

<table class="cellpad-med-dense centered">
<tbody>
<tr class="odd">
  <td>\((\varphi \qbin \scbin \alpha) \bcup
(\lnot\varphi \qbin \scbin \beta)\)</td>
  <td>&ldquo;if \(\varphi\) holds, then do \(\alpha\),
and otherwise do \(\beta\)&rdquo;,</td> </tr>
<tr class="even">
  <td>\((\varphi \qbin \scbin \alpha)^{\ast} \scbin
{\lnot\varphi} \qbin\)</td>
  <td>&ldquo;while \(\varphi\) holds, do
\(\alpha\)&rdquo;,</td> </tr>
<tr class="odd">
  <td>\(\alpha \scbin ({\lnot\varphi} \qbin
\scbin\alpha)^{\ast} \scbin {\varphi \qbin}\)</td>
  <td>&ldquo;repeat \(\alpha\) until \(\varphi\)
holds&rdquo;.</td> </tr> </tbody>
</table>

<p>
Then, it is possible to build formulas as \(p \rightarrow [(q \qbin
\scbin a) \bcup (\lnot q \qbin \scbin b)]r\) (<em>&ldquo;if <i>p</i>
holds, then <i>r</i> will be achieved by choosing between actions
<i>a</i> and <i>b</i> according to whether <i>q</i> holds&rdquo;</em>)
and \(\lnot p \rightarrow \langle a \scbin (\lnot q \qbin \scbin
a)^{\ast} \scbin q \qbin \rangle p\) (<em>&ldquo;if the desired
requirement <i>p</i> is not true yet, it is possible to achieve it by
a repeated execution of <i>a</i>&rdquo;</em>).</p>

<p>
For the semantic interpretation, a relation \(R_\alpha\) is required
for each program \(\alpha\). However, while the relations \(R_a\) for
basic programs are arbitrary, those for complex programs should behave
according to their intended meaning. The simplest way to obtain this
is to take the relations for the basic programs, and then
<em>define</em> those for complex programs in an inductive way. This
and further details about <em>PDL</em> can be found in Troquard and
Balbiani (2019:
 [<a href="../logic-dynamic/index.html#SynSem">Section 2</a>).</p>
 
<p>
The <em>Boolean modal logic</em> of Gargov and Passy 1990 and Gargov,
Passy, and Tinchev 1987) follows a similar strategy. The difference is
that, while <em>PDL</em> focuses on constructors for regular
expressions (sequential composition, non-deterministic choice, finite
iteration), Boolean modal logic focuses on constructors for the
Boolean algebra over relations: complement \((\bdash)\), union
\((\bcup)\) and intersection \((\bcap)\), together with a
&lsquo;global&rsquo; constant \((\boldsymbol{1})\). More
precisely,</p> 

\[ \begin{align} \varphi &amp; ::= p \mid \lnot \varphi \mid \varphi
\land \varphi \mid [\alpha]\varphi\\ \alpha &amp; ::= a \mid
\boldsymbol{1} \mid \bdash \alpha \mid \alpha \bcup \alpha \mid \alpha
\bcap\alpha\\ \end{align} \]

<p>
The semantic interpretation follows the same steps as in <em>PDL</em>:
relations \(R_a\) for the basic modalities <i>a</i> are assumed, and
relations for complex ones are defined in the expected way (with
\({\boldsymbol{1}}\) being interpreted with respect to the global
relation \(W \times W)\).</p>

<p>
Interestingly, by combining the negation over formulas and the Boolean
complement over relations, it is possible to define the following
operator (often called <em>window</em> (see Goldblatt 1974; van
Benthem 1979; Gargov, Passy, &amp; Tinchev 1987):</p> 

\[
\oubracket{.7em}{\alpha} \varphi := [\bdash\alpha] \lnot\varphi
\]

<p>
Window is an extremely natural operator that complements the standard
universal modality. Indeed, while formulas of the form
\([\alpha]\varphi\) express that <em>all</em> executions of \(\alpha\)
reach a \(\varphi\)-state,</p> 

\[ (M, w) \Vdash [\alpha]\varphi \quad\tiff\quad \text{for all } u \in
    W, \; \text{ if } R_{\alpha}wu \text{ then } (M, u) \Vdash
    \varphi, \]

<p>
formulas of the form \(\oubracket{.7em}{\alpha}\varphi\) express that
<em>all</em> \(\varphi\)-states are reachable by an execution of
\(\alpha\):</p> 

\[ (M, w) \Vdash \oubracket{.7em}{\alpha} \varphi \quad\tiff\quad
    \text{for all } u \in W, \; \text{ if } (M, u) \Vdash \varphi
    \text{ then } R_{\alpha}wu \]

<p>
Not only that: window allows a smooth interaction between the
constructors \(\bcup\) and \(\bcap\). As discussed in Blackburn,
Rijke, and Venema (2001: 427), </p>

<blockquote>

<p>
[i]n a sense, the relations are divided into two kingdoms: the
ordinary \([\alpha]\) modalities govern relations built with
\(\bcup\), the window modalities \(\oubracket{.7em}{\alpha}\) govern
the relations built with \(\bcap\), and the \(\bdash\) constructor
acts as a bridge between the two realms:</p> 

\[ \begin{align} \Vdash {[\alpha \bcup\beta]\varphi}
&amp;\leftrightarrow ([\alpha] \varphi \land [\beta]\varphi), &amp;
\Vdash {[\bdash\alpha]\varphi} &amp;\leftrightarrow
\oubracket{.7em}{\alpha} \lnot\varphi \\ \Vdash
\oubracket{3.1em}{\alpha \bcap\beta} \varphi &amp;\leftrightarrow
\left(\oubracket{1em}{\alpha} \varphi \land \oubracket{.8em}{\beta}
\varphi\right), &amp; \Vdash [\alpha]\lnot\varphi &amp;\leftrightarrow
\oubracket{1.8em}{\bdash\alpha}\varphi.\\ \end{align} \]

</blockquote>

<p>
Of course, many other program constructors can be used. Among them,
one worthy of mention is that for the
 <a href="../logic-dynamic/index.html#PDLCon">converse</a>
 of a given relation. Modalities for the converse of a relation have
been used in, e.g.,
 <a href="../logic-temporal/index.html#PriBasTenLogTL">tense logic</a>,
 with the &lsquo;past&rsquo; modalities (<i>H</i> and <i>P</i>, the universal and existential versions, respectively) interpreted semantically in terms of the converse of the relation used for interpreting the &lsquo;future&rsquo; modalities (<i>G</i> and <i>F</i>, respectively).</p>

<h3 id="DynaEpisLogiAppr">2.8 The <em>Dynamic Epistemic Logic</em> Approach</h3>

<p>
The case of <em>dynamic epistemic logic</em>, the study of modal
logics of model change, is of particular interest. In these systems,
the relationship between their modalities is special. Here we will
only recall the basic notions, referring the reader to the
 <a href="../dynamic-epistemic/index.html">SEP entry</a>
 by Baltag and Renne (2016) for an in-depth discussion</p>

<p>
In a nutshell, a <em>dynamic epistemic logic</em> (<em>DEL</em>)
framework has two components. The &lsquo;static&rsquo; part consists
of a &lsquo;standard&rsquo; modal system: a language including one or
more modalities for the one or more concepts under study, together
with the semantic model on which the formulas are interpreted. The
&lsquo;dynamic&rsquo; part consists of modalities expressing different
ways in which the studied concept(s) might change, with the crucial
insight being that these modalities are semantically interpreted not
on the given model, but rather on one that results from
<em>transforming</em> the given one in an appropriate way.</p>

<p>
The discussion here will focus on the paradigmatic <em>DEL</em> case,
 <a href="../dynamic-epistemic/index.html#PublAnnoLogi">public announcement logic</a>
 (<em>PAL</em>), which studies the interaction of knowledge and public
 communication.<sup>[<a href="notes.html#note-9" id="ref-9">9</a>]</sup>
 Syntactically, its language extends the basic epistemic language
\(\cL_{\left\{ K \right\}}\) with a modality \([\chi{!}]\) (for
\(\chi\) a formula of the language), thanks to which it is possible to
build formulas of the form \([\chi{!}]\varphi\): <em>&ldquo;after
\(\chi\) is publicly announced, \(\varphi\) will be the
case&rdquo;</em>. Within this new language \(\cL_{\left\{ K, {!}
\right\}}\) it is possible to build formulas describing the
<em>knowledge</em> the agent will have after a public communication
action; one example is \([(p \land q){!}] Kq\), expressing that
<em>&ldquo;after \(p \land q\) is publicly announced, the agent will
know <i>q</i>&rdquo;</em>. For the semantic interpretation, the public
announcement of any given \(\chi\) is taken to be completely
trustworthy; thus, the agent reacts to it by eliminating all
\(\lnot\chi\) possibilities from consideration. More precisely, given
a model \(M = {\langle W, R, V \rangle}\) and a formula \(\chi \in
\cL_{\left\{ K, {!} \right\}}\), the model \(M_{\chi{!}} = \langle
W_{\chi{!}}, R_{\chi{!}}, V_{\chi{!}} \rangle\) is defined as</p>

\[
\begin{align}
W_{\chi{!}}  &amp;:= \left\{ w \in W \mid (M, w) \Vdash \chi \right\}\\
R_{\chi{!}}  &amp;:= R \cap (W_{\chi{!}} \times W_{\chi{!}})\\
V_{\chi{!}}(p)  &amp;:= V(p) \cap W_{\chi{!}}
\end{align}
\]

<p>
Note how, while \(W_{\chi{!}}\) is the set of worlds of the original model
where \(\chi\) holds, \(R_{\chi{!}}\) is the restriction of the
original epistemic relation to the new domain, and so is the new
valuation function \(V_{\chi{!}}\). Then,</p> 

\[
    (M, w) \Vdash [\chi{!}] \varphi \quad\iffdef\quad (M, w) \Vdash \chi \text{ implies } (M_{\chi{!}}, w) \Vdash \varphi.
\]

<p>
Thus, \(\varphi\) is the case after \(\chi\) is publicly announced at
<i>w</i> in <i>M</i> (in symbols, \((M, w) \Vdash [\chi{!}]\varphi)\)
if and only if \(\varphi\) is true at <i>w</i> in the situation that
results from \(\chi\)&rsquo;s announcement (in symbols,
\((M_{\chi{!}}, w) \Vdash \varphi)\) whenever \(\chi\) can actually be
announced (in symbols, \((M, w) \Vdash
 \chi)\).<sup>[<a href="notes.html#note-10" id="ref-10">10</a>]</sup>
 Note that the public announcement modality \([\chi{!}]\) is
introduced <em>semantically</em>, as its semantic interpretation
requires &lsquo;extracting&rsquo; further information from the initial
model, just as the intersection of individual epistemic relations is
used to create the relation for distributed knowledge. Still, it uses
a &lsquo;more advanced&rsquo; version of such a strategy: it performs
an operation <em>over the full model</em>, thus creating a new one in
order to evaluate formulas that fall inside the scope of the new
modality.</p>

<p>
With the semantic interpretation of \([\chi{!}]\) given, it is now
possible to answer the crucial question in this setting: what is the
effect of a public announcement on an agent&rsquo;s knowledge? Or,
more precisely, how is the agent&rsquo;s knowledge <em>after</em> an
announcement related to her knowledge <em>before</em> it? Here is the
answer:</p> 

\[ \Vdash [\chi{!}] K \varphi \leftrightarrow (\chi \rightarrow K(\chi
\rightarrow [\chi{!}] \varphi)) \]

<p>
This validity characterizes the agent&rsquo;s knowledge after the
action in terms of the knowledge she had, before the action, <em>about
the effects</em> of the action. It tells us that after the public
announcement of \(\chi\) the agent will know \(\varphi\),
\([\chi{!}]K\varphi\), if and only if, provided \(\chi\) could be
announced, &lsquo;\(\chi \rightarrow \)&rsquo;, she knew that its
truthful public announcement would make \(\varphi\) true, \(K(\chi
\rightarrow [\chi{!}]\varphi)\). Note how this <em>bridge</em>
principle, relating the two involved modalities, is not
&lsquo;chosen&rsquo;: it arises as a consequence of the given
definition of what knowledge is (truth in all epistemic possibilities)
and the given understanding of what a public announcement does
(discard all possibilities where the announcement fails).</p>

<p>
The given semantic interpretation of \([\chi{!}]\) also gives rise to
other validities. Among them, consider the following:</p> 

\[ \begin{align} \Vdash [\chi{!}]p &amp; \leftrightarrow (\chi
\rightarrow p), \\
    \Vdash [\chi{!}]\lnot \varphi &amp; \leftrightarrow (\chi
    \rightarrow \lnot [\chi{!}]\varphi), \\ \Vdash [\chi{!}](\varphi
    \land \psi) &amp; \leftrightarrow ([\chi{!}]\varphi \land
    [\chi{!}]\psi). \\ \end{align} \]

<p>
These validities, together with the previous one characterizing
\([\chi{!}]K\varphi\), are known as the <em>reduction axioms</em>.
Here is our first twist: a careful look at these formulas reveals that
each one of them characterizes the truth of an announcement formula
\([\chi{!}]\varphi\) (the left-hand side of \(\leftrightarrow\)) in terms of formulas (the right-hand side of \(\leftrightarrow\)) whose sub-formulas appearing under the scope of \([\chi{!}]\) are <em>less complex</em>. Moreover: the formula dealing with atoms eliminates \([\chi{!}]\). Thus, given any concrete formula in \(\cL_{\left\{ K, {!}
\right\}}\), successive applications of these axioms will eventually
produce a <em>semantically equivalent</em> formula where no
\([\chi{!}]\) modality appears. This indicates that,
<em>expressivity-wise</em>, the public announcement modalities
\([\chi{!}]\) are not really needed: anything that can be expressed
with them can be also expressed by a formula without them. More
precisely, for any formula \(\varphi\) in \(\cL_{\left\{ K, {!}
\right\}}\), there is a formula
\({\operatorname{tr}(\varphi)}\) in \(\cL_{\left\{ K \right\}}\) such
that, for any \((M, w)\),</p> 

\[ (M, w) \Vdash \varphi \qquad\text{if and only if}\qquad (M, w)
\Vdash {\operatorname{tr}(\varphi)} \]

<p>
This <em>truth-preserving</em> translation, whose precise definition
can be found in van Ditmarsch, van der Hoek, and Kooi (2008: Section
7.4), shows that the public announcement modality can also be seen as
having a <em>syntactic</em> definition: any formula involving
\([\chi{!}]\) can be rewritten within \(\cL_{\left\{ K
 \right\}}\).<sup>[<a href="notes.html#note-11" id="ref-11">11</a>]</sup>
 Nevertheless, this is not a &lsquo;one line&rsquo; translation, as it
is the case, e.g., for the &lsquo;everybody knows&rsquo; modality
<i>E</i>. The translation is given by a <em>recursive</em> approach,
with the modality defined in a different way depending on the formula
one needs to place under its scope. This leads us to the second twist:
because of this recursive definition, even though adding \([\chi{!}]\)
does not increases the language&rsquo;s expressivity, its addition
does change the properties of the logical system. Indeed, in
\(\cL_{\left\{ K, {!} \right\}}\), the rule of <em>uniform
substitution</em> of atomic propositions by arbitrary formulas is not
validity-preserving anymore. Consider the following formula, stating
that <em>&ldquo;after the public announcement of <i>p</i>, the agent
will know that <i>p</i> is the case&rdquo;</em>: 

\[
\Vdash [p{!}]Kp.
\]

 The
formula is valid: a truthful public announcement of <i>p</i> discards
worlds from the original model <i>M</i> where <i>p</i> was not the
case. Hence, the resulting \(M_{p{!}}\) will have only worlds
satisfying <i>p</i>, thus making \(Kp\) true Now consider the
formula below, which results from substituting <i>p</i> by \(p \land
\lnot Kp\) in the previous validity: 

\[
[(p \land \lnot Kp){!}] K(p \land \lnot Kp).
\]

 The above formula
states now that </p>

<blockquote>

<p>
<em>after the public announcement of &ldquo;<i>p</i> is true and the
agent does not know it&rdquo;, she will know that &ldquo;<i>p</i> is
true and she does not know it&rdquo;.</em> </p>
</blockquote>

<p>
This formula can be equivalently stated (by distributing <i>K</i> over \(\land\) in the sub-formula under the scope of \([(p \land \lnot Kp){!}]\)) as</p> 

 \[[(p \land \lnot Kp){!}](Kp \land K\lnot Kp):\] 

<blockquote>

<p>
<em>after the public announcement of &ldquo;<i>p</i> is true and you
do not know it&rdquo;, the agent will know both that <i>p</i> is true
and that she does not know it.</em> </p>
</blockquote>

<p>
But now something is odd: after hearing \(p \land \lnot Kp\), the
agent surely should know that <i>p</i> is the case \((Kp)\). But then,
how is it possible that, at the same time, she knows that she does not
know it \((K\lnot Kp)\)?</p>

<p>
The suspicions are correct: the formula is not valid, and the model
below on the left provides a counter-example.</p>

<div class="figure" id="figure2">
<img src="figure2.svg" alt="a diagram: link to extended description below" />

<p class="center">
<span class="figlabel">Figure 2</span> [An
 <a href="figdesc.html#figure2">extended description of figure 2</a>
 is in the supplement.]</p>
</div>

<p>
In \((M, w)\), the atomic proposition <i>p</i> is the case, but the
agent does not know it: \((M, w) \Vdash p \land \lnot Kp\). Thus, \(p
\land \lnot Kp\) can be truthfully announced, which produces the
pointed model \((M_{(p \land \lnot Kp){!}}, w)\) on the right. Note
how <i>w</i> has survived the operation (it satisfies \(p \land \lnot
Kp)\), but <i>u</i> has not (it does not satisfy \(p \land \lnot Kp\),
as it makes <i>p</i> false). In the resulting pointed model, the agent
indeed knows that <i>p</i> is the case: \((M_{(p \land \lnot Kp){!}},
w) \Vdash Kp\). Nevertheless, she does not know that she does not know
<i>p</i>: \((M_{(p \land \lnot Kp){!}}, w) \not\Vdash K\lnot Kp\); in
fact, she knows that she knows <i>p</i>: \((M_{(p \land \lnot Kp){!}},
w) \Vdash
 KKp\).<sup>[<a href="notes.html#note-12" id="ref-12">12</a>]</sup></p>
 
<p>
Recapitulating, dynamic epistemic logics deal with modal operators for
model operations, thus allowing the explicit representation of actions
and the way they affect the concept under study. The particular
relationship between the &lsquo;static&rsquo; concept and the
&lsquo;dynamic&rsquo; action can be described by bridge principles
that arise naturally, and yet this does not come with an additional
cost, as the model-operation and dynamic-modality machinery can be
embedded into the static base logic. This has important repercussions,
particularly <em>complexity-wise</em>, as will be discussed in
 <a href="#CompIssu">section 3.4</a>.</p>
 
<h2 id="GeneStraForCombModaSyst">3. General Strategies for <em>Combining</em> Modal Systems</h2>

<p>
The previous section focused on some of the ways one can take a system
with a single modality and create a system with multiple modalities
from it. Another alternative to build a multi-modal system is to take
existing uni-modal systems, and then put them together by using a
particular strategy. This section contains a brief description of some
of the possible techniques; for a deeper discussion, the reader is
referred to the SEP entry on
 <a href="../logic-combining/index.html">combining logics</a>
 by Carnielli and Coniglio (2016).</p>




<h3 id="Fusi">3.1 Fusion</h3>

<p>
The method of
 <a href="../logic-combining/index.html#FusiProd">fusion</a>
 of <em>modal logics</em> (introduced in Thomason 1984) was developed
with the idea of <em>combining</em> relation-based (hence
<em>normal</em>) modal logics in both a syntactic way (by putting
together their respective Hilbert-style axiom systems) and a semantic
way (by taking the relations corresponding to the modality of each
system, and putting them together in a single
 model).<sup>[<a href="notes.html#note-13" id="ref-13">13</a>]</sup>
 Although the fusion of modal systems is fairly simple, the
<em>transference</em> results that guarantee that properties are
preserved (e.g., whether the combination of the sound and complete
axiomatization of the existing systems is indeed sound and complete
for the resulting one) are not straightforward (see, e.g., Kracht
&amp; Wolter 1991, 1997; Fine &amp; Schurz 1996; Schurz 2011).</p>

<p>
When this strategy is followed, and leaving technical details aside,
the most important decision is the possible introduction of
<em>bridge</em> principles that link the main modalities of the
systems to be combined. Paraphrasing Schurz (1991), a schema
\(\varphi\) is a <em>bridge principle</em> if and only if it contains
at least one schematic letter which has at least one occurrence within
the scope of the modality of one system and at least one occurrence
within the scope of the modality of the other. (This definition was
given in the context of the David Hume&rsquo;s discussion on whether
<em>ought</em> can be derived from <em>is</em>; see
 <a href="../logic-combining/index.html#PhilMethMotiForCombLogi">Section 1</a>
 of
 <a href="../logic-combining/index.html">combining logics</a>.)</p>
 
<p>
In order to provide a better explanation of this technique, here we
will discuss the construction of a simple temporal epistemic logic. On
the epistemic side, recall that the basic
 <a href="../logic-epistemic/index.html">epistemic logic</a>
 system is given, syntactically, by the language \(\cL_{\left\{ K
\right\}}\), and semantically, by a relational model. In it, the
modality <i>K</i> is semantically interpreted in terms of a binary
relation \(R_K\). On the temporal side, define the
&lsquo;future&rsquo; fragment of the basic
 <a href="../logic-temporal/index.html#PriBasTenLogTL">temporal (tense) logic</a>
 as a system which is syntactically specified by the language
\(\cL_{\left\{ G \right\}}\) (with <i>G</i> a <em>universal</em>
quantification on the future, and <i>F</i> its <em>existential</em>
counterpart given by \(F\varphi := \lnot G\lnot \varphi)\), and
semantically, by a relational model with \(R_G\) as the crucial
relation.</p>

<p>
The <em>fusion</em> of these systems is syntactically specified by the
language \(\cL_{\left\{ K, G \right\}}\) (i.e., a language freely
generated by the union of the modalities of \(\cL_{\left\{ K
\right\}}\) and \(\cL_{\left\{ G \right\}})\). Formulas of this
language are semantically interpreted in <em>relational</em> models of
the form \({\langle W, R_K, R_G, V \rangle}\) such that \({\langle W,
R_K, V \rangle}\) is a model for \(\cL_{\left\{ K \right\}}\) and
\({\langle W, R_G, V \rangle}\) is a model for \(\cL_{\left\{ G
\right\}}\). For the semantic interpretation, formulas of the new
language are interpreted in the standard way, with each modality using
its correspondent relation. With respect to axiom systems, it is
enough to put together those of the individual logics.</p>

<p>
But we are not done yet. As mentioned before, the most interesting
part is the possible inclusion of bridge principles. So, which is the
proper interaction between
 <a href="../logic-temporal/index.html#TemEpiLog">time and knowledge</a>?
 One might require <em>perfect recall</em>: the agent&rsquo;s
knowledge is not decreased over time or, in other words, uncertainty
at any moment should have been &lsquo;inherited&rsquo; from
uncertainty from the past. This corresponds to the following bridge
principle:</p> 

\[
K\varphi \rightarrow GK\varphi \qquad (\text{equivalently, } F\hK\varphi \rightarrow \hK\varphi).
\]

<p>
This is clearly an idealization, and as such it makes sense only under
certain interpretations; still, it might imply more than meets the
eye. Assuming that the agent never forgets the truth-value of an
atomic proposition <i>p</i> might be reasonable; but, what if
\(\varphi\) is a more complex formula, in particular one involving the
epistemic modality? For example, take the formula \(\lnot Kp \land
\lnot K\lnot p\) (<em>&ldquo;the agent does not know whether
<i>p</i>&rdquo;</em>), yielding the instance \(K(\lnot Kp \land \lnot
K\lnot p) \rightarrow GK(\lnot Kp \land \lnot K\lnot p)\)
(<em>&ldquo;if the agent knows of her ignorance about whether
<i>p</i>, then she will always know about such ignorance&rdquo;</em>).
Is this within the expected consequences?</p>

<p>
A related property is that of <em>no learning</em> (the agent&rsquo;s
knowledge is not increased over time; in other words, any current
uncertainty will be preserved). This property corresponds to</p>

\[
FK\varphi \rightarrow K\varphi \qquad (\text{equivalently, } \hK\varphi \rightarrow G\hK\varphi).
\]

<p>
A slight elaboration on these and related properties can be found on
the discussion on time and knowledge
 (<a href="#TimeKnow">section 4.2</a>;
 for a deeper study, see Halpern &amp; Vardi 1989; van Benthem &amp;
Pacuit 2006, albeit in a different semantic setting).</p>

<h4>3.1.1 &lsquo;Temporalizing&rsquo; a System</h4>

<p>
The fusion method provides a simple yet powerful strategy for adding a
further aspect to an existing modal system by using another already
existing system dealing with this further aspect independently.
Indeed, the discussed example can be seen as adding a
<em>temporal</em> aspect to the standard study of the properties of
knowledge. Besides the traditional epistemic questions (e.g., whether
knowledge should be positively/negatively introspective), one can also
discuss not only whether knowledge should change, but also the
different ways in which it might so.</p>

<p>
This idea of adding a temporal aspect makes sense not only for
knowledge, but also for other modal concepts. For example, one can
think of adding a temporal feature to a modal system for preferences,
thus discussing different ways in which the preferences of an agent
might change over time (and also <em>why</em> they do so, if further
<em>dynamic</em> machinery is added to talk about <em>actions</em> and
their consequences; Gr&uuml;ne-Yanoff &amp; Hansson 2009; Liu 2011).
Similarly, adding a temporal aspect to modal systems of
 <a href="../logic-deontic/index.html">deontic logic</a>
 raises interesting concepts and questions, an example being the
notion of <em>deontic deadlines</em>, discussed in
 <a href="#ObliTime">section 4.7</a> on
 obligations and time.</p>

<h4>3.1.2 &lsquo;Epistemizing&rsquo; a System</h4>

<p>
The study of some concepts such as preferences or obligations gives
raise to an epistemic concern: how much do the involved agents
<em>know</em> about such preferences and obligations? In most examples
where such concepts play a role, whether or not the agent knows about
the involved preferences or obligations makes an important difference.
In case of the first, should an agent act according to her and other
agents&rsquo; preferences, even when she does not know what these
preferences are? In case of the second, is an agent compelled to obey
a duty even when she does not know what the duty is?</p>

<p>
The fusion of a basic preference/deontic setting and epistemic logic
provides basic formal tools to discuss the epistemic aspects of
preferences and obligations. For example, consider the
 <a href="../logic-deontic/supplement.html#ParaEpisObliAqvi1967">paradox of epistemic obligation</a>:
 a bank is being robbed (<i>r</i>), and the guards ought to know about
the robbery \((OKr)\). But knowledge is factive \((Kr \rightarrow
r)\), so then the bank ought to be robbed \((Or)\)! More on these
concerns (under different formal systems) can be found within the
discussion on knowledge and obligations
 (<a href="#KnowObli">section 4.8</a>).</p>
 
<p>
For a deeper study on the fusion of modal logics, the reader is
referred to Wolter (1998), Gabbay, Kurucz, Wolter, and Zakharyaschev
(2003: Chapter 4), and Kurucz (2006: Section 2). Further examples of
fusion can be found
 <a href="../logic-combining/index.html#FusiProd">in the SEP entry</a>
 discussing methods for
 <a href="../logic-combining/index.html">combining logics</a>.
 Still, before closing this subsection, we add a word of caution. One
needs to be careful when building the fusion of modal systems. This is
because, in the system that results from the fusion, there are already
formulas combining the modalities of its different fragments. Then,
even if no particular bridge (valid) principles are enforced, the
language might gain in <em>expressive power</em>, which might increase
its
 <a href="../computational-complexity/index.html">complexity</a>
 profile.
 <a href="#CompIssu">Section 3.4</a>
 on complexity issues elaborates on this important but often forgotten
aspect.</p>

<h3 id="Prod">3.2 Product</h3>

<p>
The fusion of modal systems produces a rich language that allows us to
express the different ways in which the involved modalities interact
(the bridge principles). Still, from a semantic perspective, there is
still just <em>one</em> point of reference, as all formulas of this
richer language are still evaluated on a single possible world.</p>

<p>
The strategy of defining a
 <a href="../logic-combining/index.html#FusiProd">product</a>
 of modal logics (introduced in Segerberg 1973 and &Scaron;ehtman
1978) shares the idea of using a language that is freely generated by
the union of the modalities of the original languages. But, on the
semantic side, the approach is quite different: instead of working on
a one-dimension domain, it works on a <em>multi-dimensional</em>
domain that has one dimension for each one of the involved aspects
(i.e., modalities). More precisely, if the semantic models of the
to-be-combined systems are \(M_1 = {\langle W_1, R_1, V_1 \rangle}\)
and \(M_2 = {\langle W_2, R_2, V_2 \rangle}\), the models where
formulas of the resulting language are evaluated are now of the form
\(M' = {\langle W_1 \times W_2, R'_1, R'_2, V_1 \times V_2
\rangle}\). The domain \(W_1 \times W_2\) is, then, the standard
Cartesian product of the original domains, and the valuation \(V_1
\times V_2\) is such than an atom <i>p</i> is true in a world \((w_1,
w_2)\) if and only if <i>p</i> was true at \(w_1\) in \(M_1\) and also
true at \(w_2\) in \(M_2\) (i.e., \((V_1 \times V_2)(p) := V_1(p)
\times V_2(p))\). For the relations, each one of them is given as in
their original models, restricted now to their respective dimensions:
</p> 

\[
\begin{align}
    R'_1(w_1, w_2)(u_1, u_2) &amp;\quad \iffdef\quad R_1w_1u_1 \text{ and } w_2=u_2 \\
    R'_2(w_1, w_2)(u_1, u_2) &amp; \quad \iffdef\quad  w_1=u_1 \text{ and } R_2w_2u_2 \\
  \end{align}
\]

<p>
The product of modal logics is a <em>many-dimensional modal logic</em>
(Gabbay et al. 2003; Marx &amp; Venema 1997; Venema 1992). Within
these models, formulas are now evaluated in pairs \((w_1, w_2)\), with
each modality semantically interpreted in the standard way (but now
with respect the new version of its matching relation):</p>

\[
\begin{align}
    (M', (w_1, w_2)) \Vdash \Box_{1}\varphi \quad \iffdef \quad {}&amp; \text{for all } (u_1, u_2) \in W', \\
&amp; \text{ if } R'_1(w_1, w_2)(u_1, u_2) \\
&amp;\text{ then } (M', (u_1, u_2)) \Vdash \varphi \\
    (M', (w_1, w_2)) \Vdash \Box_{2}\varphi \quad \iffdef \quad {}&amp;\text{for all } (u_1, u_2) \in W', \\
&amp; \text{ if } R'_2(w_1, w_2)(u_1, u_2) \\
&amp;\text{ then } (M', (u_1, u_2)) \Vdash \varphi
  \end{align}
\]

<p>
This specific way of interpreting each one of the original modalities
yields another crucial difference between the fusion and the product
of modal systems: the latter enforces, by its own nature, certain
bridge principles (on top of those that might be added). Indeed,
because of the definition of the relations and the modalities&rsquo;
semantic interpretation, the following schemas are valid:</p>

\[
\begin{align}
    \text{Commutativity 1:}        &amp; &amp;\Diamond_{1} \Diamond_{2}\varphi \rightarrow \Diamond_{2} \Diamond_{1}\varphi \\
    \text{Commutativity 2:}        &amp; &amp; \Diamond_{2}\Diamond_{1}\varphi \rightarrow \Diamond_{1} \Diamond_{2}\varphi \\
    \text{Church-Rosser property:} &amp; &amp; \Diamond_{1}\Box_{2}\varphi \rightarrow \Box_{2}\Diamond_{1}\varphi \\
  \end{align}
\]

<p>
The product of modal systems, with its <i>n</i>-dimensional nature, is
a very useful tool and, in particular, it has been of help for dealing
with the philosophical semantics technique of
 <a href="../two-dimensional-semantics/index.html">two-dimensionalism</a>
 (see also Chalmers 2006; Stalnaker 1978). This technique has been
applied in different fields. In linguistics, it is the basis of David
Kaplan&rsquo;s semantic framework for
 <a href="../indexicals/index.html#KapTheInd">indexicals</a>
 (Kaplan 1989), which in turn has been used to explain conventional
semantic rules governing context-dependent expressions as
<em>&lsquo;I&rsquo;</em> and <em>&lsquo;now&rsquo;</em>. Consider, for
example, a setting built to talk about the features of a group of
friends at different times; the context in which formulas will be
evaluated can be defined as a tuple \((w, a, m)\), with \(w \in W\) a
possible world, \(a \in \ttA\) an agent within that world and \(m \in
T\) a moment in time when the agent exists in that world. Then, a
sentence of the form <em>&ldquo;I am tired now&rdquo;</em> corresponds
simply to an atom &ldquo;<em>tired</em>&rdquo;, with its truth-value
being potentially different in different contexts, depending on
whether, in the given world <i>w</i>, the given agent <i>a</i> is
tired at the given moment <i>m</i>. Moreover: suppose the setting contains an alethic possibility relation between worlds \((R \subseteq W \times
W)\), a <em>friendship</em> relation between agents \(({\asymp}
\subseteq \ttA\times \ttA)\) and a temporal <em>future</em> relation
between moments \((R_G \subseteq T \times T)\). Then, one can use matching modalities (the universal ones, \(\oBox\) and \([\asymp]\), for the first two; the existential one \({F}\) for the third) to express sentences as <em>&ldquo;I have a friend who is playing right now and necessarily will be tired at some moment later&rdquo;</em> \((\langle \asymp\rangle(\textit{playing} \land
\oBox F\textit{ tired}))\) and <em>&ldquo;if one of my friends is
playing now, all of them might be playing later&rdquo;</em>
\((\langle\asymp\rangle \textit{playing} \rightarrow \Diamond
F[\asymp]\textit{playing})\).</p>

<p>
In philosophy of mind, two-dimensional semantics has been used by
David Chalmers (combining both epistemic and modal domains) to provide
arguments against <em>materialism</em> in philosophy of mind (details
can be found in Chalmers 2009).</p>

<p>
A final example of the product of two modal logics (though not
originally conceived as such, and presented in a slightly different
way), is the <em>Facebook Logic</em> of Seligman, Liu, &amp; Girard
(2011, 2013), useful for talking about friends and social information
flow. The setting can be seen as the combination of a standard
single-agent epistemic logic and a modal logic for social networks
(cf. Baltag, Christoff, Rendsvig, &amp; Smets 2019; Smets &amp;
Vel&aacute;zquez-Quesada 2017). Its semantic model consists on two
domains (possible worlds <i>W</i>, agents \(\ttA)\) and two relations:
a binary epistemic relation \({\sim_a} \subseteq (W \times W)\) for
each agent \(a \in \ttA\), and a binary friendship relation
\({\asymp_w} \subseteq (\ttA\times \ttA)\) for each world \(w \in W\).
On the syntactic side, the language is freely generated by the
standard Boolean operators and two universal modalities, <i>K</i>
(knowledge) and \([\asymp]\) (friendship). These formulas are
evaluated in pairs (<em>world</em>, <em>agent</em>), with the key
clauses being the following:</p> 

\[
\begin{align}
    (M, w, a) \Vdash K\varphi    &amp; \quad\iffdef\quad \text{for all } u \in W, \text{ if } w \sim_a u \text{ then } (M, u, a) \Vdash \varphi \\
    (M, w, a) \Vdash [\asymp]\varphi &amp;  \quad\iffdef\quad  \text{for all } b \in \ttA, \text{ if } a \asymp_w b \text{ then } (M, w, b) \Vdash \varphi \\
\end{align}
\]

<p>
Note that the modalities are <em>indexical</em> in both the world
<em>and</em> the agent. Thus, while formulas of the form \(K\varphi\)
are read as <em>&ldquo;I know \(\varphi\)&rdquo;</em>, formulas of the
form \([\asymp]\varphi\) are read as <em>&ldquo;all my friends satisfy
\(\varphi\)&rdquo;</em>.</p>

<p>
The given examples show how the product strategy can be used to
&lsquo;temporalize&rsquo; and/or &lsquo;epistemize&rsquo; a given
modal system (Kaplan&rsquo;s semantic framework can be understood as
the temporalization of an alethic system, and the described
<em>Facebook Logic</em> can be understood as the
&lsquo;epistemization&rsquo; of a social network setting). For more on
the products of modal logics, the reader is referred to the
already-mentioned
 <a href="../logic-combining/index.html#FusiProd">combining logics</a>,
 and also to Gabbay et al. (2003: Chapter 5), Kurucz (2006: Section
3) and van Benthem, Bezhanishvili, et al. (2006).</p>

<h3 id="ModaFibr">3.3 Modal Fibring</h3>

<p>
The strategies of fusion and product for combining modal logics rely
in merging both the languages and the semantic models of the modal
logics to be combined. In the
 <a href="../logic-combining/index.html#FibrFibrFunc">fibring</a>
 strategy (called <em>fibring by functions</em> in Carnielli,
Coniglio, et al. 2008), the languages are also merged, but the
semantic models remain separated. Formulas can be evaluated in pointed
models of any of the original systems, in the following way. When the
modality to be semantically evaluated &lsquo;matches&rsquo; the chosen
semantic model, the evaluation is done as in the original system; when
the modality comes from the other system, the fibring strategy uses a
<em>transfer mapping</em> to obtain a model and an evaluation point in
the class of models for the modality under evaluation, and then the
evaluation proceeds as in the original system. Thus, modal fibring
requires a correspondence between the class of models of each one of
the systems, and uses it to move between them when the modality under
evaluation requires it.</p>

<p>
More precisely, let \(\cL_{\left\{ \Box_{1} \right\}}\) and
\(\cL_{\left\{ \Box_{2} \right\}}\) be the languages of the system to
be combined, and let \(\cM_1\) and \(\cM_2\) be their correspondent
<em>classes</em> of models. Let \(h_1\) be a <em>transfer mapping</em>,
taking a world of any model in \(\cM_1\), and returning a pair
consisting of a model \(M_2\) in \(\cM_2\) and a world \(w_2\) in
\(M_2\); let \(h_2\) be a <em>transfer mapping</em> in the other
direction, taking a world of any model in \(\cM_2\), and returning a
pair consisting of a model \(M_1\) in \(\cM_1\) and a world \(w_1\) in
\(M_1\). Formulas of the language \(\cL_{\left\{ \Box_{1}, \Box_{2}
\right\}}\) can be evaluated in either tuples of the form \(\langle
h_1, h_2, M_1, w_1 \rangle\) (with \(w_1\) in \(M_1 = \langle W_1,
R_1, V_1 \rangle\) and \(M_1\) in \(\cM_1)\) or else tuples of the
form \(\langle h_1, h_2, M_2, w_2 \rangle\) (with \(w_2\) in \(M_2 =
\langle W_2, R_2, V_2 \rangle\) and \(M_2\) in \(\cM_2)\). In the
first case, the semantic interpretation of Boolean operators is as
usual; for the modality \(\Box_{1}\),</p>

<table class="centered cellpad-med-dense vert-top">
<tr>
  <td>\(\langle h_1, h_2, M_1, w_1 \rangle \Vdash
\Box_{1}\varphi\)</td>
  <td>\(\iffdef\)</td>
  <td> for all \(u_1 \in W_1\), if \(R_1wu\) then \(\langle h_1, h_2,
M_1, u_1 \rangle \Vdash \varphi.\)</td> </tr>
</table>

<p>
Thus, modalities &lsquo;matching&rsquo; the model are evaluated as in their original systems. Then, for the modality \(\Box_{2}\) of the
other system, the transfer mapping \(h_1\) is used:</p> 

\[
    \langle h_1, h_2, M_1, w_1 \rangle \Vdash \Box_{2}\varphi \quad\iffdef\quad \langle h_1, h_2, h_1(w_1) \rangle \Vdash \Box_{2}\varphi
\]

<p>
In other words, when \(\Box_{2}\) needs to be evaluated, the transfer
mapping uses current evaluation point \(w_1\) to obtain a pointed
semantic model \(h_1(w_1) = (M_2, w_2)\) where the modality will be
evaluated. When the analogous situation arises, facing the evaluation
of \(\Box_{1}\) on a tuple \(\langle h_1, h_2, M_2, w_2 \rangle\), it
is the turn of the second transfer function \(h_2\) to make its
appearance, taking us then from \(\langle h_1, h_2, M_2, w_2 \rangle
\Vdash \Box_{2}\varphi\) to \(\langle h_1, h_2, h_2(w_2) \rangle
\Vdash \Box_{2}\varphi\).</p>

<p>
For more details on the fibring of modal logics, the reader is
referred to Gabbay (1999: Chapter 3). For other forms of fibring, see
 <a href="../logic-combining/index.html#FibrFibrFunc">Section 4.3</a>
 of
 <a href="../logic-combining/index.html">combining logics</a>.</p>
 
<h3 id="CompIssu">3.4 Complexity Issues</h3>

<p>
So far, this text has described different ways in which a multi-modal
system can emerge. We have briefly discussed how a single modal system
can give rise to a multi-modal one by providing either syntactic or
semantic definitions of new concepts
 (<a href="#NecePoss">section 2</a>),
 and also how two or more modal systems can be combined in order to
produce a multi-modal one
 (<a href="#GeneStraForCombModaSyst">section 3</a>).
 As the provided examples have shown (and the examples in
 <a href="#SignInteBetwModa">section 4</a>
 will continue to do), the addition of modalities allows us to
establish and/or find significant relationships between the involved
concepts, thus providing a better understanding of what each one of
them is.</p>

<p>
But there is also another side to this coin. By adding modalities to a
system, one increases its expressivity, but this may also have the
undesirable consequence of raising its
 <a href="../computational-complexity/index.html">computational complexity</a>.
 Indeed, a modal language allows us to describe a certain class of
models. If the language is fairly simple, then deciding whether a
given formula is true in a given world of a given model (the
<em>model-checking</em> problem) and deciding whether a given formula
is true in all worlds of all models in a given class (the
<em>validity</em> problem) are simple tasks. Now suppose a more
expressive language is used. It is then possible to distinguish models
that were, from the first language&rsquo;s perspective, the same
(see, e.g., the appendix on the non-definability of distributed and common knowledge within \(\cL_{\left\{ \oK{1}, \ldots, \oK{n} \right\}}\)).
However, intuitively, we might then need to make a stronger effort to
see those differences: we might need more time to make the
calculations, and we might need more space to save intermediate
results. In a single sentence, expressivity and complexity go hand in
hand, and an increase in the first typically produces an increase in
the second.</p>

<p>
The simplest example of this phenomenon is given by the relationship
between the two best-known logical languages, the propositional and
the first-order predicate one, when used to describe first-order
models. The validity problem for the propositional language, which can
be understood as one that only allows us to talk about the properties
(i.e., monadic predicates) of a single object and their Boolean
combination, is <em>decidable</em>: there are effective procedures
that can answer the validity question for any given propositional
formula. The first-order predicate language can see much more (all
objects of the domain, together with their properties and their
<i>n</i>-ary relations, among others), but this comes at a price: its
validity problem is <em>undecidable</em>, as there is no effective
procedure that can answer the validity question for all its
formulas.</p>

<p>
In the modal realm there are also such cases, some of them in which
seemingly harmless combinations produce dramatic results. An example
of this can be found in Blackburn, Rijke, and Venema (2001: Section
6.5), where it is shown that the fusion of two decidable systems, a
<em>PDL</em>-like system (with sequential composition and intersection
as the syntactic constructors) and a system with the global modality
(Goranko &amp; Passy 1992), crosses the border into undecidability.
Even if the new multi-agent system turns out not to be undecidable,
its complexity might be such that solving its validity problem for
relatively small instances is, for all practical purposes, impossible.
An example of such case is the basic multi-agent epistemic logic, with
no requirements on the accessibility relations. The validity problem
for formulas in \(\cL_{\left\{ \oK{1}, \ldots, \oK{n} \right\}}\) is
 <a href="../computational-complexity/index.html#ComClaHieThe">PSPACE</a>: the space (and thus time) required to decide whether any given \(\varphi\) is valid is given by a polynomial function. However, adding the common knowledge
operator makes the validity problem for formulas in \(\cL_{\left\{
\oK{1}, \ldots, \oK{n}, C \right\}}\) EXPTIME (sometimes also called
 <a href="../computational-complexity/index.html#ComClaHieThe">EXP</a>):
 the required time is now given by an exponential
 function.<sup>[<a href="notes.html#note-14" id="ref-14">14</a>]</sup></p>
 

<p>
A major methodological issue is then to strike a proper balance
between expressive power and computational complexity, with the best
multi-modal systems being those that manage to achieve a good
compromise in this sense. We end this section noticing briefly that,
in the case of the <em>combination</em> of modal logics, complexity
depends deeply on the assumed bridge axioms. A famous example of this
is the landmark paper by Halpern &amp; Vardi (1989) on the complexity
of (96!) epistemic and temporal logics over <em>interpreted
systems</em>, all of them differing on the used language (single or
multiple-agents, common knowledge or lack of) and the assumed bridge
principles (the aforementioned <em>perfect recall</em> and <em>no
learning</em>, <em>synchronicity</em>, unique or multiple initial
state).</p>

<h2 id="SignInteBetwModa">4. Significant Interactions Between Modalities</h2>

<p>
The previous sections have described several ways of obtaining
multi-modal systems. The current one presents some of the most
interesting examples, together with the discussions that arise
from the interplay of the modalities involved.</p>

<h3 id="RelaBetwKnowBeli">4.1 The Relationship Between Knowledge and Beliefs</h3>

<p>
The interplay between knowledge and belief is an important topic in
epistemology. Historically, one of the most important proposals is
Plato&rsquo;s characterization of knowledge as
 <a href="../knowledge-analysis/index.html#KnowJustTrueBeli">justified true belief</a>,
 which has been one of the motivations used in the development of
 <a href="../logic-justification/index.html">justification logic</a>.
 However, can knowledge be truly defined as justified true belief? The
 <a href="../knowledge-analysis/index.html#GettProb">examples</a>
 provided (among others) in Gettier (1963) seem to go against this
idea. Gettier describes situations in which an agent believes a given
\(\varphi\) and has a justification for it; moreover, \(\varphi\) is
indeed the case. Nevertheless, the justification is not an appropriate
one: \(\varphi\) happens to be the case because of some other lucky
unrelated circumstances. This has lead to proposals that focus on the
requirement of a <em>correct</em> justification (the <em>no false
lemma</em>: Clark 1963; Armstrong 1973; Shope 1983). Some others have
used a stronger <em>indefeasibility</em> requirement, stating that
knowledge is justified true belief that cannot be defeated by true
information, i.e., there is no true proposition \(\psi\) such that, if
the agent were to learn that \(\psi\) was the case, would lead her to
give up her belief, or to be no longer justified in holding it (Klein
1971; Lehrer &amp; Paxson 1969; Swain 1974). The aforementioned
topological modal approach of Baltag, Bezhanishvili, et al. (2016)
relates this idea with other epistemic concepts, and a deeper
discussion on what it means to know something can be found in
 <a href="../knowledge-analysis/index.html">the analysis of knowledge</a>
 by Ichikawa and Steup (2018).</p>

<p>
There are also other alternatives. An interesting proposal, discussed
in Lenzen (1978) and Williamson (2002), follows the other direction:
start from a chosen notion of knowledge, and then weaken it in order
to obtain a &lsquo;good&rsquo; (e.g., consistent, introspective,
possibly false) notion of belief. These ideas have been discussed in
formal settings. In Stalnaker (2006), the author argues that the
&ldquo;true&rdquo; logic of knowledge is the modal logic S4.2, given
by the standard <em>K</em> axiom \((K(\varphi \rightarrow\psi)
\rightarrow (K\varphi \rightarrow K\psi))\) and the generalization
rule \((K\varphi\) for every validity \(\varphi)\), together with
veridicality \((K\varphi \rightarrow \varphi\): knowledge is
truthful), positive introspection \((K\varphi \rightarrow KK\varphi\):
if the agent knows \(\varphi\), then she knows that she knows it) and
the &lsquo;convergence&rsquo; principle \((\hK K\varphi \rightarrow
K\hK\varphi\): if the agent considers it possible to know \(\varphi\),
then she knows that she considers \(\varphi\) a possibility). In this
setting, Stalnaker (2006) argues that belief can be defined as the
epistemic possibility of knowledge, that is,</p> 

\[
B\varphi := \hK K\varphi
\]

<p>
Note how this is exactly what the definition of belief in the
previously discussed plausibility models entails: if the modality
\([\leq]\) is understood as indefeasible knowledge (Lehrer 1990;
Lehrer &amp; Paxson 1969), then \(B\varphi :=
\langle{\leq}\rangle[{\leq}]\varphi\) states that belief is the
possibility of knowledge. In this context, it is a small step to move
from studying simple beliefs to conditional beliefs. A complete
axiomatization of the logic of indefeasible knowledge and conditional
belief, first posed as an open question in Board (2004), was provided
with a solution in Baltag and Smets (2008).</p>

<p>
A further proposal that uses knowledge as the basic notion is that of
Baltag, Bezhanishvili, &Ouml;zg&uuml;n, and Smets (2013), which
generalizes Stalnaker&rsquo;s (2006) formalization by using a
<em>topological</em> (neighborhood) semantics. An important feature of
the notion of belief that arises in this setting is that it is
subjectively indistinguishable from knowledge: an agent believes
\(\varphi\) \((B\varphi)\) if and only if she believes that she knows
it \((BK\varphi)\).</p>

<h3 id="TimeKnow">4.2 Time and Knowledge</h3>

<p>
Temporal-epistemic approaches have been briefly mentioned in this
text.
 Indeed, many logical systems have been used to describe the way in
which the knowledge of agents changes over time. The proposals include
not only <em>interpreted systems</em> (<em>IS</em>; Fagin et al. 1995)
but also <em>epistemic-temporal logic</em> (<em>ETL</em>; Parikh &amp;
Ramanujam 2003), logics of
 <a href="../agency/index.html">agency</a>
 (e.g., <em>see to it that</em> logic,
 <a href="../logic-action/index.html#StiSag">STIT</a>;
 Belnap, Perloff, &amp; Xu 2001) and the <em>DEL</em> approach
mentioned before
 (<a href="#DynaEpisLogiAppr">section 2.8</a>).
 In all of them, an important point of discussion is the interaction
between the temporal and epistemic modalities.</p>

<p>
As mentioned before, two famous requirements have been those of
<em>perfect recall</em> (the agent&rsquo;s knowledge is not decreased
over time) and <em>no learning</em> (the agent&rsquo;s knowledge is
not increased over time). In the simple fusion of epistemic logic and
the future fragment of tense logic described above, these two
requirements can be expressed, respectively, as </p> 

\[
    K\varphi \rightarrow GK\varphi \quad \text{ and } \quad FK\varphi \rightarrow K\varphi.
\]

<p>
For some, the <em>no learning</em> condition might be too harsh, as it
seems to say that the passage of time never helps to increase
knowledge. A related but more reasonable condition is that of <em>no
miracles</em>, introduced in a slightly richer setting in van Benthem
and Pacuit (2006), which states that the uncertainty of the agents
cannot be erased <em>by the same
 event</em>.<sup>[<a href="notes.html#note-15" id="ref-15">15</a>]</sup>
 A further interaction property is that of <em>synchronicity</em>,
which states that epistemic uncertainty only happens among epistemic
situations that occur at the same moment of time. For example, the
agent always knows &lsquo;what time it is&rsquo;, as she might not
know which action was executed, but she always knows that some action
has taken place.</p>

<p>
For more information on the interaction of time and knowledge, the
reader is referred, among others, to Halpern, van der Meyden, and
Vardi (2004); van Benthem, Gerbrandy, et al. (2009). See also van
Benthem and D&eacute;gremont (2010) and D&eacute;gremont (2010) for
analogous interactions between time and <em>beliefs</em>, with the
latter represented by plausibility preorders similar to the
plausibility models described before.</p>

<h3 id="KnowQues">4.3 Knowledge and Questions</h3>

<p>
The interplay between questions and propositions is an important
factor in driving reasoning, communication, and general processes of
investigation (Hintikka 2007; Hintikka, Halonen, &amp; Mutanen 2002).
Indeed, </p>

<blockquote>

<p>
[s]cientific investigation and explanation proceed in part through the
posing and answering of questions, and human-computer interaction is
often structured in terms of queries and answers. (from the SEP entry
on
 <a href="../questions/index.html">questions</a>
 by Cross &amp; Roelofsen 2018)</p>
</blockquote>

<p>
But then, what is the relationship between an agent&rsquo;s knowledge
and her questions? Maybe more important: given that different agents
might be posing different questions (i.e., they might be interested in
different issues), what is the relationship between the knowledge of
different agents?</p>

<p>
The proposal of Boddy (2014) and Baltag, Boddy, and Smets (2018)
studies these concerns (then also studying what the &lsquo;real&rsquo;
common and distributed knowledge of a group is). Their model (based on
the <em>epistemic issue</em> model introduced in van Benthem &amp;
Minica 2012) assumes that agents have not only their individual
knowledge, but also their individual <em>issues</em>: the topics that
each one of them has put on the table, which determine their
individual agenda on what is currently under investigation. On the
syntactic side, besides the standard knowledge modality \((K_i\) for
each agent <i>i</i>), there is also a modality \(Q_{i}\varphi\), read
as <em>&ldquo;\(\varphi\) can be known solely based on learnable
answers to <i>i</i>&rsquo;s questions&rdquo;</em>. In other words,
\(Q_a\) describes the maximum knowledge agent <i>a</i> can acquire,
given her questions and the answers that are learnable for her. Thus,
as a principle, if <i>a</i> knows \(\varphi\), she can know it solely
based on answers to her question(s):</p> 

\[
K_{a}\varphi \rightarrow Q_{a}\varphi
\]

<p>
More interesting is the relationship between agent <i>a</i>&rsquo;s
knowledge and that of other agent <i>b</i>: in order for an agent to
consider any potential knowledge, such knowledge must be relevant for
her in the sense that she can distinguish it as a possible answer to
one of her questions. In other words, </p>

<blockquote>

<p>
[a]gents are therefore only able to coherently represent the knowledge
of others [&hellip;] if the fact that they (the others) possess this
knowledge [&hellip;] is relevant to them. (Boddy 2014: 28) </p>
</blockquote>

<p>
Thus, &ldquo;if <i>b</i> knows something that is relevant to <i>a</i>,
then it is relevant to <i>a</i> that <i>b</i> knows this&rdquo; and
</p>

<blockquote>

<p>
if <i>b</i> can know (given her issue) anything that is relevant to
<i>a</i>, then this fact (that <i>b</i>&rsquo;s potential knowledge
includes potential knowledge of <i>a</i>) is itself relevant to
<i>a</i>. </p>
</blockquote>

<p>
In symbols,</p> 

\[
    K_{b}Q_{a}\varphi \rightarrow Q_{a} K_{b}\varphi \quad \text{ and } \quad Q_{b} Q_{a}\varphi \rightarrow Q_{a}Q_{b}\varphi.
\]

<p>
A more in-depth discussion about the consequences of adding the
agent&rsquo;s issues to the picture (including alternative definitions
for the group&rsquo;s distributed and common knowledge) can be found
in the above references.</p>

<h3 id="Agen">4.4 Agents</h3>

<p>
In the context of the design and implementation of autonomous agents,
one of the most famous architectures is the
<em>belief-desire-intention</em> (<em>BDI</em>) model (Bratman 1987;
Herzig, Lorini, Perrussel, &amp; Xiao 2017).</p>

<p>
Developed initially as a model of human practical reasoning (Bratman
1987), the <em>BDI</em> model proposes an explanation of practical
reasoning involving action, intention, belief, goal, will,
deliberation and several other concepts. Thus, it is natural to think
about combining simple modal logics for some of these notions in order
to define logics for such richer settings. Indeed, several formal
semantics for such models have been proposed, some of them based on
diverse temporal logics (Cohen &amp; Levesque 1990; Governatori,
Padmanabhan, &amp; Sattar 2002; Rao &amp; Georgeff 1991), some others
based on dynamic logics (van der Hoek, van Linder, &amp; Meyer 1999;
Singh 1998), and some based on both (Wooldridge 2000). The crucial
part in most of them is the interaction between these different
attitudes. For example, on the one hand, if an agent intends to
achieve something (say, \(I\varphi)\), one would expect for her to
desire that something \((D\varphi)\); otherwise, it does not make
sense to devote resources to achieve it. On the other hand, desiring
something should not imply an intention to achieve it: it does not
seem reasonable to commit resources to all our desires, even the
unrealistic ones (and, perhaps more importantly, intention and desires
would collapse into a single notion). Moreover, it seems clear that an
agent who desires to be rich \((Dr)\) does not necessarily believe
that she is rich \((Br)\). Finally, if an agent has an intention to
write a book \((Ib)\), should she believe that she will write it
\((BFb)\), thus ruling out all possible unforeseen circumstances that
could prevent her from doing it?</p>

<p>
A concise description of this interaction in some of these proposals
can be found in the first part of
 <a href="../logic-action/index.html#DesSpeIntAge">Subsection 4.2</a>
 in the SEP entry on
 <a href="../logic-action/index.html">the logic of action</a>
 written by Segerberg, Meyer, and Kracht (2016).</p>

<h3 id="ModaFirsOrdeLogi">4.5 Modal First-Order Logic</h3>

<p>
Modal first-order (i.e., quantified modal) logic is perhaps one of the
most intriguing multi-modal systems, as the combination of quantifiers
and modalities raises several interesting questions. Here we will
discuss briefly two important points; readers interested in a further
discussion are referred to the SEP discussion on
 <a href="../logic-modal/index.html#QuaModLog">quantified modal logic</a>
 by Garson (2018).</p>

<p>
The modal first-order language is built in a straightforward way:
simply take the classical
 <a href="../logic-classical/index.html#2">first-order language</a>,
 with its universal \((\forall)\) and existential \((\exists)\)
operators indicating quantification over objects, and add the two
basic modal alethic operators, necessity \((\Box)\) and possibility
\((\Diamond)\). The resulting language turns out to be very
expressive, allowing us to distinguish between the <em>de dicto</em>
and the <em>de re</em> readings of natural language sentences (a
contrast that can be traced back to Aristotle; see Nortmann 2002). For
example, assume that an individual <i>f</i> has exactly 3 sisters, and
consider the sentence <em>&ldquo;the number of sisters of <i>f</i> is
necessarily greater than 2&rdquo;</em>. The claim can be understood in
two different ways. Under a <em>de dicto</em> interpretation, it
states that <em>the number of sisters that <i>f</i> has</em> is
necessarily greater than 2, but this is clearly questionable: under
different circumstances, <i>f</i> might have had either more or else fewer sisters.
However, under a <em>de re</em> interpretation, the claim states that
the <em>number</em> of sisters that <i>f</i> has, the number 3, is
necessarily greater than 2: this is definitely true, at least when
restricting ourselves to the standard understanding of numbers.</p>

<p>
In modal first-order logic, the difference between <em>de re</em> and
<em>de dicto</em> is given by
 <a href="../possible-worlds/index.html#Applications">the scope of the involved quantifiers and modal operators</a>.
 On the one hand, a <em>de dicto</em> (&ldquo;of the
proposition&rdquo;) sentence indicates a property of a proposition,
with the involved quantifier occurring under the scope of modalities.
For example, the <em>de dicto</em> reading of the previous sentence is
given by the formula \(\oBox\left(\exists x (x = s(f) \land x &gt; 2)
\right)\) (with <i>s</i> a function returning its parameter&rsquo;s
number of sisters). On the other hand, a <em>de re</em> (&ldquo;of the
thing&rdquo;) sentence indicates a property of an object, with the
involved modality occurring under the scope of quantifiers. For
example, the <em>de re</em> reading of the previous sentence is given
by the formula \(\exists x \left( x = s(f) \land \oBox(x &gt; 2)
\right)\). This crucial distinction can be exemplified by the
difference between some agent <i>i</i> knowing that there is someone
that makes her <i>H</i>appy (but maybe without knowing who this
person is), \(K_i\exists x H(x, i)\), and the always preferred
existence of someone who <i>i</i> knows makes her happy \((\exists x
K_i H(x, i))\).</p>

<p>
But the expressivity comes with a cost. As usual in multi-modal
systems, the crucial question is the interaction between the involved
modalities, and in this case, the discussion typically centers on the
following two: the <em>Barcan formula</em>, \(\forall x \oBox Px
\rightarrow \oBox\forall x Px\), and its converse, \(\oBox\forall x Px
\rightarrow \forall x \oBox Px\) (see Barcan 1946). The reason for the
controversy becomes clear when the generic predicate <i>P</i> is
replaced by, say, the formula \(\exists x (x=y)\), which can be read
as <em>&ldquo;<i>x</i> exists&rdquo;</em>. Then, the first formula
becomes</p> 

 \[\forall x \oBox\exists x (x=y) \rightarrow \oBox\forall x \exists x (x=y),\]

<p>
stating that if everything exists necessarily then it is necessary
that everything exists. In terms of a possible worlds semantic model,
this boils down to stating that every object existing in an
alternative possible world should also exist in the current one: when
one moves to alternative scenarios, the domain does not grow.
Analogously, the second formula becomes </p> 

\[\oBox\forall x \exists x (x=y) \rightarrow \forall x \oBox\exists x (x=y),\]

<p>
stating that if it is necessary that everything exists then everything
exists necessarily. In terms of a possible worlds semantic model, this
boils down to stating that every object existing in the current world
should also exist in an alternative possible one: when one moves to
alternative scenarios, the domain does not shrink.</p>

<p>
Thus, a decision about whether such principles hold corresponds to
answering a crucial question when building a model for the modal
first-order language: what is the relationship between the domains of
the different possible worlds? On the one hand, from the perspective
of
 <a href="../actualism/index.html">actualism</a>,
 everything there is (everything that can in any sense be said to be)
is actual, that is, it <em>exists</em>; hence, there is a fixed domain
across all possibilities. On the other hand, from the perspective of
 <a href="../actualism/index.html#Challenge">possibilism</a>,
 &lsquo;the things that exist&rsquo; include possible but non-actual
objects; hence, different possible worlds might have different
domains. There is a large literature on the discussion between these
two positions, as the provided references show.</p>

<h3 id="DynaInte">4.6 Dynamics of Intentions</h3>

<p>
The notion of
 <a href="../intention/index.html">intention</a>
 is crucial in <em>BDI</em> systems, as it in some sense defines the
choices the agent will make, thus affecting her behavior. Thus, the
<em>dynamics</em> of intention is also a crucial subject, as it
describes the way intentions are generated, preserved, modified or
discarded.</p>

<p>
For an initial point, how do intentions change after the agent learns
a new piece of information? According to Roy (2008: Chapter 5), if the
original intentions are compatible with the new information, then they
are &lsquo;reshaped&rsquo;; otherwise, the agent discards them without
creating any new intention (or, analogously, generating an intention
for something that has been already achieved). Thus, after an
announcement of \(\chi\) the agent intends to do \(\varphi\) if and
only if \(\chi\) is compatible with her intentions and \(\varphi\) is
a restricted consequence of the agent&rsquo;s initial intentions, or
else \(\varphi\) is a &lsquo;known&rsquo; consequence of
\(\chi\)&rsquo;s announcement. In a formula,</p> 

\[
[\chi{!}]I\varphi \leftrightarrow \left( \left(\hI\chi \land I\left(\chi \rightarrow [\chi{!}]\varphi\right)\right) \lor \left(\lnot \hI\chi \land [\chi{!}]A\varphi\right) \right)
\]

<p>
There are other proposals. In van der Hoek, Jamroga, and Wooldridge
(2007), intentions are defined, roughly speaking, as plans the agent
believes have not yet been fulfilled. As a consequence of this,
changes in the agent&rsquo;s beliefs lead to changes on her
intentions. For example, after any observation, the agent will drop
intentions that she believes have been accomplished:</p> 

\[
[\chi{!}]B\varphi \rightarrow [\chi{!}]\lnot I\varphi
\]

<p>
Moreover, she will drop any intention she believes it is impossible to
achieve:</p> 

\[
[\chi{!}]B\lnot\varphi \rightarrow [\chi{!}]\lnot I\varphi
\]

<p>
But, just as changes in the agent&rsquo;s information (knowledge,
beliefs) should trigger changes in her intentions, changes in her
intentions may also trigger changes in (some of) her beliefs. Intuitively,
having the intention to achieve a given \(\varphi\) reduces the
actions that the agent &lsquo;can&rsquo; perform, from the ones she
can actually carry on, to those that will still allow (and maybe
assure) that \(\varphi\) will be achieved. In other words, a change in
the agent&rsquo;s intentions triggers also a change in her beliefs
about the (sequence of) actions that will be available in the future.
This is the idea followed in Icard, Pacuit, and Shoham (2010), which
studies the interaction between intention revision and belief revision
by introducing postulates for both actions, with these postulates
describing the two processes&rsquo; interplay. In the interesting case
of intention revision, the postulates state that (i) a new intention
will take precedence over previous ones (and thus old ones should be
eliminated when in conflict), (ii) modulo coherence, no further change
should be made on the agent&rsquo;s intentions (in particular, no
extraneous intentions should be added), and (iii) non-contingent
beliefs do not change with intention
 revision.<sup>[<a href="notes.html#note-16" id="ref-16">16</a>]</sup></p>
 
<h3 id="ObliTime">4.7 Obligations and Time</h3>

<p>
As the reader might guess, adding a temporal dimension is typically a
good idea, as in most cases it enriches the initial system by allowing
us to talk about how the concept <em>changes</em>. Besides epistemic
settings, others that benefit from this are systems of
 <a href="../logic-deontic/index.html">deontic logic</a>,
 which study the properties of concepts as <em>permissions</em> (e.g.,
&ldquo;\(\varphi\) is allowed&rdquo;) and <em>obligations</em> (e.g.,
&ldquo;\(\varphi\) is required&rdquo;). Such systems are extremely
useful, as they involve topics such as law, social and business
organizations, and even security systems.</p>

<p>
One of the interesting concepts that arise when time and obligations
interact with each other is the notion of <em>deontic deadlines</em>:
obligations that need to be fulfilled <em>only once</em>, at a time of
one&rsquo;s choosing, as long as it is before certain condition become
true. Indeed, </p>

<blockquote>

<p>
[&hellip;] deontic deadlines are interactions between two dimensions:
a deontic (normative) dimension and a temporal dimension. So, to study
[them], it makes sense to take a [&hellip;] temporal logic [&hellip;]
and a standard deontic logic [&hellip;], and combine the two in one
system. (Broersen, Dignum, Dignum, &amp; Meyer 2004: 43) </p>
</blockquote>

<p>
Such formal systems help to provide a proper understanding of what a
deadline is: as the aforementioned reference asks, </p>

<blockquote>

<p>
is a deadline (1) an obligation at a certain point in time to achieve
something before another point in time, or (2) is a deadline simply an
obligation that persists in time until a deadline is reached, or (3)
is it both? </p>
</blockquote>

<p>
Then, the formal setting also allows the possibility to make further
finer distinctions, as the one between an obligation to always satisfy
a given \(\varphi\) (in symbols, and with <i>O</i> a modality for
obligation, \(OG\varphi)\) and an obligation for \(\varphi\) that
should be always fulfilled \((GO\varphi)\). Further and deeper
discussions on deontic deadlines can be found in Broersen et al.
(2004); Broersen (2006); Brunel, Bodeveix, &amp; Filali (2006);
Demolombe, Bretier, &amp; Louis (2006); Governatori, Hulstijn,
Riveret, &amp; Rotolo (2007); and Demolombe (2014), among others.</p>

<h3 id="KnowObli">4.8 Knowledge and Obligations</h3>

<p>
Equally important is the relationship between knowledge and
obligations, as it is shown by the aforementioned
 <a href="../logic-deontic/supplement.html#ParaEpisObliAqvi1967">paradox of epistemic obligation</a>,
 which arises within the fusion
 (<a href="#Fusi">section 3.1</a>)
 of a
 <a href="../logic-deontic/index-2.html#StanDeonLogi">standard deontic logic</a>
 and a standard epistemic logic. But the relationship between these
concepts goes beyond their interaction in such a basic system. For
example, if an agent does not know about the existence of an
obligation, should she be expected to fulfill it? In some cases the
answer seems to be &ldquo;no&rdquo;: a physician whose neighbor is
having a heart attack has no obligation to provide assistance unless
she knows about the emergency. Still, in some other cases, the answer
seems to be &ldquo;yes&rdquo;: the juridical principle
&ldquo;<em>ignorantia juris non excusat</em>&rdquo; (roughly,
ignorance of the law is not excuse) is an example of this.</p>

<p>
There have been proposals dealing with these issues. One of them is by
Pacuit, Parikh, &amp; Cogan (2006), which uses a setting in which
actions can be considered &ldquo;good&rdquo; or &ldquo;bad&rdquo;. It
introduces a notion of <em>knowledge-based obligation</em> under which
an agent is obliged to perform an action \(\alpha\) if and only if
\(\alpha\) is an action which the agent can perform and she
<em>knows</em> that it is good to perform \(\alpha\). This is then a
form of <em>absolute</em> obligation which remains until the agent
performs the required action.</p>

<p>
Interestingly, the involvement of knowledge gives raise to forms of
&lsquo;defeasible&rsquo; obligations that can disappear in the light
of new information. For example, having being informed about her
neighbor&rsquo;s illness, the physician could have the obligation to
administer a certain drug; however, this obligation would disappear if
she were to learn that the neighbor is allergic to this medication.
This &lsquo;weaker&rsquo; form of obligation can also be captured
within the setting discussed in Pacuit et al. (2006).</p>

<p>
The interaction between knowledge and obligations is not limited to
the way knowledge &lsquo;defines&rsquo; obligations. An important role
is also played by whether the agent consciously violates her
commitments. In fact, most juridical systems contain the principle
that an act is only unlawful if the agent conducting it has a
&lsquo;guilty mind&rsquo; (<em>mens rea</em>): for the agent to be
guilty, she must have committed the act intentionally/purposely. Of
course, there are different levels of &lsquo;guilty minds&rsquo;, and
some legal systems distinguish between them in order to assign
&lsquo;degrees of culpability&rsquo; (e.g., an homicide is considered
more severe if done intentionally rather than accidentally). For
example, on the one hand, stating that it is illegal to do
\(\alpha\) <em>negligently</em> means that it is illegal to do
\(\alpha\) while being aware that the action carries a substantial and
unjustifiable risk. On the other hand, stating that it is illegal to
do \(\alpha\) <em>knowingly</em> means that it is illegal to do
\(\alpha\) while being certain that this conduct will lead to the
result.<sup>[<a href="notes.html#note-17" id="ref-17">17</a>]</sup>
These and other modes of <em>mens rea</em> are formalized in Broersen
(2011) within the
 <a href="../logic-action/index.html#StiSag">STIT</a>
 logic framework.</p>






<h2 id="MultModaSystPhilDisc">5. Multi-Modal Systems in Philosophical Discussions</h2>

<p>
As the previous sections indicate, the specific interplay between
different modalities (the way they are combined and which bridge
principles hold) is crucial to provide an accurate representation and
analysis of different philosophical concepts. In fact, in several
occasions, the combination of different modalities have shed light on
philosophical issues.  We will illustrate this for the concepts of
abduction, knowability, &lsquo;believing to know&rsquo;, truthmakers
and the interplay between assumptions and beliefs while keeping in
mind an endless list of other philosophical paradoxes and problems
that all arise in a multi-modal setting. (Among many others, see the
Yablo paradox in Yablo (1985, 1993) as well as the SEP discussions on
 <a href="../logic-deontic/index.html#CondObliChisPuzz">deontic paradoxes</a>
 and on
 <a href="../self-reference/index.html#ParWitSelRef">paradoxes without self-reference</a>.
 See also the SEP analyses on the
 <a href="../epistemic-paradoxes/index.html#KnoPar">knower paradox</a>,
 on
 <a href="../epistemic-paradoxes/index.html#DynEpiPar">dynamic epistemic paradoxes</a>
 and on the
 <a href="../epistemic-paradoxes/index.html#SurTesPar">surprise examination paradox</a>;
 for the latter, see also a proposed solution in Baltag and Smets
(2010
 <a href="#Oth">Other Internet Resources</a>).)</p>
 
<h3 id="AbduReas">5.1 Abductive Reasoning</h3>

<p>
The term
 <a href="../abduction/index.html">abduction</a>
 has been used in related but sometimes different senses. Roughly
speaking, abductive reasoning (also called <em>inference to the best
explanation</em>, <em>retroduction</em>, and <em>hypothetical</em>,
<em>adductive</em> or <em>presumptive</em> reasoning, among many other
terms) can be understood as the <em>process</em> through which an
agent (or a group of them) looks for an explanation of a surprising
observation. Many forms of intellectual tasks, such as medical and
fault diagnosis, legal reasoning, natural language understanding, and
(last but not least) scientific discovery, belong to this category,
thus making abduction one of the most important reasoning
processes.</p>

<p>
In its simplest form, abduction can best be described with
 <a href="../peirce/index.html">Peirce</a>&rsquo;s
 1903 schema (Hartshorne &amp; Weiss 1934: CP 5.189):</p>

<div class="indent">

<table class="centered">
<tr>
  <td>The surprising fact, <i>C</i>, is observed.</td></tr>
<tr>
  <td style="border-bottom: 2px solid black">But if <i>A</i> were
true, <i>C</i> would be a matter of course.</td></tr>
<tr>
  <td>Hence, there is reason to suspect that <i>A</i> is
true.</td></tr>
</table>
</div>

<p>
This is the understanding that has been most frequently cited and used
when providing formal approaches to abductive reasoning. Still,
typical definitions of an abductive problem and its solution(s) have
been given in terms of a (propositional, first-order) theory and a
formula, leaving the attitudes of the involved agents out of the
picture.</p>

<p>
However, there have been also proposals that formalize (parts of) the
abductive process in terms of diverse epistemic concepts (e.g.,
Levesque 1989; Boutilier &amp; Becher 1995). Among them,
Vel&aacute;zquez-Quesada, Soler-Toscano, &amp;
Nepomuceno-Fern&aacute;ndez (2013) understand abductive reasoning as a
process of belief change that is triggered by an observation and
guided by the knowledge the agent has. In symbols
(Vel&aacute;zquez-Quesada 2015), abductive reasoning from a surprising
observation \(\psi\) to a belief \(\varphi\) can be described as</p>

\[
K(\varphi \rightarrow \psi) \rightarrow [\psi{!}](K\psi \rightarrow \langle\varphi\Uparrow\rangle B\varphi,
\]

<p>
stating thus that if the agent knows \(\varphi \rightarrow \psi\) and
an announcement of \(\psi\) (&ldquo;\([\psi{!}]\)&rdquo;) makes her
know it \((\psi)\), then she can perform an act of <em>belief
revision</em> with \(\varphi\) (&ldquo;\([\varphi\Uparrow]\)&rdquo;)
in order to believe it. This formalization emphasizes not only that
the agent&rsquo;s initial knowledge plays a crucial role in the
generation of possible abductive solutions, but also that the chosen
solution can only be accepted in a weak way, therefore making it a
candidate for being discarded in the light of further information.</p>

<p>
Other proposals have incorporated further aspects into the picture.
One of them, Ma &amp; Pietarinen (2016), follows Peirce&rsquo;s latter
understanding of abductive reasoning (called then
<em>retroduction</em>: &ldquo;given a (surprising) fact <i>C</i>, if
<i>A</i> implies <i>C</i>, then it is to be inquired whether <i>A</i>
plausibly holds&rdquo;; Peirce 1967: 856) as a form of reasoning from
surprise to <em>inquiry</em>. This can possibly be related to the
notions of issues and questions described in 
<a href="#KnowQues">section 4.3</a>. As the authors mention,
</p>

<blockquote>

<p>
[t]he important discovery is that [, in the new formulation,] the
conclusion is presented in a kind of interrogative mood. But the
interrogative mood does not merely mean that a question is raised. In
fact, it means that the possible conjecture <i>A</i> becomes the
subject of inquiry: the purpose is to determine whether that <i>A</i>
is indeed plausible or not. Peirce termed such mood &ldquo;the
investigand mood&rdquo;. Hence abduction can be viewed as the dynamic
process toward a plausible conjecture and, ultimately, toward a
limited set of the most plausible conjectures.</p>
</blockquote>

<h3 id="FitcKnowPara">5.2 Fitch Knowability Paradox</h3>

<p>
 This <a href="../epistemic-paradoxes/index.html#KnowPar">paradox</a>
 emerges from what is commonly known as the verificationist thesis
(<em>VT</em>), which claims that all truths are verifiable.
Formalizing this thesis in a multi-modal logic that combines a
knowledge operator with a possibility operator would yield</p>

\[
\varphi \to \Diamond K\varphi,
\]

<p>
with \(\Diamond K\varphi\) read as <em>&ldquo;it is possible to
know \(\varphi\)&rdquo;</em>. In this context, the paradox refers to
Fitch&rsquo;s argument containing an idea conveyed to him in 1945
which shows that, if all truths are knowable, then all truths are
already known. As the argument goes, we clearly do not know all truths
(as we are not omniscient!); hence, the premise has to be false: not
all truths are knowable. The paradox can be summarized by the
derivation</p> 

\[
p \rightarrow \Diamond Kp \vdash ( p \rightarrow Kp),
\]

<p>
which poses a problem for the non-omniscient verificationist. The
derivation that leads to the paradox as we have stated it here is
based on a multi-modal logical system in which at least the following
principles hold: (i) the principle of non-contradiction, to capture
that contradictions cannot be true and can also not be considered
possible, (ii) the classical laws of double negation, transitivity of
the material implication and substitution, (iii) normality of the
modal logic operator <i>K</i>, the modal logic principle <i>T</i>
stating that knowledge is truthful, and the normality of the modal
possibility operator \(\Diamond\). The simplest presentation of the
paradox which shows how it leads to the unwanted equivalence between
truth and knowledge, can be found in van Benthem (2004). Start with
the formula stating the verificationist thesis, \(\varphi \to \Diamond
K\varphi\), and substitute \(\varphi\) with \((p \land \lnot
Kp)\):</p>

<table class="centered cellpad-med-dense vert-top">
<tbody>
<tr class="odd">
  <td>(1)</td>
  <td>\((p \land \lnot Kp) \to \Diamond K
(p \land \lnot Kp)\)</td>
  <td>Substituting \(\varphi\) with \((p \land \lnot
Kp)\) in <em>VT</em></td> </tr>
<tr class="even">
  <td>(2)</td>
  <td>\(\Diamond K(p \land \lnot Kp) \to
\Diamond(Kp \land K\lnot Kp)\)</td>
  <td><i>K</i> distributes over \(\land\)</td> </tr>
<tr class="odd">
  <td>(3)</td>
  <td>\(\Diamond(Kp \land K\lnot Kp) \to \Diamond(Kp
\land \lnot Kp)\)</td>
  <td>Knowledge is truthful in the modal logic
<em>T</em></td> </tr>
<tr class="even">
  <td>(4)</td>
  <td>\(\Diamond(Kp \land \lnot Kp) \to \bot\)</td>
  <td>Minimal modal logic for \(\Diamond\)</td> </tr>
<tr class="odd">
  <td>(5)</td>
  <td>\((p \land \lnot Kp) \to \bot\)</td>
  <td>transitivity of \(\rightarrow \), from (1) to
(4)</td> </tr>
<tr class="even">
  <td>(6)</td>
  <td>\(p \rightarrow Kp\)</td>
  <td>propositional reasoning</td> </tr> </tbody>
</table>

<p>
This paradox gave rise to an active debate in the philosophical
literature, leading us to signal out two main types of proposed
solutions: those proposing a weakening of our logical principles (as
in paraconsistent, intuitionistic or weaker modal logics) while
keeping the verification thesis, and those that in contrast do not
change/restrict the underlying logic but propose a specific
formalization or reading of the verificationist
 thesis.<sup>[<a href="notes.html#note-18" id="ref-18">18</a>]</sup>
 While we refer the reader to the SEP entry on
 <a href="../epistemic-paradoxes/index.html">epistemic paradoxes</a>
 for an overview of these proposed solutions, here it is illustrative
to highlight how this paradox, which in some sense arises from
combining a modal logic for knowledge (<i>K</i>) with a modal logic
for possibility \((\Diamond)\), can be &lsquo;demystified&rsquo; by
the further introduction of a modality for communication (related to
the public announcement modality of <em>PAL</em>). Indeed, according
to van Benthem (2004), what the verificationist thesis expresses is
not about &lsquo;static&rsquo; <em>knowability</em>, but rather about
a form of <em>learnability</em>: &ldquo;what is true may come to be
known&rdquo; (van Benthem 2004). This statement can be formally stated
in a suitable <em>arbitrary announcement</em> framework as:</p>

\[
\varphi \rightarrow \exists \psi \langle\psi{!}\rangle K\varphi,
\]

<p>
which is read as <em>&ldquo;if \(\varphi\) is the case, then there is
a formula \(\psi\) after whose announcement \(\varphi\) will be
 known&rdquo;</em>.<sup>[<a href="notes.html#note-19" id="ref-19">19</a>]</sup>
 This reading of the verificationist thesis brings us in touch with a
number of results in dynamic epistemic logic on <em>unsuccessful</em>
formulas (those that become false after being truthfully announced;
van Ditmarsch &amp; Kooi 2006; van Benthem 2011; Holliday &amp; Icard
2010), which indicate that indeed not all sentences are learnable. In
fact, this solution shows us that</p>

<blockquote>

<p>
[&hellip;] there is no saving VT&mdash;but there is also no such
gloom. For in losing a principle, we gain a general logical study of
knowledge and learning actions, and their subtle properties. The
failure of naive verificationism just highlights the intriguing ways
in which human communication works. (van Benthem 2004: 105)</p>
</blockquote>

<h3 id="ParaPerfBeli">5.3 The paradox of the perfect believer</h3>

<p>
 
On first sight it seems natural to say that one can believe to
&lsquo;know&rsquo; something, even when in fact one does not actually
know it. So believing to know something is philosophically conceived
to be different from claiming true knowledge. Yet, under the
assumption that what is known is also believed, this specific
interplay between modalities for knowledge and belief can lead us into
trouble if we identify belief with a
<span><strong>KD45</strong></span>-modality <i>B</i>, and knowledge
with a <span><strong>S5</strong></span>-modality for <i>K</i>. For
suppose \(BK\varphi \land \lnot K\varphi\) is assumed. Then, by
negative introspection of the second conjunct, we derive \(K\lnot
K\varphi\). But as knowledge implies belief, we derive \(B\lnot
K\varphi\). This together with the first conjunct \(BK\varphi\) will
give us, by additivity of belief, \(B(K\varphi \land \lnot
K\varphi)\). Hence we derive the belief in a contradiction, which is
not compatible with the assumption of consistency of beliefs (axiom
<span><strong>D</strong></span>) in
<span><strong>KD45</strong></span>. This problem is known as the
paradox of the <em>perfect believer</em> (and also as the Voorbraak
paradox), as it was originally (but equivalently) described (Voorbraak
1993) as the derivability of the <em>bridge</em> principle \(BK\varphi
\rightarrow K\varphi\), which states that a belief in knowing a given
\(\varphi\) is enough to know \(\varphi\). (The derivation of
\(BK\varphi \rightarrow K\varphi\) also relies on the negative
introspection of knowledge, the normality and consistency of beliefs,
and the bridge principle stating that knowledge implies belief; Gochet
&amp; Gribomont 2006: 114.)</p>

<p>
After presenting this problem, Voorbraak (1993) proposed to deal with
it by discarding the bridge principle \(K\varphi \rightarrow
{B\varphi}\). Another option is to allow inconsistent beliefs (Gochet
&amp; Gribomont 2006: Section 2.6). Still, a further possible
solution, closer to the spirit of these notes, is to consider an
intermediate notion of &rsquo;knowledge&rsquo; that is not as strong
as the absolute irrevisable (i.e., irrevocable) notion given by the
<span><strong>S5</strong></span> modal operator <i>K</i>. More
precisely, the proposal in Baltag and Smets (2008) looks at Lehrer&rsquo;s
<em>defeasibility</em> theory of knowledge (Lehrer 1990; Lehrer &amp;
Paxson 1969), and works with the <em>indefeasible (&ldquo;weak&rdquo;,
non-negatively-introspective) knowledge</em> given, in the
 <a href="../dynamic-epistemic/index.html#PlauModeBeliChan">plausibility models</a>
 discussed above, by the modality \([\leq]\) (read before also as
<em>safe belief</em>). Indeed, Lehrer and Stalnaker call this concept
<em>defeasible</em> knowledge, a form of knowledge that might be
defeated by <em>false</em> evidence, but cannot be defeated by
<em>true</em> evidence. The concept satisfies both the truth axiom
\(([\leq]\varphi \rightarrow \varphi)\) and positive introspection
\(([\leq]\varphi \rightarrow [\leq][\leq]\varphi)\), but it lacks
negative introspection; thus, the previous derivation of inconsistent
beliefs from an agent mistakenly believing that she (defeasibly) knows
\(\varphi\) \(({B[\leq]\varphi} \land \lnot [\leq]\varphi)\) is no
longer possible. Instead, it can be easily shown how a belief in
defeasible knowledge, \({B[\leq]\varphi}\), is equivalent to a simple
belief, \({B\varphi}\).</p>

<h3 id="TrutModaPers">5.4 Truthmakers from a modal perspective</h3>

<p>
Paraphrasing Fine (2017), a <em>truthmaker</em> is something on the
side of the world, as a fact or a state of affairs, making true
something on the side of language or thought, as a statement or a
proposition. Truthmaking has been an important topic in both
metaphysics and semantics. For the first, &ldquo;truthmaking serves as
a conduit taking us from language or thought to an understanding of
the world&rdquo; (Fine 2017: 556); for the second, it provides
adequate semantics for a given language by establishing how the world
makes sentences of the language true.</p>

<p>
In Fine (2017), the author explains the basic framework of truthmaker
(&lsquo;exact&rsquo;) semantics for propositional logic. It is based
not on <em>possible worlds</em>, but rather on <em>states</em> or
<em>situations</em>; the crucial difference is that, while a possible
world settles the truth-value of any possible statement (i.e., given a
formula and a possible world, the formula is either true or else
false), a situation might not be enough to decide whether a given
sentence holds.</p>

<p>
Formally, a <em>state space</em> is a tuple \({\langle S, \sqsubseteq
\rangle}\) where <i>S</i> is a non-empty set of states and
\({\sqsubseteq} \subseteq (S \times S)\) is a partial order (i.e., a
reflexive, transitive and antisymmetric relation), with \(s_1
\sqsubseteq s_2\) understood as <em>&ldquo;state \(s_2\) extends state
\(s_1\)&rdquo;</em>. It is assumed that any pair of states has a
<em>least upper bound</em> (i.e., a <em>supremum</em>); formally, for
any \(s_1, s_2 \in S\) there is \(t_1 \sqcup t_2 \in S\)
satisfying</p>

<ol type="i">

<li> \(t_1 \sqsubseteq (t_1 \sqcup t_2)\) and \(t_2 \sqsubseteq (t_1
\sqcup t_2)\) (so \(t_1 \sqcup t_2\) is an upper bound of both \(t_1\)
and \(t_2)\), and </li>

<li>if <i>t</i> is an upper bound of both \(t_1\) and \(t_2\), then
\((t_1 \sqcup t_2) \sqsubseteq t\) (so \(t_1 \sqcup t_2\) is the
<em>least</em> upper bound). </li>
</ol>

<p>
This supremum \(t_1 \sqcup t_2\) (its uniqueness follows from
\(\sqsubseteq\)&rsquo;s antisymmetry) can be understood as the
&lsquo;sum&rsquo;, &lsquo;merge&rsquo; or &lsquo;fusion&rsquo; of
states \(t_1\) and \(t_2\), and it provides the crucial tool for
deciding whether a &lsquo;conjunction&rsquo; is the case, as shown
below.</p>

<p>
A <em>state model</em> is a tuple \({\langle S, \sqsubseteq, V
\rangle}\) with \({\langle S, \sqsubseteq \rangle}\) a state space and
\(V:\mathtt{P}\to (\wp(S) \times \wp(S))\) a valuation function
returning not only set of states that make a given atom <i>p</i> true
(abbreviated as \(V^+(p))\), but also the set of states that make it
false (abbreviated as \(V^-(p))\). In principle, given an atom
<i>p</i>, there needs to be no relation between the two sets. They
might be overlapping \((V^+(p) \cap V^-(p) \neq \emptyset)\), thus
yielding a state that makes <i>p</i> both true and false; they might
be limited \((V^+(p) \cup V^-(p) \neq S)\), thus yielding a state that
makes <i>p</i> neither true nor false; they might be neither, thus
being exclusive \((V^+(p) \cap V^-(p) = \emptyset)\) and exhaustive
\((V^+(p) \cup V^-(p) = S)\), and making the states behave as possible worlds
with respect to <i>p</i>.</p>

<p>
Given a state model, the relations \(\Vvdash_v\) (<em>verified</em> by a
state) and \(\Vvdash_f\) (<em>falsified</em> by a state) are defined as
follows.</p>

<div class="indent">

<table class="cellpad-med-dense cemtered vert-top">
<tbody>
<tr class="odd">
  <td>\((M, s) \Vvdash_v p\)</td>
  <td><span>\(\iffdef\)</span></td>
  <td>\(s \in V^+(p)\)</td> </tr>
<tr class="even">
  <td>\((M, s) \Vvdash_v \lnot \varphi\)</td>
  <td><span>\(\iffdef\)</span></td>
  <td>\((M, s) \Vvdash_f \varphi\)</td> </tr>
<tr class="odd">
  <td>\((M, s) \Vvdash_v \varphi \land \psi\)</td>
  <td><span>\(\iffdef\)</span></td>
  <td>there are \(t_1, t_2 \in S\) with \(s = t_1 \sqcup
t_2\) such that \((M, t_1) \Vvdash_v \varphi\) and \((M, t_2) \Vvdash_v
\psi\)</td> </tr>
<tr class="even">
  <td>\((M, s) \Vvdash_v \varphi \lor \psi\)</td>
  <td><span>\(\iffdef\)</span></td>
  <td>\((M, s) \Vvdash_v \varphi\) or \((M, s) \Vvdash_v
\psi\)</td> </tr>
<tr><td>&nbsp;</td></tr>
<tr>
  <td>\((M, s) \Vvdash_f p\)</td>
  <td><span>\(\iffdef\)</span></td>
  <td>\(s \in V^-(p)\)</td> </tr>
<tr>
  <td>\((M, s) \Vvdash_f \lnot \varphi\)</td>
  <td><span>\(\iffdef\)</span></td>
  <td>\((M, s) \Vvdash_v \varphi\)</td> </tr>
<tr>
  <td>\((M, s) \Vvdash_f \varphi \land \psi\)</td>
  <td><span>\(\iffdef\)</span></td>
  <td>\((M, s) \Vvdash_f \varphi\) or \((M, s)
\Vvdash_f \psi\)</td> </tr>
<tr>
  <td>\((M, s) \Vvdash_f \varphi \lor \psi\)</td>
  <td><span>\(\iffdef\)</span></td>
  <td>there are \(t_1, t_2 \in S\) with \(s = t_1 \sqcup
t_2\) such that \((M, t_1) \Vvdash_f \varphi\) and \((M, t_2)
\Vvdash_f \psi\)</td> </tr> </tbody>
</table>

</div>

<p>
Note the clauses for verifying a conjunction and falsifying a
disjunction. A state makes a conjunction true if and only if it is the
fusion of states that verify the respective conjuncts \(\varphi\) and
\(\psi\). Analogously, a state makes a disjunction false if and only
if it is the fusion of states that falsify the respective disjuncts
\(\varphi\) and \(\psi\).</p>

<p>
Truthmaker semantics can be seen from a (multi)modal perspective (van
Benthem 1989), since a state model \({\langle S, \sqsubseteq, V
\rangle}\) can be understood as a modal information logic, and thus
can be described by modal languages. One interesting possibility (van
Benthem 2018: Section 13) starts by taking two modalities,
\(\langle\sqsubseteq\rangle\varphi\) and
\(\langle\sqsupseteq\rangle\varphi\), whose semantic interpretation is
given in the standard modal way, with the first modality relying on
the partial order \(\sqsubseteq\), and the second relying on its
converse
 \(\sqsupseteq\).<sup>[<a href="notes.html#note-20" id="ref-20">20</a>]</sup>
 Then, one can add a (binary) modality describing least upper
bound</p>

<table class="centered cellpad-med-dense vert-top">
<tr>
  <td>\((M, s) \Vdash \langle\textit{sup}\rangle(\varphi, \psi)\)</td>
  <td>\(\iffdef\)</td>
  <td>there are \(t_1, t_2 \in S\) with \(s = t_1 \sqcup t_2\) such
that \((M, t_1) \Vdash \varphi\) and \((M, t_2) \Vdash \psi\)</td>
</tr>
</table>

<p>
and a &lsquo;dual&rsquo; one describing the <em>infimum</em> (the
greatest lower
 bound)<sup>[<a href="notes.html#note-21" id="ref-21">21</a>]</sup></p>
 

<table class="centered cellpad-med-dense vert-top">
<tr>
  <td>\((M, s) \Vdash \langle\textit{inf}\rangle(\varphi, \psi)\)</td>
  <td>\(\iffdef\)</td>
  <td>there are \(t_1, t_2 \in S\) with \(s = t_1 \sqcap t_2\) such
that \((M, t_1) \Vdash \varphi\) and \((M, t_2) \Vdash \psi\)</td>
</tr>
</table>

<p>
With these tools, it is possible to define a faithful translation from
truthmaker logic into modal information logic (see van Benthem 2018:
Section 13 for details). This translation brings methods from modal
logic to the study of truthmaking. More important is the fact that it
makes truthmaker semantics, a framework that works by providing a new
meaning to Boolean connectives, completely compatible with classical
(modal) logic, which keeps standard definitions but extends the
framework&rsquo;s expressivity by studying much richer languages.</p>

<h3 id="BranKeisPara">5.5 The Brandenburger-Keisler Paradox</h3>

<p>
We finish this text by returning to the beginning. So, given that</p>

<blockquote>

<p class="left">
<em>Ann believes that Bob assumes that</em> \(\underbrace{\textit{Ann
believes that Bob's assumption is wrong}.}_{\varphi}\) </p>
</blockquote>

<p>
is the case, is \(\varphi\) (<em>&ldquo;Ann believes that Bob&rsquo;s
assumption is wrong&rdquo;</em>) true or false?</p>

<p>
As explained in Pacuit (2007), in order to show that this situation
cannot be &lsquo;represented&rsquo;, the original paper (Brandenburger
&amp; Keisler 2006) introduces a <em>belief model</em>. This structure
represents each agent&rsquo;s beliefs about the beliefs of the other
agent. More precisely, a belief model is a two-sorted structure, one
sort for each agent, with each sort representing an epistemic state
that its agent might have. The model&rsquo;s first component is its
domain, given by the union of \(W_a\) and \(W_b\), the disjoint sets
of states of Ann and Bob, respectively. The model also has a relation
for each agent, \(R_a\) and \(R_b\), with \(R_auv\) (restricted to \(u
\in W_a\) and \(v \in W_b)\) read as <em>&ldquo;in state <i>u</i>, Ann
considers <i>v</i> possible</em>, and analogous for \(R_bvu\). Again,
the structure represents each agent&rsquo;s beliefs about the beliefs
of the other, so each collection \(\cU_b\) of subsets of \(W_b\) can
be understood as a language for Ann (the beliefs she might have about
Bob&rsquo;s beliefs), and analogous for Bob; a full language is then
defined as the union of a language for each agent. For the involved
epistemic attitudes, Ann believes a given \(U \in \cU_b\) if and only
if the set of states that she considers possible is <em>a subset</em>
of <i>U</i>. On the other hand, an assumption is understood as the
strongest belief, so Ann assumes a given \(U \in \cU_a\) if and only
if the set of states she considers possible is <em>exactly</em>
<i>U</i>.</p>

<p>
With these tools, it is now possible to make precise the claim that
the situation described above cannot be represented. A language is
said to be <em>complete</em> for a belief model if and only if every
possible statement in a player&rsquo;s language (i.e., every statement
in her language that is true in at least one state) can be assumed by
the player. It is then possible to show, using a diagonal argument,
that no belief model is complete for &lsquo;its first-order
language&rsquo;, i.e., the language containing all first-order
definable subsets of the model&rsquo;s domain.</p>

</div>

<div id="bibliography">

<h2 id="Bib">Bibliography</h2>



<ul class="hanging">

<li id="ref-AgotnesDW16">&Aring;gotnes, Thomas, Hans van Ditmarsch,
and Yanjing Wang, 2018, &ldquo;True Lies&rdquo;, <em>Synthese</em>,
195(10): 4581&ndash;4615. doi:10.1007/s11229-017-1423-y
 [<a href="http://arxiv.org/abs/1606.08333" target="other">&Aring;gotnes et al. 2018 available online</a>]</li>
 
<li id="ref-ArecesF09">Areces, Carlos, and Diego Figueira, 2009,
&ldquo;Which Semantics for Neighbourhood Semantics?&rdquo; in Craig
Boutilier (ed.), <em>IJCAI 2009, Proceedings of the 21st International
Joint Conference on Artificial Intelligence, Pasadena, California,
USA, July 11-17, 2009</em>, pp. 671&ndash;676.
 [<a href="http://ijcai.org/Proceedings/09/Papers/117.pdf" target="other">Areces &amp; Figueira available online</a>]</li>
 
<li id="ref-Armstrong73">Armstrong, David Malet, 1973, <em>Belief, Truth and Knowledge</em>, Cambridge: Cambridge University Press.
doi:10.1017/CBO9780511570827</li>

<li id="ref-BalbianiBDHHL07">Balbiani, Philippe, Alexandru Baltag,
Hans P. van Ditmarsch, Andreas Herzig, Tomohiro Hoshi, and Tiago De de
Lima, 2007, &ldquo;What Can We Achieve by Arbitrary Announcements?: A
Dynamic Take on Fitch&rsquo;s Knowability&rdquo;, in <em>Proceedings
of the 11th Conference on Theoretical Aspects of Rationality and
Knowledge: TARK &rsquo;07, Brussels, Belgium</em>, ACM Press,
42&ndash;51. doi:10.1145/1324249.1324259</li>

<li id="ref-BalbianiBDHHL08">&ndash;&ndash;&ndash;, 2008,
&ldquo;&lsquo;Knowable&rsquo; as &lsquo;Known after an
Announcement&rsquo;&rdquo;, <em>The Review of Symbolic Logic</em>,
1(3): 305&ndash;334. doi:10.1017/S1755020308080210</li>

<li id="ref-sep-dynamic-epistemic">Baltag, Alexandru and Bryan Renne,
2016, &ldquo;Dynamic Epistemic Logic&rdquo;, <em>The Stanford
Encyclopedia of Philosophy</em> (Winter 2016 Edition), Edward N. Zalta
(ed.). URL =
 &lt;<a href="https://plato.stanford.edu/archives/win2016/entries/dynamic-epistemic/" target="other">https://plato.stanford.edu/archives/win2016/entries/dynamic-epistemic/</a>&gt;
 </li>

<li id="ref-BaltagSmets2006">Baltag, Alexandru and Sonja Smets, 2006,
&ldquo;Dynamic Belief Revision over Multi-Agent Plausibility
Models&rdquo;, in <em>Proceedings of the 7th Conference on Logic and
the Foundations of Game and Decision (LOFT 2006)</em>, Giacomo
Bonanno, Wiebe van der Hoek, and Michael Wooldridge (eds.), Liverpool,
UK: University of Liverpool, 11&ndash;24.
 [<a href="http://www.vub.ac.be/CLWF/SS/loft.pdf" target="other">Baltag &amp; Smets 2006 available online</a>]</li>
 
<li id="ref-BaltagSmets2008tlg">&ndash;&ndash;&ndash;, 2008, &ldquo;A
Qualitative Theory of Dynamic Interactive Belief Revision&rdquo;, in
<em>Logic and the Foundations of Game and Decision Theory (LOFT
7)</em>, Giacomo Bonanno, Wiebe van der Hoek, and Michael Wooldridge
(eds.), (Texts in Logic and Games 3), Amsterdam: Amsterdam University
Press, 13&ndash;60.
 [<a href="http://www.vub.ac.be/CLWF/SS/chapter.pdf" target="other">Baltag &amp; Smets 2008 available online</a>]</li>
 
<li id="ref-BaltagBOS13">Baltag, Alexandru, Nick Bezhanishvili,
Ayb&uuml;ke &Ouml;zg&uuml;n, and Sonja Smets, 2013, &ldquo;The
Topology of Belief, Belief Revision and Defeasible Knowledge&rdquo;,
in <em>Logic, Rationality, and Interaction: 4th International
Workshop, LORI 2013, Hangzhou, China, October 9-12, 2013</em>, Davide
Grossi, Olivier Roy, and Huaxin Huang (eds.), (Lecture Notes in
Computer Science 8196), Berlin, Heidelberg: Springer Berlin
Heidelberg, 27&ndash;40. doi:10.1007/978-3-642-40948-6_3</li>

<li id="ref-BaltagBOS16">&ndash;&ndash;&ndash;, 2016, &ldquo;Justified
Belief and the Topology of Evidence&rdquo;, in <em>Logic, Language,
Information, and Computation: 23rd International Workshop, Wollic
2016, Puebla, Mexico, August 16-19th, 2016</em>, Jouko
V&auml;&auml;n&auml;nen, &Aring;sa Hirvonen, and Ruy de Queiroz
(eds.), (Lecture Notes in Computer Science 9803), Berlin, Heidelberg:
Springer Berlin Heidelberg, 83&ndash;103.
doi:10.1007/978-3-662-52921-8_6</li>

<li id="ref-BaltagBoddySmets2017">Baltag, Alexandru, Rachel Boddy, and
Sonja Smets, 2018, &ldquo;Group Knowledge in Interrogative
Epistemology&rdquo;, in <em>Jaakko Hintikka on Knowledge and
Game-Theoretical Semantics</em>, Hans van Ditmarsch and Gabriel Sandu
(eds.), (Outstanding Contributions to Logic 12), Cham: Springer
International Publishing, 131&ndash;164.
doi:10.1007/978-3-319-62864-6_5</li>

<li id="ref-BaltagEtAl2016">Baltag, Alexandru, Zo&eacute; Christoff,
Rasmus K. Rendsvig, and Sonja Smets, 2019, &ldquo;Dynamic Epistemic
Logics of Diffusion and Prediction in Social Networks&rdquo;,
<em>Studia Logica</em>, 107(3): 489&ndash;531.
doi:10.1007/s11225-018-9804-x</li>

<li id="ref-BaltagRS12">Baltag, Alexandru, Bryan Renne, and Sonja
Smets, 2012, &ldquo;The Logic of Justified Belief Change, Soft
Evidence and Defeasible Knowledge&rdquo;, in <em>Logic, Language,
Information and Computation: 19th International Workshop, Wollic 2012,
Buenos Aires, Argentina, September 3-6, 2012</em>, Luke Ong and Ruy de
Queiroz (eds.), (Lecture Notes in Computer Science 7456), Berlin,
Heidelberg: Springer Berlin Heidelberg, 168&ndash;190.
doi:10.1007/978-3-642-32621-9_13</li>

<li id="ref-BaltagRS14"> &ndash;&ndash;&ndash;, 2014, &ldquo;The Logic
of Justified Belief, Explicit Knowledge, and Conclusive
Evidence&rdquo;, <em>Annals of Pure and Applied Logic</em>, 165(1):
49&ndash;81. doi:10.1016/j.apal.2013.07.005</li>

<li>Baltag, Alexandru, Jeremy Seligman, and Tomoyuki Yamada (eds.),
2017, <em>Logic, Rationality, and Interaction: 6th International
Workshop, LORI 2017, Sapporo, Japan, September 11-14, 2017</em>,
(Lecture Notes in Computer Science 10455), Berlin, Heidelberg:
Springer Berlin Heidelberg. doi:10.1007/978-3-662-55665-8</li>

<li id="ref-Barcan46">Barcan, Ruth C., 1946, &ldquo;A Functional
Calculus of First Order Based on Strict Implication&rdquo;, <em>The
Journal of Symbolic Logic</em>, 11(1): 1&ndash;16.
doi:10.2307/2269159</li>

<li id="ref-BelnapPX01">Belnap, Nuel D., Michael Perloff, and Ming Xu,
2001, <em>Facing the Future: Agents and Choices in Our Indeterminist
World</em>, Oxford: Oxford University Press.</li>

<li id="ref-vanBenthem1979">van Benthem, Johan, 1979, &ldquo;Minimal
Deontic Logic (Abstract)&rdquo;, <em>Bulletin of the Section of
Logic</em>, 8(1): 36&ndash;41.</li>

<li id="ref-vanBenthem89"> &ndash;&ndash;&ndash;, 1989,
&ldquo;Semantic Parallels in Natural Language and Computation&rdquo;,
in <em>Logic Colloquium &rsquo;87</em>, H.-D. Ebbinghaus, J.
Fernandez-Prida, M. Garrido, D. Lascar, and M. Rodriquez Artalejo
(eds.), (Studies in Logic and the Foundations of Mathematics 129),
Amsterdam, North-Holland: Elsevier, 331&ndash;375.
doi:10.1016/S0049-237X(08)70133-2</li>

<li id="ref-vanBenthem04womck"> &ndash;&ndash;&ndash;, 2004,
&ldquo;What One May Come to Know&rdquo;, <em>Analysis</em>, 64(2):
95&ndash;105. doi:10.1093/analys/64.2.95</li>

<li id="ref-vanBenthem06">&ndash;&ndash;&ndash;, 2006a,
&ldquo;&lsquo;One Is a Lonely Number&rsquo;: Logic and
Communication&rdquo;, in <em>Logic Colloquium &rsquo;02</em>, Zoe
Chatzidakis, Peter Koepke, and Wolfram Pohlers (eds.), Cambridge:
Cambridge University Press, 96&ndash;129.
doi:10.1017/9781316755723.006</li>

<li id="ref-vanBenthem06open">&ndash;&ndash;&ndash;, 2006b,
&ldquo;Open Problems in Logical Dynamics&rdquo;, in <em>Mathematical
Problems from Applied Logic I</em>, Dov M. Gabbay, Sergei S.
Goncharov, and Michael Zakharyaschev (eds.), (International
Mathematical Series 4), New York: Springer New York, 137&ndash;192.
doi:10.1007/0-387-31072-X_3</li>

<li id="ref-Benthem07">&ndash;&ndash;&ndash;, 2007, &ldquo;Dynamic
Logic for Belief Revision&rdquo;, <em>Journal of Applied Non-Classical
Logics</em>, 17(2): 129&ndash;155. doi:10.3166/jancl.17.129-155</li>

<li id="ref-vanBenthem2010mlom">&ndash;&ndash;&ndash;, 2010, <em>Modal
Logic for Open Minds</em>, (CSLI Lecture Notes 199), Stanford, CA:
CSLI Publications. </li>

<li id="ref-vanBenthem2011ldii"> &ndash;&ndash;&ndash;, 2011,
<em>Logical Dynamics of Information and Interaction</em>, Cambridge:
Cambridge University Press. doi:10.1017/CBO9780511974533</li>

<li id="ref-BenthemD08">van Benthem, Johan and C&eacute;dric
D&eacute;gremont, 2010, &ldquo;Bridges between Dynamic Doxastic and
Doxastic Temporal Logics&rdquo;, in <em>Logic and the Foundations of
Game and Decision Theory: LOFT 8</em>, Giacomo Bonanno, Benedikt
L&ouml;we, and Wiebe van der Hoek (eds.), (Lecture Notes in Computer
Science 6006), Berlin, Heidelberg: Springer Berlin Heidelberg,
151&ndash;173. doi:10.1007/978-3-642-15164-4_8</li>

<li id="ref-BenthemM12">van Benthem, Johan and &#350;tefan Minic&#259;, 2012,
&ldquo;Toward a Dynamic Logic of Questions&rdquo;, <em>Journal of
Philosophical Logic</em>, 41(4): 633&ndash;669.
doi:10.1007/s10992-012-9233-7</li>

<li id="ref-BenthemP06">van Benthem, Johan and Eric Pacuit, 2006,
&ldquo;The Tree of Knowledge in Action: Towards a Common
Perspective&rdquo;, in <em>Advances in Modal Logic 6, Papers from the
Sixth Conference on &ldquo;Advances in Modal Logic&rdquo;, Held in
Noosa, Queensland, Australia, on 25-28 September 2006</em>, Guido
Governatori, Ian M. Hodkinson, &amp; Yde Venema (eds.), College
Publications, 87&ndash;106,
 [<a href="http://www.aiml.net/volumes/volume6/vanBenthem-Pacuit.ps" target="other">Benthem and Pacuit 2006 available online</a>]</li>
 
<li id="ref-vanBenthemPacuit2011"> &ndash;&ndash;&ndash;, 2011,
&ldquo;Dynamic Logics of Evidence-Based Beliefs&rdquo;, <em>Studia
Logica</em>, 99(1&ndash;3): 61&ndash;92.
doi:10.1007/s11225-011-9347-x</li>

<li id="ref-BenthemBCS06">van Benthem, Johan, Guram Bezhanishvili,
Balder ten Cate, and Darko Sarenac, 2007, &ldquo;Multimodal Logics of
Products of Topologies&rdquo;, <em>Studia Logica</em>, 84(3):
369&ndash;392. doi:10.1007/s11225-006-9013-x</li>

<li id="ref-BenthemEK06">van Benthem, Johan, Jan van Eijck, and
Barteld Kooi, 2006, &ldquo;Logics of Communication and Change&rdquo;,
<em>Information and Computation</em>, 204(11): 1620&ndash;1662.
doi:10.1016/j.ic.2006.04.006</li>

<li id="ref-BenthemDP14">van Benthem, Johan, David
Fern&aacute;ndez-Duque, and Eric Pacuit, 2014, &ldquo;Evidence and
Plausibility in Neighborhood Structures&rdquo;, <em>Annals of Pure and
Applied Logic</em>, 165(1): 106&ndash;133.
doi:10.1016/j.apal.2013.07.007</li>

<li id="ref-BenthemGP07">van Benthem, Johan, Jelle Gerbrandy, and Eric
Pacuit, 2007, &ldquo;Merging Frameworks for Interaction: DEL and
ETL&rdquo;, in <em>Proceedings of the 11th Conference on Theoretical
Aspects of Rationality and Knowledge (TARK &rsquo;07), Brussels,
Belgium, June 25&ndash;27, 2007</em>, ACM Press, 72&ndash;81.
doi:10.1145/1324249.1324262</li>

<li id="ref-BenthemGHP09">van Benthem, Johan, Jelle Gerbrandy,
Tomohiro Hoshi, and Eric Pacuit, 2009, &ldquo;Merging Frameworks for
Interaction&rdquo;, <em>Journal of Philosophical Logic</em>, 38(5):
491&ndash;526. doi:10.1007/s10992-008-9099-x</li>

<li id="ref-vanBenthemBlackburn2006">Blackburn, Patrick and Johan van
Benthem, 2006, &ldquo;Modal Logic: A Semantic Perspective&rdquo;, in
<em>Studies in Logic and Practical Reasoning, Volume 3</em>, Patrick
Blackburn, Johan van Benthem, and Frank Wolter (eds.), Amsterdam:
Elsevier, 1&ndash;84. doi:10.1016/S1570-2464(07)80004-8
 [<a href="http://www.illc.uva.nl/Publications/ResearchReports/PP-2006-30.text.pdf" target="other">Blackburn &amp; Benthem available online</a>]</li>
 
<li id="ref-BlackburnRijkeVenema2001">Blackburn, Patrick, Maarten de
Rijke, and Yde Venema, 2001, <em>Modal Logic</em>, Cambridge:
Cambridge University Press. doi:10.1017/CBO9781107050884</li>

<li id="ref-Board04">Board, Oliver, 2004, &ldquo;Dynamic Interactive
Epistemology&rdquo;, <em>Games and Economic Behavior</em>, 49(1):
49&ndash;80. doi:10.1016/j.geb.2003.10.006</li>

<li id="ref-Boddy14">Boddy, Rachel, 2014, <em>Epistemic Issues and
Group Knowledge</em>, Master&rsquo;s thesis, Institute for Logic,
Language; Computation (University of Amsterdam).
 [<a href="http://www.illc.uva.nl/Research/Publications/Reports/MoL-2014-03.text.pdf" target="other">Boddy 2014 available online</a>]</li>
 
<li id="ref-BoutilierB95">Boutilier, Craig and Veronica Beche, 1995,
&ldquo;Abduction as Belief Revision&rdquo;, <em>Artificial
Intelligence</em>, 77(1): 43&ndash;94.
doi:10.1016/0004-3702(94)00025-V</li>

<li id="ref-BrandenburgerK06">Brandenburger, Adam and H. Jerome
Keisler, 2006, &ldquo;An Impossibility Theorem on Beliefs in
Games&rdquo;, <em>Studia Logica</em>, 84(2): 211&ndash;240.
doi:10.1007/s11225-006-9011-z</li>

<li id="ref-Bratman87">Bratman, Michael E., 1987, <em>Intention,
Plans, and Practical Reason</em>, Cambridge, MA: Harvard University
Press. </li>

<li id="ref-Broersen06">Broersen, Jan, 2006, &ldquo;Strategic Deontic
Temporal Logic as a Reduction to ATL, with an Application to
Chisholm&rsquo;s Scenario&rdquo;, in Goble and Meyer 2006:
53&ndash;68. doi:10.1007/11786849_7</li>

<li id="ref-Broersen11">&ndash;&ndash;&ndash;, 2011, &ldquo;Deontic
Epistemic Stit Logic Distinguishing Modes of Mens Rea&rdquo;,
<em>Journal of Applied Logic</em>, 9(2): 137&ndash;152.
doi:10.1016/j.jal.2010.06.002</li>

<li id="ref-BroersenDDM04">Broersen, Jan, Frank Dignum, Virginia
Dignum, and John-Jules Ch. Meyer, 2004, &ldquo;Designing a Deontic
Logic of Deadlines&rdquo;, in <em>Deontic Logic in Computer Science:
7th International Workshop on Deontic Logic in Computer Science, DEON
2004, Madeira, Portugal, May 26-28, 2004</em>, Alessio Lomuscio and
Donald Nute (eds.), Berlin, Heidelberg: Springer Berlin Heidelberg,
3065:43&ndash;56. doi:10.1007/978-3-540-25927-5_5</li>

<li id="ref-BrunelBF06">Brunel, Julien, Jean-Paul Bodeveix, and Mamoun
Filali, 2006, &ldquo;A State/Event Temporal Deontic Logic&rdquo;, in
Goble and Meyer 2006: 85&ndash;100. doi:10.1007/11786849_9</li>

<li id="ref-sep-logic-combining">Carnielli, Walter and Marcelo Esteban
Coniglio, 2016, &ldquo;Combining Logics&rdquo;, in <em>The Stanford
Encyclopedia of Philosophy</em> (Winter 2016 Edition), Edward N. Zalta (ed.).
URL =
 &lt;<a href="https://plato.stanford.edu/archives/win2016/entries/logic-combining/" target="other">https://plato.stanford.edu/archives/win2016/entries/logic-combining/</a>&gt;</li>
 
<li id="ref-CarnielliEtAl2008">Carnielli, Walter, Marcelo Coniglio,
Dov M. Gabbay, Paula Gouveia, and Cristina Sernadas, 2008,
<em>Analysis and Synthesis of Logics</em>, (Applied Logic Series 35),
Dordrecht: Springer Netherlands. doi:10.1007/978-1-4020-6782-2</li>

<li id="ref-Chalmers06">Chalmers, David, 2006, &ldquo;The Foundations
of Two-Dimensional Semantics&rdquo;, in <em>Two-Dimensional Semantics:
Foundations and Applications</em>, Manuel Garc&iacute;a-Carpintero
&amp; Josep Maci&agrave; (eds.), Oxford: Oxford University Press, pp.
55&ndash;140.
 [<a href="http://consc.net/papers/foundations.html" target="other">Chalmers 2006 available online</a>]</li>
 
<li id="ref-Chalmers09">Chalmers, David J., 2009, &ldquo;The
Two-Dimensional Argument Against Materialism&rdquo;, in <em>The Oxford
Handbook of Philosophy of Mind</em>, Ansgar Beckermann, Brian P.
McLaughlin, &amp; Sven Walter (eds.), Oxford: Oxford University Press,
pp. 313&ndash;335,. doi:10.1093/oxfordhb/9780199262618.003.0019</li>

<li id="ref-Clark63">Clark, Michael, 1963, &ldquo;Knowledge and
Grounds: A Comment on Mr. Gettier&rsquo;s Paper&rdquo;,
<em>Analysis</em>, 24(2): 46&ndash;48. doi:10.1093/analys/24.2.46</li>

<li id="ref-CohenL90">Cohen, Philip R. and Hector J. Levesque, 1990,
&ldquo;Intention Is Choice with Commitment&rdquo;, <em>Artificial
Intelligence</em>, 42(2&ndash;3): 213&ndash;261.
doi:10.1016/0004-3702(90)90055-5</li>

<li id="ref-sep-questions">Cross, Charles and Floris Roelofsen, 2018,
&ldquo;Questions&rdquo;, in <em>The Stanford Encyclopedia of
Philosophy</em> (Spring 2018 Edition), Edward N. Zalta (ed.). URL =
 &lt;<a href="https://plato.stanford.edu/archives/spr2018/entries/questions/" target="other">https://plato.stanford.edu/archives/spr2018/entries/questions/</a>&gt;</li>
 
<li id="ref-Degremont2010">D&eacute;gremont, C&eacute;dric, 2010,
<em>The Temporal Mind: Observations on Belief Change in Temporal
Systems</em>, PhD thesis, Institute for Logic, Language; Computation
(ILLC), Universiteit van Amsterdam (UvA), Amsterdam, The Netherlands.
 [<a href="https://www.illc.uva.nl/Research/Publications/Dissertations/DS-2010-03.text.pdf" target="other">D&eacute;gremont 2010 available online</a>]</li>
 
<li id="ref-Demolombe14">Demolombe, Robert, 2014, &ldquo;Obligations
with Deadlines: A Formalization in Dynamic Deontic Logic&rdquo;,
<em>Journal of Logic and Computation</em>, 24(1): 1&ndash;17.
doi:10.1093/logcom/exs015</li>

<li id="ref-DemolombeBL06">Demolombe, Robert, Philippe Bretier, and
Vincent Louis, 2006, &ldquo;Norms with Deadlines in Dynamic Deontic
Logic&rdquo;, in <em>ECAI 2006, 17th European Conference on Artificial
Intelligence, August 29&ndash;September 1, 2006, Riva Del Garda,
Italy, Including Prestigious Applications of Intelligent Systems (PAIS
2006)</em>, Gerhard Brewka, Silvia Coradeschi, Anna Perini, &amp;
Paolo Traverso (eds.), (Frontiers in Artificial Intelligence and
Applications 141), IOS Press, pp. 751&ndash;752.</li>

<li id="ref-Ditmarsch14">van Ditmarsch, Hans, 2014, &ldquo;Dynamics of
Lying&rdquo;, <em>Synthese</em>, 191(5): 745&ndash;777.
doi:10.1007/s11229-013-0275-3</li>

<li id="ref-DitmarschK06">van Ditmarsch, Hans and Barteld Kooi, 2006,
&ldquo;The Secret of My Success&rdquo;, <em>Synthese</em>, 151(2):
201&ndash;232. doi:10.1007/s11229-005-3384-9</li>

<li id="ref-DitmarschESW12">van Ditmarsch, Hans, Jan van Eijck, Floor
Sietsma, and Yanjing Wang, 2012, &ldquo;On the Logic of Lying&rdquo;,
in <em>Games, Actions and Social Software: Multidisciplinary
Aspects</em>, Jan van Eijck and Rineke Verbrugge (eds.), Berlin,
Heidelberg: Springer Berlin Heidelberg, 7010:41&ndash;72.
doi:10.1007/978-3-642-29326-9_4</li>

<li id="ref-vanDitmarschEtAl2007">van Ditmarsch, Hans, Wiebe van der
Hoek, and Barteld Kooi, 2007, <em>Dynamic Epistemic Logic</em>,
Dordrecht: Springer Netherlands. doi:10.1007/978-1-4020-5839-4</li>

<li id="ref-Dubber02">Dubber, Markus D., 2002, <em>Criminal Law: Model
Penal Code</em>, Foundation Press.</li>

<li id="ref-Engeler67">Engeler, Erwin, 1967, &ldquo;Algorithmic
Properties of Structures&rdquo;, <em>Mathematical Systems Theory</em>,
1(2): 183&ndash;195. doi:10.1007/BF01705528</li>

<li id="ref-FaginHMV95">Fagin, Ronald, Joseph Y. Halpern, Yoram Moses,
and Moshe Y. Vardi, 1995, <em>Reasoning about Knowledge</em>,
Cambridge, MA: The MIT Press.</li>

<li id="ref-Fine17">Fine, Kit, 2017, &ldquo;Truthmaker
Semantics&rdquo;, in <em>A Companion to the Philosophy of
Language</em>, second edition, Bob Hale, Crispin Wright, and Alexander
Miller (eds.), Chichester, UK: John Wiley &amp; Sons, Ltd, 2:
556&ndash;577. doi:10.1002/9781118972090.ch22</li>

<li id="ref-FineS1996">Fine, Kit and Gerhard Schurz, 1996,
&ldquo;Transfer Theorems for Multimodal Logics&rdquo;, in <em>Logic
and Reality: Essays on the Legacy of Arthur Prior</em>, B.J. Copeland
(ed.), Oxford: Oxford University Press, pp. 169&ndash;213. </li>

<li id="ref-FrenchHIK13">French, Tim, Wiebe van der Hoek, Petar Iliev,
and Barteld Kooi, 2013, &ldquo;On the Succinctness of Some Modal
Logics&rdquo;, <em>Artificial Intelligence</em>, 197): 56&ndash;85.
doi:10.1016/j.artint.2013.02.003</li>

<li id="ref-Gabbay1999">Gabbay, Dov M. (ed.), 1999, <em>Fibring
Logics</em>, (Oxford Logic Guides 38), Oxford, UK: Clarendon
Press.</li>

<li id="ref-GabbayEtAl2003">Gabbay, Dov M., Agi Kurucz, Frank Wolter,
and Michael Zakharyaschev, 2003, <em>Many-Dimensional Modal Logics:
Theory and Applications</em>, (Studies in Logic and the Foundations of
Mathematics 148), North Holland: Elsevier. </li>

<li id="ref-GargovPassy1990">Gargov, George and Solomon Passy, 1990,
&ldquo;A Note on Boolean Modal Logic&rdquo;, in <em>Mathematical
Logic</em>, Petio Petrov Petkov (ed.), Plenum Press, 311&ndash;321.
doi:10.1007/978-1-4613-0609-2_21</li>

<li id="ref-GargovPassyTinchev1987">Gargov, George, Solomon Passy, and
Tinko Tinchev, 1987, &ldquo;Modal Environment for Boolean
Speculations&rdquo;, in <em>Mathematical Logic and Its
Applications</em>, Dimiter G. Skordev (ed.), Boston, MA: Springer US,
253&ndash;263. doi:10.1007/978-1-4613-0897-3_17</li>

<li id="ref-sep-logic-modal">Garson, James, 2018, &ldquo;Modal
Logic&rdquo;, in <em>The Stanford Encyclopedia of Philosophy</em>
(Fall 2018 Edition), Edward N. Zalta (ed.). URL =
 &lt;<a href="https://plato.stanford.edu/archives/fall2018/entries/logic-modal/" target="other">https://plato.stanford.edu/archives/fall2018/entries/logic-modal/</a>&gt;</li>
 
<li id="ref-Gettier63">Gettier, Edmund L., 1963, &ldquo;Is Justified

True Belief Knowledge?&rdquo;, <em>Analysis</em>, 23(6):

121&ndash;123. doi:10.1093/analys/23.6.121</li>

<li id="ref-Gilbert87">Gilbert, Margaret, 1987, &ldquo;Modelling

Collective Belief&rdquo;, <em>Synthese</em>, 73(1): 185&ndash;204.

doi:10.1007/BF00485446</li>

<li>Goble, Lou and John-Jules Ch. Meyer (eds.), 2006, <em>Deontic
Logic and Artificial Normative Systems: 8th International Workshop on
Deontic Logic in Computer Science, DEON 2006, Utrecht, The
Netherlands, July 12-14, 2006</em>, (Lecture Notes in Computer Science
4048), Berlin, Heidelberg: Springer Berlin Heidelberg.
doi:10.1007/11786849</li>

<li id="ref-GochetGribomont2006">Gochet, Paul and Pascal Gribomont,
2006, &ldquo;Epistemic Logic&rdquo;, in <em>Handbook of the History of
Logic, Volume 7: Logic and the Modalities in the Twentieth
Century</em>, Dov M. Gabbay &amp; John Woods (eds.), Amsterdam:
North-Holland, 99&ndash;195. doi:10.1016/S1874-5857(06)80028-2</li>

<li id="ref-Goldblatt74">Goldblatt, Robert I., 1974, &ldquo;Semantic
Analysis of Orthologic&rdquo;, <em>Journal of Philosophical
Logic</em>, 3(1&ndash;2): 19&ndash;35. doi:10.1007/BF00652069</li>

<li id="ref-GorankoP92">Goranko, Valentin and Solomon Passy, 1992,
&ldquo;Using the Universal Modality: Gains and Questions&rdquo;,
<em>Journal of Logic and Computation</em>, 2(1): 5&ndash;30.
doi:10.1093/logcom/2.1.5</li>

<li id="ref-GovernatoriHRR07">Governatori, Guido, Joris Hulstijn,
R&eacute;gis Riveret, and Antonino Rotolo, 2007, &ldquo;Characterising
Deadlines in Temporal Modal Defeasible Logic&rdquo;, in <em>AI 2007:
Advances in Artificial Intelligence, 20th Australian Joint Conference
on Artificial Intelligence, Gold Coast, Australia, December 2-6,
2007</em>, Mehmet A. Orgun and John Thornton (eds.), (Lecture Notes in
Computer Science 4830), Berlin, Heidelberg: Springer Berlin
Heidelberg, 486&ndash;496. doi:10.1007/978-3-540-76928-6_50</li>

<li id="ref-GovernatoriPS02">Governatori, Guido, Vineet Padmanabhan,
and Abdul Sattar, 2002, &ldquo;On Fibring Semantics for BDI
Logics&rdquo;, in <em>Logics in Artificial Intelligence: European
Conference, JELIA 2002, Cosenza, Italy, September, 23-26</em>, Sergio
Flesca, Sergio Greco, Giovambattista Ianni, and Nicola Leone (eds.),
(Lecture Notes in Computer Science 2424), Berlin, Heidelberg: Springer
Berlin Heidelberg, 198&ndash;210. doi:10.1007/3-540-45757-7_17</li>

<li id="ref-Grove1988">Grove, Adam, 1988, &ldquo;Two Modellings for
Theory Change&rdquo;, <em>Journal of Philosophical Logic</em>, 17(2).
doi:10.1007/BF00247909</li>

<li id="ref-GruneH09">Gr&uuml;ne-Yanoff, Till and Sven Ove Hansson,
2009, &ldquo;Preference Change: An Introduction&rdquo;, in
<em>Preference Change</em>, Till Gr&uuml;ne-Yanoff and Sven Ove
Hansson (eds.), Dordrecht: Springer Netherlands, 1&ndash;26.
doi:10.1007/978-90-481-2593-7_1</li>

<li id="ref-HalpernMV04">Halpern, Joseph Y., Ron van der Meyden, and
Moshe Y. Vardi, 2004, &ldquo;Complete Axiomatizations for Reasoning
about Knowledge and Time&rdquo;, <em>SIAM Journal on Computing</em>,
33(3): 674&ndash;703. doi:10.1137/S0097539797320906</li>

<li id="ref-HalpernSS09a">Halpern, Joseph Y., Dov Samet, and Ella
Segev, 2009a, &ldquo;Defining Knowledge in Terms of Belief: The Modal
Logic Perspective&rdquo;, <em>The Review of Symbolic Logic</em>,
2(03): 469. doi:10.1017/S1755020309990141</li>

<li id="ref-HalpernSS09">&ndash;&ndash;&ndash;, 2009b, &ldquo;On
Definability in Multimodal Logic&rdquo;, <em>The Review of Symbolic
Logic</em>, 2(03): 451. doi:10.1017/S175502030999013X</li>

<li id="ref-HalpernV89">Halpern, Joseph Y. and Moshe Y. Vardi, 1989,
&ldquo;The Complexity of Reasoning about Knowledge and Time. I. Lower
Bounds&rdquo;, <em>Journal of Computer and System Sciences</em>,
38(1): 195&ndash;237. doi:10.1016/0022-0000(89)90039-1</li>

<li id="ref-HarelKozenTiuryn2000">Harel, David, Dexter Kozen, and
Jerzy Tiuryn, 2000, <em>Dynamic Logic</em>, Cambridge, MA: MIT
Press.</li>

<li id="ref-Peirce34">Hartshorne, Charles and Paul Weiss (eds.), 1934,
<em>Collected Papers of Charles S. Peirce</em> Vol. V (Pragmatism and
Pramaticism) and VI (Scientific Metaphysics), Cambridge: Belknap
Press.</li>

<li id="ref-HerzigLPX17">Herzig, Andreas, Emiliano Lorini, Laurent
Perrussel, and Zhanhao Xiao, 2017, &ldquo;BDI Logics for BDI
Architectures: Old Problems, New Perspectives&rdquo;,
<em>K&uuml;nstliche Intelligenz</em>, 31(1): 73&ndash;83.
doi:10.1007/s13218-016-0457-5</li>

<li id="ref-Hintikka07">Hintikka, Jaakko, 2007, <em>Socratic
Epistemology: Explorations of Knowledge-Seeking by Questioning</em>,
Cambridge: Cambridge University Press.</li>

<li id="ref-HintikkaHM02">Hintikka, Jaakko, Ilpo Halonen, and Arto
Mutanen, 2002, &ldquo;Interrogative Logic as a General Theory of
Reasoning&rdquo;, in <em>Handbook of the Logic of Argument and
Inference</em>, Dov M. Gabbay, Ralph H. Johnson, Hans J&uuml;rgen
Ohlbach, and John Woods (eds.), Amsterdam: Elsevier,
295&ndash;337.</li>

<li id="ref-Hoare69">Hoare, Charles Antony Richard, 1969, &ldquo;An
axiomatic basis for computer programming&rdquo;, <em>Communications of
the ACM</em>, 12(10): 576&ndash;580.  doi:10.1145/363235.363259</li>

<li id="ref-HoekJW07">van der Hoek, Wiebe, Wojciech Jamroga, and
Michael Wooldridge, 2007, &ldquo;Towards a Theory of Intention
Revision&rdquo;, <em>Synthese</em>, 155(2): 265&ndash;290.
doi:10.1007/s11229-006-9145-6</li>

<li id="ref-HoekLM99">van der Hoek, Wiebe, Bernd van Linder, and
John-Jules Ch. Meyer, 1999, &ldquo;An Integrated Modal Approach to
Rational Agents&rdquo;, in <em>Foundations of Rational Agency</em>,
Michael Wooldridge and Anand Rao (eds.), (Applied Logic Series 14),
Dordrecht: Springer Netherlands, 133&ndash;167.
doi:10.1007/978-94-015-9204-8_7</li>

<li id="ref-HollidayI10">Holliday, Wesley H. and Thomas F. Icard III,
2010, &ldquo;Moorean Phenomena in Epistemic Logic&rdquo;, in
<em>Advances in Modal Logic 8, Papers from the Eighth Conference on
&ldquo;Advances in Modal Logic&rdquo;, Held in Moscow, Russia, 24-27
August 2010</em>, Lev D. Beklemishev, Valentin Goranko, &amp; Valentin
B. Shehtman (eds.), College Publications, pp. 178&ndash;199.
 [<a href="http://www.aiml.net/volumes/volume8/Holliday-Icard.pdf" target="other">Holliday and Icard 2010 available online</a>]</li>
 
<li id="ref-HollidayHI12">Holliday, Wesley H., Tomohiro Hoshi, and
Thomas F. Icard III, 2012, &ldquo;A Uniform Logic of Information
Dynamics&rdquo;, in <em>Advances in Modal Logic 9, Papers from the
Ninth Conference on &ldquo;Advances in Modal Logic&rdquo;, Held in
Copenhagen, Denmark, 22-25 August 2012</em>, Thomas Bolander, Torben
Bra&uuml;ner, Silvio Ghilardi, &amp; Lawrence S. Moss (eds.), College
Publications, pp. 348&ndash;367.
 [<a href="http://www.aiml.net/volumes/volume9/Holliday-Hoshi-Icard.pdf" target="other">Holliday, Hoshi, et al. 2012 available online</a></li>
 
<li id="ref-HollidayHI13">&ndash;&ndash;&ndash;, 2013,
&ldquo;Information Dynamics and Uniform Substitution&rdquo;,
<em>Synthese</em>, 190(S1): 31&ndash;55.
doi:10.1007/s11229-013-0278-0</li>

<li id="ref-IcardPS10">Icard III, Thomas F., Eric Pacuit, and Yoav
Shoham, 2010, &ldquo;Joint Revision of Belief and Intention&rdquo;, in
<em>Principles of Knowledge Representation and Reasoning: Proceedings
of the Twelfth International Conference, KR 2010, Toronto, Ontario,
Canada, May 9-13, 2010</em>, Fangzhen Lin, Ulrike Sattler, &amp;
Miroslaw Truszczynski (eds.), AAAI Press.
 [<a href="http://aaai.org/ocs/index.php/KR/KR2010/paper/view/1297" target="other">Icard, Pacuit, and Shoham 2010 available online</a>]</li>
 
<li id="ref-sep-knowledge-analysis">Ichikawa, Jonathan Jenkins and
Matthias Steup, 2018, &ldquo;The Analysis of Knowledge&rdquo;, in
<em>The Stanford Encyclopedia of Philosophy</em> (Summer 2018 Edition),
Edward N. Zalta (ed.). URL =
 &lt;<a href="https://plato.stanford.edu/archives/sum2018/entries/knowledge-analysis/" target="other">https://plato.stanford.edu/archives/sum2018/entries/knowledge-analysis/</a>&gt;</li>
 
<li id="ref-Kaplan89">Kaplan, David, 1989, &ldquo;Demonstratives. an
Essay on the Semantics, Logic, Metaphysics, and Epistemology of
Demonstratives and Other Indexicals&rdquo;, in <em>Themes from
Kaplan</em>, Joseph Almog, John Perry, &amp; Howard Wettstein (eds.),
Oxford: Oxford University Press, pp. 481&ndash;563.</li>

<li id="ref-Kleene1956">Kleene, Stephen C., 1956,
&ldquo;Representation of Events in Nerve Nets and Finite
Automata&rdquo;, in <em>Automata Studies</em>, Claude E. Shannon &amp;
John McCarthy (eds.), Princeton, NJ: Princeton University Press, pp.
3&ndash;42.</li>

<li id="ref-Klein71">Klein, Peter D., 1971, &ldquo;A Proposed
Definition of Propositional Knowledge&rdquo;, <em>The Journal of
Philosophy</em>, 68(16): 471. doi:10.2307/2024845</li>

<li id="ref-KrachtW91">Kracht, Marcus and Frank Wolter, 1991,
&ldquo;Properties of Independently Axiomatizable Bimodal
Logics&rdquo;, <em>The Journal of Symbolic Logic</em>, 56(4):
1469&ndash;1485. doi:10.2307/2275487</li>

<li id="ref-KrachtW97">&ndash;&ndash;&ndash;, 1997, &ldquo;Simulation
and Transfer Results in Modal Logic: A Survey&rdquo;, <em>Studia
Logica</em>, 59(2): 149&ndash;177. doi:10.1023/A:1004900300438</li>

<li id="ref-Kurucz2006">Kurucz, Agi, 2006, &ldquo;Combining Modal
Logics&rdquo;, in <em>Handbook of Modal Logic</em>, Vol. 3, Patrick
Blackburn, Johan van Benthem, &amp; Frank Wolter (eds.), Amsterdam:
Elsevier Science, pp. 869&ndash;924.</li>

<li id="ref-Lehrer1990">Lehrer, Keith, 1990, <em>Theory of
Knowledge</em>, London, UK: Routledge.</li>

<li id="ref-LehrerP69">Lehrer, Keith and Thomas Paxson, Jr, 1969,
&ldquo;Knowledge: Undefeated Justified True Belief&rdquo;, <em>The
Journal of Philosophy</em>, 66(8): 225. doi:10.2307/2024435</li>

<li id="ref-Lenzen78">Lenzen, Wolfgang, 1978, <em>Recent Work in
Epistemic Logic</em>, North-Holland: Acta Philosophica Fennica.</li>

<li id="ref-Levesque89">Levesque, Hector J., 1989, &ldquo;A
Knowledge-Level Account of Abduction&rdquo;, in <em>Proceedings of the
11th International Joint Conference on Artificial Intelligence.
Detroit, MI, USA, August 1989</em>, N.S. Stidharan (ed.), Morgan
Kaufmann, 1061&ndash;1067.
 [<a href="http://ijcai.org/Proceedings/89-2/" target="other">Levesque 1989 available online</a>]</li>
 
<li id="ref-Liu11">Liu, Fenrong, 2011, <em>Reasoning about Preference
Dynamics</em>, (Synthese Library 354), Dordrecht: Springer
Netherlands. doi:10.1007/978-94-007-1344-4</li>

<li id="ref-LoriniDDHM09">Lorini, Emiliano, Mehdi Dastani, Hans van
Ditmarsch, Andreas Herzig, and John-Jules Meyer, 2009,
&ldquo;Intentions and Assignments&rdquo;, in <em>Logic, Rationality,
and Interaction: Second International Workshop, LORI 2009, Chongqing,
China, October 8-11, 2009. Proceedings</em>, Xiangdong He, John Horty,
and Eric Pacuit (eds.) (Lecture Notes in Computer Science 5834),
Berlin, Heidelberg: Springer Berlin Heidelberg, 198&ndash;211.
doi:10.1007/978-3-642-04893-7_16</li>

<li id="ref-Lutz06">Lutz, Carsten, 2006, &ldquo;Complexity and
Succinctness of Public Announcement Logic&rdquo;, in <em>5th
International Joint Conference on Autonomous Agents and Multiagent
Systems (AAMAS 2006), Hakodate, Japan, May 8-12, 2006</em>, Hideyuki
Nakashima, Michael P. Wellman, Gerhard Weiss, and Peter Stone (eds.),
ACM Press, 137&ndash;143. doi:10.1145/1160633.1160657</li>

<li id="ref-MaP16">Ma, Minghui and Ahti-Veikko Pietarinen, 2016,
&ldquo;A Dynamic Approach to Peirce&rsquo;s Interrogative Construal of
Abductive Logic&rdquo;, <em>IfCoLog Journal of Logics and Their
Applications</em>, 3(1): 73&ndash;104.
 [<a href="http://www.collegepublications.co.uk/downloads/ifcolog00005.pdf" target="other">Ma and Pietarinen 2016 available online</a>]</li>
 
<li id="ref-MarxVenema97">Marx, Maarten and Yde Venema, 1997,
<em>Multi-Dimensional Modal Logic</em>, (Applied Logic Series 4),
Dordrecht: Springer Netherlands. doi:10.1007/978-94-011-5694-3</li>

<li id="ref-Montague70">Montague, Richard, 1970, &ldquo;Universal
Grammar&rdquo;, <em>Theoria</em>, 36(3): 373&ndash;398.
doi:10.1111/j.1755-2567.1970.tb00434.x</li>

<li id="ref-Nortmann02">Nortmann, Ulrich, 2002, &ldquo;The Logic of
Necessity in Aristotle: an Outline of Approaches to the Modal
Syllogistic, Together with a General Account of de Dicto&mdash;and de
Re&mdash;Necessity&rdquo;, <em>History and Philosophy of Logic</em>,
23(4): 253&ndash;265. doi:10.1080/0144534021000050506</li>

<li id="ref-Pacuit07">Pacuit, Eric, 2007, &ldquo;Understanding the
Brandenburger-Keisler Paradox&rdquo;, <em>Studia Logica</em>, 86(3):
435&ndash;454. doi:10.1007/s11225-007-9069-2</li>

<li id="ref-sep-epistemic-game">Pacuit, Eric and Olivier Roy, 2017,
&ldquo;Epistemic Foundations of Game Theory&rdquo;, in <em>The
Stanford Encyclopedia of Philosophy</em> (Summer 2017 Edition), Edward N.
Zalta (ed.). URL =
 &lt;<a href="https://plato.stanford.edu/archives/sum2017/entries/epistemic-game/" target="other">https://plato.stanford.edu/archives/sum2017/entries/epistemic-game/</a>&gt;</li>
 
<li id="ref-PacuitPC06">Pacuit, Eric, Rohit Parikh, and Eva Cogan,
2006, &ldquo;The Logic of Knowledge Based Obligation&rdquo;,
<em>Synthese</em>, 149(2): 311&ndash;341.
doi:10.1007/s11229-005-3877-6</li>

<li id="ref-ParikhR03">Parikh, Rohit and Ramaswamy Ramanujam, 2003,
&ldquo;A Knowledge Based Semantics of Messages&rdquo;, <em>Journal of
Logic, Language and Information</em>, 12(4): 453&ndash;467.
doi:10.1023/A:1025007018583</li>

<li id="ref-Peirce67">Peirce, Charles S., 1967, &ldquo;Manuscripts in
the Houghton Library of Harvard University, as Identified by Richard
Robin&rdquo;, in <em>Annotated Catalogue of the Papers of Charles S.
Peirce</em>, Amherst: University of Massachusetts Press.</li>

<li id="ref-Quinton76">Quinton, Anthony, 1976, &ldquo;The Presidential
Address&#8239;: Social Objects&rdquo;, <em>Proceedings of the Aristotelian
Society</em>, 76(1): 1&ndash;28. doi:10.1093/aristotelian/76.1.1</li>

<li id="ref-RaoG91">Rao, Anand S. and Michael P. Georgeff, 1991,
&ldquo;Modeling Rational Agents Within a Bdi-Architecture&rdquo;, in
<em>Proceedings of the 2nd International Conference on Principles of
Knowledge Representation and Reasoning (Kr&rsquo;91). Cambridge, Ma,
Usa, April 22&ndash;25, 1991.</em>, James F. Allen, Richard Fikes,
&amp; Erik Sandewall (eds.), Morgan Kaufmann, pp. 473&ndash;484.</li>

<li id="ref-Roy2008">Roy, Olivier, 2008, <em>Thinking Before Acting.
Intentions, Logic, Rational Choice</em>, PhD thesis, Institute for
Logic, Language; Computation (ILLC), Universiteit van Amsterdam (UvA),
Amsterdam, The Netherlands.
 [<a href="http://www.illc.uva.nl/Research/Dissertations/DS-2008-03.text.pdf" target="other">Roy 2008 available online</a>]</li>
 
<li id="ref-Schurz91">Schurz, Gerhard, 1991, &ldquo;How Far Can
Hume&rsquo;s Is-Ought Thesis Be Generalized?: An Investigation in
Alethic-Deontic Modal Predicate Logic&rdquo;, <em>Journal of
Philosophical Logic</em>, 20(1): 37&ndash;95.
doi:10.1007/BF00454742</li>

<li id="ref-Schurz11">&ndash;&ndash;&ndash;, 2011, &ldquo;Combinations
and Completeness Transfer for Quantified Modal Logics&rdquo;,
<em>Logic Journal of IGPL</em>, 19(4): 598&ndash;616.
doi:10.1093/jigpal/jzp085</li>

<li id="ref-Scott70">Scott, Dana, 1970, &ldquo;Advice on Modal
Logic&rdquo;, in <em>Philosophical Problems in Logic</em>, Karel
Lambert (ed.), Dordrecht: Springer Netherlands, 143&ndash;173.
doi:10.1007/978-94-010-3272-8_7</li>

<li id="ref-Segerberg73">Segerberg, Krister, 1973,
&ldquo;Two-Dimensional Modal Logic&rdquo;, <em>Journal of
Philosophical Logic</em>, 2(1): 77&ndash;96.
doi:10.1007/BF02115610</li>

<li id="ref-sep-logic-action">Segerberg, Krister, John-Jules Meyer,
and Marcus Kracht, 2016, &ldquo;The Logic of Action&rdquo;, in <em>The
Stanford Encyclopedia of Philosophy</em> (Winter 2016 Edition), Edward N.
Zalta (ed.). URl =
 &lt;<a href="https://plato.stanford.edu/archives/win2016/entries/logic-action/" target="other">https://plato.stanford.edu/archives/win2016/entries/logic-action/</a>&gt;</li>
 
<li id="ref-Sehtman78">&Scaron;ehtman, Valentin B., 1978,
&ldquo;Two-Dimensional Modal Logic&rdquo;, <em>Matematicheskie
Zametki</em>, 23(5): 759&ndash;772.
 [<a href="http://mi.mathnet.ru/eng/mz10005" target="other">&Scaron;ehtman 1978 available online</a>]</li>
 
<li id="ref-SeligmanLG11">Seligman, Jeremy, Fenrong Liu, and Patrick
Girard, 2011, &ldquo;Logic in the Community&rdquo;, in <em>Logic and
Its Applications</em>, Mohua Banerjee and Anil Seth (eds.), (Lecture
Notes in Computer Science 6521), Berlin, Heidelberg: Springer Berlin
Heidelberg, 178&ndash;188. doi:10.1007/978-3-642-18026-2_15</li>

<li id="ref-SeligmanLG13">&ndash;&ndash;&ndash;, 2013, &ldquo;Facebook
and the Epistemic Logic of Friendship&rdquo;, in <em>Proceedings of
the 14th Conference on Theoretical Aspects of Rationality and
Knowledge (TARK 2013), Chennai, India, January 7-9, 2013</em>,
Burkhard C. Schipper (ed.), pp. 229&ndash;238.
 [<a href="http://www.tark.org/proceedings/tark_jan7_13/p229-seligman.pdf" target="other">Seligman, Liu, and Girard 2013 available online</a>]</li>
 
<li id="ref-Shope83">Shope, Robert K., 1983, <em>The Analysis of
Knowing. a Decade of Research</em>, Princeton, ,NJ: Princeton
University Press.</li>

<li id="ref-Singh98">Singh, Munindar P., 1998, &ldquo;Semantical
Considerations on Intention Dynamics for BDI Agents&rdquo;,
<em>Journal of Experimental &amp; Theoretical Artificial
Intelligence</em>, 10(4): 551&ndash;564.
doi:10.1080/095281398146752</li>

<li id="ref-SmetsVelazquez2017-1th">Smets, Sonja, and
Vel&aacute;zquez-Quesada, Fernando R., 2017, &ldquo;How to Make
Friends: A Logical Approach to Social Group Creation&rdquo;, in
Baltag, Seligman, &amp; Yamada 2017: 377&ndash;390.
doi:10.1007/978-3-662-55665-8_26</li>

<li id="ref-Spohn1988">Spohn, Wolfgang, 1988, &ldquo;Ordinal
Conditional Functions: A Dynamic Theory of Epistemic States&rdquo;, in
<em>Causation in Decision, Belief Change, and Statistics: Proceedings
of the Irvine Conference on Probability and Causation</em>, William L.
Harper and Brian Skyrms (eds.), Dordrecht: Springer Netherlands,
105&ndash;134. doi:10.1007/978-94-009-2865-7_6</li>

<li id="ref-Stalnaker78">Stalnaker, Robert, 1978,
&ldquo;Assertion&rdquo;, in <em>Pragmatics</em>, Peter Cole (ed.), New
York: Academic Press, pp. 315&ndash;332.</li>

<li id="ref-Stalnaker06">&ndash;&ndash;&ndash;, 2006, &ldquo;On Logics
of Knowledge and Belief&rdquo;, <em>Philosophical Studies</em>,
128(1): 169&ndash;199. doi:10.1007/s11098-005-4062-y</li>

<li id="ref-Swain74">Swain, Marshall, 1974, &ldquo;Epistemic
Defeasibility&rdquo;, <em>The American Philosophical Quarterly</em>,
11(1): 15&ndash;25. </li>

<li id="ref-Thomason1984">Thomason, Richmond H., 1984,
&ldquo;Combinations of Tense and Modality&rdquo;, in <em>Handbook of
Philosophical Logic</em>, volume 2, Dov Gabbay and Franz Guenthner
(eds.), Dordrecht: Springer Netherlands, 135&ndash;165.
doi:10.1007/978-94-009-6259-0_3</li>

<li id="ref-sep-logic-dynamic">Troquard, Nicolas and Philippe
Balbiani, 2019, &ldquo;Propositional Dynamic Logic&rdquo;, in <em>The
Stanford Encyclopedia of Philosophy</em> (Spring 2019 Edition), Edward N.
Zalta (ed.). URL =
 &lt;<a href="https://plato.stanford.edu/archives/spr2019/entries/logic-dynamic/" target="other">https://plato.stanford.edu/archives/spr2019/entries/logic-dynamic/</a>&gt;;</li>
 
<li id="ref-Velazquez15">Vel&aacute;zquez-Quesada, Fernando R., 2015,
&ldquo;Reasoning Processes as Epistemic Dynamics&rdquo;,
<em>Axiomathes</em>, 25(1): 41&ndash;60.
 [<a href="http://link.springer.com/article/10.1007/s10516-014-9255-6" target="other">Vel&aacute;zquez-Quesada 2015 available online</a>]</li>

<li id="ref-Velazquez2017subBR">&ndash;&ndash;&ndash;, 2017, &ldquo;On
Subtler Belief Revision Policies&rdquo;, in Baltag, Seligman, &amp;
Yamada 2017: 314&ndash;329 doi:10.1007/978-3-662-55665-8_22 </li>

<li id="ref-VSN13">Vel&aacute;zquez-Quesada, Fernando R., Fernando
Soler-Toscano, and &Aacute;ngel Nepomuceno-Fern&aacute;ndez, 2013,
&ldquo;An Epistemic and Dynamic Approach to Abductive Reasoning:
Abductive Problem and Abductive Solution&rdquo;, <em>Journal of
Applied Logic</em>, 11(4): 505&ndash;522.
doi:10.1016/j.jal.2013.07.002</li>

<li id="ref-Venema1992">Venema, Yde, 1992, <em>Many-Dimensional Modal
Logic</em>, PhD thesis, Universiteit van Amsterdam, Amsterdam, The
Netherlands.
 [<a href="https://www.illc.uva.nl/Research/Publications/Dissertations/HDS-04-Yde-Venema.text.pdf" target="other">Venema 1992 available online</a>]</li>
 
<li id="ref-Voorbraak93">Voorbraak, Frans, 1993, <em>As Far as I Know.
Epistemic Logic and Uncertainty</em>, PhD thesis, Department of
Philosophy, University of Utrecht, Utretch, The Netherlands.</li>

<li id="ref-Williamson00">Williamson, Timothy, 2002, <em>Knowledge and
Its Limits</em>, Oxford: Oxford University Press.
doi:10.1093/019925656X.001.0001</li>

<li id="ref-Wolter1998">Wolter, Frank, 1998, &ldquo;Fusions of Modal
Logics Revisited&rdquo;, in <em>Advances in Modal Logic, Volume
1</em>, Marcus Kracht, Maarten de Rijke, Heinrich Wansing, &amp;
Michael Zakharyaschev (eds.), (CSLI Lecture Notes 87), Stanford, CA:
CSLI Publications, pp. 361&ndash;379.</li>

<li id="ref-Wooldridge00">Wooldridge, Michael, 2000, <em>Reasoning
About Rational Agents</em>, Cambridge, MA: The MIT Press.</li>

<li id="ref-Yablo85">Yablo, Stephen, 1985, &ldquo;Truth and
Reflection&rdquo;, <em>Journal of Philosophical Logic</em>, 14(3):
297&ndash;349. doi:10.1007/BF00249368</li>

<li id="ref-Yablo93">&ndash;&ndash;&ndash;, 1993, &ldquo;Paradox
without Self-Reference&rdquo;, <em>Analysis</em>, 53(4):
251&ndash;252. doi:10.1093/analys/53.4.251</li>
</ul>

</div>

<div id="academic-tools">

<h2 id="Aca">Academic Tools</h2>

<blockquote>
<table class="vert-top">
<tr>
<td><img src="../../symbols/sepman-icon.jpg" alt="sep man icon" /></td>
<td><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=phil-multimodallogic" target="other">How to cite this entry</a>.</td>
</tr>

<tr>
<td><img src="../../symbols/sepman-icon.jpg" alt="sep man icon" /></td>
<td><a href="https://leibniz.stanford.edu/friends/preview/phil-multimodallogic/" target="other">Preview the PDF version of this entry</a> at the
 <a href="https://leibniz.stanford.edu/friends/" target="other">Friends of the SEP Society</a>.</td>
</tr>

<tr>
<td><img src="../../symbols/inpho.png" alt="inpho icon" /></td>
<td><a href="https://www.inphoproject.org/entity?sep=phil-multimodallogic&amp;redirect=True" target="other">Look up topics and thinkers related to this entry</a>
 at the Internet Philosophy Ontology Project (InPhO).</td>
</tr>

<tr>
<td><img src="../../symbols/pp.gif" alt="phil papers icon" /></td>
<td><a href="https://philpapers.org/sep/phil-multimodallogic/" target="other">Enhanced bibliography for this entry</a>
at <a href="https://philpapers.org/" target="other">PhilPapers</a>, with links to its database.</td>
</tr>

</table>
</blockquote>

</div>




<div id="other-internet-resources">

<h2 id="Oth">Other Internet Resources</h2>



<ul class="hanging">

<li id="ref-BaltagSmets2010NASSLLIslides">Baltag, Alexandru and Sonja
Smets, 2010, <em>Multi-Agent Belief Dynamics</em>, course at
NASSLLI'10. URL =
 &lt;<a href="https://sites.google.com/site/thesonjasmetssite/teaching/nasslli-2010" target="other">https://sites.google.com/site/thesonjasmetssite/teaching/nasslli-2010</a>&gt;</li>
 
<li id="ref-vanBenthem2018">van Benthem, Johan, 2018, <em>Implicit and
Explicit Stances in Logic</em>, manuscript. URL =
 &lt;<a href="https://eprints.illc.uva.nl/1583/" class="uri">https://eprints.illc.uva.nl/1583/</a>&gt;</li>
 
 <li><a href="https://www.iep.utm.edu/yablo-pa/" target="other">Yablo paradox</a>,
 Internet Encyclopedia of Philosophy</li>
</ul>

</div>

<div id="related-entries">

<h2 id="Rel">Related Entries</h2>

<p>

 <a href="../abduction/index.html">abduction</a> |
 <a href="../actualism/index.html">actualism</a> |
 <a href="../agency/index.html">agency</a> |
 <a href="../common-knowledge/index.html">common knowledge</a> |
 <a href="../computational-complexity/index.html">computational complexity theory</a> |
 <a href="../epistemic-paradoxes/index.html">epistemic paradoxes</a> |
 <a href="../epistemology/index.html">epistemology</a> |
 <a href="../epistemology-social/index.html">epistemology: social</a> |
 <a href="../epistemic-game/index.html">game theory: epistemic foundations of</a> |
 <a href="../indexicals/index.html">indexicals</a> |
 <a href="../intention/index.html">intention</a> |
 <a href="../knowledge-analysis/index.html">knowledge: analysis of</a> |
 <a href="../logic-action/index.html">logic: action</a> |
 <a href="../logic-classical/index.html">logic: classical</a> |
 <a href="../logic-combining/index.html">logic: combining</a> |
 <a href="../logic-deontic/index.html">logic: deontic</a> |
 <a href="../dynamic-epistemic/index.html">logic: dynamic epistemic</a> |
 <a href="../logic-epistemic/index.html">logic: epistemic</a> |
 <a href="../logic-justification/index.html">logic: justification</a> |
 <a href="../logic-modal/index.html">logic: modal</a> |
 <a href="../logic-belief-revision/index.html">logic: of belief revision</a> |
 <a href="../logic-dynamic/index.html">logic: propositional dynamic</a> |
 <a href="../logic-temporal/index.html">logic: temporal</a> |
 <a href="../modeltheory-fo/index.html">model theory: first-order</a> |
 <a href="../peirce/index.html">Peirce, Charles Sanders</a> |
 <a href="../possible-worlds/index.html">possible worlds</a> |
 <a href="../quantification/index.html">quantifiers and quantification</a> |
 <a href="../questions/index.html">questions</a> |
 <a href="../russell-paradox/index.html">Russell&rsquo;s paradox</a> |
 <a href="../self-reference/index.html">self-reference</a> |
 <a href="../two-dimensional-semantics/index.html">semantics: two-dimensional</a>

</p>

</div>



<script type="text/javascript" src="local.js"></script>
<script type="text/javascript" src="../../MathJax/MathJaxdda6.js?config=TeX-AMS-MML_HTMLorMML"></script>

</div><!-- #aueditable --><!--DO NOT MODIFY THIS LINE AND BELOW-->

<!-- END ARTICLE HTML -->

</div> <!-- End article-content -->

  <div id="article-copyright">
    <p>
 <a href="../../info.html#c">Copyright &copy; 2019</a> by

<br />
Sonja Smets
&lt;<a href="m&#97;ilto:S&#37;2eJ&#37;2eL&#37;2eSmets&#37;40uva&#37;2enl"><em>S<abbr title=" dot ">&#46;</abbr>J<abbr title=" dot ">&#46;</abbr>L<abbr title=" dot ">&#46;</abbr>Smets<abbr title=" at ">&#64;</abbr>uva<abbr title=" dot ">&#46;</abbr>nl</em></a>&gt;<br />
<a href="https://staff.fnwi.uva.nl/f.r.velazquezquesada/" target="other">Fernando Vel&aacute;zquez-Quesada</a>
&lt;<a href="m&#97;ilto:F&#37;2eR&#37;2eVelazquezQuesada&#37;40uva&#37;2enl"><em>F<abbr title=" dot ">&#46;</abbr>R<abbr title=" dot ">&#46;</abbr>VelazquezQuesada<abbr title=" at ">&#64;</abbr>uva<abbr title=" dot ">&#46;</abbr>nl</em></a>&gt;
    </p>
  </div>

</div> <!-- End article -->

<!-- NOTE: article banner is outside of the id="article" div. -->
<div id="article-banner" class="scroll-block">
  <div id="article-banner-content">
    <a href="../../fundraising/index.html">
    Open access to the SEP is made possible by a world-wide funding initiative.<br />
    The Encyclopedia Now Needs Your Support<br />
    Please Read How You Can Help Keep the Encyclopedia Free</a>
  </div>
</div> <!-- End article-banner -->

    </div> <!-- End content -->

    <div id="footer">

      <div id="footer-menu">
        <div class="menu-block">
          <h4><i class="icon-book"></i> Browse</h4>
          <ul role="menu">
            <li><a href="../../contents.html">Table of Contents</a></li>
            <li><a href="../../new.html">What's New</a></li>
            <li><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/random">Random Entry</a></li>
            <li><a href="../../published.html">Chronological</a></li>
            <li><a href="../../archives/index.html">Archives</a></li>
          </ul>
        </div>
        <div class="menu-block">
          <h4><i class="icon-info-sign"></i> About</h4>
          <ul role="menu">
            <li><a href="../../info.html">Editorial Information</a></li>
            <li><a href="../../about.html">About the SEP</a></li>
            <li><a href="../../board.html">Editorial Board</a></li>
            <li><a href="../../cite.html">How to Cite the SEP</a></li>
            <li><a href="../../special-characters.html">Special Characters</a></li>
            <li><a href="../../tools/index.html">Advanced Tools</a></li>
            <li><a href="../../contact.html">Contact</a></li>
          </ul>
        </div>
        <div class="menu-block">
          <h4><i class="icon-leaf"></i> Support SEP</h4>
          <ul role="menu">
            <li><a href="../../support/index.html">Support the SEP</a></li>
            <li><a href="../../support/friends.html">PDFs for SEP Friends</a></li>
            <li><a href="../../support/donate.html">Make a Donation</a></li>
            <li><a href="../../support/sepia.html">SEPIA for Libraries</a></li>
          </ul>
        </div>
      </div> <!-- End footer menu -->

      <div id="mirrors">
        <div id="mirror-info">
          <h4><i class="icon-globe"></i> Mirror Sites</h4>
          <p>View this site from another server:</p>
        </div>
        <div class="btn-group open">
          <a class="btn dropdown-toggle" data-toggle="dropdown" href="https://plato.stanford.edu/">
            <span class="flag flag-usa"></span> USA (Main Site) <span class="caret"></span>
            <span class="mirror-source">Philosophy, Stanford University</span>
          </a>
          <ul class="dropdown-menu">
            <li><a href="../../mirrors.html">Info about mirror sites</a></li>
          </ul>
        </div>
      </div> <!-- End mirrors -->
      
      <div id="site-credits">
        <p>The Stanford Encyclopedia of Philosophy is <a href="../../info.html#c">copyright &copy; 2021</a> by <a href="http://mally.stanford.edu/">The Metaphysics Research Lab</a>, Department of Philosophy, Stanford University</p>
        <p>Library of Congress Catalog Data: ISSN 1095-5054</p>
      </div> <!-- End site credits -->

    </div> <!-- End footer -->

  </div> <!-- End container -->

   <!-- NOTE: Script required for drop-down button to work (mirrors). -->
  <script>
    $('.dropdown-toggle').dropdown();
  </script>

</body>

<!-- Mirrored from seop.illc.uva.nl/entries/phil-multimodallogic/ by HTTrack Website Copier/3.x [XR&CO'2014], Wed, 22 Jun 2022 19:53:00 GMT -->
</html>
