<!DOCTYPE html>
<!--[if lt IE 7]> <html class="ie6 ie"> <![endif]-->
<!--[if IE 7]>    <html class="ie7 ie"> <![endif]-->
<!--[if IE 8]>    <html class="ie8 ie"> <![endif]-->
<!--[if IE 9]>    <html class="ie9 ie"> <![endif]-->
<!--[if !IE]> --> <html> <!-- <![endif]-->

<!-- Mirrored from seop.illc.uva.nl/entries/closure-epistemic/ by HTTrack Website Copier/3.x [XR&CO'2014], Wed, 22 Jun 2022 19:46:24 GMT -->
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>
Epistemic Closure (Stanford Encyclopedia of Philosophy)
</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="robots" content="noarchive, noodp" />
<meta property="citation_title" content="Epistemic Closure" />
<meta property="citation_author" content="Luper, Steven" />
<meta property="citation_publication_date" content="2001/12/31" />
<meta name="DC.title" content="Epistemic Closure" />
<meta name="DC.creator" content="Luper, Steven" />
<meta name="DCTERMS.issued" content="2001-12-31" />
<meta name="DCTERMS.modified" content="2016-02-24" />

<!-- NOTE: Import webfonts using this link: -->
<link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,300,600,200&amp;subset=latin,latin-ext" rel="stylesheet" type="text/css" />

<link rel="stylesheet" type="text/css" media="screen,handheld" href="../../css/bootstrap.min.css" />
<link rel="stylesheet" type="text/css" media="screen,handheld" href="../../css/bootstrap-responsive.min.css" />
<link rel="stylesheet" type="text/css" href="../../css/font-awesome.min.css" />
<!--[if IE 7]> <link rel="stylesheet" type="text/css" href="../../css/font-awesome-ie7.min.css"> <![endif]-->
<link rel="stylesheet" type="text/css" media="screen,handheld" href="../../css/style.css" />
<link rel="stylesheet" type="text/css" media="print" href="../../css/print.css" />
<link rel="stylesheet" type="text/css" href="../../css/entry.css" />
<!--[if IE]> <link rel="stylesheet" type="text/css" href="../../css/ie.css" /> <![endif]-->
<script type="text/javascript" src="../../js/jquery-1.9.1.min.js"></script>
<script type="text/javascript" src="../../js/bootstrap.min.js"></script>

<!-- NOTE: Javascript for sticky behavior needed on article and ToC pages -->
<script type="text/javascript" src="../../js/jquery-scrolltofixed-min.js"></script>
<script type="text/javascript" src="../../js/entry.js"></script>

<!-- SEP custom script -->
<script type="text/javascript" src="../../js/sep.js"></script>
</head>

<!-- NOTE: The nojs class is removed from the page if javascript is enabled. Otherwise, it drives the display when there is no javascript. -->
<body class="nojs article" id="pagetopright">
<div id="container">
<div id="header-wrapper">
  <div id="header">
    <div id="branding">
      <div id="site-logo"><a href="../../index.html"><img src="../../symbols/sep-man-red.png" alt="SEP logo" /></a></div>
      <div id="site-title"><a href="../../index.html">Stanford Encyclopedia of Philosophy</a></div>
    </div>
    <div id="navigation">
      <div class="navbar">
        <div class="navbar-inner">
          <div class="container">
            <button class="btn btn-navbar collapsed" data-target=".collapse-main-menu" data-toggle="collapse" type="button"> <i class="icon-reorder"></i> Menu </button>
            <div class="nav-collapse collapse-main-menu in collapse">
              <ul class="nav">
                <li class="dropdown open"><a id="drop1" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-book"></i> Browse</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop1">
                    <li><a href="../../contents.html">Table of Contents</a></li>
                    <li><a href="../../new.html">What's New</a></li>
                    <li><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/random">Random Entry</a></li>
                    <li><a href="../../published.html">Chronological</a></li>
                    <li><a href="../../archives/index.html">Archives</a></li>
                  </ul>
                </li>
                <li class="dropdown open"><a id="drop2" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-info-sign"></i> About</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop2">
                    <li><a href="../../info.html">Editorial Information</a></li>
                    <li><a href="../../about.html">About the SEP</a></li>
                    <li><a href="../../board.html">Editorial Board</a></li>
                    <li><a href="../../cite.html">How to Cite the SEP</a></li>
                    <li><a href="../../special-characters.html">Special Characters</a></li>
                    <li><a href="../../tools/index.html">Advanced Tools</a></li>
                    <li><a href="../../contact.html">Contact</a></li>
                  </ul>
                </li>
                <li class="dropdown open"><a id="drop3" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-leaf"></i> Support SEP</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop3">
                    <li><a href="../../support/index.html">Support the SEP</a></li>
                    <li><a href="../../support/friends.html">PDFs for SEP Friends</a></li>
                    <li><a href="../../support/donate.html">Make a Donation</a></li>
                    <li><a href="../../support/sepia.html">SEPIA for Libraries</a></li>
                  </ul>
                </li>
              </ul>
            </div>
          </div>
        </div>
      </div>
    </div>
    <!-- End navigation -->
    
    <div id="search">
      <form id="search-form" method="get" action="https://seop.illc.uva.nl/search/searcher.py">
        <input type="search" name="query" placeholder="Search SEP" />
        <div class="search-btn-wrapper"><button class="btn search-btn" type="submit"><i class="icon-search"></i></button></div>
      </form>
    </div>
    <!-- End search --> 
    
  </div>
  <!-- End header --> 
</div>
<!-- End header wrapper -->

<div id="content">

<!-- Begin article sidebar -->
<div id="article-sidebar" class="sticky">
  <div class="navbar">
    <div class="navbar-inner">
      <div class="container">
        <button class="btn btn-navbar" data-target=".collapse-sidebar" data-toggle="collapse" type="button"> <i class="icon-reorder"></i> Entry Navigation </button>
        <div id="article-nav" class="nav-collapse collapse-sidebar in collapse">
          <ul class="nav">
            <li><a href="#toc">Entry Contents</a></li>
            <li><a href="#Bib">Bibliography</a></li>
            <li><a href="#Aca">Academic Tools</a></li>
            <li><a href="https://leibniz.stanford.edu/friends/preview/closure-epistemic/">Friends PDF Preview <i class="icon-external-link"></i></a></li>
            <li><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=closure-epistemic">Author and Citation Info <i class="icon-external-link"></i></a> </li>
            <li><a href="#pagetopright" class="back-to-top">Back to Top <i class="icon-angle-up icon2x"></i></a></li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</div>
<!-- End article sidebar --> 

<!-- NOTE: Article content must have two wrapper divs: id="article" and id="article-content" -->
<div id="article">
<div id="article-content">

<!-- BEGIN ARTICLE HTML -->


<div id="aueditable"><!--DO NOT MODIFY THIS LINE AND ABOVE-->

<h1>Epistemic Closure</h1><div id="pubinfo"><em>First published Mon Dec 31, 2001; substantive revision Wed Feb 24, 2016</em></div>

<div id="preamble">

<p>
Most of us think we can safely enlarge our knowledge base by accepting
things that are entailed by (or logically implied by) things we know.
Roughly speaking, the set of things we know is closed under entailment
(or under deduction or logical implication), so we know that a given
claim is true upon recognizing, and accepting thereby, that it follows
from what we know. This is not to say that our usual way of adding to
our knowledge is simply to recognize and accept what follows from what
we already know. Obviously much more is involved. For instance, we
gather data and construct explanations of those data, and under
suitable circumstances we learn from others. More to the point at
hand, when we claim that we know, of some proposition, that it is
true, that claim is itself subject to error; often, seeing what
follows from a knowledge claim prompts us to reassess and even
withdraw our claim, instead of concluding, of the things that follow
from it, that we know that they are true. Still, it seems reasonable
to think that if we <em>do</em> know that some proposition is true
then we are in a position to know, of the things that follow from it,
that they, too, are true. However, some theorists have denied that
knowledge is closed under entailment. The arguments against closure
include the following:</p>

<div class="indent">

<p>
<em>The argument from the analysis of knowledge</em>: given the
correct analysis, knowledge is not closed, so it isn&rsquo;t. For
example, if the correct analysis includes a tracking condition, then
closure fails.</p>

<p>
<em>The argument from nonclosure of knowledge modes</em>: since the
modes of gaining, preserving or extending knowledge, such as
perception, testimony, proof, memory, indication, and information are
not individually closed, neither is knowledge.</p>

<p>
<em>The argument from unknowable (or not easily knowable)
propositions</em>: certain sorts of propositions cannot be known
(without special measures); given closure, they could be known
(without special measures), by deducing them from mundane claims we
known, so knowledge is not closed.</p>

<p>
<em>The argument from skepticism</em>: skepticism is false but it
would be true if knowledge were closed, so knowledge is not
closed.</p>
</div>

<p>
While proponents of closure have responses to these arguments, they
also argue, somewhat in the style of G. E. Moore (1959), that closure
itself is a firm datum&mdash;it is obvious enough to rule out any
understanding of knowledge or related notions that undermines
closure.</p>

<p>
A closely related idea is that it is rational (justifiable) for us to
believe anything that follows from what it is rational for us to
believe. This idea is intimately related to the thesis that knowledge
is closed, since, according to some theorists, knowing <em>p</em>
entails justifiably believing <em>p</em>. If knowledge entails
justification, closure failure of the latter might lead to closure
failure of the former.</p>
</div>

<div id="toc">
<!--Entry Contents-->
<ul>
 <li><a href="#CloPri">1. The Closure Principle</a></li>
 <li><a href="#ArgAnaKno">2. The Argument From the Analysis of Knowledge</a>
<ul>
 <li><a href="#CloFaiDueTraConKno">2.1 Closure Fails Due to the Tracking Condition on Knowledge</a></li>
 <li><a href="#CloFaiRelAltApp">2.2 Closure Fails on a Relevant Alternatives Approach</a></li>
 <li><a href="#CloRel">2.3 Closure and Reliabilism</a></li>
 </ul></li>
 <li><a href="#ArgNonKnoMod">3. The Argument From Nonclosure of Knowledge Modes</a>
<ul>
 <li><a href="#KnoModNon">3.1 Knowledge Modes and Nonclosure</a></li>
 <li><a href="#ResDre">3.2 Responses to Dretske</a></li>
 </ul></li>
 <li><a href="#ArgNotEasKnoPro">4. The Argument From Not (Easily) Knowable Propositions</a>
<ul>
 <li><a href="#ArgLimPro">4.1 The Argument from Limiting Propositions</a></li>
 <li><a href="#ArgLotPro">4.2 The Argument from Lottery Propositions</a></li>
 </ul></li>
 <li><a href="#ArgSke">5. The Argument From Skepticism</a>
<ul>
 <li><a href="#SkeAnt">5.1 Skepticism and Antiskepticism</a></li>
 <li><a href="#TraSke">5.2 Tracking and Skepticism</a></li>
 <li><a href="#SafIndSke">5.3 Safe Indication and Skepticism</a></li>
 <li><a href="#ConSke">5.4 Contextualism and Skepticism</a></li>
 </ul></li>
 <li><a href="#CloRatBel">6. Closure of Rational Belief</a>
 </li>
 <li><a href="#Bib">Bibliography</a></li>
 <li><a href="#Aca">Academic Tools</a></li>
 <li><a href="#Oth">Other Internet Resources</a></li>
 <li><a href="#Rel">Related Entries</a></li>
 </ul>
<!--Entry Contents-->
<hr />
</div>

<div id="main-text">

<h2><a name="CloPri">1. Knowledge Closure</a></h2>

<p>
Precisely what is meant by the claim that knowledge is closed under
entailment? One response is that the following straight principle of
closure of knowledge under entailment is true:</p>

<dl class="sentag tag4em">
<dt>(<b>SP</b>)</dt>
<dd>If person <em>S</em> knows <em>p</em>, and <em>p</em>
entails <em>q</em>, then <em>S</em> knows <em>q</em>.</dd>
</dl>

<p>
The conditional involved in the straight principle might be the
material conditional, the subjunctive conditional, or entailment,
yielding three possibilities, each stronger than the one before:</p>

<dl class="sentag tag4em">
<dt>(<b>SP1</b>)</dt>
<dd><em>S</em> knows <em>p</em> and <em>p</em> entails
<em>q</em> only if <em>S</em> knows <em>q</em>.</dd>

<dt>(<b>SP2</b>)</dt>
<dd>If <em>S</em> were to know something, <em>p</em>, that
entailed <em>q</em>, <em>S</em> would know <em>q</em>.</dd>

<dt>(<b>SP3</b>)</dt>
<dd>It is necessarily the case that: <em>S</em> knows
<em>p</em> and <em>p</em> entails <em>q</em> only if <em>S</em> knows
<em>q</em>.</dd>
</dl>

<p>
However, each version of the straight principle is false, since we can
know one thing, <em>p</em>, but fail to see that <em>p</em> entails
<em>q,</em> or for some other reason fail to believe <em>q</em>. Since
knowledge entails belief (according to nearly all theorists), we fail
to know <em>q</em>. A less obvious worry is that we might reason badly
in coming to believe that <em>p</em> entails <em>q</em>. Perhaps we
think that <em>p</em> entails <em>q</em> because we think everything
entails everything, or because we have a warm tingly feeling between
our toes. Hawthorne (2005) raises the possibility that, in the course
of grasping that <em>p</em> entails <em>q</em>, <em>S</em> will cease
to know <em>p</em>. He also notes that <b>SP1</b> is defensible on the
(deviant) assumption that a thought, <em>p</em>, is equivalent to
another, <em>q</em>, if <em>p</em> and <em>q</em> hold in all of the
same possible worlds. Suppose <em>p</em> entails <em>q</em>. Then
<em>p</em> is equivalent to the conjunction of <em>p</em> and
<em>q</em>, and so the thought <em>p</em> is identical to the thought
<em>p</em> and <em>q</em>. Hence in knowing <em>p</em> <em>S</em>
knows <em>p</em> and <em>q</em>. Assuming that, in knowing <em>p</em>
and <em>q</em>, <em>S</em> knows <em>p</em> and S knows <em>q</em>,
then when <em>S</em> knows <em>p</em> <em>S</em> knows <em>q</em>, as
<b>SP1</b> says.</p>

<p>
The straight principle needs qualifying, but this should not concern
us so long as the qualifications are natural given the idea we are
trying to capture, namely, that we can extend our knowledge by
recognizing, and accepting thereby, things that follow from something
that we know. The qualifications embedded in the following principle
(construed as a material conditional) seem natural enough:</p>

<dl class="sentag tag4em">
<dt>(<b>K</b>)</dt>
<dd>If, while knowing <em>p</em>, <em>S</em> believes <em>q</em>
because <em>S</em> knows that <em>p</em> entails <em>q</em>, then
<em>S</em> knows <em>q</em>.</dd>
</dl>

<p>
As Williamson (2000) notes, the idea that we can extend our knowledge
by applying deduction to what we know supports a closure principle
that is stronger than <b>K</b>. It is a principle that says we know
things we believe on the grounds that they are jointly implied by
several separate known items. Suppose I know Mary is tall and I know
Mary is left handed. <b>K</b> does not authorize my putting these two
pieces of knowledge together so as to know that Mary is tall and left
handed. But the following generalized closure principle covers
deductions involving separate known items:</p>

<dl class="sentag tag4em">
<dt>(<b>GK</b>)</dt>
<dd>If, while knowing various propositions, <em>S</em> believes
<em>p</em> because <em>S</em> knows that they entail <em>p</em>, then
<em>S</em> knows <em>p</em>.</dd>
</dl>

<p>
Some theorists distinguish between something they call &ldquo;single
premise&rdquo; and something they call &ldquo;multiple-premise
closure&rdquo;. Such theorists would deny that <b>K</b> captures
&ldquo;single premise&rdquo; closure, because <b>K</b> says that
<em>S</em> knows <em>q</em> if <em>S</em> knows that <em>two</em>
things are true: that <em>p</em> is true as well as that <em>p</em>
entails <em>q</em>. The &ldquo;single premise&rdquo; closure principle
is usually formulated roughly as follows (following Williamson 2002
and Hawthorne 2004):</p>

<dl class="sentag tag4em">
<dt>(<b>SPK</b>)</dt>
<dd>If, while knowing <em>p</em>, <em>S</em> believes
<em>q</em> by competently deducing <em>q</em> from <em>p</em>, then
<em>S</em> knows <em>q</em>.</dd>
</dl>

<p>
However, it is far from clear that one may competently deduce
<em>q</em> from <em>p</em> without relying on any knowledge aside from
<em>p</em>. Fortunately, it seems that nothing hinges on this
possibility, except perhaps for people interested in whether we can
identify something that can appropriately be labeled &ldquo;single
premise closure principle&rdquo;.</p>

<p>
Proponents of closure might accept both <b>K</b> and <b>GK</b>,
perhaps further qualified in natural ways (but they might not: see the
concerns about justification closure raised in section 6). By
contrast, Fred Dretske and Robert Nozick reject <b>K</b> and therefore
<b>GK</b> as well. They reject any closure principle, no matter how
narrowly restricted, that warrants our knowing that skeptical
hypotheses (e.g., I am a brain in a vat) are false on the basis of
mundane knowledge claims (e.g., I am not in a vat). In addition to
rejecting <b>K</b> and <b>GK</b>, they deny knowledge closure across
instantiation and simplification, but not across equivalence (Nozick
1981: 227&ndash;229): </p>

<dl class="sentag tag4em">
<dt>(<b>KI</b>)</dt>
<dd>If, while knowing that all things are <em>F</em>,
<em>S</em> believes a particular thing <em>a</em> is <em>F</em>
because <em>S</em> knows it is entailed by the fact that all things
are <em>F</em>, then <em>S</em> knows <em>a</em> is <em>F</em>.</dd>

<dt>(<b>KS</b>)</dt>
<dd>If, while knowing <em>p</em> and <em>q</em>, <em>S</em>
believes <em>q</em> because <em>S</em> knows that <em>q</em> is
entailed by <em>p</em> and <em>q</em>, then <em>S</em> knows
<em>q</em>.</dd>

<dt>(<b>KE</b>)</dt>
<dd>If, while knowing <em>p</em>, <em>S</em> believes
<em>q</em> because <em>S</em> knows <em>q</em> is equivalent to
<em>p</em>, then <em>S</em> knows <em>q</em>.</dd>
</dl>

<p>
Let us turn to their arguments.</p>

<h2><a name="ArgAnaKno">2. The Argument From the Analysis of Knowledge</a></h2>

<p>
The argument from the analysis of knowledge says that the correct
account of knowledge leads to <b>K</b> failure. We can distinguish two
versions. According to the first version, <b>K</b> fails because
knowledge requires belief tracking. According to the second, any
relevant alternatives account, such as Dretske&rsquo;s and Nozick&rsquo;s, leads
to <b>K</b> failure. According to Dretske (2003: 112&ndash;3; 2005:
19), any relevant alternatives account leads &ldquo;naturally&rdquo;
but &ldquo;not inevitably&rdquo; to <b>K</b> failure. </p>

<h3><a name="CloFaiDueTraConKno">2.1 Closure Fails Due to the Tracking Condition on Knowledge</a></h3>

<p>
In rough outline, the first version involves defending say Dretske&rsquo;s
or Nozick&rsquo;s tracking analysis of knowledge, then showing that it
undermines <b>K</b> (versions of the tracking account are also
defended by Becker 2009, by Murphy and Black 2007, and by Roush 2005,
the last of whom modifies the tracking account so as to preserve
closure; for criticisms of Rouse see Brueckner 2012). We can skip the
defense, which consists largely in showing that tracking does a better
job than competitors in dealing with our epistemic intuitions about
cases of purported knowledge. We may also simplify the analyses.
According to Nozick, to know <em>p</em> is, very roughly (and ignoring
his thoroughly discredited fourth condition for knowledge, criticized,
e.g, in Luper 1984 and 2009 and in Kripke 2011), to have a belief
<em>p</em> which meets the following condition
(&lsquo;<b>BT</b>&rsquo; for belief tracking):</p>


<dl class="sentag tag4em">
<dt>(<b>BT</b>)</dt>
<dd>were <em>p</em> false, <em>S</em> would not believe
<em>p</em>.</dd>
</dl>

<p>
That is, in the close worlds to the actual world in which
<em>not-p</em> holds, <em>S</em> does not believe <em>p</em>. The
actual world is one&rsquo;s situation as it is when one arrives at the
belief <em>p</em>. <b>BT</b> requires that in all nearby
<em>not-p</em> worlds <em>S</em> fails to believe <em>p</em>. (The
semantics of subjunctive conditionals is clarified in Stalnaker 1968,
Lewis 1973, and modified by Nozick 1981 note 8.) On Dretske&rsquo;s view
knowing <em>p</em> is roughly a matter of having a reason <em>R</em>
for believing <em>p</em> which meets the following condition
(&lsquo;<b>CR</b>&rsquo; for conclusive reason):</p>

<dl class="sentag tag4em">
<dt>(<b>CR</b>)</dt>
<dd>were <em>p</em> false, <em>R</em> would not hold.</dd>
</dl>

<p>
That is, in the close worlds to the actual world in which
<em>not-p</em> holds, <em>R</em> does not. When <em>R</em> meets this
condition, Dretske says <em>R</em> is a conclusive reason for
believing <em>p</em>.</p>

<p>
Dretske pointed out (2003, n. 9; 2005, n. 4) that his view does not
face one of the objections which Saul Kripke (2011, 162&ndash;224; Dretske
had access to a draft circulated prior to publication) deploys against
Nozick&rsquo;s account. Suppose I am driving through a neighborhood in
which, unbeknownst to me, papier-m&acirc;ch&eacute; barns are
scattered, and I see that the object in front of me is a barn. I also
notice that it is red. Because I have barn-before-me percepts, I
believe <em>barn</em>: the object in front of me is a (ordinary) barn
(the example is attributed to Ginet in Goldman 1976). Our intuitions
suggest that I fail to know <em>barn</em>. And so say <b>BT</b> and
<b>CR</b>. But now suppose that the neighborhood has no fake
<em>red</em> barns; the only fake barns are blue. (Call this the red
barn case.) Then on Nozick&rsquo;s view I can track the fact that there is a
red barn, since I would not believe there was a red barn (via my
red-barn percepts) if no red barn were there, but I cannot track the
fact that there is a barn, since I might believe there was a barn (via
<em>blue</em>-barn percepts) even if no barn were there. Dretske said
that this juxtaposition, in which I know something yet fail to know a
second thing that is intimately related to the first (there being a
red barn, which I know, entails there being a barn, which I do not),
&ldquo;is an embarrassment,&rdquo; and in this respect, he thought,
his view is superior to Nozick&rsquo;s. Let <em>R</em>, my basis for belief,
be the fact that I have red-barn percepts. If no barn were there,
<em>R</em> would fail to hold, so I know a barn is there. Further, if
no <em>red</em> barn were there, <em>R</em> would still fail to hold,
so I know a <em>red</em> barn is there. So Dretske can avoid the
objectionable juxtaposition. Still, it is surprising that Dretske
cited the red barn case as the basis for preferring his version of
tracking over Nozick&rsquo;s. First, Dretske himself accepted juxtapositions
of knowledge and ignorance that are at least equally bizarre, as we
shall see. Second, Nozick avoided the very juxtaposition Dretske
discussed by restating his account to make reference to the methods
via which we come to believe things (Hawthorne 2005). On a more
polished version of his account, Nozick said that to know <em>p</em>
is, roughly, to have a belief <em>p</em>, arrived at through a method
<em>M</em>, which meets the following condition
(&lsquo;<b>BMT</b>&rsquo; for belief method tracking):</p>

<dl class="sentag tag4em">
<dt>(<b>BMT</b>)</dt>
<dd>were <em>p</em> false, <em>S</em> would not believe
<em>p</em> via <em>M</em>.</dd>
</dl>

<p>
If no red barn were there I would believe neither that there was a
barn, nor that there was a <em>red</em> barn, via red-barn percepts.
</p>

<p>
Third, the red barn case is one about which intuitions will vary. It
is not obvious that I <em>do</em> know there is a red barn in the
circumstances Dretske sketches, which differ from those in Ginet&rsquo;s
original barn case (where I fail to know <em>barn</em>) only in the
stipulations that I see a red barn and that none of the barn simulacra
are red. What is more, both Dretske&rsquo;s and Nozick&rsquo;s accounts have the
odd implication that I know there is a barn if I base my belief on my
red barn percepts yet I fail to know this if, in basing it on my barn
percepts, I ignore the barn&rsquo;s color. Presumably the barn&rsquo;s color is
not relevant to its being a barn. </p>

<p>
The tracking accounts permit counterexamples to <b>K</b>. Dretske&rsquo;s
well-known illustration is the zebra case (1970): suppose you are at a
zoo in ordinary circumstances standing in front of a cage marked
&lsquo;zebra&rsquo;; the animal in the cage is a zebra, and you
believe <em>zeb</em>, the animal in the cage is a zebra, because you
have zebra-in-a-cage visual percepts. It occurs to you that
<em>zeb</em> entails <em>not-mule</em>, it is not the case that the
animal in the cage is a cleverly disguised mule rather than a zebra.
You then believe <em>not-mule</em> by deducing it from <em>zeb</em>.
What do you know? You know <em>zeb</em>, since, if <em>zeb</em> were
false, you would not have zebra-in-a-cage visual percepts; instead,
you would have empty-cage percepts, or aardvark-in-a-cage percepts, or
the like. Do you know <em>not-mule</em>? If <em>not-mule</em> were
false, you would still have zebra-in-a-cage visual percepts (and you
would still believe <em>zeb</em>, and you would still believe
<em>not-mule</em> by deducing it from <em>zeb</em>). So you do
<em>not</em> know <em>not-mule</em>. But notice that we have:</p>

<ol type="a">

<li>You know <em>zeb</em></li>

<li>You believe <em>not-mule</em> by recognizing that <em>zeb</em>
entails <em>not-mule</em></li>

<li>You do not know <em>not-mule</em>.</li>
</ol>

<p>
In view of (a)&ndash;(c), we have a counterexample to <b>K</b>, which
entails that if (a) you know <em>zeb</em>, and (b) you believe
<em>not-mule</em> by recognizing that <em>zeb</em> entails
<em>not-mule</em>, then you <em>do</em> know <em>not-mule</em>,
contrary to (c).</p>

<p>
Having rejected <b>K</b>, and denying that we know things like
<em>not-mule</em>, Nozick also had to deny closure across
simplification. For if some proposition <em>p</em> entails another
proposition <em>q</em>, then <em>p</em> is equivalent to the
conjunction <em>p &amp; q</em>; accordingly, given closure across
equivalence, which Nozick accepted, if we know <em>zeb</em> we can
know the conjunction <em>zeb &amp; not-mule</em>, but if we also
accept closure across simplification, we will be able to know
<em>not-mule</em>. </p>

<p>
In response to this first version of the argument from the analysis of
knowledge, some theorists (e.g., Luper 1984, BonJour 1987, DeRose
1995) argued that <b>K</b> has great plausibility in its own right
(which Dretske acknowledged in 2005: 18) so it should be abandoned
only in the face of compelling reasons, yet there are no such
reasons.</p>

<p>
To show there are no compelling reasons to abandon <b>K</b>, theorists
have provided accounts of knowledge that (a) handle our intuitions at
least as successfully as the tracking analyses and yet (b) underwrite
<b>K</b>. One way to do this is to weaken the tracking analysis so
that we know things that we track or that we believe because we know
that they follow from things that we track (this sort of option has
been turned against Nozick by various theorists; Roush defends it in
2005, 41&ndash;51). Another approach is as follows. Knowing <em>p</em> is
roughly a matter of having a reason <em>R</em> for believing
<em>p</em> which meets the following condition
(&lsquo;<b>SI</b>&rsquo; for safe indication):</p>

<dl class="sentag tag4em">
<dt>(<b>SI</b>)</dt>
<dd>if <em>R</em> held, <em>p</em> would be true.</dd>
</dl>

<p>
<b>SI</b> requires that <em>p</em> be true in the nearby <em>R</em>
worlds. When <em>R</em> meets this condition, let us say that
<em>R</em> is a <em>safe indicator</em> that <em>p</em> is true.
(Different versions of the safety condition have been defended; see,
for example, Luper 1984; Sosa 1999, 2003, 2007, 2009; Williamson 2000;
and Pritchard 2007.) <b>SI</b> is the contraposition of <b>CR</b>, but
the contraposition of a subjunctive conditional is not equivalent to
the original.</p>

<p>
Let us suppose without argument that <b>SI</b> handles cases of
knowledge and ignorance as intuitively as <b>CR</b>. Why say <b>SI</b>
underwrites <b>K</b>? The key point is that if <b>R</b> safely
indicates that <em>p</em> is true, then it safely indicates that
<em>q</em> is true, where <em>q</em> is any of <em>p</em>&rsquo;s
consequences. Put another way, the point is that the following
reasoning is valid (being an instance of strengthening the
consequence):</p>

<ol>

<li>If <em>R</em> held, <em>p</em> would be true (i.e., <em>R</em>
safely indicates that <em>p</em>)</li>

<li><em>p</em> entails <em>q</em></li>

<li>So if <em>R</em> held, <em>q</em> would be true (i.e., <em>R</em>
safely indicates that <em>q</em>)</li>
</ol>

<p>
Hence, if a person <em>S</em> knows <em>p</em> on the basis of
<em>R</em>, <em>S</em> is in a position to know <em>q</em> on the
basis of <em>R</em>, where <em>q</em> follows from <em>p</em>.
<em>S</em> is also in a position to know <em>q</em> on the basis of
the conjunction of <em>R</em> together with the fact that <em>p</em>
entails <em>q</em>. Thus if <em>S</em> knows <em>p</em> on some basis
<em>R</em>, and believes <em>q</em> on the basis of <em>R</em> (on
which <em>p</em> rests) together with the fact that <em>p</em> entails
<em>q</em>, then <em>S</em> knows <em>q</em>. Again: if</p>

<ol type="a">

<li><em>S</em> knows <em>p</em> (on the basis of <em>R</em>), and</li>

<li><em>S</em> believes <em>q</em> by recognizing that <em>p</em>
entails <em>q</em> (so that <em>S</em> believe <em>q</em> on the basis
of <em>R</em>, on which <em>p</em> rests, together with the fact that
<em>p</em> entails <em>q</em>),</li>
</ol>

<p>
then</p>

<ol type="a" start="3">
<li><em>S</em> knows <em>q</em> (on the basis of <em>R</em> and the
fact that <em>p</em> entails <em>q</em>),</li>
</ol>

<p>
as <b>K</b> requires. To illustrate, let us use Dretske&rsquo;s example.
Having based your belief <em>zeb</em> on your zebra-in-the-cage
percepts, you know <em>zeb</em> according to <b>SI</b>: given your
circumstances, if you had those percepts, <em>zeb</em> would be true.
Moreover, when you believe <em>not-mule</em> by first believing
<em>zeb</em> on the basis of your zebra-in-the-cage percepts then
deducing <em>not-mule</em> from <em>zeb</em>, you know
<em>not-mule</em> according to <b>SI</b>: if you had those percepts
not only would <em>zeb</em> hold, so would its consequence
<em>not-mule</em>.</p>

<p>
Let us digress briefly in order to note that some versions of the
safety account will not uphold closure (Murphy 2005 presses this
objection against Sosa&rsquo;s version of the safety account). For example,
at one point Ernest Sosa discussed the following version of the
condition:</p>

<p class="indent">
If <em>S</em> were to believe <em>p</em>, <em>p</em> would be true.
</p>

<p>
This is to require that one&rsquo;s <em>belief</em> safely indicates its own
truth. However, it is entirely possible to be so situated that one&rsquo;s
belief safely indicates its truth even though the requisite condition
is not met for something that follows from that belief. The point can
be illustrated with a version of the red barn case. Suppose that (on
the basis of my red-barn percepts) I believe <em>red barn</em>: there
is a red barn in front of me. Suppose, too, that there is indeed a red
barn there. However (you guessed it) many fake barns are scattered
through the neighborhood, all of which are blue, not red. In the close
worlds in which I believe <em>red barn</em>, I am correct, so I meet
the requisite condition for knowing <em>red barn</em>, which is that
my believing <em>red barn</em> safely indicates its own truth. Now,
<em>red barn</em> entails <em>barn</em>: there is a barn in front of
me. But, according to the view on offer, the requisite condition for
knowing <em>barn</em> is not that my belief <em>red barn</em> safely
indicates that <em>barn</em> holds. What is required instead is that
my belief <em>barn</em> safely indicates its <em>own</em> truth.
Assuming that I would believe <em>barn</em> if I saw one of the blue
fakes, then my belief <em>barn</em> does not safely indicate its
truth.</p>

<p>
To pick up the thread again: now, <b>K</b> fails if knowledge entails
<b>CR</b> but not if knowledge entails <b>SI</b>, but it may not be
possible to underwrite <b>K</b> merely by replacing <b>CR</b> with
<b>SI</b>, since some other condition for knowledge might block
closure. We can underwrite closure if we assume that believing
<em>p</em> on &ldquo;safe&rdquo; grounds is <em>sufficient</em> for
knowing <em>p</em>, but this assumption is dubious. As we have
understood safety, we can believe things on safe grounds without
knowing them. An obvious example is any necessary truth: because it
holds in all possible worlds we can safely believe it for any reason.
For another example, recall the red barn case discussed earlier:
despite the many fake blue barns in the neighborhood, my red-barn
percepts are safe indicators that the object in front of me is a barn
and that it is a red barn, so no objectionable <em>juxtaposition</em>
(such as I know <em>there is a red barn</em> but not <em>there is a
barn</em>) occurs, but some theorists will insist that, in the
circumstances sketched, I know <em>neither</em> that the object is a
barn nor that it is a red barn. </p>

<h3><a name="CloFaiRelAltApp">2.2 Closure Fails on a Relevant Alternatives Approach</a></h3>

<p>
The second version of the argument from the analysis of knowledge has
it that any relevant alternatives view, not just tracking accounts, is
in tension with <b>K</b>. An analysis is a relevant alternatives
account when it meets two conditions. First, it yields an appropriate
understanding of &lsquo;relevant alternative.&rsquo; Dretske&rsquo;s
approach qualifies since it allows us to say that an alternative
<em>A</em> to <em>p</em> is relevant if and only if:</p>

<dl class="sentag tag4em">
<dt>(<b>CRA</b>)</dt>
<dd>were <em>p</em> false, <em>A</em> might hold.</dd>
</dl>

<p>
According to the second condition, the analysis must say that knowing
<em>p</em> requires ruling out all <em>relevant</em> alternatives to
<em>p</em> but not all <em>alternatives</em> to <em>p</em>. Dretske&rsquo;s
approach qualifies once again. It says an alternative <em>A</em> is
ruled out on the basis of <em>R</em> if and only if the following
condition is met:</p>

<dl class="sentag tag4em">
<dt>(<b>CRR</b>)</dt>
<dd>were <em>A</em> to hold <em>R</em> would not hold.</dd>
</dl>

<p>
And, on Dretske&rsquo;s approach, an alternative <em>A</em> must be ruled
out if and only if <em>A</em> meets <b>CRA</b>.</p>

<p>
So the tracking account is a relevant alternatives approach. But why
say that relevant alternatives accounts of knowledge are in tension
with <b>K</b>? We will say this if, like Dretske, we accept the
following crucial tenet: the negation of a proposition <em>p</em> is
automatically a relevant alternative to <em>p</em> (no matter how
bizarre or remote <em>not-p</em> might be) but often <em>not</em> a
relevant alternative to things that imply <em>p</em>. For a relevant
alternatives theorist, this tenet suggests that we can know something
<em>p</em> only if we can rule out <em>not-p</em> but we can know
things that entail <em>p</em> even if we cannot rule out
<em>not-p</em>, which opens up the possibility that there are cases
that violate <b>K</b>. For while our inability to rule out
<em>not-p</em> stops us from knowing <em>p</em> it does not stop us
from knowing things that entail <em>p</em>. And an example is ready to
hand: the zebra case. Perhaps you cannot rule out <em>mule</em>; but
that stops you from knowing <em>not-mule</em> without stopping you
from knowing <em>zeb</em>. These points can be restated in terms of
the conclusive reasons account. For Dretske, the negation of a
proposition <em>p</em> is automatically a relevant alternative since
condition <b>CRA</b> is automatically met; that is, it is vacuously
true that:</p>

<p class="indent">
were <em>p</em> false, <em>not-p</em> might hold.</p>

<p>
Therefore <em>mule</em> is a relevant alternative to
<em>not-mule</em>. Furthermore, you fail to know <em>not-mule</em>
since you cannot rule out <em>mule</em>: you believe <em>not-mule</em>
on the basis of your zebra-in-the-cage percepts, but you would still
have these if <em>mule</em> held, contrary to <b>CRR</b>. Yet you know
<em>zeb</em> in spite of your inability to rule out <em>mule</em>, for
were <em>zeb</em> false you would not have your zebra-in-the-cage
percepts.</p>

<p>
According to the second version of the argument from the analysis of
knowledge any relevant alternatives view is in tension with <b>K</b>.
How compelling is this argument? As Dretske acknowledged (2003), it is
actually a weak challenge to <b>K</b> since some relevant alternatives
accounts are fully consistent with <b>K</b>. For an example, we have
only to adapt the safe indication view so as to make it clear that it
is a relevant alternatives account (Luper 1984, 1987c, 2006).</p>

<p>
The safe indication view can be adapted in two steps. First, we say
that an alternative to <em>p</em>, <em>A</em>, is relevant if and only
if the following condition is met:</p>

<dl class="sentag tag4em">
<dt>(<b>SRA</b>)</dt>
<dd>In <em>S</em>&rsquo;s circumstances, <em>A</em> might hold.</dd>
</dl>

<p>
Thus any possibility that is remote is automatically irrelevant,
failing <b>SRA</b>. Second, we say that <em>A</em> is ruled out on the
basis of <em>R</em> if and only if the following condition is met:</p>

<dl class="sentag tag4em">
<dt>(<b>SIR</b>)</dt>
<dd>were <em>R</em> to hold <em>A</em> would not hold.</dd>
</dl>

<p>
This way of understanding relevant alternatives upholds <b>K</b>. The
key point is that if <em>S</em> knows <em>p</em> on the basis of
<em>R</em>, and is thus able to rule out <em>p</em>&rsquo;s relevant
alternatives, then <em>S</em> can also rule out <em>q</em>&rsquo;s relevant
alternatives, where <em>q</em> is anything <em>p</em> implies. If
<em>R</em> were to hold, <em>q</em>&rsquo;s alternatives would not.</p>

<p>
Apparently, the relevant alternatives account can be construed in a
way that supports <b>K</b> as well as a way that does not. Hence
Dretske is not well positioned to claim that the relevant alternatives
view leads &ldquo;naturally&rdquo; to closure failure.</p>

<h3><a name="CloRel">2.3 Closure and Reliabilism</a></h3>

<p>
On one version of reliabilism (defended by Ramsey 1931 and Armstrong
1973, among others) one knows <em>p</em> if and only if one arrives at
(or sustains) the belief <em>p</em> via a reliable method. Is the
reliabilist committed to <em>K</em>? The answer depends on precisely
how the relevant notion of reliability is understood. If we understand
reliability as tracking theorists do, we will reject closure. But
there are other versions of reliabilism which sustain <em>K</em>. For
example, the safe indication account is a type of reliabilism. Also,
we could say that a true belief <em>p</em> is reliably formed if and
only if based on an event that <em>usually</em> would occur only if
<em>p</em> (or a <em>p</em>-type belief) were true. Any event that, in
this sense, reliably indicates that <em>p</em> is true will also
reliably indicate that <em>p</em>&rsquo;s consequences are true.</p>

<h2><a name="ArgNonKnoMod">3. The Argument From Nonclosure of Knowledge Modes</a></h2>

<p>
Dretske argued (2003, 2005) that we should expect <b>K</b> failure
because none of the modes of gaining, preserving or extending
knowledge are individually closed. Dretske made his point in the form
of a rhetorical question: &ldquo;how is one supposed to get closure on
something when every way of getting, extending and preserving it is
open (2003: 113&ndash;4)?&rdquo;</p>

<h3><a name="KnoModNon">3.1 Knowledge Modes and Nonclosure</a></h3>

<p>
As examples of modes of gaining, sustaining and extending knowledge
Dretske suggested perception, testimony, proof, memory, indication,
and information. To say of these items that they are not individually
closed is to say that the following modes closure principles, with or
without the parenthetical qualifications, are false:</p>

<dl class="sentag tag4em">
<dt>(<b>PC</b>)</dt>
<dd>If <em>S</em> <em>perceives</em> <em>p</em>, and (<em>S</em>
believes <em>q</em> because <em>S</em> knows) <em>p</em>
entails <em>q</em>, then <em>S</em> perceives <em>q</em>.</dd>

<dt>(<b>TC</b>)</dt>
<dd>If <em>S</em> has <em>received testimony</em> that
<em>p</em>, and (<em>S</em> believes <em>q</em> because <em>S</em>
knows) <em>p</em> entails <em>q</em>, then <em>S</em> has received
testimony that <em>q</em>.</dd>

<dt>(<b>OC</b>)</dt>
<dd>If <em>S</em> has <em>proven</em> <em>p</em>, and (<em>S</em>
believes <em>q</em> because <em>S</em> knows) <em>p</em>
entails <em>q</em>, then <em>S</em> has proven <em>q</em>.</dd>

<dt>(<b>RC</b>)</dt>
<dd>If <em>S</em> <em>remembers</em> <em>p</em>, and
(<em>S</em> believes <em>q</em> because <em>S</em> knows) <em>p</em>
entails <em>q</em>, then <em>S</em> remembers <em>q</em>.</dd>

<dt>(<b>IC</b>)</dt>
<dd>If <em>R</em> <em>indicates</em> <em>p</em>, and
(<em>S</em> believes <em>q</em> because <em>S</em> knows) <em>p</em>
entails <em>q</em>, then <em>R</em> indicates <em>q</em>.</dd>

<dt>(<b>NC</b>)</dt>
<dd>If <em>R</em> <em>carries the information</em> <em>p</em>, and
(<em>S</em> believes <em>q</em> because <em>S</em> knows)
<em>p</em> entails <em>q</em>, then <em>R</em> carries the information
<em>q</em>.</dd>
</dl>

<p>
And, according to Dretske, each of these principles fails. We may
perceive that we have hands, for example, without perceiving that
there are physical things.</p>

<h3><a name="ResDre">3.2 Responses to Dretske</a></h3>

<p>
There have been various rejoinders to Dretske&rsquo;s argument from
nonclosure of knowledge modes.</p>

<p>
First, failure of one or more of the modes closure principles does not
imply that <b>K</b> fails. What matters is whether the various modes
of knowledge Dretske discusses position us to know the consequences of
the things we know. In other words, the issue is whether the following
principle is true:</p>

<dl class="sentag tag4em">
<dt>(<b>T</b>)</dt>
<dd>If, while knowing <em>p</em> via perception, testimony, proof,
memory, or something that indicates or carries the information
that <em>p</em>, <em>S</em> believes <em>q</em> because <em>p</em>
entails <em>q</em>, then <em>S</em> knows <em>q</em>.</dd>
</dl>

<p>
Second, theorists have defended some of these modes closure
principles, such as <b>PC</b>, <b>IC</b> and <b>NC</b>. Dretske
rejects these three principles because he thinks perception,
indication and information are best analyzed in terms of conclusive
reasons, which undermines closure. But the three principles (or
something very much like them) may be defended if we analyze
perception, indication and information in terms of safe indication.
Consider <b>IC</b> and <b>NC</b>. Both are true if we analyze
indication and information as follows:</p>

<p class="indent">
<em>R</em> indicates <em>p</em> iff <em>p</em> would be true if
<em>R</em> held.</p>

<p class="indent">
<em>R</em> carries the information that <em>p</em> iff <em>p</em>
would be true if <em>R</em> held.</p>

<p>
A version of <b>PC</b> may be defended if we make use of Dretske&rsquo;s own
notion of indirect perception (1969). Consider a scientist who studies
the behavior of electrons by watching bubbles they leave behind in a
cloud chamber. The electrons themselves are invisible, but the
scientist can perceive <em>that</em> the (invisible) electrons are
moving in certain ways <em>by</em> perceiving that the (visible)
bubbles left behind are arranging themselves in specific ways. What we
directly perceive positions us to perceive various things indirectly.
Now assume that when we directly or indirectly perceive <em>p</em>,
and this causes us to believe <em>q</em>, where <em>p</em> entails
<em>q</em>, we are positioned to perceive <em>q</em> indirectly. Then
we are well on our way to accepting some version of <b>PC</b>, such
as, for example:</p>

<dl class="sentag tag4em">
<dt>(<b>SPC</b>)</dt>
<dd>If <em>S</em> perceives <em>p</em>, and this causes
<em>S</em> to believe <em>q</em>, then <em>S</em> perceives
<em>q</em>.</dd>
</dl>

<h2><a name="ArgNotEasKnoPro">4. The Argument From Not (Easily) Knowable Propositions</a></h2>

<p>
Another anticlosure argument is that there are some sorts of
propositions we cannot know unless perhaps we take extraordinary
measures, yet such propositions are entailed by mundane claims whose
truth we do know. Since this would be impossible if <b>K</b> were
correct, <b>K</b> must be false. The same difficulty is sometimes
discussed under the heading <em>problem of easy knowledge</em>, since
some theorists (Cohen 2002) believe that certain things are difficult
to know, in the sense that they cannot be known by deduction from
banal knowledge. The argument has different versions depending on
which propositions are said to be hard knowledge. According to Dretske
(and perhaps Nozick as well), we cannot easily know that <em>limiting
propositions</em> or <em>heavyweight propositions</em> are true. These
resemble propositions Moore (1959) considered certainly true and that
Wittgenstein (1969) declared to be unknowable (but Wittgenstein
considered them unknowable on the dubious grounds that they must be
true if we are to entertain doubts). Another possibility is that we
cannot easily know <em>lottery propositions</em>. A special case of
the argument from unknowable propositions starts with the claim that
we cannot know the falsity of skeptical hypotheses. We will consider
this third view in the next section.</p>

<h3><a name="ArgLimPro">4.1 The Argument from Limiting Propositions</a></h3>

<p>
Dretske did not clearly delineate the class of propositions he called
&ldquo;limiting&rdquo; (in 2003) or &ldquo;heavyweight&rdquo; (in
2005). Some of the examples he provided are &ldquo;There is a
past,&rdquo; &ldquo;There are physical objects,&rdquo; and &ldquo;I am
not being fooled by a clever deception.&rdquo; He appeared to think
that these propositions have a property we may call
&ldquo;elusiveness,&rdquo; where <em>p</em> is elusive for me if and
only if <em>p</em>&rsquo;s falsity would not change my experiences. But
being limiting does not coincide with being elusive. If there were no
physical objects, my experiences would be changed dramatically, since
I would not exist. So some limiting propositions are not elusive. As
to whether all elusive claims are limiting, it is hard to say, because
of the squishiness of the term &ldquo;limiting&rdquo;.
<em>Not-mule</em> is elusive, but is it limiting?</p>

<p>
Can&rsquo;t we know limiting propositions? If not, and if we do know things
that entail them, Dretske thought he had further support for his
conclusive reasons view, assuming, as he did, that his view rules out
our knowing limiting propositions (while allowing knowledge of things
that entail them). However, this assumption is false (Hawthorne 2005,
Luper 2006). We do have conclusive reason to believe some limiting
propositions, such as that there are physical objects. Still, Dretske
might abandon the notion of a limiting proposition in favor of the
notion of elusive propositions, and cite, in favor of his conclusive
reasons view, and against <b>K</b>, the facts that we cannot know
elusive claims but we can know things that imply them.</p>

<p>
In order to rule out knowledge of limiting/elusive propositions,
Dretske offered two sorts of argument, which we may call the
<em>argument from perception</em> and the <em>argument from
pseudocircularity</em>.</p>

<p>
The argument from perception starts with the claims that (a) we do not
perceive that limiting/elusive claims hold and (b) we do not know, via
perception, that limiting/elusive claims hold. Since it is hard to see
how else we could know limiting/elusive propositions, (a) and (b) are
good grounds for concluding that we just do not know that they
hold.</p>

<p>
There is no doubt that (a) and (b) have considerable plausibility.
Nonetheless, they are controversial. To explain the truth of (a) and
(b), Dretske counted on his conclusive reasons analysis of perception.
His critics may cite the safe indication account of perception as the
basis for rejecting (a) and (b). Luper (2006), for example, argues
against both, chiefly on the grounds that we can perceive and know
some elusive claims (such as <em>not-mule</em>) indirectly, by
directly perceiving claims (such as <em>zeb</em>) that entail
them.</p>

<p>
Dretske suggested another reason for ruling out knowledge of
limiting/elusive claims. He thought we can know banal facts (e.g., we
ate breakfast) without knowing limiting/elusive claims they entail
(e.g., the past is real) <em>so long as</em> those limiting/elusive
claims are <em>true</em>, but we cannot then turn around and employ
the former as our basis for knowing the latter. Suppose we take
ourselves to know some claim, <em>q</em>, by inferring it from another
claim, <em>p</em>, which we know, but our knowing <em>p</em> in the
first place depends on the truth of <em>q</em>. Call this
<em>pseudocircular reasoning</em>. According to Dretske,
pseudocircular reasoning is unacceptable, and yet it is precisely what
we rely on when we attempt to know limiting/elusive claims such as
denials of skeptical hypotheses by deducing them from ordinary
knowledge claims that entail them: we will not know the latter in the
first place unless the former are true. The problem Dretske here
raised was pressed earlier by critics of broadly reliabilist accounts
of knowledge, such as Richard Fumerton (1995, 178). Jonathan Vogel
(2000) discusses it under the heading <em>bootstrapping</em>, the
procedure employed when, e.g., someone who has no initial evidence
about the reliability of a gas gauge, comes to believe <em>p</em> on
several different occasions because the gauge indicates <em>p</em>,
and thereby knows <em>p</em> according to reliabilist accounts of
knowledge, then infers that the gauge is reliable, by induction. By
bootstrapping we may move&mdash;illegitimately, according to
Vogel&mdash;from beliefs formed through a reliable process to the
knowledge that those beliefs were arrived at through a reliable
process. One may know <em>p</em> using a gauge in the first instance
only if that gauge is reliable; hence, to conclude it is reliable
solely on the basis of its track record involves pseudocircular
reasoning.</p>

<p>
Theorists have long objected to knowledge claims whose truth depends
on a fact that itself has not been established, especially if that
fact is merely taken for granted. It is also standard to reject any
knowledge claim whose pedigree smacks of circularity. Both worries
arise if we claim to know that one proposition, <em>q</em>, is true on
the grounds that it is entailed by a second proposition, <em>p</em>,
even though the truth of <em>q</em> was taken for granted in coming to
know that <em>p</em> is true. Many theorists will reject
pseudocircular reasoning on precisely these traditional grounds.
Dretske did not share the first worry but he did raise the second, the
concern about pseudocircular reasoning. But there is a growing body of
work that breaks with tradition and defends some forms of epistemic
circularity (this work is heavily criticized, in turn, on the grounds
that it is open to versions of traditional objections). Max Black
(1949) and Nelson Goodman (1955) were early examples; others include
Van Cleve 1979 and 2003; Luper 2004; Papineau 1992; and Alston 1993.
Dretske himself meant to break with tradition, writing under the
banner of &lsquo;externalism.&rsquo; He explicitly said that most, if
not all, of our mundane knowledge claims depend on facts we have not
established. Indeed, he cited this as a virtue of his conclusive
reasons view. Yet nothing in the nature of the conclusive reasons
account rules out our knowing limiting propositions using
pseudocircular reasoning, which leaves his reservations mysterious. A
set of jar-ish experiences can constitute a conclusive reason for
believing <em>jar</em>, a jar of cookies is in front of me. If I then
believe <em>objects</em>, there are physical objects, because it is
entailed by <em>jar</em>, I have conclusive reason for believing
<em>objects</em>, a limiting proposition. (If <em>objects</em> were
false, <em>jar</em> would be too, and I would lack my jar-ish
experiences.)</p>

<p>
Dretske might have fallen back on the view that the conclusive reasons
account rules out knowing elusive, as opposed to limiting, claims
through pseudocircular reasoning, because we lack conclusive reasons
for elusive claims no matter what sort of reasoning we employ. But
this does not put Dretske&rsquo;s account at odds with pseudocircular
reasoning. And even this more limited position can be challenged
(adapting a charge against Nozick in Shatz 1987). We might insist that
<em>p</em> itself is a conclusive reason for believing <em>q</em> when
we know <em>p</em> and <em>p</em> entails <em>q</em>. After all,
assuming <em>p</em> entails <em>q</em>, if <em>q</em> were false so
would <em>p</em> be. On this strategy we have a further argument for
<b>K</b>: if <em>S</em> knows <em>p</em> (relying on some conclusive
reason <em>R</em>), and <em>S</em> believes <em>q</em> because
<em>S</em> knows <em>p</em> entails <em>q</em>, <em>S</em> has a
conclusive reason for believing <em>q</em>, namely <em>p</em> (rather
than <em>R</em>), and hence <em>S</em> knows <em>q</em>.</p>

<p>
Another doubt about knowing elusive claims deductively via mundane
claims is that this maneuver is improperly ampliative. Cohen claims
that knowing the table is red does not position us to know &ldquo;I am
not a brain-in-a-vat being deceived into believing that the table is
red&rdquo; nor &ldquo;it&rsquo;s not the case that the table is white [but]
illuminated by red lights&rdquo; (2002: 313). In the transition from
the former to the latter, our knowledge appears to have been amplified
improperly. This concern may be due at least in large part to lack of
precision in the application of entailment or deductive implication
(Klein 2004). Let <em>red</em> be the proposition that the table is
red, <em>white</em> the proposition that the table is white, and
<em>light</em> the proposition that the table is being illuminated by
a red light. <em>Red</em> does not entail anything about the
conditions under which the table is illuminated. In particular it does
not entail the conjunction, <em>light &amp; not-white</em>. The most
we can infer is that the conjunction, <em>white &amp; light</em>, is
false, and that gives us no information whatever about the lighting
conditions of the table. One could as easily infer the falsity of the
conjunction, <em>white</em> <em>&amp;</em> <em>not-light</em>. No
amplification of the original known proposition, <em>red</em>, has
come about.</p>

<h3><a name="ArgLotPro">4.2 The Argument from Lottery Propositions</a></h3>

<p>
It seems apparent that I do not know <em>not-win</em>, I will not win
the state lottery tonight, even though my odds for hitting it big are
vanishingly small. But suppose my heart&rsquo;s desire is to own a 10
million dollar villa in the French Riviera. It seems plausible to say
that I know <em>not-buy</em>, I will not buy that villa tomorrow,
since I lack the means, and that I know the conditional, if
<em>win</em> then <em>buy</em>, i.e., tomorrow I will buy the villa if
I win the state lottery tonight. From the conditional and
<em>not-buy</em> it follows that <em>not-win</em>, so, given closure,
knowing the conditional and <em>not-buy</em> positions me to know
<em>not-win</em>. As this reasoning shows, the unknowability of claims
like <em>not-win</em> together with the knowability of claims like
<em>not-buy</em> position us to launch another challenge to
closure.</p>

<p>
Let a <em>lottery proposition</em> be a proposition, like
<em>not-win</em>, that (at least normally) is supportable only on the
grounds that its probability is very high but less than 1. Vogel
(1990, 2004) and Hawthorne (2004, 2005) have noted that a great number
of propositions that do not actually involve lotteries resemble
lottery propositions in that they can be given a probability that is
close to but less than 1. Such propositions might be described as
<em>lotteryesque</em>. The events mentioned in a claim can be subsumed
under indefinitely many reference classes, and there is no
authoritative way to choose which among these determines the
probability of the subsumed events. By carefully selecting among these
classes we can often find ways to suggest that the probability of a
claim is less than 1. Take, for example, <em>not-stolen</em>, the
proposition that the car you just parked in front of the house has not
been stolen: by selecting the class, <em>red cars stolen from in front
of your house in the last hour</em>, we can portray the statistical
probability of <em>not-stolen</em> as 1. But by selecting, <em>cars
stolen in the U.S.</em>, we can portray the probability as
significantly less than 1. If, like lottery propositions, lotteryesque
propositions are not easily known, they increase the pressure on the
closure principle, since they are entailed by a wide range of mundane
propositions which become unknowable, given closure.</p>

<p>
How great a threat to <b>K</b> (and <b>GK</b>) are lottery and
lotteryesque propositions? The matter is somewhat controversial.
However, there is a great deal to be said for treating lottery
propositions one way and lotteryesque propositions another.</p>

<p>
As for lottery propositions: several theorists suggest that we do not
in fact know that they are true because knowing them requires
believing them because of something that <em>establishes</em> their
truth, and we (normally) cannot establish the truth of lottery
propositions. There are various ways to understand what is meant by
&ldquo;establishing&rdquo; the truth of a claim. Dretske, as we have
seen, thinks that knowledge entails having a conclusive reason for
thinking as we do. David Armstrong (1973, p. 187) said that knowledge
entails having a belief state that &ldquo;ensures&rdquo; truth. Safe
indication theorists suggest that we know things when we believe them
because of something that safely indicates their truth. And Harman and
Sherman (2004, p. 492) say that knowledge requires believing as we do
because of something &ldquo;that settles the truth of that
belief.&rdquo; On all four views, we fail to know that a claim is true
when our only grounds for believing it is that it is highly likely.
However, the unknowability of lottery propositions is not a
substantial threat to closure, since it is not obvious that there are
propositions that are both known to be true and that entail lottery
propositions. Consider the example discussed earlier: the conditional
if <em>win</em> then <em>buy</em> together with <em>not-buy</em>. If I
know these, then, by <b>GK</b>, I know <em>not-win</em>, a lottery
proposition. But it is quite plausible to deny that I do know these.
After all, I might win the lottery.</p>

<p>
Now consider lotteryesque propositions. We cannot defend closure by
denying that we know any mundane proposition that entails a
lotteryesque proposition since it is clear that we know that many
things are true that entail lotteryesque propositions. To defend
closure we must instead say that lotteryesque propositions are
knowable. They differ from genuine lottery propositions in that they
may be supportable on grounds that establish their truth. If I base my
belief <em>not-stolen</em> solely on crime statistics, I will fail to
know that it is true. But I can instead base it on observations, such
as having just parked it in my garage, and so forth, that, under the
circumstances, establish that <em>not-stolen</em> holds.</p>

<h2><a name="ArgSke">5. The Argument From Skepticism</a></h2>

<p>
According to Dretske and Nozick, we can account for the appeal of
skepticism and explain where it goes wrong if we accept their view of
knowledge and reject <b>K</b>. Rejecting knowledge closure is
therefore the key to resolving skepticism. Given the importance of
insight into the problem of skepticism, they would seem to have a good
case for denying closure. Let us consider the story they present, and
some worries about its acceptability.</p>

<h3><a name="SkeAnt">5.1 Skepticism and Antiskepticism</a></h3>

<p>
Dretske and Nozick focused on a form of skepticism that combines
<b>K</b> with the assumption that we do not know that skeptical
hypotheses are false. For example, I do not know
<em>not</em>-<em>biv</em>: I am not a brain in a vat on a planet far
from earth being deceiving by alien scientists. On the strength of
these assumptions, skeptics argue that we do not know all sorts of
commonsense claims that entail the falsity of skeptical hypotheses.
For example, since <em>not</em>-<em>biv</em> is entailed by
<em>h</em>, I am in San Antonio, skeptics may argue as follows:</p>

<dl class="sentag tag4em">
<dt>(1)</dt>
<dd><b>K</b> is true; i.e., if, while knowing <em>p</em>, <em>S</em>
believes <em>q</em> because <em>S</em> knows that <em>p</em> entails
<em>q</em>, then <em>S</em> knows <em>q</em>.</dd>

<dt>(2)</dt>
<dd><em>h</em> entails <em>not-biv</em>.</dd>

<dt>(3)</dt>
<dd>So if I know <em>h</em> and I believe <em>not-biv</em> because I
know it is entailed by <em>h</em> then I
know <em>not-biv</em>.</dd>

<dt>(4)</dt>
<dd>But I do not know <em>not-biv</em>.</dd>

<dt>(5)</dt>
<dd>Hence I do not know <em>h</em>.</dd>
</dl>

<p>
Dretske and Nozick were well aware that this argument can be turned on
its head, as follows:</p>

<dl class="sentag tag4em">

<dt>(1)</dt>
<dd><b>K</b> is true; i.e., if, while knowing <em>p</em>, <em>S</em>
believes <em>q</em> because <em>S</em> knows that <em>p</em> entails
<em>q</em>, then <em>S</em> knows <em>q</em>.</dd>

<dt>(2)</dt>
<dd><em>h</em> entails <em>not-biv</em>.</dd>

<dt>(3)</dt>
<dd>So if I know <em>h</em> and I believe <em>not-biv</em> because I
know it is entailed by <em>h</em> then I
know <em>not-biv</em>.</dd>

<dt>(4)&prime;</dt>
<dd>I do know <em>h</em>.</dd>

<dt>(5)&prime;</dt>
<dd>Hence I do know <em>not-biv</em>.</dd>
</dl>

<p>
Turning tables on the skeptic in this way was roughly Moore&rsquo;s (1959)
antiskeptical strategy. (Tendentiously, some writers now call this
strategy <em>dogmatism</em>). However, instead of <b>K</b>, Moore
presupposed the truth of a stronger principle:</p>

<dl class="sentag tag4em">
<dt>(<b>PK</b>)</dt>
<dd>If, while knowing <em>p</em>, <em>S</em> believes
<em>q</em> because <em>S</em> knows that <em>q</em> is entailed by
<em>S</em>&rsquo;s knowing <em>p</em>, then <em>S</em> knows <em>q</em>.</dd>
</dl>

<p>
Unlike <b>K</b>, <b>PK</b> underwrites Moore&rsquo;s famous argument: Moore
knows he is standing; his knowing that he is standing entails that he
is not dreaming; therefore, he knows (or rather is in a position to
know) that he is not dreaming.</p>

<h3><a name="TraSke">5.2 Tracking and Skepticism</a></h3>

<p>
According to Dretske and Nozick, skepticism is appealing because
skeptics are partially right. They are correct when they say that we
do not know that skeptical hypotheses fail to hold. For I do not track
<em>not</em>-<em>biv</em>: if <em>biv</em> were true, I would still
have the experiences that lead me to believe that <em>biv</em> is
false. Something similar can be said about antiskepticism:
antiskeptics are correct when they say we know all sorts of
commonsense claims that entail the falsity of skeptical hypotheses.
Having gotten this far, however, skeptics appeal to K, and argue that
since I would know <em>not-biv</em> if I knew <em>h</em>, then I must
not know <em>h</em> after all, while Moore-style antiskeptics appeal
to <b>K</b> in order to conclude that I do know <em>not-biv</em>. But
this is precisely where skeptics and antiskeptics alike go wrong, for
<b>K</b> is false. Consider the position skeptics are in. Having
accepted the tracking view&mdash;as they do when they deny that we
know skeptical hypotheses are false&mdash;skeptics cannot appeal to
the principle of closure, which is false on the tracking theory. We
track (hence know) the truth of ordinary knowledge claims yet fail to
track (or know) the truth of things that follow, such as that
incompatible skeptical hypotheses are false.</p>

<p>
One shortcoming of this story is that it cannot come to terms with all
types of skepticism. There are two main forms of skepticism (and
various sub-categories): regress (or Pyrrhonian) skepticism, and
indiscernability (Cartesian) skepticism. At best, Dretske and Nozick
have provided a way of dealing with the latter.</p>

<p>
Another worry about Dretske&rsquo;s and Nozick&rsquo;s response to Cartesian
skepticism is that it forces us to give up <b>K</b> (as well as
<b>GK</b>, and closure across instantiation and simplification). Given
the intuitive appeal of these principles, some theorists have looked
for alternative ways of explaining skepticism, which they then offer
as superior in part on the grounds that they do no violence to
<b>K</b>. Consider two possibilities, one offered by advocates of the
safe indication theory, and one by contextualists.</p>

<h3><a name="SafIndSke">5.3 Safe Indication and Skepticism</a></h3>

<p>
Advocates of the safe indication theory accept the gist of the
tracking theorist explanation of the appeal of skepticism but retain
the principle of closure. One reason skepticism tempts us is that we
tend to confuse <b>CR</b> with <b>SI</b> (Sosa 1999, Luper 1984,
1987c, 2003a). After all, <b>CR</b>&mdash;if <em>p</em> were false,
<em>R</em> would not hold&mdash;closely resembles
<b>SI</b>&mdash;<em>R</em> would hold only if <em>p</em> were true.
When we run the two together, we sometimes apply <b>CR</b> and
conclude that we do not know that skeptical scenarios do not hold.
Then we shift back to the safe indication account, and go along with
skeptics when they appeal to the principle of entailment, which is
sustained by the safe indication account, and conclude that ordinary
knowledge claims are false. But, as Moore claimed, skeptics are wrong
when they say we do not know that skeptical hypotheses are false.
Roughly, we know skeptical possibilities do not hold since (given our
circumstances) they are remote.</p>

<p>
Skepticism might also result from the assumption that, if a belief
formation method <em>M</em> were, in some situation, to yield a belief
without enabling us to know the truth of that belief, then it cannot
ever generate bona fide knowledge (of that sort of belief), no matter
what circumstances it is used in. (<em>M</em> must be strengthened
somehow, say with a supplemental method, or with evidence about the
circumstances at hand, if knowledge is to be procured.) This
assumption might rest on the idea that any belief <em>M</em> yields
is, at best, accidentally correct, if in any circumstances <em>M</em>
yields a false or an accidentally correct belief (Luper 1987b,c). On
this assumption, we can rule out a method of belief formation
<em>M</em> as a source of knowledge merely by sketching circumstances
in which <em>M</em> yields a belief that is false or accidentally
correct. Traditional skeptical scenarios suffice; so do Gettieresque
situations. Externalist theorists reject the assumption, saying that
<em>M</em> can generate knowledge when used in circumstances under
which the belief it yields is not accidentally correct. In highly
Gettierized circumstances <em>M</em> must put us in an especially
strong epistemic position if <em>M</em> is to generate knowledge; in
ordinary circumstances, less exacting methods can produce knowledge.
The standards a method must meet to produce knowledge depend on the
context in which it is used. This view, on which the requirements for
a subject or agent <em>S</em> to know <em>p</em> vary with
<em>S</em>&rsquo;s context (e.g., how exacting <em>S</em>&rsquo;s method of belief
formation must be to yield knowledge depend on <em>S</em>&rsquo;s
circumstances), might be called <em>agent-centered</em> (or
<em>subject</em>) <em>contextualism</em>. Both tracking theorists and
safe indication theorists defend agent-centered contextualism.</p>

<h3><a name="ConSke">5.4 Contextualism and Skepticism</a></h3>

<p>
Theorists writing under the label &ldquo;contextualism,&rdquo; such as
David Lewis (1979, 1996), Stewart Cohen (1988, 1999), and Keith DeRose
(1995), offer a related way of explaining skepticism without denying
closure. For clarity, we might call them <em>speaker</em>-centered (or
<em>attributor</em>) contextualists since they contrast their view
with agent-centered contextualism. According to (speaker-centered)
contextualists, whether it is correct for a <em>judge</em> to
attribute knowledge to someone depends on that <em>judge&rsquo;s</em>
context, and the standards for knowledge differ from context to
context. When the man on the street judges knowledge, the applicable
standards are relatively modest. But an epistemologist takes all sorts
of possibilities seriously that are ignored by ordinary folk, and so
must apply quite stringent standards in order to reach correct
assessments. What passes for knowledge in ordinary contexts does not
qualify for knowledge in contexts where heightened criteria apply.
Skepticism is explained by the fact that the contextual variation of
epistemic standards is easily overlooked. Skeptics note that in the
epistemic context it is inappropriate to grant anyone knowledge.
However, skeptics assume&mdash;falsely&mdash;that what goes in the
epistemic context goes in all contexts. They assume that since those
who take skepticism seriously must deny anyone knowledge, then
everyone, regardless of context, should deny anyone knowledge. Yet
people in ordinary contexts are perfectly correct in claiming that
they know all sorts of things.</p>

<p>
Furthermore, the closure principle is correct, contextualists say, so
long as it is understood to operate within given contexts, not across
contexts. That is, so long as we stay within a given context, we know
the things we deduce from other things we know. But if I am in an
ordinary context, knowing I am in San Antonio, I cannot come to know,
via deduction, that I am not a brain in a vat on a distant planet,
since the moment I take that skeptical possibility seriously, I
transform my context into one in which heightened epistemic standards
apply. When I take the vat possibility seriously, I must wield
demanding standards that rule out my knowing I am not a brain in a
vat. By the same token, these standards preclude my knowing I am in
San Antonio. Thinking seriously about knowledge undermines our
knowledge.</p>

<h2><a name="CloRatBel">6. Closure of Rational Belief</a></h2>

<p>
To say that justified belief is closed under entailment is to say that
something like one of the following principles is correct (or that
both are):</p>

<dl class="sentag tag4em">
<dt>(<b>J</b>)</dt>
<dd>If, while justifiably believing <em>p</em>, <em>S</em>
believes <em>q</em> because <em>S</em> knows <em>p</em> entails
<em>q</em>, then <em>S</em> justifiably believes <em>q</em>.</dd>

<dt>(<b>GJ</b>)</dt>
<dd>If, while justifiably believing various propositions,
<em>S</em> believes <em>p</em> because S knows that they entail
<em>p</em>, then <em>S</em> justifiably believes <em>p</em>.</dd>
</dl>

<p>
However, <b>GJ</b> generates paradoxes (Kyburg 1961). To see why,
notice that if the chances of winning a lottery are sufficiently
remote, I am justified in believing that my ticket, ticket 1, will
lose. I am also justified in believing that ticket 2 will lose, and
that 3 will lose, and so on. However, I am not justified in believing
the conjunction of these propositions. If I were, I would justifiably
believe that no ticket will win. If a proposition is justified when
probable enough, lottery examples undermine <b>GJ</b>. No matter how
great the probability that suffices for justification, unless that
probability is 1, in some lotteries we will be justified in believing,
of an arbitrary ticket, that it will lose, and thus, by <b>GJ</b>, we
will be justified in believing that all of the tickets will lose.</p>

<p>
Even if we reject <b>GJ</b>, it does not follow that we must reject
<b>GK</b>, which concerns <em>knowledge</em> closure. Consider the
lottery example again. How justified we are in believing that ticket 1
will lose depends on how probable its losing is. Now, the probability
that ticket 2 will lose is equal to the probability that ticket 1 will
lose. The same goes for each ticket. However, consider the
conjunction, <em>Ticket 1 will lose &amp; ticket 2 will lose</em>. The
probability of this conjunctive proposition is less than the
probability of either of its conjuncts. Suppose we continue to add
conjuncts. For example, next in line will be: <em>Ticket 1 will lose
&amp; ticket 2 will lose &amp; ticket 3 will lose</em>. Each time a
conjunct is added, the probability of the resulting proposition is
still lower. This illustrates the fact that we can begin with a
collection of propositions each of which surpasses some threshold
level of justification (let it be whatever is necessary for a belief
to count as &ldquo;justified&rdquo; according to <b>GJ</b>) and, by
conjoining them, we can end up with a proposition which falls below
that threshold level of justification. We may &ldquo;justifiably
believe&rdquo; each conjunct, but not the conjunction, so <b>GJ</b>
fails. However, we need not reject <b>GK</b> on these grounds. Even if
we grant that we <em>justifiably believe</em> that <em>Ticket 1 will
lose</em> is true we might deny that we <em>know</em> that this
proposition is true. We might take the position that if we believe
some proposition <em>p</em> on the basis of its probability, nothing
less than a probability of 1 will suffice to enable us to know that it
is true. In that case <b>GK</b> will not succumb to our objection to
<b>GJ</b>, for if the probability of two or more propositions is 1
then the probability of their conjunction is also 1. </p>

<p>
We can reject <b>GJ</b>. Should we also reject <b>J</b>? The status of
this principle is much more controversial. Some theorists argue
against it using counterexamples like Dretske&rsquo;s own zebra case:
because the zebra is in plain sight, you seem fully justified in
believing <em>zeb</em>, but it is not so clear that you are justified
in believing <em>not-mule</em>, even if you deduce this belief from
<em>z</em><em>eb</em>. Anyone who rejects <b>K</b> on the grounds that
<b>K</b> sanctions the knowledge of limiting or heavyweight
propositions (discussed earlier) is likely to reject <b>J</b> on
similar grounds: justifiably believing that we have hands, it might
seem, does not position us to justifiably believe that there are
physical objects even if we see that the former entails the latter.
</p>

<p>
One response is that cases such as Dretske&rsquo;s do not count against
<b>J</b>, but rather against the following principle (of the
transmissibility of evidence):</p>

<dl class="sentag tag4em">
<dt>(<b>E</b>)</dt>
<dd>If <em>e</em> is evidence for <em>p</em>, and <em>p</em>
entails <em>q</em>, then <em>e</em> is evidence for <em>q</em>.</dd>
</dl>

<p>
Even if we reject this principle, it does not follow that
justification is not closed under entailment, as Peter Klein (1981)
pointed out. Arguably, for justification closure, all that is
necessary is that when, given all of our relevant evidence <em>e</em>,
we are justified in believing <em>p</em>, we also <em>have</em>
sufficient justification for believing each of <em>p</em>&rsquo;s
consequences. Our justification for <em>p</em>&rsquo;s consequences need not
be <em>e</em>. Instead, it might be <em>p</em> itself, which is, after
all, a justified belief. And since <em>p</em> entails its
consequences, it is sufficient to justify them. Moreover, any good
evidence we have against a consequence of <em>p</em> counts against
<em>p</em> itself, preventing us from being justified in believing
<em>p</em> in the first place, so if we are justified in believing
<em>p</em>, considering all our evidence, pro and con, we will not
have overwhelming evidence against propositions entailed by
<em>p</em>. (A similar move could be defended against the tracking
theorists when they deny the closure of knowledge: if we track
<em>p</em>, and believe <em>q</em> by deducing it from <em>p</em>,
then we track <em>q</em> if we take <em>p</em> as our basis for
believing <em>q</em>.) Looked at in this way, <b>J</b> seems
plausible. (There is a substantial literature on the transmissibility
of evidence and its failure; see, for example, Crispin Wright (1985)
and Martin Davies (1998).</p>

<p>
Some final observations can be made using Roderick Firth&rsquo;s (1978)
distinction between propositional and doxastic justification.
Proposition <em>p</em> has propositional justification for S if and
only if, given the grounds <em>S</em> possesses, <em>p</em> would
count as rational. That <em>p</em> has propositional justification for
<em>S</em> does not require that <em>S</em> actually base <em>p</em>
on these grounds, or even that <em>S</em> believe <em>p</em>. Whether
<em>S</em>&rsquo;s belief has doxastic justification depends on <em>S</em>&rsquo;s
actual grounds for believing <em>p</em>: if, on these grounds,
<em>p</em> would count as rational, then <em>p</em> possesses doxastic
justification. Consider the following principles:</p>

<dl class="sentag tag4em">
<dt>(<b>JD</b>)</dt>
<dd>If <em>p</em> is doxastically justified for <em>S</em>, and
<em>p</em> entails <em>q</em>, then <em>q</em> is doxastically
justified for <em>S</em>.</dd>

<dt>(<b>JP</b>)</dt>
<dd>If <em>p</em> is propositionally justified for <em>S</em>,
and <em>p</em> entails <em>q</em>, then <em>q</em> is propositionally
justified for <em>S</em>.</dd>
</dl>

<p>
Clearly <b>JD</b> faces two fatal objections. First, we might fail to
believe some of the things implied by our beliefs. Second, we may have
perfectly respectable reasons for believing something <em>p</em>, yet,
failing to see that <em>p</em> entails <em>q</em>, we might not be
aware of any grounds for believing <em>q</em>, or, worse, we might
believe <em>q</em> for bogus reasons. But neither difficulty threatens
<b>JP</b>. First, propositional justification does not entail belief.
Second, <em>S</em> might be propositionally justified in believing
<em>q</em> on the basis of <em>p</em> whether or not <em>S</em> fails
to see that <em>p</em> entails <em>q</em>, and even if <em>S</em>
believes <em>q</em> for bogus reasons. As further support for
<b>JP</b>, we might cite the fact that, if <em>p</em> entails
<em>q</em>, whatever counts against <em>q</em> also counts against
<em>p</em>.</p>
</div>

<div id="bibliography">

<h2><a name="Bib">Bibliography</a></h2>

<ul class="hanging">

<li>Alston, W., 1993, <em>The Reliability of Sense Perception</em>,
Ithaca: Cornell University Press.</li>

<li>Armstrong, D., 1973, <em>Belief, Truth and Knowledge</em>,
Cambridge: Cambridge University Press.</li>

<li>Audi, R., 1995, &ldquo;Deductive Closure, Defeasibility and
Scepticism: A Reply to Feldman.&rdquo; <em>Philosophical
Quarterly</em>, 45: 494&ndash;499.</li>

<li>Becker, K., 2009, <em>Epistemology Modalized</em>, New York:
Routledge.</li>

<li>Black, M., 1949, &ldquo;The Justification of Induction,&rdquo;
<em>Language and Philosophy</em>, Cornell University Press.</li>

<li>Black, T., and Murphy, P., 2007, &ldquo;In Defense of
Sensitivity&rdquo;, <em>Synthese</em>, 154(1): 53&ndash;71.</li>

<li>Bogdan, R.J., 1985, &ldquo;Cognition and Epistemic Closure,&rdquo;
<em>American Philosophical Quarterly</em>, 22: 55&ndash;63.</li>

<li>BonJour, L., 1987, &ldquo;Nozick, Externalism, and
Skepticism,&rdquo; in Luper 1987a, 297&ndash;313.</li>

<li>Brueckner, A., 1985a, &ldquo;Losing Track of the Sceptic,&rdquo;
<em>Analysis</em>, 45: 103&ndash;104.</li>

<li>&ndash;&ndash;&ndash;, 1985b, &ldquo;Skepticism and Epistemic
Closure,&rdquo; <em>Philosophical Topics</em>, 13: 89&ndash;117.</li>

<li>&ndash;&ndash;&ndash;, 1985c, &ldquo;Transmission for Knowledge
Not Established,&rdquo; <em>Philosophical Quarterly</em>, 35:
193&ndash;196.</li>

<li>&ndash;&ndash;&ndash;, 2012, &ldquo;Roush on Knowledge: Tracking
Redux?,&rdquo; in K. Becker and T. Black (eds.), <em>The Sensitivity
Principle in Epistemology</em>, Cambridge: Cambridge University
Press.</li>

<li>Cohen, S., 1987, &ldquo;Knowledge, Context, and Social
Standards,&rdquo; <em>Synthese</em>, 73: 3&ndash;26.</li>

<li>&ndash;&ndash;&ndash;, 1988, &ldquo;How to be a
Fallibilist,&rdquo; <em>Philosophical Perspectives 2:
Epistemology</em>, Atascadero, CA: Ridgeview, 91&ndash;123.</li>

<li>&ndash;&ndash;&ndash;, 1999, &ldquo;Contextualism, Skepticism, and
the Structure of Reasons,&rdquo; <em>Philosophical Perspectives 13:
Epistemology</em>, Atascadero, CA: Ridgeview, 57&ndash;89.</li>

<li>&ndash;&ndash;&ndash;, 2002, &ldquo;Basic Knowledge and the
Problem of Easy Knowledge,&rdquo; <em>Philosophy and Phenomenological
Research</em>, 65.2: 309&ndash;329.</li>

<li>Davies, M., 1998, &ldquo;Externalism, Architecturalism, and
Epistemic Warrant,&rdquo; in Crispin Wright, Barry Smith, and Cynthia
Macdonald (eds.), <em>Knowing Our Own Minds,</em> Oxford: Oxford
University Press, pp. 321&ndash;361.</li>

<li>DeRose, K., 1995, &ldquo;Solving the Skeptical Problem,&rdquo;
<em>Philosophical Review</em>, 104: 1&ndash;52.</li>

<li>Dretske, F., 1969, <em>Seeing and Knowing</em>, Chicago:
University of Chicago Press.</li>

<li>&ndash;&ndash;&ndash;, 1970, &ldquo;Epistemic Operators,&rdquo;
<em>Journal of Philosophy</em>, 67: 1007&ndash;1023.</li>

<li>&ndash;&ndash;&ndash;, 1971, &ldquo;Conclusive Reasons,&rdquo;
<em>Australasian Journal of Philosophy</em>, 49: 1&ndash;22.</li>

<li>&ndash;&ndash;&ndash;, 1972, &ldquo;Contrastive Statements,&rdquo;
<em>Philosophical Review</em>, 81: 411&ndash;430.</li>

<li>&ndash;&ndash;&ndash;, 2003, &ldquo;Skepticism: What Perception
Teaches,&rdquo; in Luper 2003b, pp. 105&ndash;118.</li>

<li>&ndash;&ndash;&ndash;, 2005, &ldquo;Is Knowledge Closed Under
Known Entailment?&rdquo; in Steup 2005.</li>

<li>Feldman, R., 1995, &ldquo;In Defense of Closure,&rdquo;
<em>Philosophical Quarterly</em>, 45: 487&ndash;494.</li>

<li>Firth, R., 1978, &ldquo;Are Epistemic Concepts Reducible to
Ethical Concepts?&rdquo; in Alvin Goldman and Jaegwon Kim (eds.),
<em>Values and Morals</em>, Dordrecht: D. Reidel Publishing Co.</li>

<li>Fumerton, R., 1995, <em>Metaepistemology</em>, <em>and
Skepticism</em>, Lanham, MD: Rowman and Littlefield.</li>

<li>Goldman, A., 1976, &ldquo;Discrimination and Perceptual
Knowledge,&rdquo; <em>Journal of Philosophy</em>, 73:
771&ndash;791.</li>

<li>&ndash;&ndash;&ndash;, 1979, &ldquo;What is Justified
Belief?,&rdquo; in <em>Justification and Knowledge</em>, G.S. Pappas
(ed.), Dordrecht: D. Reidel.</li>

<li>Goodman, N., 1955, <em>Fact, Fiction, and Forecast</em>. (4th
ed.), Harvard University Press, 1983.</li>

<li>Hales, S., 1995, Epistemic Closure Principles, <em>Southern
Journal of Philosophy</em>, 33: 185&ndash;201.</li>

<li>Harman, G. and Sherman, B., 2004, &ldquo;Knowledge, Assumptions,
Lotteries,&rdquo; <em>Philosophical Issues</em>, 14:
492&ndash;500.</li>

<li>Hawthorne, J., 2004, <em>Knowledge and Lotteries</em>, Oxford:
Oxford University Press.</li>

<li>&ndash;&ndash;&ndash;, 2005, &ldquo;The Case for Closure,&rdquo;
in Steup 2005.</li>

<li> Jaeger, C. 2004, &ldquo;Skepticism, Information, and Closure:
Dretske&rsquo;s Theory of Knowledge,&rdquo; <em>Erkenntnis</em>, 61:
187&ndash;201.</li>

<li> Klein, P., 1981, <em>Certainty: A Refutation of Skepticism</em>,
Minneapolis, MN: University of Minnesota Press.</li>

<li>&ndash;&ndash;&ndash;, 1995, &ldquo;Skepticism and Closure: Why
the Evil Genius Argument Fails,&rdquo; <em>Philosophical Topics</em>,
23: 213&ndash;236.</li>

<li>&ndash;&ndash;&ndash;, 2004, &ldquo;Closure Matters: Academic
Skepticism and Easy Knowledge,&rdquo; <em>Philosophical Issues</em>,
14(1): 165&ndash;184.</li>

<li>Kripke, S., 2011, &ldquo;Nozick on Knowledge,&rdquo; in
<em>Philosophical Troubles</em> (Collected Papers, Volume 1), New
York: Oxford University Press.</li>

<li>Kyburg, H., 1961, <em>Probability and the Logic of Rational
Belief</em>, Dordrecht: Kluwer.</li>

<li>Lewis, D., 1973, <em>Counterfactuals</em>, Cambridge: Cambridge
University Press.</li>

<li>&ndash;&ndash;&ndash;, 1979, &ldquo;Scorekeeping in a Language
Game,&rdquo; <em>Journal of Philosophical Logic</em>, 8:
339&ndash;359.</li>

<li>&ndash;&ndash;&ndash;, 1996, &ldquo;Elusive Knowledge,&rdquo;
<em>Australasian Journal of Philosophy</em>, 74: 549&ndash;567.</li>

<li>Luper, S., 1984, &ldquo;The Epistemic Predicament: Knowledge,
Nozickian Tracking, and Skepticism,&rdquo; <em>Australasian Journal of
Philosophy</em>, 62: 26&ndash;50.</li>

<li>&ndash;&ndash;&ndash; (ed.), 1987a, <em>The</em>, <em>Possibility
of Knowledge: Nozick and His Critics</em>, Totowa, NJ: Rowman and
Littlefield.</li>

<li>&ndash;&ndash;&ndash;, 1987b, &ldquo;The Possibility of
Skepticism,&rdquo; in Luper 1987a.</li>

<li>&ndash;&ndash;&ndash;, 1987c, &ldquo;The Causal Indicator Analysis
of Knowledge,&rdquo; <em>Philosophy and Phenomenological
Research</em>, 47: 563&ndash;587.</li>

<li>&ndash;&ndash;&ndash;, 2003a, &ldquo;Indiscernability
Skepticism,&rdquo; in S. Luper 2003b, pp. 183&ndash;202.</li>

<li>&ndash;&ndash;&ndash;, (ed.) 2003b, <em>The Skeptics</em>,
Hampshire: Ashgate Publishing, Limited.</li>

<li>&ndash;&ndash;&ndash;, 2004, &ldquo;Epistemic Relativism,&rdquo;
<em>Philosophical Issues</em>, 14, a supplement to
<em>No&ucirc;s</em>, 2004, 271&ndash;295.</li>

<li>&ndash;&ndash;&ndash;, 2006, &ldquo;Dretske on Knowledge
Closure,&rdquo; <em>Australasian Journal of Philosophy</em>, 84(3):
379&ndash;394.</li>

<li>&ndash;&ndash;&ndash;, 2012, &ldquo;False Negatives,&rdquo; in K.
Becker and T. Black (eds.), <em>The Sensitivity Principle in
Epistemology</em>, Cambridge: Cambridge University Press.</li>

<li>Moore, G. E., 1959, &ldquo;Proof of an External World,&rdquo; and
&ldquo;Certainty,&rdquo; in <em>Philosophical Papers</em>, London:
George Allen &amp; Unwin, Ltd.</li>

<li>Murphy, P., 2005, &ldquo;Closure Failures for Safety,&rdquo;
<em>Philosophia</em>, 33: 331&ndash;334.</li>

<li>Nozick, R., 1981, <em>Philosophical Explanations</em>, Cambridge:
Cambridge University Press.</li>

<li>Papineau, D., 1992, &ldquo;Reliabilism, Induction, and
Scepticism,&rdquo; <em>The Philosophical Quarterly</em>, 42:
1&ndash;20.</li>

<li>Pritchard, D., 2007, &ldquo;Anti-Luck Epistemology,&rdquo;
<em>Synthese</em>, 158: 227&ndash;298.</li>

<li>Ramsey, F. P., 1931, <em>The Foundations of Mathematics and Other
Logical Essays</em>, London: Routledge and Kegan Paul.</li>

<li>Roush, S., 2005, <em>Tracking Truth: Knowledge, Evidence and
Science</em>, Oxford: Oxford University Press.</li>

<li>Sextus Empiricus, 1933a, <em>Outlines of Pyrrhonism</em>, R.G.
Bury (trans), London: W. Heinemann, Loeb Classical Library.</li>

<li>Shatz, D., 1987, &ldquo;Nozick&rsquo;s Conception of Skepticism,&rdquo;
in <em>The Possibility of Knowledge</em>, S. Luper (ed.), Totowa, NJ:
Rowman and Littlefield.</li>

<li>Sosa, E., 1999, &ldquo;How to Defeat Opposition to Moore,&rdquo;
<em>Philosophical Perspectives</em>, 13: 141&ndash;152.</li>

<li>&ndash;&ndash;&ndash;, 2003, &ldquo;Neither Contextualism Nor
Skepticism,&rdquo; in <em>The Skeptics</em>, S. Luper (ed.),
Hampshire: Ashgate Publishing, Limited, pp. 165&ndash;182.</li>

<li>&ndash;&ndash;&ndash;, 2007, <em>A Virtue Epistemology: Apt Belief
and Reflective Knowledge Volume I</em>, Oxford: Oxford University
Press.</li>

<li>&ndash;&ndash;&ndash;, 2009, <em>A Virtue Epistemology: Apt Belief
and Reflective Knowledge Volume II</em>, Oxford: Oxford University
Press.</li>

<li>Stalnaker, R., 1968, &ldquo;A Theory of Conditionals,&rdquo;
<em>American Philosophical Quarterly</em> (Monograph No. 2),
98&ndash;112.</li>

<li>Steup, M. and Sosa, E. (eds.), 2005, <em>Contemporary Debates in
Epistemology</em>, Malden, MA: Blackwell.</li>

<li>Stine, G.C., 1971, &ldquo;Dretske on Knowing the Logical
Consequences,&rdquo; <em>Journal of Philosophy</em>, 68:
296&ndash;299.</li>

<li>&ndash;&ndash;&ndash;, 1976, &ldquo;Skepticism, Relevant
Alternatives, and Deductive Closure,&rdquo; <em>Philosophical
Studies</em>, 29: 249&ndash;261.</li>

<li>Van Cleve, J., 1979, &ldquo;Foundationalism, Epistemic Principles,
and the Cartesian Circle,&rdquo; <em>Philosophical Review</em>, 88:
55&ndash;91.</li>

<li>&ndash;&ndash;&ndash;, 2003, &ldquo;Is Knowledge Easy&mdash;or
Impossible? Externalism as the Only Alternative to Skepticism,&rdquo;
in S. Luper 2003b, pp. 45&ndash;60.</li>

<li>Vogel, J., 1990, &ldquo;Are There Counterexamples to the Closure
Principle?&rdquo; in <em>Doubting: Contemporary Perspectives on
Skepticism</em>, M. Roth and G. Ross (eds.), Dordrecht: Kluwer
Academic Publishers.</li>

<li>&ndash;&ndash;&ndash;, 2000, &ldquo;Reliabilism Leveled,&rdquo;
<em>Journal of Philosophy</em>, 97: 602&ndash;623.</li>

<li>&ndash;&ndash;&ndash;, 2004, &ldquo;Speaking of Knowledge,&rdquo;
<em>Philosophical Issues</em>, 14: 501&ndash;509.</li>

<li>Williamson, T., 2000, <em>Knowledge and Its Limits</em>, Oxford:
Oxford University Press.</li>

<li>Wittgenstein, L., 1969, <em>On Certainty</em>, G.E.M. Anscombe
(trans.), New York: Harper and Row, Inc.</li>

<li>Wright, C., 1985, &ldquo;Facts and Certainty,&rdquo;
<em>Proceedings of the British Academy</em>, 71: 429&ndash;472.</li>
</ul>

</div> 

<div id="academic-tools">

<h2 id="Aca">Academic Tools</h2>

<blockquote>
<table class="vert-top">
<tr>
<td><img src="../../symbols/sepman-icon.jpg" alt="sep man icon" /></td>
<td><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=closure-epistemic" target="other">How to cite this entry</a>.</td>
</tr>

<tr>
<td><img src="../../symbols/sepman-icon.jpg" alt="sep man icon" /></td>
<td><a href="https://leibniz.stanford.edu/friends/preview/closure-epistemic/" target="other">Preview the PDF version of this entry</a> at the
 <a href="https://leibniz.stanford.edu/friends/" target="other">Friends of the SEP Society</a>.</td>
</tr>

<tr>
<td><img src="../../symbols/inpho.png" alt="inpho icon" /></td>
<td><a href="https://www.inphoproject.org/entity?sep=closure-epistemic&amp;redirect=True" target="other">Look up topics and thinkers related to this entry</a>
 at the Internet Philosophy Ontology Project (InPhO).</td>
</tr>

<tr>
<td><img src="../../symbols/pp.gif" alt="phil papers icon" /></td>
<td><a href="https://philpapers.org/sep/closure-epistemic/" target="other">Enhanced bibliography for this entry</a>
at <a href="https://philpapers.org/" target="other">PhilPapers</a>, with links to its database.</td>
</tr>

</table>
</blockquote>

</div>

<div id="other-internet-resources">

<h2><a name="Oth">Other Internet Resources</a></h2>

<p>[Please contact the author with suggestions.]</p>

</div>

<div id="related-entries">

<h2><a name="Rel">Related Entries</a></h2>

<p>

 <a href="../confirmation/index.html">confirmation</a> |
 <a href="../contextualism-epistemology/index.html">contextualism, epistemic</a> |
 <a href="../evidence/index.html">evidence</a> |
 <a href="../knowledge-analysis/index.html">knowledge: analysis of</a> |
 <a href="../reliabilism/index.html">reliabilist epistemology</a> |
 <a href="../skepticism/index.html">skepticism</a> |
 <a href="../skepticism-content-externalism/index.html">skepticism: and content externalism</a>

</p>

</div> 


</div><!-- #aueditable --><!--DO NOT MODIFY THIS LINE AND BELOW-->

<!-- END ARTICLE HTML -->

</div> <!-- End article-content -->

  <div id="article-copyright">
    <p>
 <a href="../../info.html#c">Copyright &copy; 2016</a> by

<br />
<a href="http://www.trinity.edu/departments/philosophy/steven_luperhome_page.htm" target="other">Steven Luper</a>

    </p>
  </div>

</div> <!-- End article -->

<!-- NOTE: article banner is outside of the id="article" div. -->
<div id="article-banner" class="scroll-block">
  <div id="article-banner-content">
    <a href="../../fundraising/index.html">
    Open access to the SEP is made possible by a world-wide funding initiative.<br />
    The Encyclopedia Now Needs Your Support<br />
    Please Read How You Can Help Keep the Encyclopedia Free</a>
  </div>
</div> <!-- End article-banner -->

    </div> <!-- End content -->

    <div id="footer">

      <div id="footer-menu">
        <div class="menu-block">
          <h4><i class="icon-book"></i> Browse</h4>
          <ul role="menu">
            <li><a href="../../contents.html">Table of Contents</a></li>
            <li><a href="../../new.html">What's New</a></li>
            <li><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/random">Random Entry</a></li>
            <li><a href="../../published.html">Chronological</a></li>
            <li><a href="../../archives/index.html">Archives</a></li>
          </ul>
        </div>
        <div class="menu-block">
          <h4><i class="icon-info-sign"></i> About</h4>
          <ul role="menu">
            <li><a href="../../info.html">Editorial Information</a></li>
            <li><a href="../../about.html">About the SEP</a></li>
            <li><a href="../../board.html">Editorial Board</a></li>
            <li><a href="../../cite.html">How to Cite the SEP</a></li>
            <li><a href="../../special-characters.html">Special Characters</a></li>
            <li><a href="../../tools/index.html">Advanced Tools</a></li>
            <li><a href="../../contact.html">Contact</a></li>
          </ul>
        </div>
        <div class="menu-block">
          <h4><i class="icon-leaf"></i> Support SEP</h4>
          <ul role="menu">
            <li><a href="../../support/index.html">Support the SEP</a></li>
            <li><a href="../../support/friends.html">PDFs for SEP Friends</a></li>
            <li><a href="../../support/donate.html">Make a Donation</a></li>
            <li><a href="../../support/sepia.html">SEPIA for Libraries</a></li>
          </ul>
        </div>
      </div> <!-- End footer menu -->

      <div id="mirrors">
        <div id="mirror-info">
          <h4><i class="icon-globe"></i> Mirror Sites</h4>
          <p>View this site from another server:</p>
        </div>
        <div class="btn-group open">
          <a class="btn dropdown-toggle" data-toggle="dropdown" href="https://plato.stanford.edu/">
            <span class="flag flag-usa"></span> USA (Main Site) <span class="caret"></span>
            <span class="mirror-source">Philosophy, Stanford University</span>
          </a>
          <ul class="dropdown-menu">
            <li><a href="../../mirrors.html">Info about mirror sites</a></li>
          </ul>
        </div>
      </div> <!-- End mirrors -->
      
      <div id="site-credits">
        <p>The Stanford Encyclopedia of Philosophy is <a href="../../info.html#c">copyright &copy; 2021</a> by <a href="http://mally.stanford.edu/">The Metaphysics Research Lab</a>, Department of Philosophy, Stanford University</p>
        <p>Library of Congress Catalog Data: ISSN 1095-5054</p>
      </div> <!-- End site credits -->

    </div> <!-- End footer -->

  </div> <!-- End container -->

   <!-- NOTE: Script required for drop-down button to work (mirrors). -->
  <script>
    $('.dropdown-toggle').dropdown();
  </script>

</body>

<!-- Mirrored from seop.illc.uva.nl/entries/closure-epistemic/ by HTTrack Website Copier/3.x [XR&CO'2014], Wed, 22 Jun 2022 19:46:24 GMT -->
</html>
