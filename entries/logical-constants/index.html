<!DOCTYPE html>
<!--[if lt IE 7]> <html class="ie6 ie"> <![endif]-->
<!--[if IE 7]>    <html class="ie7 ie"> <![endif]-->
<!--[if IE 8]>    <html class="ie8 ie"> <![endif]-->
<!--[if IE 9]>    <html class="ie9 ie"> <![endif]-->
<!--[if !IE]> --> <html> <!-- <![endif]-->

<!-- Mirrored from seop.illc.uva.nl/entries/logical-constants/ by HTTrack Website Copier/3.x [XR&CO'2014], Wed, 22 Jun 2022 19:52:17 GMT -->
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>
Logical Constants (Stanford Encyclopedia of Philosophy)
</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="robots" content="noarchive, noodp" />
<meta property="citation_title" content="Logical Constants" />
<meta property="citation_author" content="MacFarlane, John" />
<meta property="citation_publication_date" content="2005/05/16" />
<meta name="DC.title" content="Logical Constants" />
<meta name="DC.creator" content="MacFarlane, John" />
<meta name="DCTERMS.issued" content="2005-05-16" />
<meta name="DCTERMS.modified" content="2015-06-18" />

<!-- NOTE: Import webfonts using this link: -->
<link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,300,600,200&amp;subset=latin,latin-ext" rel="stylesheet" type="text/css" />

<link rel="stylesheet" type="text/css" media="screen,handheld" href="../../css/bootstrap.min.css" />
<link rel="stylesheet" type="text/css" media="screen,handheld" href="../../css/bootstrap-responsive.min.css" />
<link rel="stylesheet" type="text/css" href="../../css/font-awesome.min.css" />
<!--[if IE 7]> <link rel="stylesheet" type="text/css" href="../../css/font-awesome-ie7.min.css"> <![endif]-->
<link rel="stylesheet" type="text/css" media="screen,handheld" href="../../css/style.css" />
<link rel="stylesheet" type="text/css" media="print" href="../../css/print.css" />
<link rel="stylesheet" type="text/css" href="../../css/entry.css" />
<!--[if IE]> <link rel="stylesheet" type="text/css" href="../../css/ie.css" /> <![endif]-->
<script type="text/javascript" src="../../js/jquery-1.9.1.min.js"></script>
<script type="text/javascript" src="../../js/bootstrap.min.js"></script>

<!-- NOTE: Javascript for sticky behavior needed on article and ToC pages -->
<script type="text/javascript" src="../../js/jquery-scrolltofixed-min.js"></script>
<script type="text/javascript" src="../../js/entry.js"></script>

<!-- SEP custom script -->
<script type="text/javascript" src="../../js/sep.js"></script>
</head>

<!-- NOTE: The nojs class is removed from the page if javascript is enabled. Otherwise, it drives the display when there is no javascript. -->
<body class="nojs article" id="pagetopright">
<div id="container">
<div id="header-wrapper">
  <div id="header">
    <div id="branding">
      <div id="site-logo"><a href="../../index.html"><img src="../../symbols/sep-man-red.png" alt="SEP logo" /></a></div>
      <div id="site-title"><a href="../../index.html">Stanford Encyclopedia of Philosophy</a></div>
    </div>
    <div id="navigation">
      <div class="navbar">
        <div class="navbar-inner">
          <div class="container">
            <button class="btn btn-navbar collapsed" data-target=".collapse-main-menu" data-toggle="collapse" type="button"> <i class="icon-reorder"></i> Menu </button>
            <div class="nav-collapse collapse-main-menu in collapse">
              <ul class="nav">
                <li class="dropdown open"><a id="drop1" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-book"></i> Browse</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop1">
                    <li><a href="../../contents.html">Table of Contents</a></li>
                    <li><a href="../../new.html">What's New</a></li>
                    <li><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/random">Random Entry</a></li>
                    <li><a href="../../published.html">Chronological</a></li>
                    <li><a href="../../archives/index.html">Archives</a></li>
                  </ul>
                </li>
                <li class="dropdown open"><a id="drop2" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-info-sign"></i> About</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop2">
                    <li><a href="../../info.html">Editorial Information</a></li>
                    <li><a href="../../about.html">About the SEP</a></li>
                    <li><a href="../../board.html">Editorial Board</a></li>
                    <li><a href="../../cite.html">How to Cite the SEP</a></li>
                    <li><a href="../../special-characters.html">Special Characters</a></li>
                    <li><a href="../../tools/index.html">Advanced Tools</a></li>
                    <li><a href="../../contact.html">Contact</a></li>
                  </ul>
                </li>
                <li class="dropdown open"><a id="drop3" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-leaf"></i> Support SEP</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop3">
                    <li><a href="../../support/index.html">Support the SEP</a></li>
                    <li><a href="../../support/friends.html">PDFs for SEP Friends</a></li>
                    <li><a href="../../support/donate.html">Make a Donation</a></li>
                    <li><a href="../../support/sepia.html">SEPIA for Libraries</a></li>
                  </ul>
                </li>
              </ul>
            </div>
          </div>
        </div>
      </div>
    </div>
    <!-- End navigation -->
    
    <div id="search">
      <form id="search-form" method="get" action="https://seop.illc.uva.nl/search/searcher.py">
        <input type="search" name="query" placeholder="Search SEP" />
        <div class="search-btn-wrapper"><button class="btn search-btn" type="submit"><i class="icon-search"></i></button></div>
      </form>
    </div>
    <!-- End search --> 
    
  </div>
  <!-- End header --> 
</div>
<!-- End header wrapper -->

<div id="content">

<!-- Begin article sidebar -->
<div id="article-sidebar" class="sticky">
  <div class="navbar">
    <div class="navbar-inner">
      <div class="container">
        <button class="btn btn-navbar" data-target=".collapse-sidebar" data-toggle="collapse" type="button"> <i class="icon-reorder"></i> Entry Navigation </button>
        <div id="article-nav" class="nav-collapse collapse-sidebar in collapse">
          <ul class="nav">
            <li><a href="#toc">Entry Contents</a></li>
            <li><a href="#Bib">Bibliography</a></li>
            <li><a href="#Aca">Academic Tools</a></li>
            <li><a href="https://leibniz.stanford.edu/friends/preview/logical-constants/">Friends PDF Preview <i class="icon-external-link"></i></a></li>
            <li><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=logical-constants">Author and Citation Info <i class="icon-external-link"></i></a> </li>
            <li><a href="#pagetopright" class="back-to-top">Back to Top <i class="icon-angle-up icon2x"></i></a></li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</div>
<!-- End article sidebar --> 

<!-- NOTE: Article content must have two wrapper divs: id="article" and id="article-content" -->
<div id="article">
<div id="article-content">

<!-- BEGIN ARTICLE HTML -->


<div id="aueditable"><!--DO NOT MODIFY THIS LINE AND ABOVE-->

<h1>Logical Constants</h1><div id="pubinfo"><em>First published Mon May 16, 2005; substantive revision Thu Jun 18, 2015</em></div>

<div id="preamble">

<p>

Logic is usually thought to concern itself only with features that
sentences and arguments possess in virtue of their logical structures
or <em>forms</em>. The logical form of a sentence or argument is
determined by its syntactic or semantic structure and by the placement
of certain expressions called &ldquo;logical constants.&rdquo;<sup>[<a name="note-1" href="notes.html#1">1</a>]</sup>
 Thus, for example, the
sentences</p>

<p class="indent">Every boy loves some girl.</p>

<p>

and</p>

<p class="indent">Some boy loves every girl.</p>

<p>

are thought to differ in logical form, even though they share a
common syntactic and semantic structure, because they differ in the
placement of the logical constants &ldquo;every&rdquo; and &ldquo;some&rdquo;. By contrast, the
sentences</p>

<p class="indent">Every girl loves some boy.</p>

<p>

and</p>

<p class="indent">Every boy loves some girl.</p>

<p>

are thought to have the same logical form, because &ldquo;girl&rdquo; and &ldquo;boy&rdquo;
are not logical constants. Thus, in order to settle questions about
logical form, and ultimately about which arguments are logically valid
and which sentences logically true, we must distinguish the &ldquo;logical
constants&rdquo; of a language from its nonlogical expressions.</p>

<p>

While it is generally agreed that signs for negation, conjunction,
disjunction, conditionality, and the first-order quantifiers should
count as logical constants, and that words like &ldquo;red&rdquo;, &ldquo;boy&rdquo;, &ldquo;taller&rdquo;,
and &ldquo;Clinton&rdquo; should not, there is a vast disputed middle ground. Is
the sign for identity a logical constant? Are tense and modal operators
logical constants? What about &ldquo;true&rdquo;, the epsilon of set-theoretic
membership, the sign for mereological parthood, the second-order
quantifiers, or the quantifier &ldquo;there are infinitely many&rdquo;? Is there a
distinctive logic of agency, or of knowledge? In these border areas our
intuitions from paradigm cases fail us; we need something more
principled.</p>

<p>

However, there is little philosophical consensus about the basis for
the distinction between logical and nonlogical expressions. Until this
question is resolved, we lack a proper understanding of the scope and
nature of logic, and of the significance of the distinction between the
&ldquo;formal&rdquo; properties and relations logic studies and related but
non-formal ones. For example, the sentence</p>

<p class="indent">If Socrates is human and mortal, then he is
mortal.</p>

<p>

is generally taken to be a logical truth, while the sentence</p>

<p class="indent">If Socrates is orange, then he is colored.</p>

<p>

is not, even though intuitively both are true, necessary, knowable
<em>a priori</em>, and analytic. What is the significance of the
distinction we are making between them in calling one but not the other
&ldquo;logically true&rdquo;? A principled demarcation of logical constants might
offer an answer to this question, thereby clarifying what is at stake
in philosophical controversies for which it matters what counts as
logic (for example, logicism and structuralism in the philosophy of
mathematics).</p>

<p>

This article will discuss the problem of logical constants and
survey the main approaches to solving or resolving it.</p>

</div>

<div id="toc">
<!--Entry Contents-->
<ul>
<li><a href="#SynTer">1. Syncategorematic terms</a></li>
<li><a href="#GraCri">2. Grammatical criteria</a></li>
<li><a href="#DavApp">3. A Davidsonian approach</a></li>
<li><a href="#TopNeu">4. Topic neutrality</a></li>
<li><a href="#PerInv">5. Permutation invariance</a></li>
<li><a href="#InfCha">6. Inferential characterizations</a>
   <ul>
   <li><a href="#SemValDet">6.1 Semantic value determination</a></li>
   <li><a href="#SenDet">6.2 Sense determination</a></li>
   </ul></li>
<li><a href="#PraDem">7. Pragmatic demarcations</a></li>
<li><a href="#ProPse">8. Problem or pseudoproblem?</a></li>
<li><a href="#FurRea">Further reading</a></li>
<li><a href="#Bib">Bibliography</a></li>
<li><a href="#Aca">Academic Tools</a></li>
<li><a href="#Oth">Other Internet Resources</a></li>
<li><a href="#Rel">Related Entries</a></li>
</ul>
<!--Entry Contents-->

<hr />

</div>

<div id="main-text">

<h2><a name="SynTer">1. Syncategorematic terms</a></h2>

<p>

The most venerable approach to demarcating the logical constants
identifies them with the language&rsquo;s <em>syncategorematic</em> signs:
signs that signify nothing by themselves, but serve to indicate how
independently meaningful terms are combined. This approach was natural
in the context of the &ldquo;term logics&rdquo; that were dominant until the
nineteenth century. All propositions were thought to be composed out of
propositions of subject-predicate form by means of a small number of
connectives (&ldquo;and&rdquo;, &ldquo;or&rdquo;, &ldquo;if &hellip;then&rdquo;, and so on). In this framework,
words divide naturally into those that can be used as subjects or
predicates (&ldquo;categorematic&rdquo; words) and those whose function is to
indicate the relation between subject and predicate or between two
distinct subject-predicate propositions (&ldquo;syncategorematic&rdquo; words). For
example, &ldquo;Socrates&rdquo;, &ldquo;runs&rdquo;, &ldquo;elephant&rdquo;, and &ldquo;large&rdquo; are categorematic
words, while &ldquo;only&rdquo;, &ldquo;every&rdquo;, &ldquo;necessarily&rdquo;, and &ldquo;or&rdquo; are
syncategorematic. (For a more detailed account of the distinction, see
Kretzmann 1982, 211&ndash;214.) The syncategorematic words were naturally
seen as indicating the <em>structure</em> or <em>form</em> of the
proposition, while the categorematic words supplied its &ldquo;matter.&rdquo; Thus
the fourteenth-century logician Buridan writes:</p>

<blockquote>I say that in a proposition (as we&rsquo;re speaking here of
matter and form), we understand by the &ldquo;matter&rdquo; of the proposition or
<em>consequentia</em> the purely categorical terms, i.e. subjects and
predicates, omitting the syncategorematic terms that enclose them and
through which they are conjoined or negated or distributed or forced to
a certain mode of supposition. All the rest, we say, pertains to the
form. (Buridan 1976, I.7.2)</blockquote>

<p>

The Fregean revolution in our conception of
 <a href="../logical-form/index.html">logical form</a>
 made this way of demarcating the logical constants
problematic. Whereas the term logicians had seen every proposition as
composed of subject and predicate terms linked together by
syncategorematic &ldquo;glue,&rdquo; Frege taught us to see sentences and
propositions as built up recursively by functional application and
functional abstraction (for a good account, see Dummett 1981, ch. 2).
To see the difference between the two approaches, consider the
sentence</p>

\[\label{moby}
\text{Every boat is smaller than Moby Dick.}
\]

<p>

A term logician would have regarded \(\refp{moby}\) as composed of a subject
term (&ldquo;boat&rdquo;) and a predicate term (&ldquo;thing smaller than Moby Dick&rdquo;)
joined together in a universal affirmative categorical form. Frege, by
contrast, would have regimented \(\refp{moby}\) as</p>

\[\label{moby-frege}
  \forall x (x~\text{is a boat}
  \supset x~\text{is smaller than Moby Dick})
  \]

<p>
which he would have analyzed as the result of applying the
second-level function<sup>[<a name="note-2" href="notes.html#2">2</a>]</sup>
</p>

\[\label{second-level}
\forall x (\Phi(x) \supset \Psi(x))
\]

<p>to the first level functions</p>

\[\label{function-boat}
\xi~\text{is a boat}
\]

<p>and</p>

\[\label{function-smaller}
\xi~\text{is smaller than Moby Dick}.
\]

<p>
(The Greek letters \(\xi\), \(\Phi\), and \(\Psi\) here indicate the
functions&rsquo; argument places: lowercase Greek letters indicate places
that can be filled by proper names, while uppercase Greek letters
indicate places that must be filled by function expressions like
\(\refp{function-boat}\)
and \(\refp{function-smaller}\).) He would have regarded \(\refp{function-smaller}\)
as itself the result of
&ldquo;abstracting&rdquo; on the place occupied by &ldquo;Shamu&rdquo; in
</p>

\[\label{shamu-smaller}
\text{Shamu is smaller than Moby Dick,}
\]

<p>which in turn is the result of applying the function</p>

\[\label{smaller-than}
\zeta~\text{is smaller than}~\xi
\]

<p>
to &ldquo;Shamu&rdquo; and &ldquo;Moby Dick&rdquo;. Frege showed that by describing
sentences and propositions this way, in terms of their
function/argument composition, we can represent the logical relations
between them in a far more complete, perspicuous, and systematic way
than was possible with the old subject/predicate model of propositional
form.</p>

<p>

However, once we have thrown out the old subject/predicate model, we
can no longer identify the categorematic terms with the subject and
predicate terms, as the medievals did. Nor can we think of the
syncategorematic terms as the expressions that have no &ldquo;independent&rdquo;
significance, or as the &ldquo;glue&rdquo; that binds together the categorematic
terms to form a meaningful whole. Granted, there is a sense in which
the &ldquo;logical&rdquo; function \(\refp{second-level}\) is the glue that binds
together \(\refp{function-boat}\) and \(\refp{function-smaller}\)
to yield \(\refp{moby-frege}\). But in the very same sense, the function
\(\refp{smaller-than}\) is the glue
that binds together &ldquo;Shamu&rdquo; and &ldquo;Moby Dick&rdquo; to yield
\(\refp{shamu-smaller}\). If we count
all functional expressions as syncategorematic on the grounds that they
are &ldquo;incomplete&rdquo; or &ldquo;unsaturated&rdquo; and thus not &ldquo;independently
meaningful,&rdquo; then the syncategorematic expressions will include not
just connectives and quantifiers, but ordinary predicates. On the other
hand, if we count all the functional expressions as categorematic, then
the syncategoremata will be limited to variables, parentheses, and
other signs that serve to indicate functional application and
abstraction. In neither case would the distinction be useful for
demarcating the logical constants. An intermediate proposal would be to
count first-level functions as categoremata and second-level functions
as syncategoremata. That would make \(\refp{second-level}\) syncategorematic and
\(\refp{function-boat}\) and \(\refp{function-smaller}\) categorematic. However, not
every second-level function is
(intuitively) &ldquo;logical.&rdquo; Consider, for example, the second-level
function</p>

\[
\text{Every dog}~x~\text{such that}~\Phi(x)~\text{is such that}~\Psi(x).
\]

<p>

Granted, standard logical languages do not have a simple expression
for this function, but there is no reason in principle why we could not
introduce such an expression. Conversely, not every first-level
function is (intuitively) nonlogical: for example, the identity
relation is usually treated as logical.</p>

<p>

In sum, it is not clear how the distinction between categorematic
and syncategorematic terms, so natural in the framework of a term
logic, can be extended to a post-Fregean function/argument conception
of propositional structure. At any rate, none of the natural ways of
extending the distinction seem apt for the demarcation of the logical
constants. Carnap concedes that the distinction between categorematic
and syncategorematic expressions &ldquo;seems more or less a matter of
convention&rdquo; (1947, 6&ndash;7). However, the idea that logical constants are
syncategoremata does not wither away entirely with the demise of term
logics. Its influence can still be felt in Wittgenstein&rsquo;s insistence
that the logical constants are like punctuation marks (1922,
&sect;5.4611),<sup>[<a name="note-3" href="notes.html#3">3</a>]</sup>
 in Russell&rsquo;s claim that logical constants
indicate logical form and not propositional constituents (1992, 98;
1920, 199), and in the idea (found in Quine and Dummett) that the
logical constants of a language can be identified with its grammatical
particles.</p>

<h2><a name="GraCri">2. Grammatical criteria</a></h2>

<p>

Quine and Dummett propose that the logical constants of a language
are its grammatical <em>particles</em>&mdash;the expressions by means
of which complex sentences are built up, step by step, from atomic
ones&mdash;while non-logical expressions are the simple expressions of
which atomic sentences are composed (see Quine 1980, Quine 1986,
Dummett 1981, 21&ndash;2, and for discussion, F&oslash;llesdal 1980 and
Harman 1984). On this conception, &ldquo;[l]ogic studies the truth conditions
that hinge solely on grammatical constructions&rdquo; (Quine 1980,
 17).<sup>[<a name="note-4" href="notes.html#4">4</a>]</sup>
This criterion yields appropriate results when applied to the language
of first-order logic (FOL) and other standard logical languages. In FOL
(without identity), <em>all</em> singular terms and predicates are
paradigm nonlogical constants, and <em>all</em> operators and
connectives are paradigm logical
 constants.<sup>[<a name="note-5" href="notes.html#5">5</a>]</sup></p>

<p>

However, this nice coincidence of intuitively logical expressions and
grammatical particles in FOL cannot be taken as support for the
Quine/Dummett proposal, because FOL was <em>designed</em> so that its
grammatical structure would reflect logical structure. It is easy
enough to design other artificial languages for which the grammatical
criterion gives intuitively inappropriate results. For example, take
standard FOL and add a variable-binding operator &ldquo;&cent;&rdquo; whose
interpretation is &ldquo;there is at least one cat such that &hellip;.&rdquo; The
grammatical criterion counts &ldquo;&cent;&rdquo; as a logical constant, but
surely it is not one.</p>

<p>

Moreover, there are alternative ways of regimenting the grammar of
FOL on which the standard truth-functional connectives are not
grammatical particles, but members of a small lexical category (Quine
1986, 28&ndash;9). For example, instead of recognizing four grammatical
operations that form one sentence from two sentences (one that takes
\(P\) and \(Q\) and yields \(\cq{P \vee Q}\), one
that takes \(P\) and \(Q\) and yields \(\cq{P \and Q}\), and so
on), we could recognize a single grammatical operation that forms one
sentence from two sentences and one connective. On this way of
regimenting the grammar of FOL, \(\dq{\and}\) and
 \(\dq{\vee}\)
 would not count as grammatical particles.</p>

<p>

The upshot is that a grammatical demarcation of logical constants will
not impose significant constraints on what counts as a logical
constant unless it is combined with some principle for limiting the
languages to which it applies (excluding, for example, languages with
the operator &ldquo;&cent;&rdquo;) and privileging some regimentations of their
grammars over others (excluding, for example, regimentations that
treat truth-functional connectives as members of a small lexical
category).  Quine&rsquo;s own approach is to privilege the language best
suited for the articulation of scientific theories and the grammar
that allows the most economical representation of the truth conditions
of its sentences. Thus the reason Quine holds that logic should
restrict itself to the study of inferences that are truth-preserving
in virtue of their grammatical structures is not that he thinks there
is something special about the grammatical particles (in an arbitrary
language), but rather that he thinks we should employ a language in
which grammatical structure is a perspicuous guide to truth
conditions: &ldquo;what we call logical form is what grammatical form
becomes when grammar is revised so as to make for efficient general
methods of exploring the interdependence of sentences in respect of
their truth values&rdquo; (1980, 21).</p>

<p>

Instead of applying the grammatical criterion to artificial
languages like FOL, one might apply it to natural languages like
English. One could then appeal to the work of empirical linguists for a
favored grammatical regimentation. Contemporary linguists posit a
structural representation called LF that resolves issues of scope and
binding crucial to semantic evaluation. But the question remains which
lexical items in the LF should count as logical constants. Generalizing
Quine&rsquo;s proposal, one might identify the logical constants with members
of small, &ldquo;closed&rdquo; lexical categories: for example, conjunctions and
determiners. However, by this criterion prepositions in English would
count as logical constants (Harman 1984, 121). Alternatively, one might
identify the logical constants with members of <em>functional
categories</em> (including tense, complementizers, auxiliaries,
determiners, and pronouns), and the nonlogical constants with members
of <em>substantive categories</em> (including nouns, verbs, adjectives,
adverbs, and prepositions) (for this terminology, see Chomsky 1995, 6,
54 and Radford 2004, 41). If a distinction that plays an important role
in a theory of linguistic competence should turn out to coincide (in
large part) with our traditional distinction between logical and
nonlogical constants, then this fact would stand in need of
explanation. Why should we treat inferences that are truth-preserving
in virtue of their LF structures and functional words differently from
those that are truth-preserving in virtue of their LF structures and
substantive words? Future work in linguistics, cognitive psychology and
neurophysiology may provide the materials for an interesting answer to
this question, but for now it is important that the question be asked,
and that we keep in mind the possibility of a sceptical answer.</p>

<h2><a name="DavApp">3. A Davidsonian approach</a></h2>

<p>

The Quinean approach identifies the logical constants as the
expressions that play a privileged, &ldquo;structural&rdquo; role in a systematic
grammatical theory for a language. An alternative approach, due to
Quine&rsquo;s student
 <a href="../davidson/index.html">Donald Davidson</a>,
 identifies the logical constants as the expressions that play a
privileged, &ldquo;structural&rdquo; role in a systematic theory of
<em>meaning</em> for a language. A Davidsonian theory of meaning takes
the form of a
 <a href="../tarski-truth/index.html">Tarskian truth theory</a>.
 Thus, it contains two kinds of axioms: <em>base clauses</em> that
specify the satisfaction conditions of atomic
 sentences,<sup>[<a name="note-6" href="notes.html#6">6</a>]</sup>
 and <em>recursive
clauses</em> that specify the satisfaction conditions of complex
sentences in terms of the satisfaction conditions of their proper
 parts.<sup>[<a name="note-7" href="notes.html#7">7</a>]</sup>
 For example:</p>

<div class="indent">
<p>

<em>Base Clauses:</em></p>

<ul>
<li>For all assignments \(a\), Ref(&ldquo;Bill Clinton&rdquo;, \(a\)) =
Bill Clinton.</li>

<li>For all assignments \(a\), Ref(&ldquo;Hilary Clinton&rdquo;, \(a\)) =
Hilary Clinton.</li>

<li>If \(\upsilon\) is a variable, then for all assignments \(a\),
Ref(\(\upsilon\), \(a\)) = \(a(\upsilon)\), the value \(a\) assigns to \(\upsilon\).</li>

<li>For all terms \(\tau\), \(\sigma\), and all assignments \(a\),
\(\cq{\tau \text{ is taller than } \sigma}\)
 is satisfied by \(a\) iff Ref(\(\tau\), \(a\)) is taller than
Ref(\(\sigma\), \(a\)).</li> </ul>

<p>

<em>Recursive Clauses:</em></p>

<ul>
  <li>For all assignments \(a\) and all sentences \(\phi, \psi\),
  \(\cq{\phi \text{ or } \psi}\)
  is satisfied by \(a\) iff \(\phi\) is satisfied by \(a\) or \(\psi\)
  is satisfied by \(a\).</li>

<li>For all assignments \(a\), all sentences \(\phi, \psi\), and all
  variables \(\upsilon\),
  \(\cq{[\text{Some}~\upsilon : \phi]~\psi }\)
 is satisfied by \(a\) iff there is an assignment
 \(a'\) that differs from \(a\) at most in the value it
 assigns to \(\upsilon\), satisfies \(\phi\), and satisfies \(\psi\).</li> </ul>
</div>

<p>

Davidson suggests that &ldquo;[t]he logical constants may be identified as
those iterative features of the language that require a recursive
clause in the characterization of truth or satisfaction&rdquo; (1984, 71).
(In our example, &ldquo;or&rdquo; and &ldquo;some&rdquo;.) </p>

<p>

This criterion certainly gives reasonable results when applied to
standard truth theories like the one above (although the sign for
identity once more gets counted as nonlogical). But as Davidson goes on
to observe, &ldquo;[l]ogical form, in this account, will of course be
relative to the choice of a metalanguage (with its logic) and a theory
of truth&rdquo; (1984, 71). Different truth theories can be given for the
same language, and they can agree on the truth conditions of whole
sentences while differing in which expressions they treat in the
recursive clauses. Here are two examples (both discussed further in
Evans 1976).</p>

<p>

1. We might have recursive clauses for &ldquo;large&rdquo; and other gradable
adjectives, along these lines:</p>

<p class="indent">For all assignments \(a\), terms \(\tau\), and
  sentences \(\phi\),
  \(\cq{\tau \text{ is a large } \phi }\)
 is satisfied by \(a\) iff Ref(\(\tau\), \(a\))
 is a large satisfier of \(\phi\) on \(a\). (cf. Evans 1976,
 203)</p>

<p>

We would in this case have to use a metalanguage with a stronger
logic, one that provides rules for manipulating &ldquo;large satisfier of
\(\phi\) on \(a\).&rdquo; (As Evans notes, all we would really need in
order to derive T-sentences would be a rule licensing the derivation
of
\(\cq{\tau \text{ is a large satisfier of } \phi \text{ on } a}\)
from
\(\cq{\phi \equiv \psi}\) and
\(\cq{\tau \text{ is a larger satisfier of } \psi \text{ on } a}\).) But
such a metalanguage cannot be ruled out without begging the question
about the logicality of &ldquo;large.&rdquo;</p>

<p>

2. We might assign values to &ldquo;and&rdquo;, &ldquo;or&rdquo;, and the other
truth-functional connectives in the <em>base</em> clauses, allowing us
to get by with a single generic recursive clause for truth-functional
connectives:</p>

<div class="indent">
<p>

<em>Base:</em> For all assignments \(a\), Ref(&ldquo;or&rdquo;, \(a\))
= Boolean disjunction (the binary truth function that takes the value
True when either argument is True, and False otherwise).</p>

<p>

<em>Recursive:</em> For all assignments \(a\), sentences \(\phi,
\psi\), and truth-functional connectives \(@\), \(\cq{\phi @ \psi }\)
is satisfied
by \(a\) iff Ref(\(@, a\))(Val(\(\phi, a\)), Val(\(\psi,a\))) = True
(where Val(\(\phi, a\)) = True if \(\phi\) is
satisfied by \(a\), False if \(\phi\) is not satisfied by
\(a\)). (cf. Evans 1976, 214)</p>
</div>

<p>

This approach requires a stronger metatheory than the usual
approach, since it requires quantification over truth functions. But it
is not clear why this is an objection. It is still possible to derive
T-sentences whose right sides are no more ontologically committed than
the sentences named on their left sides, like</p>

\[
\text{&ldquo;Snow is white or grass is green&rdquo; is } \mathrm{true} \\
\text{ iff snow is white or grass is green}.
\]

<p>

So it is hard to see how the use of functions here is any more
objectionable than Davidson&rsquo;s own appeal to sequences or assignments of
values to variables.</p>

<p>

In sum, the problem with Davidson&rsquo;s truth-theoretic proposal is much
like the problem discussed above with Quine&rsquo;s grammatical proposal.
Without further constraints on the theory of meaning (or, in Quine&rsquo;s
case, the grammar), it does not yield a definite criterion for logical
constancy. I do not mean to suggest that either Davidson or Quine was
deluded on this score. As we saw above, Quine appeals to pragmatic
considerations to pick out a favored language and grammatical
regimentation. No doubt Davidson would do the same, arguing (for
example) that the advantages of using a simple and well-understood
logic in the metalanguage outweigh any putative advantages of treating
&ldquo;large&rdquo; and the like in recursive clauses. (For a recent defense of a
Davidsonian criterion against Evans&rsquo;s objections, see Lepore and Ludwig
2002.)</p>

<h2><a name="TopNeu">4. Topic neutrality</a></h2>

<p>

Logic, it seems, is not about anything in particular; relatedly, it is
applicable everywhere, no matter what we are reasoning about. So it is
natural to suppose that the logical constants can be marked out as the
&ldquo;topic-neutral&rdquo; expressions (Ryle 1954, 116; Peacocke 1976, 229; Haack
1978, 5&ndash;6; McCarthy 1981, 504; Wright 1983, 133; Sainsbury 2001,
365). We have reason to care about the topic-neutral expressions, and
to treat them differently from others, because we are interested in
logic as a <em>universal</em> canon for reasoning, one that is
applicable not just to reasoning about this or that domain, but to all
reasoning.</p>

<p>

Unfortunately, the notion of topic neutrality is too vague to be of
much help when it comes to the hard cases for which we <em>need</em> a
principle of demarcation. Take arithmetic, for instance. Is it
topic-neutral? Well, yes: anything can be counted, so the theorems of
arithmetic will be useful in any field of inquiry. But then again, no:
arithmetic has its own special subject matter, the natural numbers and
the arithmetical relations that hold between them. The same can be
said about set theory: on the one hand, anything we can reason about
can be grouped into sets; on the other hand, set theory seems to be
about a particular corner of the universe&mdash;the sets&mdash;and
thus to have its own special &ldquo;topic.&rdquo; The general problem of which
these two cases are instances might be called the <em>antinomy of
topic-neutrality</em>. As George Boolos points out, the antinomy can
be pressed all the way to paradigm cases of logical constants: &ldquo;it
might be said that logic is not so &lsquo;topic-neutral&rsquo; as it
is often made out to be: it can easily be said to be about the notions
of negation, conjunction, identity, and the notions expressed by
&lsquo;all&rsquo; and &lsquo;some&rsquo;, among others &hellip;&rdquo;
(1975, 517). It is plausible to think that the source of the antinomy
is the vagueness of the notion of topic neutrality, so let us consider
some ways in which we might make this notion more precise.</p>

<p>

Gilbert Ryle, who seems to have coined the expression
&ldquo;topic-neutral&rdquo;, gives the following rough criterion:</p>

<blockquote>We may call English expressions &ldquo;topic-neutral&rdquo; if a
foreigner who understood them, but only them, could get no clue at all
from an English paragraph containing them what that paragraph was
about. (1954,
 116)<sup>[<a name="note-8" href="notes.html#8">8</a>]</sup></blockquote>

<p>

There are, I suppose, a few paradigm cases of such expressions:
&ldquo;is&rdquo;, for instance, and &ldquo;if&rdquo;. But the criterion gives little help when
we venture beyond these clear-cut cases. The problem is that one might
answer the question &ldquo;what is this paragraph about?&rdquo; at many different
levels of generality. Suppose I understand English badly, and I hear
someone say:</p>

<blockquote>blah blah blah <em>and not</em> blah blah blah <em>because
it</em> blah blah blah <em>to be</em> blah blah blah <em>and was
always</em> blah blah blah. <em>But every</em> blah blah <em>is</em>
blah blah, <em>although a few</em> blah blah <em>might be</em>
blah.</blockquote>

<p>

Do I have any clue as to what the paragraph is about? Well, surely I
have <em>some</em> clue. &ldquo;Because&rdquo; reveals that the passage is about
causal or explanatory relations. &ldquo;It&rdquo; reveals that the passage is about
at least one object that is not known to be a person. The tense
operator &ldquo;was always&rdquo; reveals that it is about events that occur in
time. &ldquo;Might be&rdquo; reveals that it is about the realm of the possible (or
the unknown), and not just the actual (or the known). Finally, &ldquo;every&rdquo;
and &ldquo;a few&rdquo; reveal that it is about discrete, countable objects.
Perhaps some of these words are not topic-neutral and should not be
included in the domain of logic, but we certainly don&rsquo;t want to rule
out <em>all</em> of them. And Ryle&rsquo;s criterion gives no guidance about
where to draw the line. One might even suspect that there is no line,
and that topic neutrality is a matter of degree, truth-functional
expressions being more topic-neutral than quantifiers, which are more
topic-neutral than tense and modal operators, which are more
topic-neutral than epistemic expressions, and so on (Lycan 1989).</p>

<p>

The problem with Ryle&rsquo;s account is its reliance on vague and
unclarified talk of &ldquo;aboutness.&rdquo; If we had a precise philosophical
account of what it is for a statement to be <em>about</em> a particular
object or subject matter, then we could define a topic-neutral
statement as one that is not about anything&mdash;or, perhaps, one that
is about everything indifferently. Here we might hope to appeal to
Nelson Goodman&rsquo;s classic account of &ldquo;absolute aboutness,&rdquo; which implies
that logical truths are not absolutely about anything (1961, 256), or
to David Lewis&rsquo;s (1988) account of what it is for a proposition to be
about a certain subject matter, which implies that logical truths are
about <em>every</em> subject matter indifferently. However, neither
account is appropriate for our purpose. On Goodman&rsquo;s account, &ldquo;what a
statement is absolutely about will depend in part upon what logic is
presupposed,&rdquo; and hence upon which expressions are taken to be logical
constants (253&ndash;4), so it would be circular to appeal to Goodman&rsquo;s
account of aboutness in a demarcation of the logical constants. On
Lewis&rsquo;s account, <em>all</em> necessarily true propositions turn out to
be topic-neutral. But if there is any point to invoking topic
neutrality in demarcating logic, it is presumably to distinguish the
logical truths from a wider class of necessary propositions, some of
which are subject matter-specific. If we are willing to broaden the
bounds of logic to encompass all necessary propositions (or,
alternatively, all analytic sentences), then we might as well demarcate
logic as the realm of necessary truth (alternatively, analytic truth).
It is only if we want to <em>distinguish</em> the logical from the
generically necessary, or to demarcate logic without appealing to modal
notions at all, that we need to invoke topic neutrality. And in neither
of these cases will Lewis&rsquo;s criterion of aboutness be of service.</p>

<p>

We rejected Ryle&rsquo;s criterion for topic-neutrality because it
appealed to an unclarified notion of aboutness. We rejected Goodman&rsquo;s
explication of aboutness because it assumed that the line between logic
and non-logic had already been drawn. And we rejected Lewis&rsquo;s account
of aboutness because it did not distinguish logical truths from other
kinds of necessary truths. How else might we cash out the idea that
logic is &ldquo;not about anything in particular&rdquo;? Two approaches have been
prominent in the literature.</p>

<p>

The first starts from the idea that what makes an expression
specific to a certain domain or topic is its capacity to
<em>discriminate</em> between different individuals. For example, the
monadic predicate &ldquo;is a horse&rdquo;, the dyadic predicate &ldquo;is taller than&rdquo;,
and the quantifier &ldquo;every animal&rdquo; all distinguish between Lucky Feet,
on the one hand, and the Statue of Liberty, on the other:</p>

<ul>
<li>&ldquo;Lucky Feet is a horse&rdquo; is true; &ldquo;The Statue of Liberty is a horse&rdquo;
is false.</li>

<li>&ldquo;The Statue of Liberty is taller than Lucky Feet&rdquo; is true; &ldquo;Lucky
Feet is taller than the Statue of Liberty&rdquo; is false.</li>

<li>The truth of &ldquo;Every animal is healthy&rdquo; depends on whether Lucky
Feet is healthy, but not on whether the Statue of Liberty is
healthy.</li>
</ul>

<p>

On the other hand, the monadic predicate &ldquo;is a thing&rdquo;, the dyadic
predicate &ldquo;is identical with&rdquo;, and the quantifier &ldquo;everything&rdquo; do not
distinguish between Lucky Feet and the Statue of Liberty. In fact, they
do not distinguish between <em>any</em> two particular objects. As far
as they are concerned, one object is as good as another and might just
as well be switched with it. Expressions with this kind of indifference
to the particular identities of objects might reasonably be said to be
topic-neutral. As we will see in the next section, this notion of topic
neutrality can be cashed out in a mathematically precise way as
invariance under arbitrary permutations of a domain. It is in this
sense that the basic concepts of arithmetic and set theory are not
topic-neutral, since they distinguish some objects (the empty set, the
number 0) from others.</p>

<p>

The second approach locates the topic neutrality of logic in its
universal applicability. On this conception, logic is useful for the
guidance and criticism of reasoning about any subject
whatsoever&mdash;natural or artefactual, animate or inanimate, abstract
or concrete, normative or descriptive, sensible or merely
conceptual&mdash;because it is intimately connected somehow with the
very conditions for thought or reasoning. This notion of topic
neutrality is not equivalent to the one just discussed. It allows that
a science with its own proprietary domain of objects, like arithmetic
or set theory, might still count as topic-neutral in virtue of its
completely general applicability. Thus, Frege, who took arithmetic to
be about numbers, which he regarded as genuine objects, could still
affirm its absolute topic neutrality:</p>

<blockquote>&hellip;the basic propositions on which arithmetic is based
cannot apply merely to a limited area whose peculiarities they express
in the way in which the axioms of geometry express the peculiarities of
what is spatial; rather, these basic propositions must extend to
everything that can be thought. And surely we are justified in
ascribing such extremely general propositions to logic. (1885, 95, in
Frege 1984; for further discussion, see MacFarlane 2002)</blockquote>

<p>

The tradition of demarcating the logical constants as expressions
that can be characterized by purely inferential introduction and
elimination rules can be seen as a way of capturing this notion of
completely general applicability. For, plausibly, it is the fact that
the logical constants are characterizable in terms of notions
fundamental to thought or reasoning (for example, valid inference) that
accounts for their universal applicability.</p>

<p>

The antinomy with which we started can now be resolved
by disambiguating.  Arithmetic and set theory make distinctions among
objects, and so are not topic-neutral
in the first sense, but they might
still be topic-neutral in the second sense, by virtue of their universal
applicability to reasoning about any subject.
We are still faced with a decision about which of
these notions of topic neutrality is distinctive of logic. Let us postpone this
problem, however, until we have had a closer look at both notions.</p>

<!--pdf include
<br />
<br />
pdf include-->

<h2><a name="PerInv">5. Permutation invariance</a></h2>

<p>

A number of philosophers have suggested that what is distinctive of
logical constants is their insensitivity to the particular identities
of objects, or, more precisely, their <em>invariance</em> under
arbitrary permutations of the domain of objects (Mautner 1946;
Mostowski 1957, 13; Scott 1970, 160&ndash;161; McCarthy 1981, 1987; Tarski
1986; van Benthem 1989; Sher 1991, 1996; McGee 1996).</p>

<p>

Let us unpack that phrase a bit. A <em>permutation</em> of a
collection of objects is a one-one mapping from that collection onto
itself. Each object gets mapped to an object in the collection
(possibly itself), and no two objects are mapped to the same object.
For example, the following mapping is a permutation of the first five
letters of the alphabet:</p>

\[\begin{align*}
\textrm{A} &amp;\Rightarrow \textrm{C} \\
\textrm{B} &amp;\Rightarrow \textrm{B} \\
\textrm{C} &amp;\Rightarrow \textrm{E} \\
\textrm{D} &amp;\Rightarrow \textrm{A} \\
\textrm{E} &amp;\Rightarrow \textrm{D} \\
\end{align*}\]

<p>

And the function \(f(x) = x + 1\) is a
permutation of the set of integers onto itself. (Note, however, that a
permutation need not be specifiable either by enumeration, as in our
first example, or by a rule, as in our second.)</p>

<p>
The extension of a predicate is invariant under a permutation of the domain if
replacing each of its members with the object to
which the permutation maps it leaves us with the same set we
started with.  Thus, for example, the extension of &ldquo;is a
letter between \(\textrm{A}\) and \(\textrm{E}\)&rdquo; is invariant under the permutation of
letters described above. By contrast, the
extension of &ldquo;is a vowel between \(\textrm{A}\) and \(\textrm{E}\)&rdquo;,
the set \(\{\textrm{A}, \textrm{E}\}\),
is not invariant under this permutation, which transforms it
to a different set, \(\{\textrm{C}, \textrm{D}\}\).
</p>

<p>
We can make the notion of permutation invariance more precise
as follows. Given a permutation \(p\) of objects on a domain \(D\),
we define a transformation \(p^*\) of
arbitrary types in the hierarchy:</p>

<ul>
<li>if \(x\) is an object in \(D\), \(p^*(x) = p(x)\).</li>

<li>if \(x\) is a set, then \(p^*(x) =
\{ y : \exists z (z \in x \and y = p^*(z))\}\)
(that is, the set of objects to which
\(p^*\) maps members of \(x\)).</li>

<li>if \(x\) is an ordered \(n\)-tuple
\(\langle x_1, \dots, x_n \rangle\), then
\(p^*(x) = \langle p^*(x_1), \dots, p^*(x_n) \rangle\)
(that is, the \(n\)-tuple of objects to which \(p^*\) maps
\(x_1, \dots, x_n\)).<sup>[<a name="note-9" href="notes.html#9">9</a>]</sup></li>
</ul>

<p>

These clauses can be applied recursively to define
transformations of sets of ordered tuples in \(D\) (the extensions
of two-place predicates), sets
of sets of objects in \(D\) (the extensions of unary first-order quantifiers),
and so on. (For an introduction to
the type theoretic hierachy, see
the entry on <a href="../type-theory/index.html">Type Theory</a>.) Where \(x\) is an
item in this hierarchy, we say that \(x\) is <em>invariant
under</em> a permutation \(p\) just in case \(p^*(x) = x\).
To return to our example above, the set 
\(\{\textrm{A}, \textrm{B}, \textrm{C}, \textrm{D}, \textrm{E}\}\) is
invariant under all permutations of the letters \(\textrm{A}\) through \(\textrm{E}\):
no matter how we switch these letters around, we end up with the same
set.  But it is not invariant under all permutations of the entire
alphabet.  For example, the permutation that switches the letters \(\textrm{A}\)
and \(\textrm{Z}\), mapping all the other letters to themselves, transforms 
\(\{\textrm{A}, \textrm{B}, \textrm{C}, \textrm{D}, \textrm{E}\}\) to 
\(\{\textrm{Z}, \textrm{B}, \textrm{C}, \textrm{D}, \textrm{E}\}\).  The set containing all the letters,
however, is invariant under all permutations of letters.  So is
the set of all sets containing at least two letters, and the relation
of identity, which holds between each letter and itself.</p>

<p>

So far we have defined permutation invariance for objects, tuples,
and sets, but not for predicates, quantifiers, or other linguistic
expressions. But it is the latter, not the former, that we need to sort
into logical and nonlogical constants. The natural thought is that an
expression should count as permutation-invariant just in case its
extension on each domain of objects is invariant under all permutations
of that domain. (As usual, the extension of a name on a domain is the
object it denotes, the extension of a monadic predicate is the set of
objects in the domain to which it applies, and the extension of an
\(n\)-adic predicate is the set of \(n\)-tuples of objects in
the domain to which it applies.) As it stands, this definition does not
apply to sentential connectives, which do not have
extensions in the usual
 sense,<sup>[<a name="note-10" href="notes.html#10">10</a>]</sup>
 but it can be extended to cover them in a natural way (following
McGee 1996, 569). We can think of the semantic value of an \(n\)-ary
quantifier or sentential connective \(C\) on a domain \(D\)
as a function from \(n\)-tuples of sets of assignments (of values
from \(D\) to the language&rsquo;s variables) to sets of
assignments. Where the input to the function is the \(n\)-tuple
of sets of assignments that satisfy \(\phi_1, \dots, \phi_n\),
its output is the set of assignments
that satisfies \(C\phi_1 \dots \phi_n\).
(Check your understanding by thinking about how this works for
the unary connective \(\exists x\).)
We can then define permutation
invariance for these semantic values as follows. Where \(A\) is a
set of assignments and \(p\) is a permutation of a domain \(D\), let
\(p^\dagger(A) = \{ p \circ a : a \in
A\}\).<sup>[<a name="note-11" href="notes.html#11">11</a>]</sup>
 Then if \(e\) is the semantic value of an \(n\)-place
connective or quantifier (in the sense defined above), \(e\) is
invariant under a permutation \(p\) just in case for any
\(n\)-tuple \(\langle A_1, \dots, A_n \rangle\) of
sets of assignments, \(p^\dagger (e(\langle A_1, \dots, A_n\rangle)) =
e(\langle p^\dagger (A_1), \dots, p^\dagger (A_n)\rangle\)).
And a connective or quantifier
is permutation-invariant just in case its semantic value on each domain of
objects is invariant under all permutations of that domain.</p>

<p>

It turns out that this condition does not quite suffice to weed out
<em>all</em> sensitivity to particular features of objects, for it
allows that a permutation-invariant constant might behave differently
on domains containing different kinds of objects. McGee (1996, 575)
gives the delightful example of <em>wombat disjunction</em>, which
behaves like disjunction if the domain contains wombats and like
conjunction otherwise. Sher&rsquo;s fix, and McGee&rsquo;s, is to consider not just
permutations&mdash;bijections of the domain onto itself&mdash;but
arbitrary bijections of the domain onto another domain of equal
 cardinality.<sup>[<a name="note-12" href="notes.html#12">12</a>]</sup>
 For simplicity, we will ignore this
complication in what follows and continue to talk of permutations.</p>

<p>

Which expressions get counted as logical constants, on this
criterion? The monadic predicates &ldquo;is a thing&rdquo; (which applies to
everything) and &ldquo;is not anything&rdquo; (which applies to nothing), the
identity predicate, the truth-functional connectives, and the standard
existential and universal quantifiers all pass the test. So do the
standard first-order binary quantifiers like &ldquo;most&rdquo; and &ldquo;the&rdquo; (see
 the entry on 
 <a href="../descriptions/index.html">descriptions</a>).
 Indeed, because cardinality is permutation-invariant, every
cardinality quantifier is included, including &ldquo;there are infinitely
many&rdquo;, &ldquo;there are uncountably many&rdquo;, and others that are not
first-order definable. Moreover, the second-order quantifiers count as
logical (at least on the standard semantics, in which they range over
arbitrary subsets of the domain), as do all higher-order
quantifiers. On the other hand, all proper names are excluded, as are
the predicates &ldquo;red&rdquo;, &ldquo;horse&rdquo;, &ldquo;is a successor of&rdquo;, and &ldquo;is a member
of&rdquo;, as well as the quantifiers &ldquo;some dogs&rdquo; and &ldquo;exactly two natural
numbers&rdquo;. So the invariance criterion seems to accord at least
partially with common intuitions about logicality or topic neutrality,
and with our logical practice. Two technical results allow us to be a
bit more precise about the extent of this accord: Lindenbaum and
Tarski (1934&ndash;5) show that all of the relations definable in the
language of <em>Principia Mathematica</em> are
permutation-invariant. Moving in the other direction, McGee (1996)
shows that every permutation-invariant operation can be defined in
terms of operations with an intuitively logical character (identity,
substitution of variables, finite or infinite disjunction, negation,
and finite or infinite existential quantification). He also
generalizes the Lindenbaum-Tarski result by showing that every
operation so definable is permutation invariant.</p>

<p>

As Tarski and others have pointed out, the permutation invariance
criterion for logical constants can be seen as a natural generalization
of Felix Klein&rsquo;s (1893) idea that different geometries can be
distinguished by the groups of transformations under which their basic
notions are invariant. Thus, for example, the notions of Euclidean
geometry are invariant under similarity transformations, those of
affine geometry under affine transformations, and those of topology
under bicontinuous transformations. In the same way, Tarski suggests
(1986, 149), the <em>logical</em> notions are just those that are
invariant under the widest possible group of transformations: the group
of <em>permutations</em> of the elements in the domain. Seen in this
way, the logical notions are the end point of a chain of progressively
more abstract, &ldquo;formal,&rdquo; or topic-neutral notions defined by their
invariance under progressively wider groups of transformations of a
domain.<sup>[<a name="note-13" href="notes.html#13">13</a>]</sup></p>

<p>

As an account of the distinctive generality of logic, then,
permutation invariance has much to recommend it. It is philosophically
well-motivated and mathematically precise, it yields results that
accord with common practice, and it gives determinate rulings about
some borderline cases (for example, set-theoretic membership). Best of
all, it offers hope for a sharp and principled demarcation of logic
that avoids cloudy epistemic and semantic terms like &ldquo;about&rdquo;,
&ldquo;analytic&rdquo;, and &ldquo;<em>a
 priori</em>&rdquo;.<sup>[<a name="note-14" href="notes.html#14">14</a>]</sup></p>

<p>

A limitation of the permutation invariance criterion (as it has been
stated so far) is that it applies only to extensional operators and
connectives. It is therefore of no help in deciding, for instance,
whether the necessity operator in S4 modal logic or the <em>H</em>
operator (&ldquo;it has
always been the case that&rdquo;) in temporal logic are bona
fide logical constants, and these are among the questions that we
wanted a criterion to resolve. However, the invariance criterion can be
extended in a natural way to intensional operators. The usual strategy
for handling such operators semantically is to relativize truth not
just to an assignment of values to variables, but also to a possible
world and a time. In such a framework, one might demand that logical
constants be insensitive not just to permutations of the domain of
objects, but to permutations of the domain of possible worlds and the
domain of times (see Scott 1970, 161, McCarthy 1981, 511&ndash;13, van
Benthem 1989, 334). The resulting criterion is fairly stringent: it
counts the S5 necessity operator as a logical constant, but not the S4
necessity operator or the <em>H</em> operator in temporal logic.
The reason is that the latter two operators are sensitive to
<em>structure</em> on the domains of worlds and
times&mdash;the &ldquo;accessibility relation&rdquo; in the former case, the
relation of temporal ordering in the latter&mdash;and this structure is
not preserved by all permutations of these
 domains.<sup>[<a name="note-15" href="notes.html#15">15</a>]</sup>
 (See the entries on 
 <a href="../logic-modal/index.html">modal logic</a>
 and
 <a href="../logic-temporal/index.html">temporal logic</a>.)</p>

<p>

One might avoid this consequence by requiring only invariance under
permutations that preserve the relevant structure on these domains
(accessibility relations, temporal ordering). But one would then be
faced with the task of explaining why <em>this</em> structure deserves
special treatment (cf. van Benthem 1989, 334). And if we are allowed to
keep some structure on the domain of worlds or times fixed, the
question immediately arises why we should not also keep some structure
on the domain of <em>objects</em> fixed: for example, the set-theoretic
membership relation, the mereological part/whole relation, or the
distinction between existent and nonexistent objects (see the
entry on <a href="../logic-free/index.html">free logics</a>).
Whatever resources we appeal to in answering this question
will be doing at least as much work as permutation invariance in the
resulting demarcation of logical constants.</p>

<p>

It may seem that the only principled position is to demand
invariance under <em>all</em> permutations. But even that position
needs justification, especially when one sees that it is possible to
formulate even stricter invariance conditions. Feferman (1999) defines
a &ldquo;similarity invariance&rdquo; criterion that counts the truth-functional
operators and first-order existential and universal quantifiers as
logical constants, but not identity, the first-order cardinality
quantifiers, or the second-order quantifiers. Feferman&rsquo;s criterion
draws the line between logic and mathematics much closer to the
traditional boundary than the permutation invariance criterion does.
Indeed, one of Feferman&rsquo;s criticisms of the permutation invariance
criterion is that it allows too many properly mathematical notions to
be expressed in purely logical terms.  Bonnay (2008) argues for
a different criterion, invariance under potential isomorphism, which
counts finite cardinality quantifiers and the notion of finiteness as
logical, while excluding the higher cardinality
quantifiers&mdash;thus &ldquo;[setting] the boundary between
logic and mathematics somewhere between arithmetic and set theory&rdquo;
(37; see Feferman 2010, &sect;6, for further discussion).
Feferman (2010) suggests that instead of relying solely
on invariance, we might combine invariance under permutations
with a separate <em>absoluteness</em> requirement, which captures the
insensitivity of logic to controversial set-theoretic theses like
axioms of infinity.  He shows that the logical operations that
are both permutation-invariant and absolutely definable
with respect to Kripke&ndash;Platek set theory without an
axiom of infinity are just those definable in first-order logic.
</p>

<p>

There is another problem that afflicts any attempt to demarcate the
logical constants by appeal to mathematical properties like invariance.
As McCarthy puts it: &ldquo;the logical status of an expression is not
settled by the functions it introduces, independently of how these
functions are <em>specified</em>&rdquo; (1981, 516). Consider a two-place
predicate \(\dq{\approx}\), whose meaning is given by the following
definition:</p>

\[
\cq{\alpha \approx \beta }\text{ is true on an
assignment } a \text{ just in case }\\
a(\alpha) \text{ and } a(\beta) \text{ have exactly the same mass.}
\]

<p>

According to the invariance criterion, \(\dq{\approx}\) is a logical
constant just in case its extension on every domain is invariant under
every permutation of that domain. On a domain \(D\) containing no
two objects with exactly the same mass, \(\dq{\approx}\) has the same
extension as \(\dq{=}\)&mdash;the set \(\{ \langle x, x \rangle :
x \in D\}\)&mdash;and as we have seen, this extension
is invariant under every permutation of the domain. Hence, if there is
<em>no</em> domain containing two objects with exactly the same mass,
\(\dq{\approx}\) counts as a logical constant, and
\(\dq{\forall x (x \approx x)}\) as a logical
truth.<sup>[<a name="note-16" href="notes.html#16">16</a>]</sup>
But it
seems odd that the logical status of \(\dq{\approx}\) and
\(\dq{\forall x (x \approx x)}\) should depend on a matter of
contingent fact: whether there are distinct objects with identical
mass. Do we really want to say that if we lived in a world in which no
two objects had the same mass, \(\dq{\approx}\) would be a logical
 constant?<sup>[<a name="note-17" href="notes.html#17">17</a>]</sup></p>

<p>

A natural response to this kind of objection would be to require
that the extension of a logical constant on every <em>possible</em>
domain of objects be invariant under every permutation of that domain,
or, more generally, that a logical constant satisfy the permutation
invariance criterion as a matter of <em>necessity</em>. But this would
not get to the root of the problem. For consider the unary connective
\(\dq{\#}\), defined by the clause</p>

\[
\cq{\#\phi}~\text{is true on an assignment } a \text{ just in case }\\
\phi \text{ is not true on } a \text { and water is } H_{2}O.
\]

<p>
Assuming that Kripke (1971; 1980) is right that water is <em>necessarily</em>
H<sub><font size="2">2</font></sub>O,
\(\dq{\#}\) has the same extension as
\(\dq{\neg}\) in every possible world, and so satisfies the permutation
invariance criterion as a matter of necessity (McGee 1996, 578). But intuitively, it does
not seem that \(\dq{\#}\) should be counted a logical
 constant.<sup>[<a name="note-18" href="notes.html#18">18</a>]</sup></p>

<p>

One might evade this counterexample by appealing to an
<em>epistemic</em> modality instead of a metaphysical one. This is
McCarthy&rsquo;s strategy (1987, 439). Even if it is metaphysically necessary
that water is H<sub><font size="2">2</font></sub>O, there are
presumably epistemically possible worlds, or information states, in
which water is not H<sub><font size="2">2</font></sub>O. So if we
require that a logical constant be permutation invariant as a matter of
epistemic necessity (or <em>a priori</em>), \(\dq{\#}\) does not count as a
logical constant. But even on this version of the criterion, a
connective like \(\dq{\%}\), defined by</p>

\[
\cq{\%\phi}~\text{is true on an assignment } a \text{ just in case }\\
\phi \text { is not true on } a \text{ and there are no male widows.}
\]

<p>
would count as a logical constant (G&oacute;mez-Torrente
2002, 21), assuming that it is epistemically necessary that there are
no male widows. It may be tempting to solve <em>this</em> problem by
appealing to a distinctively <em>logical</em> modality&mdash;requiring,
for example, that logical constants have permutation-invariant
extensions as a matter of <em>logical</em> necessity. But we would then
be explicating the notion of a logical constant in terms of an obscure
primitive notion of logical necessity which we could not, on pain of
circularity, explicate by reference to logical constants. (McCarthy
1998, &sect;3 appeals explicitly to logical possibility and notices the
threat of circularity here.)</p>

<p>

McGee&rsquo;s strategy is to invoke semantic notions instead of modal
ones: he suggests that &ldquo;[a] connective is a logical connective if and
only if it follows from the meaning of the connective that it is
invariant under arbitrary bijections&rdquo; (McGee 1996, 578). But this
approach, like McCarthy&rsquo;s, seems to count \(\dq{\%}\) as a logical constant.
And, like McCarthy&rsquo;s, it requires appeal to a notion that does not seem
any clearer than the notion of a logical constant: the notion of
following (logically?) from the meaning of the connective.</p>

<p>

Sher&rsquo;s response to the objection is radically different from McGee&rsquo;s
or McCarthy&rsquo;s. She suggests that &ldquo;logical terms are identified with
their (actual) extensions,&rdquo; so that \(\dq{\#}\), \(\dq{\%}\),
and \(\dq{\neg}\) are just
different notations for the same term. More precisely: if these
expressions are used the way a logical constant must be used&mdash;as
rigid
 designators<sup>[<a name="note-19" href="notes.html#19">19</a>]</sup>
 of their semantic values&mdash;then they can be identified with the
operation of Boolean negation and hence with each other. &ldquo;Qua
quantifiers, &lsquo;the number of planets&rsquo; and &lsquo;9&rsquo; are
indistinguishable&rdquo; (Sher 1991, 64). But it is not clear what Sher can
mean when she says that logical terms can be identified with their
extensions. We normally individuate connectives
<em>intentionally</em>, by the conditions for grasping them or the
rules for their use, and not by the truth functions they express. For
example, we recognize a difference between \(\dq{\and}\), defined by
</p>

\[
\cq{\phi \and \psi } \text{ is true on an assignment \(a\) just in case}\\
\phi \text{ is true on \(a\) and \(\psi\) is true on \(a\)},
\]

<p>and \(\dq{@}\), defined by</p>

\[
\cq{\phi\ @\ \psi } \text{ is true on an assignment \(a\) just in case}\\
\text{it is not the case either that \(\phi\) is not true on \(a\)}\\
\text{or that \(\psi\) is not true on \(a\)},
\]

<p>
even though they express the same truth function. The distinction
between these terms is not erased, as Sher seems to suggest, if we use
them as rigid designators for the truth functions they express. (That
&ldquo;Hesperus&rdquo;, &ldquo;Phosphorus&rdquo;, and &ldquo;the planet
I actually saw near the horizon on the morning of November 1, 2004&rdquo;
all rigidly designate Venus
does not entail that they have the same meaning.)
Thus Sher&rsquo;s proposal can only be
understood as a <em>stipulation</em> that if one of a pair of
coreferential rigid designators counts as a logical constant, the other
does too. But it is not clear why we should accept this stipulation. It
certainly has some counterintuitive consequences: for example, that
\(\dq{P \vee \#P}\) is a logical
truth, at least when \(\dq{\#}\) is used rigidly (see G&oacute;mez-Torrente
2002, 19, and the response in Sher 2003).</p>

<p>

It is hard not to conclude from these discussions that the
permutation invariance criterion gives at best a necessary condition
for logical constancy. Its main shortcoming is that it operates at the
level of reference rather than the level of sense; it looks at the
logical operations expressed by the constants, but not at their
meanings. An adequate criterion, one might therefore expect, would
operate at the level of sense, perhaps attending to the way we
<em>grasp</em> the meanings of logical constants.</p>

<h2><a name="InfCha">6. Inferential characterizations</a></h2>

<p>

At the end of the section on topic neutrality, we distinguished two
notions of topic neutrality. The first notion&mdash;insensitivity to
the distinguishing features of individuals&mdash;is effectively
captured by the permutation invariance criterion. How might we capture
the second&mdash;universal applicability to all thought or reasoning,
regardless of its subject matter? We might start by identifying certain
ingredients that must be present in anything that is to count as
thought or reasoning, then class as logical any expression that can be
understood in terms of these ingredients alone. That would ensure a
special connection between the logical constants and thought or
reasoning as such, a connection that would explain logic&rsquo;s universal
applicability.</p>

<p>

Along these lines, it has been proposed that the logical constants
are just those expressions that can be characterized by a set of purely
inferential introduction and elimination
 rules.<sup>[<a name="note-20" href="notes.html#20">20</a>]</sup>
 To grasp the meaning
of the conjunction connective \(\dq{\and}\), for example, it is arguably
sufficient to learn that it is governed by the rules:

\begin{equation*}
\frac{A, B}{A \and B}
\quad
\frac{A \and B}{A}
\quad
\frac{A \and B}{B}
\end{equation*}

Thus the meaning of \(\dq{\and}\) can be grasped by anyone who understands
the significance of the horizontal line in an inference rule. (Contrast
\(\dq{\%}\) from the last section, which cannot be grasped by anyone who does
not understand what a male is and what a widow is.) Anyone who is
capable of articulate thought or reasoning at all should be able to
understand these inference rules, and should therefore be in a position
to grasp the meaning of \(\dq{\and}\). Or so the thought
 goes.<sup>[<a name="note-21" href="notes.html#21">21</a>]</sup></p>

<p>

To make such a proposal precise, we would have to make a number of
additional decisions:</p>

<ul>
<li>
<p>

We would have to decide whether to use natural deduction rules or
sequent rules.  (See the entry on
<a href="../proof-theory-development/index.html#NatDedSeqCal">the development of
  proof theory</a>.)</p>
</li>

<li>
<p>

If we opted to use sequent rules, we would have to decide whether or
not to allow &ldquo;substructure&rdquo; (see the entry on
 <a href="../logic-substructural/index.html">substructural logics</a>)
 and whether to allow multiple conclusions in the sequents. We would
also have to endorse a particular set of purely structural rules
(rules not involving any expression of the language essentially).</p>
</li>

<li>
<p>

We would have to specify whether it is introduction or elimination
rules, or both, that are to characterize the meanings of logical
constants.<sup>[<a name="note-22" href="notes.html#22">22</a>]</sup>
 (In a sequent formulation, we would have to
distinguish between right and left introduction and elimination
rules.)</p>
</li>

<li>
<p>

We would have to allow for subpropositional structure in our rules,
in order to make room for quantifier rules.</p>
</li>

<li>
<p>

We would have to say when an introduction or elimination rule counts
as &ldquo;purely inferential,&rdquo; to exclude rules like these:

\begin{equation*}
\frac{a~\text{is red}}{Ra}
\quad
\frac{A, B, \text{water is}~H_{2}O}{A * B}
\end{equation*}

The strictest criterion would allow only rules in which every sign,
besides a single instance of the constant being characterized, is
either structural (like the comma) or schematic (like \(\dq{A}\)).
But although this condition is met by the standard rules for
conjunction, it is not met by the natural deduction introduction rule
for negation, which must employ either another logical constant
(\(\dq{\bot}\)) or another instance of the negation sign than the one being
introduced. Thus one must either relax the condition for being &ldquo;purely
inferential&rdquo; or add more structure (see especially Belnap 1982).</p>
</li>
</ul>

<p>

Different versions of the inferential characterization approach make
different decisions about these matters, and these differences affect
which constants get certified as &ldquo;logical.&rdquo; For example, if we use
single-conclusion sequents with the standard rules for the constants,
we get the intuitionistic connectives, while if we use
multiple-conclusion sequents, we get the classical connectives (Kneale
1956, 253). If we adopt Do&scaron;en&rsquo;s constraints on acceptable rules
(Do&scaron;en 1994, 280), the S4 necessity operator gets counted as a
logical constant, while if we adopt Hacking&rsquo;s constraints, it doesn&rsquo;t
(Hacking 1979, 297). Thus, if we are to have any hope of deciding the
hard cases in a principled way, we will have to motivate all of the
decisions that distinguish our version of the inferential
characterization approach from the others. Here, however, we will avoid
getting into these issues of detail and focus instead on the basic
idea.</p>

<p>

The basic idea is that the logical constants are distinguished from
other sorts of expressions by being &ldquo;characterizable&rdquo; in terms of
purely inferential rules. But what does &ldquo;characterizable&rdquo; mean here? As
G&oacute;mez-Torrente (2002, 29) observes, it might be taken to require
either the fixation of reference (semantic value) or the fixation of
sense:</p>

<div class="indent">
<p>

<em>Semantic value determination:</em> A constant \(c\) is
characterizable by rules \(R\) iff its being governed by
\(R\) suffices to fix its reference or semantic value (for
example, the truth function it expresses), given certain semantic
background assumptions (Hacking 1979, 299, 313).</p>

<p>


<em>Sense determination:</em> A constant \(c\) is
characterizable by rules \(R\) iff its being governed by \(R\) suffices
to fix its sense: that is, one can grasp the sense of \(c\) simply by
learning that it is governed by \(R\) (Popper 1946&ndash;7, 1947; Kneale
1956, 254&ndash;5; Peacocke 1987; Hodes 2004, 135).</p>
</div>

<p>

Let us consider these two versions of the inferential
characterization approach in turn.</p>

<h3><a name="SemValDet">6.1 Semantic value determination</a></h3>

<p>

Hacking shows that, given certain background semantic assumptions
(bivalence, valid inference preserves truth), any introduction and
elimination rules meeting certain proof-theoretic conditions
(subformula property, provability of elimination theorems for Cut,
Identity, and Weakening) will uniquely determine a semantics for the
constant they govern (Hacking 1979, 311&ndash;314). It is in this sense that
these rules &ldquo;fix the meaning&rdquo; of the constant: &ldquo;they are such that if
strong semantic assumptions of a general kind are made, then the
specific semantics of the individual logical constants is thereby
determined&rdquo; (313).</p>

<p>

The notion of determination of semantic value in a well-defined
semantic framework is, at least, clear&mdash;unlike the general notion
of determination of sense. However, as G&oacute;mez-Torrente points
out, by concentrating on the fixation of reference (or semantic value)
rather than sense, Hacking opens himself up to an objection not unlike
the objection to permutation-invariance approaches we considered above
(see also Sainsbury 2001, 369). Consider the quantifier \(\dq{W}\),
which means &ldquo;not for all not &hellip;, if all are not male widows, and for
all not &hellip;, if not all are not male widows&rdquo; (G&oacute;mez-Torrente
2002, 29). (It is important here that \(\dq{W}\) is a primitive sign
of the language, not one introduced by a definition in terms of
\(\dq{\forall}\), \(\dq{\neg}\), &ldquo;male&rdquo;, and
&ldquo;widow&rdquo;.) Since there are no male
widows, \(\dq{W}\) has the same semantic value as our ordinary
quantifier \(\dq{\exists}\). (As above, we can think of the semantic value of
a quantifier as a function from sets of assignments to sets of
assignments.) Now let \(R\) be the standard introduction and
elimination rules for \(\dq{\exists}\), and let \(R'\) be the
result of substituting \(\dq{W}\) for \(\dq{\exists}\) in these rules.
Clearly, \(R'\) is no less &ldquo;purely inferential&rdquo; than
\(R\). And if \(R\) fixes a semantic value for
\(\dq{\exists}\), then \(R'\) fixes a semantic value&mdash;the very
same semantic value&mdash;for \(\dq{W}\). So if logical constants are
expressions whose semantic values can be fixed by means of purely
inferential introduction and elimination rules, \(\dq{W}\) counts as
a logical constant if and only if \(\dq{\exists}\) does.</p>

<p>

Yet intuitively there is an important difference between these
constants. We might describe it this way: whereas learning the rules
\(R\) is sufficient to impart a full grasp of \(\dq{\exists}\), one could
learn the rules \(R'\) without fully understanding what is
meant by \(\dq{W}\). To understand \(\dq{W}\) one must know about
the human institution of marriage, and that accounts for our feeling
that \(\dq{W}\) is not &ldquo;topic-neutral&rdquo; enough to be a logical
constant. However, this difference between \(\dq{W}\) and \(\dq{\exists}\)
cannot be discerned if we talk only of reference or semantic value; it
is a difference in the <em>senses</em> of the two expressions.</p>

<!--pdf include
<br />
pdf include-->

<h3><a name="SenDet">6.2 Sense determination</a></h3>

<p>

The idea that introduction and/or elimination rules fix the
<em>sense</em> of a logical constant is often motivated by talk of the
rules as <em>defining</em> the constant.  Gentzen remarks that the natural
deduction rules &ldquo;represent, as it were, the
&lsquo;definitions&rsquo; of the symbols concerned, and the eliminations are no
more, in the final analysis, than the consequences of these definitions&rdquo;
(1935, &sect;5.13; 1969, 80).
However, a genuine definition would permit the constant to be
eliminated from every context in which it occurs (see the entry
on <a href="../definitions/index.html">Definitions</a>), and introduction and
elimination rules for logical constants do not, in general, permit
this. For example, in an intuitionistic sequent calculus, there is no
sequent (or group of sequents) not containing \(\dq{\rightarrow}\)
that is equivalent to the sequent \(\dq{A \rightarrow B \vdash C}\).
For this reason, Kneale
(1956, 257) says only that we can &ldquo;treat&rdquo; the rules as definitions,
Hacking (1979) speaks of the rules &ldquo;not as defining but only as characterizing
the logical constants,&rdquo; and Do&scaron;en (1994) says that the rules
provide only an &ldquo;analysis,&rdquo; not a
 definition.<sup>[<a name="note-23" href="notes.html#23">23</a>]</sup></p>

<p>

However, even if the rules are not &ldquo;definitions,&rdquo; there may still be
something to say for the claim that they &ldquo;fix the senses&rdquo; of the
constants they introduce. For it may be that a speaker&rsquo;s grasp of the
meaning of the constants consists in her mastery of these rules: her
disposition to accept inferences conforming to the rules as
&ldquo;primitively compelling&rdquo; (Peacocke 1987, Hodes 2004). (A speaker finds
an inference form primitively compelling just in case she finds it
compelling and does not take its correctness to require external
ratification, e.g. by inference.) If the senses of logical constants
are individuated in this way by the conditions for their grasp, we can
distinguish between truth-functionally equivalent constants with
different meanings, like
\(\dq{\vee}\), \(\dq{\ddagger}\), and \(\dq{\dagger}\),
as defined below:</p>

\begin{align*}
A \vee B &amp; \quad A~\text{or}~B\\
A \ddagger B &amp;  \quad \text{not both not}~A~\text{and not}~B\\
A \dagger B &amp;  \quad (A~\text{or}~B)~\text{and no widows are male}
\end{align*}

<p>

To understand \(\dq{\vee}\) one must find
the standard introduction rules primitively
compelling:</p>

\[\label{or-intro}
\frac{A}{A \vee B}
\quad
\frac{B}{A \vee B}
\]

<p>

To understand \(\dq{\ddagger}\) one must find the
following elimination rule primitively compelling:</p>

\[\label{ddagger-elim}
\frac{\neg A, \neg B, A \ddagger B}{C}
\]

<p>

Finally, to grasp the sense of \(\dq{\dagger}\) one must find these
introduction rules primitively compelling:</p>

\[\label{dagger-intro}
\frac{A, \text{no widows are male}}{A \dagger B}
\quad
\frac{B, \text{no widows are male}}{A \dagger B}
\]

<p>

\(\dq{\vee}\) and \(\dq{\ddagger}\) will count as
logical constants, because their sense-constitutive rules are purely
inferential, while \(\dq{\dagger}\) will not, because its rules are not.
(In the same way we can distinguish \(\dq{\exists}\) from
\(\dq{W}\).) Note that appropriately rewritten versions of \(\refp{or-intro}\)
will <em>hold</em> for \(\dq{\ddagger}\) and \(\dq{\dagger}\); the difference is
that one can grasp \(\dq{\ddagger}\) and \(\dq{\dagger}\) (but not
\(\dq{\vee}\)) without finding these rules <em>primitively</em>
compelling (Peacocke 1987, 156; cp. Sainsbury 2001, 370&ndash;1).</p>

<p>

Some critics have doubted that the introduction and elimination
rules for the logical constants exhaust the aspects of the use of these
constants that must be mastered if one is to understand them. For
example, it has been suggested that in order to grasp the conditional
and the universal quantifier, one must be disposed to treat certain
kinds of inductive evidence as grounds for the assertion of
conditionals and universally quantified claims (Dummett 1991, 275&ndash;8;
G&oacute;mez-Torrente 2002, 26&ndash;7; Sainsbury 2001, 370&ndash;1). It is not
clear that these additional aspects of use can be captured in &ldquo;purely
inferential&rdquo; rules, or that they can be derived from aspects of use
that can be so captured.</p>

<p>

It is sometimes thought that Prior&rsquo;s (1960) example of a
connective &ldquo;tonk,&rdquo;</p>

\[
\frac{A}{A~\text{tonk}~B} \quad \frac{A~\text{tonk}~B}{B}
\]

<p>
whose rules permit
inferring anything from anything, decisively refutes
the idea that the senses of logical constants are fixed
by their introduction and/or elimination rules. But although
Prior&rsquo;s example
(anticipated in Popper 1946&ndash;7, 284) certainly shows that <em>not all</em> sets of
introduction and elimination rules determine a coherent meaning for a
logical constant, it does not show that <em>none</em> do,
or that the logical constants are
not distinctive in having their meanings determined in this way.
For some attempts to articulate conditions under
which introduction and elimination rules do fix a meaning, see Belnap
(1962), Hacking (1979, 296&ndash;8), Kremer (1988, 62&ndash;6),
and Hodes (2004, 156&ndash;7).</p>

<p>
Prawitz (1985; 2005) argues that
 <em>any</em> formally suitable introduction rule can fix the meaning for a
logical constant. On Prawitz&rsquo;s view, the lesson we learn from Prior is that we cannot
<em>also</em> stipulate an elimination rule, but must
justify any proposed elimination rule by showing that there is a procedure
for rearranging any direct proof of the premises
of the elimination rule into a direct proof of the conclusion.
Thus, we can stipulate
the introduction rule for &ldquo;tonk&rdquo;, but must then
content ourselves with the strongest elimination rule for which such a procedure
is available:</p>

\[
\frac{A~\text{tonk}~B}{A}.
\]

<p>
Other philosophers reject Prawitz's (and Gentzen's) view that the introduction
rules have priority in fixing the meanings of constants, but
retain the idea that the introduction and elimination rules that fix the meaning of
a constant must be in <em>harmony</em>:
the elimination rules must not permit us to infer more from a compound sentence
than would be justified by the premises of the corresponding introduction rules
(Dummett 1981, 396; Tennant 1987, 76-98).
(For analyses of various notions of harmony, and their relation to notions like
normalizability and conservativeness, see Milne 1994, Read 2010, and Steinberger 2011.)
</p>

<h2><a name="PraDem">7. Pragmatic demarcations</a></h2>

<p>

The proposals for demarcating logical constants that we have
examined so far have all been <em>analytical demarcations</em>. They
have sought to identify some favored property (grammatical
particlehood, topic neutrality, permutation invariance,
characterizability by inferential rules, etc.) as a necessary and
sufficient condition for an expression to be a logical constant. A
fundamentally different strategy for demarcating the constants is to
start with a <em>job description</em> for logic and identify the
constants as the expressions that are necessary to do that job. For
example, we might start with the idea that the job of logic is to serve
as a &ldquo;framework for the deductive sytematization of scientific
theories&rdquo; (Warmbrod 1999, 516), or to characterize mathematical
structures and represent mathematical reasoning (Shapiro 1991), or to
&ldquo;[express] explicitly <em>within</em> a language the features of the
use of that language that confer conceptual contents on the states,
attitudes, performances, and expressions whose significances are
governed by those practices&rdquo; (Brandom 1994, xviii). Let us call
demarcations of this kind <em>pragmatic demarcations</em>.</p>

<p>

There are some very general differences between the two kinds of
demarcations. Unlike analytical demarcations, pragmatic demarcations
are guided by what Warmbrod calls a &ldquo;requirement of minimalism&rdquo;:</p>

<blockquote>&hellip;logical theory should be as simple, as modest in its
assumptions, and as flexible as possible given the goal of providing a
conceptual apparatus adequate for the project of systematization. In
practice, the minimalist constraint dictates that the set of terms
recognized as logical constants should be as small as possible.
(Warmbrod 1999, 521)</blockquote>

<p>

Or, in Harman&rsquo;s pithier formulation: &ldquo;Count as logic only as much as
you have to&rdquo; (Harman 1972, 79). Warmbrod uses this constraint to argue
that the theory of identity is not part of logic, on the grounds that it is
not needed to do the job he has identified for logic: &ldquo;[w]e can
systematize the same sets of sentences by recognizing only the
truth-functional connectives and first-order quantifiers as constants,
treating &lsquo;=&rsquo; as an ordinary predicate, and adopting
 appropriate axioms
for identity&rdquo; (521; cf. Quine 1986, 63, 1980, 28). On similar grounds,
both Harman and Warmbrod argue that modal operators should not be
considered part of
 logic.<sup>[<a name="note-24" href="notes.html#24">24</a>]</sup>
 Their point is not that identity or
modal operators lack some feature that the first-order quantifiers and
truth-functional operators possess, but merely that, since we
<em>can</em> get by without taking these notions to be part of our
logic, we should. Warmbrod and Tharp even explore the possibility of
taking truth-functional logic to be the whole of logic and viewing
quantification theory as a non-logical theory (Warmbrod 1999, 525;
Tharp 1975, 18), though both reject this idea on pragmatic grounds.</p>

<p>

While pragmatic demarcations seek to minimize what counts as logic,
analytical demarcations are inclusive. They count as logical
<em>any</em> expression that has the favored property. It is simply
irrelevant whether an expression is <em>required</em> for a particular
purpose: its logicality rests on features that it has independently of
any use to which we might put it.</p>

<p>

Relatedly, pragmatic approaches tend to be holistic. Because it is
whole logical <em>systems</em> that can be evaluated as sufficient or
insufficient for doing the &ldquo;job&rdquo; assigned to logic, properties of
systems tend to be emphasized in pragmatic demarcations. For example,
Wagner (1987, 10&ndash;11) invokes Lindstrom&rsquo;s theorem&mdash;that first-order
logic is the only logic that is either complete or compact and
satisfies the L&ouml;wenheim-Skolem theorem&mdash;in arguing that logic
should be limited to first-order logic, and Kneale and Kneale (1962,
724, 741) invoke G&ouml;del&rsquo;s incompleteness theorems to similar
effect. Although nothing about the idea of an analytical demarcation
excludes appeal to properties of whole systems, analytical demarcations
tend to appeal to <em>local</em> properties of particular expressions
rather than global systemic properties.</p>

<p>

Finally, on a pragmatic demarcation, what counts as logic may depend
on the current state of scientific and mathematical theory. If the
advance of science results in an increase or decrease in the resources
needed for deductive systematization of science (or whatever is the
favored task of logic), what counts as logic changes accordingly
(Warmbrod 1999, 533). On an analytical demarcation, by contrast,
whether particular resources are logical depends only on whether they
have the favored property. If they do not, and if it turns out that
they are needed for the deductive systematization of theories, then the
proper conclusion to draw is that logic alone is not adequate for this
task.</p>

<h2><a name="ProPse">8. Problem or pseudoproblem?</a></h2>

<p>

Now that we have gotten a sense for the tremendous variety of
approaches to the problem of logical constants, let us step back and
reflect on the problem itself and its motivation. We can distinguish
four general attitudes toward the problem of logical constants: those
of the Demarcater, the Debunker, the Relativist, and the Deflater.</p>

<p>

<em>Demarcaters</em> hold that the demarcation of logical constants
is a genuine and important problem, whose solution can be expected to
illuminate the nature and special status of logic. On their view, the
task of logic is to study features that arguments possess in virtue of
their logical forms or
 structures.<sup>[<a name="note-25" href="notes.html#25">25</a>]</sup>
 Although there may be some sense in
which the argument</p>

\[\label{chicago-north}
\frac{\text{Chicago is north of New Orleans}}
{\text{New Orleans is south of Chicago}}
\]

<p>
is a good or &ldquo;valid&rdquo; argument, it is not <em>formally</em> valid.  On
the Demarcater&rsquo;s view, logicians who investigate the (non-formal) kind
of &ldquo;validity&rdquo; possessed by \(\refp{chicago-north}\) are straying from
the proper province
of logic into some neighboring domain (here, geography or lexicography;
in other cases, mathematics or metaphysics). For the Demarcater, then,
understanding the distinction between logical and nonlogical constants
is essential for understanding what logic is about. (For a forceful
statement of the Demarcater&rsquo;s point of view, see Kneale 1956.)</p>

<p>

<em>Debunkers</em>, on the other hand, hold that the so-called
&ldquo;problem of logical constants&rdquo; is a pseudoproblem (Bolzano 1929,
&sect;186; Lakoff 1970, 252&ndash;4; Coffa 1975; Etchemendy 1983, 1990,
ch.&nbsp;9; Barwise and Feferman 1985, 6; Read 1994). They do not
dispute that logicians have traditionally concerned themselves with
argument forms in which a limited number of expressions occur
essentially. What they deny is that these expressions and argument
forms define the <em>subject matter</em> of logic. On their view, logic
is concerned with validity <em>simpliciter</em>, not just validity that
holds in virtue of a limited set of &ldquo;logical forms.&rdquo; The logician&rsquo;s
<em>method</em> for studying validity is to classify arguments by their
forms, but these forms (and the logical constants that in part define
them) are logic&rsquo;s <em>tools</em>, not its subject matter. The forms and
constants with which logicians are concerned at a particular point in
the development of logic are just a reflection of the logicians&rsquo;
progress (up to that point) in systematically classifying valid
inferences. Asking what is special about these forms and constants is
thus a bit like asking what is special about the mountains that can be
climbed in a day: &ldquo;The information so derived will be too closely
dependent upon the skill of the climber to tell us much about
geography&rdquo; (Coffa 1975, 114). What makes people logicians is not their
concern with &ldquo;and&rdquo;, &ldquo;or&rdquo;, and &ldquo;not&rdquo;, but their concern with validity,
consequence, consistency, and proof, and the distinctive methods they
bring to their investigations.</p>

<p>

A good way to see the practical difference between Debunkers and
Demarcaters is by contrasting their views on the use of counterexamples
to show invalidity. Demarcaters typically hold that one can show an
argument to be invalid by exhibiting another argument with the same
logical form that has true premises and a false conclusion. Of course,
an argument will always instantiate multiple forms. For example, the
argument</p>

\[\label{firefighter}
\frac{\text{Firefighter(Joe)}}
{\exists x\,\text{Firefighter}(x)}
\]

<p>can be seen as an instance of the propositional logical form</p>

\[\label{propform}
\frac{P}{Q}
\]

<p>as well as the more articulated form</p>

\[\label{quantform}
\frac{F(a)}
{\exists x F(x)}.
\]

<p>
As Massey (1975) reminds us, the fact that there are other arguments
with the form \(\refp{propform}\) that have true premises and a false conclusion does
not show that \(\refp{firefighter}\) is invalid (or even that it is
&ldquo;formally&rdquo; invalid).
The Demarcater will insist that a genuine counterexample to the formal
validity of \(\refp{firefighter}\) would have to exhibit the <em>full</em>
logical structure of \(\refp{firefighter}\), which is not \(\refp{propform}\) but
\(\refp{quantform}\).  Thus the Demarcater&rsquo;s
use of counterexamples to demonstrate the formal invalidity of
arguments presupposes a principled way of discerning the <em>full</em>
logical structure of an argument, and hence of distinguishing logical
constants from nonlogical
 constants.<sup>[<a name="note-26" href="notes.html#26">26</a>]</sup></p>

<p>

The Debunker, by contrast, rejects the idea that one of the many
argument forms \(\refp{firefighter}\) instantiates should be privileged as
<em>the</em> logical form of \(\refp{firefighter}\). On the Debunker&rsquo;s
view, counterexamples never
show anything about a particular argument. All they show is that a
<em>form</em> is invalid (that is, that it has invalid instances). To
show that a particular <em>argument</em> is invalid, one sort of Debunker
holds, one needs to describe a possible situation in which the premises
would be true and the conclusion false, and to give a formal
counterexample is not to do <em>that</em>.</p>

<p>

The Demarcater will object that the Debunker&rsquo;s tolerant attitude
leaves us with no coherent distinction between logic and other
disciplines. For surely it is the chemist, not the logician, who will
be called upon to tell us whether the following argument is a good
one:</p>

\[\label{litmus}
\frac{\text{HCl turns litmus paper red}}
{\text{HCl is an acid}}.
\]

<p>
Without a principled distinction between logical and nonlogical
constants, it seems, logic would need to be a kind of universal
science: not just a canon for inference, but an encyclopedia. If logic
is to be a distinctive discipline, the Demarcater will argue, it must
concern itself not with all kinds of validity or goodness of arguments,
but with a special, privileged kind: <em>formal</em> validity.</p>

<p>

Against this, the Debunker might insist that deductive validity is a
feature arguments have by virtue of the meanings of the terms contained
in them, so that anyone who understands the premises and conclusion of
an argument must be in a position to determine, without recourse to
empirical investigation, whether it is valid. On this conception, logic
is the study of <em>analytic</em> truth, consequence, consistency, and
validity. Because the relation between premise and conclusion in
\(\refp{litmus}\)
depends on empirical facts, not the meanings of terms, \(\refp{litmus}\) is not
deductively
 valid.<sup>[<a name="note-27" href="notes.html#27">27</a>]</sup></p>

<p>

This response will not be available to those who have reservations
about the
 <a href="../analytic-synthetic/index.html">analytic/synthetic distinction</a>.
 An important example is Tarski (1936a; 1936b; 1983;
1987; 2002), who was much concerned to define logical truth and
consequence in purely mathematical terms, without appealing to suspect
modal or epistemic notions. On Tarski&rsquo;s account, an argument is valid
just in case there is no interpretation of its nonlogical constants on
which the premises are true and the conclusion false. On this account,
an argument containing no nonlogical constants is valid just in case it
is materially truth-preserving (it is not the case that its premises
are true and its conclusion false). Thus, as Tarski notes, if
<em>every</em> expression of a language counted as a logical constant,
logical validity would reduce to material truth preservation (or, on
later versions of Tarski&rsquo;s definition, to material truth preservation
on every nonempty domain) (1983, 419). Someone who found this result
intolerable might take it to show either that there <em>must</em> be a
principled distinction between logical and nonlogical constants (the
Demarcater&rsquo;s conclusion), or that Tarski&rsquo;s definition is misguided (the
Debunker&rsquo;s conclusion; see Etchemendy 1990, ch. 9).</p>

<p>

Tarski&rsquo;s own reaction was more cautious. After concluding that the
distinction is &ldquo;certainly not quite arbitrary&rdquo; (1983, 418), he
writes:</p>

<blockquote>Perhaps it will be possible to find important objective
arguments which will enable us to justify the traditional boundary
between logical and extra-logical expressions. But I also consider it
to be quite possible that investigations will bring no positive
results in this direction, so that we shall be compelled to regard
such concepts as &lsquo;logical consequence&rsquo;, &lsquo;analytical
statement&rsquo;, and &lsquo;tautology&rsquo; as relative concepts
which must, on each occasion, be related to a definite, although in
greater or less degree arbitrary, division of terms into logical and
extra-logical. (420; see also Tarski 1987)</blockquote>

<p>

Here Tarski is describing a position distinct from both the
Demarcater&rsquo;s position and the Debunker&rsquo;s. The <em>Relativist</em>
agrees with the Demarcater that logical consequence must be understood
as <em>formal</em> consequence, and so presupposes a distinction
between logical and nonlogical constants. But she agrees with the
Debunker that we should not ask, &ldquo;Which expressions are logical
constants and which are not?&rdquo; The way she reconciles these apparently
conflicting positions is by <em>relativizing</em> logical consequence
to a choice of logical constants. For each set <em>C</em> of logical
constants, there will be a corresponding notion of
<em>C</em>-consequence. None of these notions is to be identified with
consequence <em>simpliciter</em>; different ones are useful for
different purposes. In the limiting case, where every expression of the
language is taken to be a logical constant, we get material
consequence, but this is no more (and no less) <em>the</em> consequence
relation than any of the others.</p>

<p>

Like the Relativist, the <em>Deflater</em> seeks a moderate middle
ground between the Demarcater and the Debunker. The Deflater agrees
with the Demarcater that there is a real distinction between logical
and nonlogical constants, and between formally and materially valid
arguments. She rejects the Relativist&rsquo;s position that logical
consequence is a relative notion. But she also rejects the Demarcater&rsquo;s
project of finding precise and illuminating necessary and sufficient
conditions for logical constancy. &ldquo;Logical constant&rdquo;, she holds, is a
&ldquo;family resemblance&rdquo; term, so we should not expect to uncover a hidden
essence that all logical constants share. As Wittgenstein said about
the concept of number: &ldquo;the strength of the thread does not reside in
the fact that some one fibre runs through its whole length, but in the
overlapping of many fibres&rdquo; (Wittgenstein 1958, &sect;67). That does
not mean that there is no distinction between logical and nonlogical
constants, any more than our inability to give a precise definition of
&ldquo;game&rdquo; means that there is no difference between games and other
activities. Nor does it mean that the distinction does not matter. What
it means is that we should not expect a principled criterion for
logical constancy that explains why logic has a privileged
epistemological or semantic status. (For a nice articulation of this
kind of view, see G&oacute;mez-Torrente 2002.)</p>

<p>

The debate between these four positions cannot be resolved here,
because to some extent &ldquo;the proof is in the pudding.&rdquo; A compelling and
illuminating account of logical constants&mdash;one that vindicated a
disciplinary segregation of \(\refp{chicago-north}\) from
\(\refp{firefighter}\) by showing how these arguments are importantly
different&mdash;might give us reason to be Demarcaters. But it is
important not to get so caught up in the debates between different
Demarcaters, or between Demarcaters and Debunkers, that one loses sight
of the other positions one might take toward the problem of logical
 constants.</p>

<h2><a name="FurRea">Further reading</a></h2>

<p>

Other recent general discussions of the problem of logical constants
include Peacocke 1976, McCarthy 1998, Warmbrod 1999, Sainsbury 2001,
ch. 6, and G&oacute;mez-Torrente 2002. Tarski 1936b is essential
background to all of these.</p>

<p>

For a discussion of grammatical criteria for logical terms, see
Quine 1980 and F&oslash;llesdal&rsquo;s (1980) reply.</p>

<p>

For a discussion of the Davidsonian approach, see
Davidson 1984, Evans 1976, Lycan 1989, Lepore and Ludwig 2002,
and Edwards 2002.</p>

<p>

Tarski 1986 is a brief and cogent exposition of the
permutation-invariance approach. For elaboration and
criticism, see McCarthy 1981, van Bentham 1989,
Sher 1991, McGee 1996, Feferman 1999 and 2010, Bonnay 2008,
and Dutilh Novaes 2014. Bonnay 2014 surveys recent work
in this area.
</p>

<p>

Hacking 1979 and Peacocke 1987 are good representatives of the two
versions of the inferential characterization approach discussed above.
Popper&rsquo;s papers (1946&ndash;7, 1947) are still worth reading; see
Schroeder-Heister 1984 for critical discussion and Koslow 1999 for a
modern approach reminiscent of Popper&rsquo;s. See also Kneale 1956, Kremer
1988, Prawitz 1985 and 2005, Tennant 1987, ch. 9, Dummett 1991, ch. 11, Do&scaron;en 1994, Hodes
2004, and Read 2010.</p>

<p>

For examples of pragmatic demarcations, see Wagner 1987 and
Warmbrod 1999.  A different kind of pragmatic approach can
be found in Brandom (2000, ch. 1; 2008, ch. 2), who characterizes
logical vocabulary in terms of its <em>expressive</em> role.</p>

<p>

For critiques of the whole project of demarcating the logical
constants, see Coffa 1975, Etchemendy (1983; 1990, ch. 9), and Read
1994.</p>

</div>

<div id="bibliography">

<h2><a name="Bib">Bibliography</a></h2>

<ul class="hanging">

<li>Barwise, J. and S. Feferman (eds.), 1985. <em>Model-Theoretic
Logics</em>, New York: Springer-Verlag.</li>

<li>Belnap, N. D., 1962. &ldquo;Tonk, Plonk and
Plink,&rdquo; <em>Analysis</em>, 23: 130&ndash;134.</li>

<li>&ndash;&ndash;&ndash;, 1982. &ldquo;Display
Logic,&rdquo; <em>Journal of Symbolic Logic</em>, 11:
357&ndash;417.</li>

<li>Bolzano, B., 1929. <em>Wissenschaftslehre</em> (2nd edition),
Leipzig: Felix Meiner.</li>

<li>Bonnay, D., 2008. &ldquo;Logicality and Invariance,&rdquo;
<em>Bulletin of Symbolic Logic</em>, 14: 29&ndash;68.</li>

<li>&ndash;&ndash;&ndash;, 2014. &ldquo;Logical Constants, or How to
use Invariance in Order to Complete the Explication of Logical
Consequence,&rdquo; <em>Philosophy Compass</em>, 9: 54&ndash;65.</li>

<li>Boolos, G., 1975. &ldquo;On Second-order Logic,&rdquo; <em>Journal
of Philosophy</em>, 72: 509&ndash;527.</li>

<li>Brandom, R., 1994. <em>Making It Explicit</em>, Cambridge: Harvard
University Press.</li>

<li>&ndash;&ndash;&ndash;, 2000. <em>Articulating Reasons: An
  Introduction to Inferentialism</em>, Cambridge: Harvard University
  Press.</li>

<li>&ndash;&ndash;&ndash;, 2008. <em>Between Saying and Doing: Towards
an Analytic Pragmatism</em>, Oxford: Oxford University Press.</li>

<li>Bueno, O., and S. A. Shalkowski, 2013. &ldquo;Logical Constants: A
Modalist Approach,&rdquo; <em>No&ucirc;s</em>, 47: 1&ndash;24.</li>

<li>Buridan, J., 1976. <em>Tractatus de Consequentiis</em>, Louvain:
Publications Universitaires.</li>

<li>Carnap, R., 1947. <em>Meaning and Necessity</em>, Chicago:
University of Chicago Press.</li>

<li>Chomsky, N., 1995. <em>The Minimalist Program</em>, Cambridge: MIT
Press.</li>

<li>Coffa, J. A., 1975. &ldquo;Machian Logic,&rdquo; <em>Communication
and Cognition</em>, 8: 103&ndash;129.</li>

<li>Davidson, D., 1984. <em>Inquiries into Truth and
Interpretation</em>, Oxford: Oxford University Press.</li>

<li>Do&scaron;en, K., 1994. &ldquo;Logical Constants as Punctuation
Marks,&rdquo; in D.&nbsp;M. Gabbay (ed.), <em>What Is a Logical
System?</em>, Oxford: Clarendon Press, 273&ndash;296.</li>

<li>Dummett, M., 1981. <em>Frege: Philosophy of Language</em> (2nd
edition), Cambridge: Harvard University Press.</li>

<li>&ndash;&ndash;&ndash;, 1991. <em>The Logical Basis of
Metaphysics</em>, Cambridge: Harvard University Press.</li>

<li>Dutilh Novaes, Catarina, 2012. &ldquo;Reassessing Logical
Hylomorphism and the Demarcation of Logical
Constants,&rdquo; <em>Synthese</em>, 185: 387&ndash;410.</li>

<li>&ndash;&ndash;&ndash;, 2014. &ldquo;The Undergeneration of
Permutation Invariance as a Criterion for Logicality,&rdquo;
<em>Erkenntnis</em>, 79: 81&ndash;97.</li>

<li>Edwards, J., 2002. &ldquo;Theories of Meaning and Logical
Constants: Davidson versus Evans,&rdquo; <em>Mind</em>, 111:
249&ndash;279.</li>

<li>Etchemendy, J., 1983. &ldquo;The Doctrine of Logic as Form,&rdquo;
<em>Linguistics and Philosophy</em>, 6: 319&ndash;334.</li>

<li>&ndash;&ndash;&ndash;, 1990. <em>The Concept of Logical
Consequence</em>, Cambridge, MA: Harvard University Press.</li>

<li>&ndash;&ndash;&ndash;, 2008. &ldquo;Reflections on
Consequence&rdquo; in <em>New Essays on Tarski and Philosophy</em>,
Douglas Patterson (ed.), New York: Oxford University Press,
pp. 263&ndash;299.</li>

<li>Evans, G., 1976. &ldquo;Semantic Structure and Logical
Form,&rdquo; in G.&nbsp;Evans and J.&nbsp;McDowell (eds.), <em>Truth
and Meaning: Essays in Semantics</em>, Oxford: Clarendon Press,
199&ndash;222.</li>

<li>Feferman, S., 1999. &ldquo;Logic, Logics, and
Logicism,&rdquo; <em>Notre Dame Journal of Formal Logic</em>, 40:
31&ndash;54.</li>

<li>&ndash;&ndash;&ndash;, 2010. &ldquo;Set-theoretical Invariance
Criteria for Logicality,&rdquo; <em>Notre Dame Journal of Formal
Logic</em>, 51: 3&ndash;19.</li>

<li>&ndash;&ndash;&ndash;, 2015. &ldquo;Which Quantifiers are Logical?
A combined semantical and inferential criterion,&rdquo; In Alessandro
Torza (ed.), <em>Quantifiers, Quantifiers, and Quantifiers</em>,
Dordrecht: Springer (Synthese Library).</li>

<li>F&oslash;llesdal, D., 1980. &ldquo;Comments on Quine,&rdquo; in
S.&nbsp;Kanger and S.&nbsp;&Ouml;hman (eds.), <em>Philosophy and
Grammar</em>, Dordrecht: D. Reidel, 29&ndash;35.</li>

<li>Frege, G., 1885. &ldquo;&Uuml;ber formale Theorien der
Arithmetik&rdquo; (&ldquo;On Formal Theories of
Arithmetic&rdquo;). <em>Sitzungsberichte der Jenaischen Gesellschaft
f&uuml;r Medizin und Naturwissenschaft</em> (Supplement), 2:
94&ndash;104.</li>

<li>&ndash;&ndash;&ndash;, 1906. &ldquo;&Uuml;ber die Grundlagen der
Geometrie II&rdquo; (&ldquo;On the Foundations of Geometry: Second
series&rdquo;). <em>Jahresbericht der Deutschen Mathematiker
Vereiningung</em>, 15: 293&ndash;309, 377&ndash;403,
423&ndash;430.</li>

<li>&ndash;&ndash;&ndash;, 1984. <em>Collected Papers on Mathematics,
Logic, and Philosophy</em>, Oxford: Basil Blackwell.</li>

<li>Gabbay, D. M. (ed.), 1994. <em>What Is a Logical System?</em>
Oxford: Clarendon Press.</li>

<li>Gentzen, G., 1935. &ldquo;Untersuchungen &uuml;ber das logische
Schliessen&rdquo; (&ldquo;Investigations into Logical
Deduction&rdquo;).
<em>Mathematisches Zeitschrift</em>, 39: 176&ndash;210, 405&ndash;431.</li>

<li>&ndash;&ndash;&ndash;, 1969. <em>The Collected Papers of Gerhard
Gentzen</em>, Amsterdam: North Holland.</li>

<li>G&oacute;mez-Torrente, M., 2002. &ldquo;The Problem of Logical
Constants,&rdquo; <em>Bulletin of Symbolic Logic</em>, 8:
1&ndash;37.</li>

<li>Goodman, N., 1961. &ldquo;About,&rdquo; <em>Mind</em>, 70:
1&ndash;24.</li>

<li>Haack, S., 1978. <em>Philosophy of Logics</em>, Cambridge:
Cambridge University Press.</li>

<li>Hacking, I., 1979. &ldquo;What is Logic?&rdquo; <em>Journal of
Philosophy</em> 76: 285&ndash;319.</li>

<li>Harman, G., 1972. &ldquo;Is Modal Logic
Logic?&rdquo; <em>Philosophia</em>, 2: 75&ndash;84.</li>

<li>&ndash;&ndash;&ndash;, 1984. &ldquo;Logic and
Reasoning,&rdquo; <em>Synthese</em>, 60: 107&ndash;127.</li>

<li>Hodes, H., 2004. &ldquo;On the Sense and Reference of a Logical
Constant,&rdquo; <em>Philosophical Quarterly</em>, 54:
134&ndash;165.</li>

<li>Kaplan, D., 1989. &ldquo;Demonstratives: An Essay on the
Semantics, Logic, Metaphysics, and Epistemology of Demonstratives and
Other Indexicals,&rdquo; in J.&nbsp;Almog, J.&nbsp;Perry, and
H.&nbsp;Wettstein (eds.), <em>Themes from Kaplan</em>, Oxford: Oxford
University Press, 481&ndash;566.</li>

<li>Klein, F., 1893. &ldquo;A Comparative Review of Recent Researches
in Geometry,&rdquo; <em>New York Mathematical Society Bulletin</em>,
2: 215&ndash;249.</li>

<li>Kneale, W., 1956. &ldquo;The Province of Logic,&rdquo; in
H.&nbsp;D, Lewis (ed.), <em>Contemporary British Philosophy</em>,
London: George Allen and Unwin, 237&ndash;261.</li>

<li>Kneale, W. and M. Kneale, 1962. <em>The Development of Logic</em>,
Oxford: Oxford University Press.</li>

<li>Koslow, A., 1992. <em>A Structuralist Theory of Logic</em>,
Cambridge: Cambridge University Press.</li>

<li>&ndash;&ndash;&ndash;, 1999. &ldquo;The Implicational Nature of
Logic: A Structuralist Account,&rdquo; <em>European Philosophical
Review</em>, 4: 111&ndash;155.</li>

<li>Kremer, M., 1988. &ldquo;Logic and Meaning: The Philosophical
Significance of the Sequent Calculus,&rdquo; <em>Mind</em>, 47:
50&ndash;72.</li>

<li>Kretzmann, N., 1982. &ldquo;Syncategorema, Exponibilia,
Sophismata,&rdquo; in N.&nbsp;Kretzmann, A.&nbsp;Kenny, and
J.&nbsp;Pinborg (eds.), <em>The Cambridge History of Later Medieval
Philosophy</em>, Cambridge: Cambridge University Press,
211&ndash;245.</li>

<li>Kripke, S., 1971. &ldquo;Identity and Necessity,&rdquo; in
M. K. Munitz (ed.), <em>Identity and Individuation</em>, New York: New
York University Press, 135&ndash;64.</li>

<li>&ndash;&ndash;&ndash;, 1980. <em>Naming and Necessity</em>,
Cambridge: Harvard University Press.</li>

<li>Kuhn, S. T., 1981. &ldquo;Logical Expressions, Constants, and
Operator Logic,&rdquo; <em>Journal of Philosophy</em>, 78:
487&ndash;499.</li>

<li>Lakoff, G., 1970. &ldquo;Linguistics and Natural Logic,&rdquo;
<em>Synthese</em>, 22: 151&ndash;271.</li>

<li>Lepore, E. and K. Ludwig, 2002. &ldquo;What is Logical
Form?&rdquo; in G.&nbsp;Preyer and G.&nbsp;Peter (eds.), <em>Logical
Form and Language</em>, Oxford: Clarendon Press, 54&ndash;90.</li>

<li>Lewis, D., 1988. &ldquo;Relevant
Implication,&rdquo; <em>Theoria</em>, 54: 161&ndash;174.</li>

<li>Lindenbaum, A. and A. Tarski, 1934&ndash;5. &ldquo;&Uuml;ber die
Beschr&auml;nktheit der Ausdrucksmittel deduktiver Theorien&rdquo;
(&ldquo;On the Limitations of the Means of Expression of Deductive
Theories&rdquo;). <em>Ergebnisse eines mathematischen
Kolloquiums</em>, 7: 15&ndash;22. (English translation in Tarski
1983.)</li>

<li>Lycan, W. G., 1989. &ldquo;Logical Constants and the Glory of
Truth-conditional Semantics,&rdquo; <em>Notre Dame Journal of Formal
Logic</em>, 30: 390&ndash;401.</li>

<li>MacFarlane, J., 2002. &ldquo;Frege, Kant, and the Logic in
Logicism,&rdquo;
<em>Philosophical Review</em>, 111, 25&ndash;65.</li>

<li>Massey, G. J., 1975. &ldquo;Are There Any Good Arguments that Bad
Arguments are Bad?&rdquo; <em>Philosophy in Context</em>, 4:
61&ndash;77.</li>

<li>Mautner, F. I., 1946. &ldquo;An Extension of Klein&rsquo;s
Erlanger Program: Logic as Invariant-theory,&rdquo; <em>Americal
Journal of Mathematics</em> 68: 345&ndash;384.</li>

<li>McCarthy, T., 1981. &ldquo;The Idea of a Logical
Constant,&rdquo; <em>Journal of Philosophy</em>, 78:
499&ndash;523.</li>

<li>&ndash;&ndash;&ndash;, 1987. &ldquo;Modality, Invariance, and
Logical Truth,&rdquo;
<em>Journal of Philosophical Logic</em>, 16: 423&ndash;443.</li>

<li>&ndash;&ndash;&ndash;, 1998. &ldquo;Logical Constants,&rdquo; in
E.&nbsp;Craig (ed,), <em>Routledge Encyclopedia of Philosophy</em>
(Volume 5), London: Routledge, 599&ndash;603.</li>

<li>McGee, V., 1996. &ldquo;Logical Operations,&rdquo; <em>Journal of
Philosophical Logic</em>, 25: 567&ndash;580.</li>

<li>Milne, P., 1994. &ldquo;Clasical Harmony: Rules of
Inference and the Meaning of the Logical Constants.&rdquo;
<em>Synthese</em>, 100: 49&ndash;94.</li>

<li>Mostowski, A., 1957. &ldquo;On a Generalization of
Quantifiers,&rdquo;
<em>Fundamenta Mathematicae</em>, 44: 12&ndash;35.</li>

<li>Neale, S., 1990. <em>Descriptions</em>, Cambridge, MA: MIT
Press.</li>

<li>Peacocke, C., 1976. &ldquo;What Is a Logical
Constant?&rdquo; <em>Journal of Philosophy</em>, 73:
221&ndash;240.</li>

<li>&ndash;&ndash;&ndash;, 1987. &ldquo;Understanding Logical
Constants: A Realist&rsquo;s Account,&rdquo; <em>Proceedings of the
British Academy</em>, 73: 153&ndash;200.  Reprinted in T. J. Smiley
and T. R. Baldwin (eds.), <em>{Studies in the Philosophy of Logic and
Knowledge</em> (Oxford: Oxford University Press, 2004),
163&ndash;208.</li>

<li>Popper, K. R., 1946&ndash;7. &ldquo;Logic Without
Assumptions,&rdquo; <em>Proceedings of the Aristotelian Society</em>
(New Series), 47: 251&ndash;292.</li>

<li>&ndash;&ndash;&ndash;, 1947. &ldquo;New Foundations for
Logic,&rdquo; <em>Mind</em>, 56: 193&ndash;235. (Errata
in <em>Mind</em>, 57: 69.)</li>

<li>Prawitz, D., 1985. &ldquo;Remarks on Some Approaches to the
Concept of Logical Consequence,&rdquo; <em>Synthese</em>, 62:
153&ndash;171.</li>

<li>&ndash;&ndash;&ndash;, 2005. &ldquo;Logical Consequence from a
Constructive Point of View,&rdquo; in S. Shapiro (ed.), <em>The Oxford
Handbook of Philosophy of Mathematics and Logic</em>, Oxford: Oxford
University Press, 671&ndash;95.</li>

<li>Prior, A. N., 1960. &ldquo;The Runabout Inference-ticket,&rdquo;
<em>Analysis</em>, 21: 38&ndash;39.</li>

<li>Quine, W. V., 1980. &ldquo;Grammar, Truth, and Logic,&rdquo; in
S.&nbsp;Kanger and S.&nbsp;&Ouml;man (eds.), <em>Philosophy and
Grammar</em>, Dordrecht: D. Reidel, 17&ndash;28.</li>

<li>&ndash;&ndash;&ndash;, 1986. <em>Philosophy of Logic</em> (2nd
edition), Cambridge: Harvard University Press.</li>

<li>Radford, A., 2004. <em>Minimalist Syntax: Exploring the Structure
of English</em>, Cambridge: Cambridge University Press.</li>

<li>Read, S., 1994. &ldquo;Formal and Material
Consequence,&rdquo; <em>Journal of Philosophical Logic</em>, 23:
247&ndash;265.</li>

<li>&ndash;&ndash;&ndash;, 2010. &ldquo;General-Elimination Harmony
and the Meaning of the Logical Constants,&rdquo; <em>Journal of
Philosophical Logic</em>, 39: 557&ndash;576.</li>

<li>Ricketts, T., 1997. &ldquo;Frege&rsquo;s 1906 Foray into
Metalogic,&rdquo;
<em>Philosophical Topics</em>, 25: 169&ndash;188.</li>

<li>Russell, B., 1920. <em>Introduction to Mathematical
Philosophy</em>, London. George Allen and Unwin.</li>

<li>&ndash;&ndash;&ndash;, 1992. <em>Theory of Knowledge: The 1913
Manuscript</em>, London: Routledge.</li>

<li>Ryle, G., 1954. <em>Dilemmas</em>, Cambridge: Cambridge University
Press.</li>

<li>Sainsbury, M., 2001. <em>Logical Forms: An Introduction to
Philosophical Logic</em> (2nd edition), Oxford: Blackwell.</li>

<li>Schroeder-Heister, P., 1984. &ldquo;Popper&rsquo;s Theory of
Deductive Inference and the Concept of a Logical
Constant,&rdquo; <em>History and Philosophy of Logic</em>, 5:
79&ndash;110.</li>

<li>Scott, D., 1970. &ldquo;Advice on Modal Logic,&rdquo; in
K.&nbsp;Lambert (ed.),
<em>Philosophical Problems in Logic: Some Recent Developments</em>,
Dordrecht: D. Reidel, 143&ndash;173.</li>

<li>Sellars, W., 1962. &ldquo;Naming and Saying,&rdquo; <em>Philosophy
of Science</em>, 29: 7&ndash;26.</li>

<li>Shapiro, S., 1991. <em>Foundations Without Foundationalism: A Case
for Second-Order Logic</em>, Oxford: Oxford University Press.</li>

<li>Sher, G., 1991. <em>The Bounds of Logic: a Generalized
Viewpoint</em>, Cambridge, MA: MIT Press.</li>

<li>&ndash;&ndash;&ndash;, 1996. &ldquo;Did Tarski Commit
&lsquo;Tarski&rsquo;s Fallacy&rsquo;?&rdquo; <em>Journal of Symbolic
Logic</em>, 61: 653&ndash;686.</li>

<li>&ndash;&ndash;&ndash;, 2003. &ldquo;A Characterization of Logical
Constants <em>Is</em> Possible,&rdquo; <em>Theoria: Revista de Teoria,
Historia y Fundamentos de la Ciencia</em>, 18: 189&ndash;197.</li>

<li>Steinberger, F., 2011. &ldquo;What Harmony Could and Could Not
Be.&rdquo; <em>Australasian Journal of Philosophy</em>,
89: 617&ndash;39.</li>

<li>Tarski, A., 1936a. &ldquo;O pojeciu wynikania logicznego&rdquo;
(&ldquo;On the Concept of Logical Consequence&rdquo;). <em>Przeglad
Filozoficzny</em>, 39: 58&ndash;68.  (English translation in Tarski
2002.)</li>

<li>&ndash;&ndash;&ndash;, 1936b. &ldquo;&Uuml;ber den Begriff der
logischen Folgerung&rdquo; (&ldquo;On the Concept of Logical
Consequence&rdquo;), <em>Actes du Congr&egrave;s International de
Philosophie Scientifique</em>, 7: 1&ndash;11. (English translation in
Tarski 1983, 409&ndash;20.)</li>

<li>&ndash;&ndash;&ndash;, 1983. <em>Logic, Semantics,
Metamathematics</em>, J.&nbsp;Corcoran (ed.). Indianapolis:
Hackett.</li>

<li>&ndash;&ndash;&ndash;, 1986. &ldquo;What are Logical
Notions?&rdquo; <em>History and Philosophy of Logic</em>, 7:
143&ndash;154. (Transcript of a 1966 talk, ed.
J.&nbsp;Corcoran.)</li>

<li>&ndash;&ndash;&ndash;, 1987. &ldquo;A Philosophical Letter of
Alfred Tarski,&rdquo; <em>Journal of Philosophy</em>, 84:
28&ndash;32. (Letter to Morton White, written in 1944.)</li>

<li>&ndash;&ndash;&ndash;, 2002. &ldquo;On the Concept of Following
Logically,&rdquo; <em>History and Philosophy of Logic</em>, 23:
155&ndash;196. (Translation of Tarski 1936a by M.&nbsp;Stroinska and
D.&nbsp;Hitchcock.)</li>

<li>Tennant, N., 1987. <em>Anti-realism and Logic.</em>  Oxford: Clarendon Press.</li>

<li>Tharp, L. H., 1975. &ldquo;Which Logic Is the Right Logic?&rdquo;
<em>Synthese</em>, 31: 1&ndash;21.</li>

<li>van Benthem, J., 1989. &ldquo;Logical Constants Across Varying
Types,&rdquo;
<em>Notre Dame Journal of Formal Logic</em>, 30: 315&ndash;342.</li>

<li>Wagner, S. J., 1987. &ldquo;The Rationalist Conception of
Logic,&rdquo;
<em>Notre Dame Journal of Formal Logic</em>, 28: 3&ndash;35.</li>

<li>Warmbrod, K., 1999. &ldquo;Logical
Constants,&rdquo; <em>Mind</em>, 108: 503&ndash;538.</li>

<li>Wittgenstein, L., 1922. <em>Tractatus Logico-Philosophicus</em>,
Trans. C.&nbsp;K.&nbsp;Ogden. London: Routledge and Kegan Paul.</li>

<li>&ndash;&ndash;&ndash;, 1958. <em>Philosophical Investigations</em>
(2nd ed.).  Trans. G. E. M. Anscombe. Oxford: Blackwell.</li>

<li>Wright, C., 1983. <em>Frege&rsquo;s Conception of Numbers as
Objects</em>, Scots Philosophical Monographs, Aberdeen: Aberdeen
University Press.</li>

<li>Zucker, J. I., 1978. &ldquo;The Adequacy Problem for Classical
Logic,&rdquo;
<em>Journal of Philosophical Logic</em>, 7: 517&ndash;535.</li>

<li>&ndash;&ndash;&ndash;, and R. S. Tragesser, 1978. &ldquo;The
Adequacy Problem for Inferential Logic,&rdquo; <em>Journal of
Philosophical Logic</em>, 7: 501&ndash;516.</li>
</ul>

</div>

<div id="academic-tools">

<h2><a id="Aca">Academic Tools</a></h2>

<blockquote>
<table>
<tr><td valign="top"><img src="../../symbols/sepman-icon.jpg" alt="sep man icon" /></td>
<td><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=logical-constants" target="other">How to cite this entry</a>.</td>
</tr>
<tr><td valign="top"><img src="../../symbols/sepman-icon.jpg" alt="sep man icon" /></td>
<td><a href="https://leibniz.stanford.edu/friends/preview/logical-constants/" target="other">Preview the PDF version of this entry</a> at the <a href="https://leibniz.stanford.edu/friends/" target="other">Friends of the SEP Society</a>.</td>
</tr>
<tr><td valign="top"><img src="../../symbols/inpho.png" alt="inpho icon" /></td>
<td><a href="https://www.inphoproject.org/entity?sep=logical-constants&amp;redirect=True" target="other">Look up topics and thinkers related to this entry</a>
 at the Internet Philosophy Ontology Project (InPhO).</td>
</tr>
<tr><td valign="top"><img src="../../symbols/pp.gif" alt="phil papers icon" /></td>
<td><a href="http://philpapers.org/sep/logical-constants/" target="other">Enhanced bibliography for this entry</a> at <a href="http://philpapers.org/" target="other">PhilPapers</a>, with links to its database.</td>
</tr>
</table>
</blockquote>

</div>

<div id="other-internet-resources">

<h2><a name="Oth">Other Internet Resources</a></h2>

<ul>

<li>MacFarlane, J., 2000.
 <a href="http://johnmacfarlane.net/dissertation.pdf" target="other"><em>What Does It Mean to Say that Logic Is Formal?</em></a>.
 Ph.D. dissertation, University of Pittsburgh.</li>

</ul>

</div>

<div id="related-entries">

<h2><a name="Rel">Related Entries</a></h2>

<p>

 <a href="../analytic-synthetic/index.html">analytic/synthetic distinction</a> |
 <a href="../davidson/index.html">Davidson, Donald</a> |
 <a href="../definitions/index.html">definitions</a> |
 <a href="../logic-modal/index.html">logic: modal</a> |
 <a href="../logic-substructural/index.html">logic: substructural</a> |
 <a href="../logic-temporal/index.html">logic: temporal</a> |
 <a href="../logical-consequence/index.html">logical consequence</a> |
 <a href="../logical-form/index.html">logical form</a> |
 <a href="../proof-theoretic-semantics/index.html">semantics: proof-theoretic</a> |
 <a href="../tarski-truth/index.html">Tarski, Alfred: truth definitions</a>

</p>

</div>

<div id="acknowledgments">

<h3>Acknowledgments</h3>

<p>
 I am grateful to Fabrizio Cariani, Kosta Do&scaron;en, Solomon
Feferman, Mario G&oacute;mez-Torrente, Graham Priest, Greg Restall,
Gila Sher, and an anonymous reviewer for comments that helped improve this entry. Parts of
the entry are derived from chapters 1, 2, 3, and 6 of my dissertation,
&ldquo;What Does It Mean to Say that Logic is Formal?&rdquo;
(University of Pittsburgh, 2000).</p>

</div>

<script type="text/javascript" src="local.js"></script>
<script type="text/javascript" src="../../MathJax/MathJaxdda6.js?config=TeX-AMS-MML_HTMLorMML"></script>

</div><!-- #aueditable --><!--DO NOT MODIFY THIS LINE AND BELOW-->

<!-- END ARTICLE HTML -->

</div> <!-- End article-content -->

  <div id="article-copyright">
    <p>
 <a href="../../info.html#c">Copyright &copy; 2015</a> by

<br />
<a href="http://johnmacfarlane.net/" target="other">John MacFarlane</a>
&lt;<a href="m&#97;ilto:jgm&#37;40berkeley&#37;2eedu"><em>jgm<abbr title=" at ">&#64;</abbr>berkeley<abbr title=" dot ">&#46;</abbr>edu</em></a>&gt;
    </p>
  </div>

</div> <!-- End article -->

<!-- NOTE: article banner is outside of the id="article" div. -->
<div id="article-banner" class="scroll-block">
  <div id="article-banner-content">
    <a href="../../fundraising/index.html">
    Open access to the SEP is made possible by a world-wide funding initiative.<br />
    The Encyclopedia Now Needs Your Support<br />
    Please Read How You Can Help Keep the Encyclopedia Free</a>
  </div>
</div> <!-- End article-banner -->

    </div> <!-- End content -->

    <div id="footer">

      <div id="footer-menu">
        <div class="menu-block">
          <h4><i class="icon-book"></i> Browse</h4>
          <ul role="menu">
            <li><a href="../../contents.html">Table of Contents</a></li>
            <li><a href="../../new.html">What's New</a></li>
            <li><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/random">Random Entry</a></li>
            <li><a href="../../published.html">Chronological</a></li>
            <li><a href="../../archives/index.html">Archives</a></li>
          </ul>
        </div>
        <div class="menu-block">
          <h4><i class="icon-info-sign"></i> About</h4>
          <ul role="menu">
            <li><a href="../../info.html">Editorial Information</a></li>
            <li><a href="../../about.html">About the SEP</a></li>
            <li><a href="../../board.html">Editorial Board</a></li>
            <li><a href="../../cite.html">How to Cite the SEP</a></li>
            <li><a href="../../special-characters.html">Special Characters</a></li>
            <li><a href="../../tools/index.html">Advanced Tools</a></li>
            <li><a href="../../contact.html">Contact</a></li>
          </ul>
        </div>
        <div class="menu-block">
          <h4><i class="icon-leaf"></i> Support SEP</h4>
          <ul role="menu">
            <li><a href="../../support/index.html">Support the SEP</a></li>
            <li><a href="../../support/friends.html">PDFs for SEP Friends</a></li>
            <li><a href="../../support/donate.html">Make a Donation</a></li>
            <li><a href="../../support/sepia.html">SEPIA for Libraries</a></li>
          </ul>
        </div>
      </div> <!-- End footer menu -->

      <div id="mirrors">
        <div id="mirror-info">
          <h4><i class="icon-globe"></i> Mirror Sites</h4>
          <p>View this site from another server:</p>
        </div>
        <div class="btn-group open">
          <a class="btn dropdown-toggle" data-toggle="dropdown" href="https://plato.stanford.edu/">
            <span class="flag flag-usa"></span> USA (Main Site) <span class="caret"></span>
            <span class="mirror-source">Philosophy, Stanford University</span>
          </a>
          <ul class="dropdown-menu">
            <li><a href="../../mirrors.html">Info about mirror sites</a></li>
          </ul>
        </div>
      </div> <!-- End mirrors -->
      
      <div id="site-credits">
        <p>The Stanford Encyclopedia of Philosophy is <a href="../../info.html#c">copyright &copy; 2021</a> by <a href="http://mally.stanford.edu/">The Metaphysics Research Lab</a>, Department of Philosophy, Stanford University</p>
        <p>Library of Congress Catalog Data: ISSN 1095-5054</p>
      </div> <!-- End site credits -->

    </div> <!-- End footer -->

  </div> <!-- End container -->

   <!-- NOTE: Script required for drop-down button to work (mirrors). -->
  <script>
    $('.dropdown-toggle').dropdown();
  </script>

</body>

<!-- Mirrored from seop.illc.uva.nl/entries/logical-constants/ by HTTrack Website Copier/3.x [XR&CO'2014], Wed, 22 Jun 2022 19:52:17 GMT -->
</html>
