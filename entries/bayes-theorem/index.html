<!DOCTYPE html>
<!--[if lt IE 7]> <html class="ie6 ie"> <![endif]-->
<!--[if IE 7]>    <html class="ie7 ie"> <![endif]-->
<!--[if IE 8]>    <html class="ie8 ie"> <![endif]-->
<!--[if IE 9]>    <html class="ie9 ie"> <![endif]-->
<!--[if !IE]> --> <html> <!-- <![endif]-->

<!-- Mirrored from seop.illc.uva.nl/entries/bayes-theorem/ by HTTrack Website Copier/3.x [XR&CO'2014], Wed, 22 Jun 2022 19:39:19 GMT -->
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>
Bayes’ Theorem (Stanford Encyclopedia of Philosophy)
</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="robots" content="noarchive, noodp" />
<meta property="citation_title" content="Bayes’ Theorem" />
<meta property="citation_author" content="Joyce, James" />
<meta property="citation_publication_date" content="2003/06/28" />
<meta name="DC.title" content="Bayes’ Theorem" />
<meta name="DC.creator" content="Joyce, James" />
<meta name="DCTERMS.issued" content="2003-06-28" />
<meta name="DCTERMS.modified" content="2003-09-30" />

<!-- NOTE: Import webfonts using this link: -->
<link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,300,600,200&amp;subset=latin,latin-ext" rel="stylesheet" type="text/css" />

<link rel="stylesheet" type="text/css" media="screen,handheld" href="../../css/bootstrap.min.css" />
<link rel="stylesheet" type="text/css" media="screen,handheld" href="../../css/bootstrap-responsive.min.css" />
<link rel="stylesheet" type="text/css" href="../../css/font-awesome.min.css" />
<!--[if IE 7]> <link rel="stylesheet" type="text/css" href="../../css/font-awesome-ie7.min.css"> <![endif]-->
<link rel="stylesheet" type="text/css" media="screen,handheld" href="../../css/style.css" />
<link rel="stylesheet" type="text/css" media="print" href="../../css/print.css" />
<link rel="stylesheet" type="text/css" href="../../css/entry.css" />
<!--[if IE]> <link rel="stylesheet" type="text/css" href="../../css/ie.css" /> <![endif]-->
<script type="text/javascript" src="../../js/jquery-1.9.1.min.js"></script>
<script type="text/javascript" src="../../js/bootstrap.min.js"></script>

<!-- NOTE: Javascript for sticky behavior needed on article and ToC pages -->
<script type="text/javascript" src="../../js/jquery-scrolltofixed-min.js"></script>
<script type="text/javascript" src="../../js/entry.js"></script>

<!-- SEP custom script -->
<script type="text/javascript" src="../../js/sep.js"></script>
</head>

<!-- NOTE: The nojs class is removed from the page if javascript is enabled. Otherwise, it drives the display when there is no javascript. -->
<body class="nojs article" id="pagetopright">
<div id="container">
<div id="header-wrapper">
  <div id="header">
    <div id="branding">
      <div id="site-logo"><a href="../../index.html"><img src="../../symbols/sep-man-red.png" alt="SEP logo" /></a></div>
      <div id="site-title"><a href="../../index.html">Stanford Encyclopedia of Philosophy</a></div>
    </div>
    <div id="navigation">
      <div class="navbar">
        <div class="navbar-inner">
          <div class="container">
            <button class="btn btn-navbar collapsed" data-target=".collapse-main-menu" data-toggle="collapse" type="button"> <i class="icon-reorder"></i> Menu </button>
            <div class="nav-collapse collapse-main-menu in collapse">
              <ul class="nav">
                <li class="dropdown open"><a id="drop1" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-book"></i> Browse</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop1">
                    <li><a href="../../contents.html">Table of Contents</a></li>
                    <li><a href="../../new.html">What's New</a></li>
                    <li><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/random">Random Entry</a></li>
                    <li><a href="../../published.html">Chronological</a></li>
                    <li><a href="../../archives/index.html">Archives</a></li>
                  </ul>
                </li>
                <li class="dropdown open"><a id="drop2" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-info-sign"></i> About</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop2">
                    <li><a href="../../info.html">Editorial Information</a></li>
                    <li><a href="../../about.html">About the SEP</a></li>
                    <li><a href="../../board.html">Editorial Board</a></li>
                    <li><a href="../../cite.html">How to Cite the SEP</a></li>
                    <li><a href="../../special-characters.html">Special Characters</a></li>
                    <li><a href="../../tools/index.html">Advanced Tools</a></li>
                    <li><a href="../../contact.html">Contact</a></li>
                  </ul>
                </li>
                <li class="dropdown open"><a id="drop3" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-leaf"></i> Support SEP</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop3">
                    <li><a href="../../support/index.html">Support the SEP</a></li>
                    <li><a href="../../support/friends.html">PDFs for SEP Friends</a></li>
                    <li><a href="../../support/donate.html">Make a Donation</a></li>
                    <li><a href="../../support/sepia.html">SEPIA for Libraries</a></li>
                  </ul>
                </li>
              </ul>
            </div>
          </div>
        </div>
      </div>
    </div>
    <!-- End navigation -->
    
    <div id="search">
      <form id="search-form" method="get" action="https://seop.illc.uva.nl/search/searcher.py">
        <input type="search" name="query" placeholder="Search SEP" />
        <div class="search-btn-wrapper"><button class="btn search-btn" type="submit"><i class="icon-search"></i></button></div>
      </form>
    </div>
    <!-- End search --> 
    
  </div>
  <!-- End header --> 
</div>
<!-- End header wrapper -->

<div id="content">

<!-- Begin article sidebar -->
<div id="article-sidebar" class="sticky">
  <div class="navbar">
    <div class="navbar-inner">
      <div class="container">
        <button class="btn btn-navbar" data-target=".collapse-sidebar" data-toggle="collapse" type="button"> <i class="icon-reorder"></i> Entry Navigation </button>
        <div id="article-nav" class="nav-collapse collapse-sidebar in collapse">
          <ul class="nav">
            <li><a href="#toc">Entry Contents</a></li>
            <li><a href="#Bib">Bibliography</a></li>
            <li><a href="#Aca">Academic Tools</a></li>
            <li><a href="https://leibniz.stanford.edu/friends/preview/bayes-theorem/">Friends PDF Preview <i class="icon-external-link"></i></a></li>
            <li><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=bayes-theorem">Author and Citation Info <i class="icon-external-link"></i></a> </li>
            <li><a href="#pagetopright" class="back-to-top">Back to Top <i class="icon-angle-up icon2x"></i></a></li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</div>
<!-- End article sidebar --> 

<!-- NOTE: Article content must have two wrapper divs: id="article" and id="article-content" -->
<div id="article">
<div id="article-content">

<!-- BEGIN ARTICLE HTML -->


<div id="aueditable"><!--DO NOT MODIFY THIS LINE AND ABOVE-->

<h1>Bayes&rsquo; Theorem</h1><div id="pubinfo"><em>First published Sat Jun 28, 2003; substantive revision Tue Sep 30, 2003</em></div>

<div id="preamble">

<p>

Bayes' Theorem is a simple mathematical formula used for calculating
conditional probabilities.  It figures prominently in
<em>subjectivist</em> or <em>Bayesian</em> approaches to epistemology,
statistics, and inductive logic. Subjectivists, who maintain that
rational belief is governed by the laws of probability, lean heavily
on conditional probabilities in their theories of evidence and their
models of empirical learning.  Bayes' Theorem is central to these
enterprises both because it simplifies the calculation of conditional
probabilities and because it clarifies significant features of
subjectivist position.  Indeed, the Theorem's central insight &mdash;
that a hypothesis is confirmed by any body of data that its truth
renders probable &mdash; is the cornerstone of all subjectivist
methodology.  </p>

</div>

<div id="toc">
<!--Entry Contents-->
<ul>
<li><a href="#1">1. Conditional Probabilities and Bayes' Theorem</a></li>
<li><a href="#2">2. Special Forms of Bayes' Theorem</a></li>
<li><a href="#3">3. The Role of Bayes' Theorem in Subjectivist Accounts of Evidence</a></li>
<li><a href="#4">4. The Role of Bayes' Theorem in Subjectivist Models of Learning</a></li>
<li><a href="#Bib">Bibliography</a></li>
<li><a href="#Aca">Academic Tools</a></li>
<li><a href="#Oth">Other Internet Resources</a></li>
<li><a href="#Rel">Related Entries</a></li>
</ul>
<!--Entry Contents-->

<hr />

</div>

<div id="main-text">

<h2><a name="1"></a>1. Conditional Probabilities and Bayes' Theorem</h2>

<p>
 The probability of a hypothesis <em>H</em> conditional on a given
body of data <em>E</em> is the ratio of the unconditional probability
of the conjunction of the hypothesis with the data to the
unconditional probability of the data alone.</p>

<blockquote>
<table>
<tr>
<td><b>(1.1)</b>&nbsp;</td>
<td><b>Definition</b>.</td>
</tr>

<tr>
<td></td>
 <td>The probability of <em>H</em> conditional on <em>E</em> is
defined as <b>P</b><em><sub>E</sub></em>(<em>H</em>) =
<b>P</b>(<em>H</em> &amp; <em>E</em>)<b>/P</b>(<em>E</em>),
provided that both terms of this ratio exist and <b>P</b>(<em>E</em>)
 &gt;  
 0.<sup>[<a href="notes.html#1" name="note-1">1</a>]</sup></td>
 </tr>
</table>
</blockquote>

<p>
 To illustrate, suppose J. Doe is a randomly chosen American who was alive
on January 1, 2000.  According to the United States Center for Disease
Control, roughly 2.4 million of the 275 million Americans alive on that
date died during the 2000 calendar year.  Among the approximately 16.6
million senior citizens (age 75 or greater) about 1.36 million died.  The
unconditional probability of the hypothesis that our J. Doe died during
2000, <em>H</em>, is just the population-wide mortality rate
<b>P</b>(<em>H</em>) = 2.4M/275M = 0.00873.  To find the probability
of J.  Doe's death conditional on the information, <em>E</em>, that he
or she was a senior citizen, we divide the probability that he or she was
a senior who died, <b>P</b>(<em>H</em> &amp; <em>E</em>) 
= 1.36M/275M = 0.00495, by the probability that he or she was a senior citizen, 
<b>P</b>(<em>E</em>) = 16.6M/275M = 0.06036.  Thus, the probability of J. Doe's 
death given that he or she was a senior is
<b>P</b><sub><em>E</em></sub>(<em>H</em>) = <b>P</b>(<em>H</em> &amp;
<em>E</em>)/<b>P</b>(<em>E</em>) = 0.00495/0.06036 = 0.082.  Notice how the
size of the <em>total</em> population factors out of this equation, so that
<b>P</b><sub><em>E</em></sub>(<em>H</em>) is just the proportion of seniors
who died.  One should contrast this quantity, which gives the mortality
rate among senior citizens, with the "inverse" probability of <em>E</em>
conditional on <em>H</em>, <b>P</b><sub><em>H</em></sub>(<em>E</em>) =
<b>P</b>(<em>H</em> &amp; <em>E</em>)/<b>P</b>(<em>H</em>) =
0.00495/0.00873 = 0.57, which is the proportion of deaths <em>in the
total population</em> that occurred among seniors.</p>

<p>
 Here are some straightforward consequences of (1.1):</p>

<ul>

<li><em>Probability</em>. <b>P</b><sub><em>E</em></sub> is a
probability
 function.<sup>[<a href="notes.html#2" name="note-2">2</a>]</sup></li>

<li><em>Logical Consequence</em>. If <em>E</em> entails <em>H</em>,
then <b>P</b><sub><em>E</em></sub>(<em>H</em>) = 1.</li>

<li><em>Preservation of Certainties</em>. If <b>P</b>(<em>H</em>) = 1,
then <b>P</b><sub><em>E</em></sub>(<em>H</em>) = 1.</li>

<li><em>Mixing</em>. <b>P</b>(<em>H</em>) =
<b>P</b>(<em>E</em>)<b>P</b><sub><em>E</em></sub>(<em>H</em>) +
 <b>P</b>(~<em>E</em>)<b>P<sub>~</sub></b><sub><em>E</em></sub>(<em>H</em>).<sup>[<a href="notes.html#3" name="note-3">3</a>]</sup></li>

</ul>

<p>

The most important fact about conditional probabilities is undoubtedly
<em>Bayes' Theorem</em>, whose significance was first appreciated by
the British cleric Thomas Bayes in his posthumously published
masterwork, "An Essay Toward Solving a Problem in the Doctrine of
Chances" (Bayes 1764).  Bayes' Theorem relates the "direct"
probability of a hypothesis conditional on a given body of data,
<b>P</b><sub><em>E</em></sub>(<em>H</em>), to the "inverse"
probability of the data conditional on the hypothesis,
<b>P</b><sub><em>H</em></sub>(<em>E</em>).</p>

<blockquote>
<table>
<tr>
<td><b>(1.2)</b></td>
<td><b>Bayes' Theorem</b>.</td>
</tr>

<tr>
<td></td>
 <td><b>P</b><sub><em>E</em></sub>(<em>H</em>) =
 [<b>P</b>(<em>H</em>)<b>/P</b>(<em>E</em>)]
 <b>P</b><sub><em>H</em></sub>(<em>E</em>)</td>
</tr>
</table>
</blockquote>

<p>
 In an unfortunate, but now unavoidable, choice of terminology,
statisticians refer to the inverse probability
<b>P</b><sub><em>H</em></sub>(<em>E</em>) as the "likelihood" of
<em>H</em> on <em>E</em>.  It expresses the degree to which the
hypothesis <em>predicts</em> the data given the background information
codified in the probability <b>P</b>.</p>

<p>
 In the example discussed above, the condition that J. Doe died during 2000
is a fairly strong predictor of senior citizenship.  Indeed, the equation
<b>P</b><sub><em>H</em></sub>(<em>E</em>) = 0.57 tells us that 57% of the
total deaths occurred among seniors that year.  Bayes' theorem lets
us use this information to compute the "direct" probability of J. Doe
dying given that he or she was a senior citizen.  We do this by
multiplying the "prediction term"
<b>P</b><sub><em>H</em></sub>(<em>E</em>) by the ratio of the total number
of deaths in the population to the number of senior citizens in the
population, <b>P</b>(<em>H</em>)/<b>P</b>(<em>E</em>) = 2.4M/16.6M =
0.144.  The result is <b>P</b><sub><em>E</em></sub>(<em>H</em>) = 0.57 &times;
0.144 = 0.082, just as expected.</p>

<p>
 Though a mathematical triviality, Bayes' Theorem is of great value
in calculating conditional probabilities because inverse probabilities
are typically both easier to ascertain and less subjective than direct
probabilities. People with different views about the unconditional
probabilities of <em>E</em> and <em>H</em> often disagree about
<em>E</em>'s value as an indicator of <em>H</em>.  Even so, they can
agree about the degree to which the hypothesis predicts the data if
they know any of the following intersubjectively available facts: (a)
<em>E</em>'s <em>objective</em> probability given <em>H</em>, (b) the
frequency with which events like <em>E</em> will occur if <em>H</em>
is true, or (c) the fact that <em>H</em> logically entails
<em>E</em>. Scientists often design experiments so that likelihoods
can be known in one of these "objective" ways.  Bayes' Theorem then
ensures that any dispute about the significance of the experimental
results can be traced to "subjective" disagreements about the
unconditional probabilities of <em>H</em> and <em>E</em>.</p>

<p>
 When both <b>P</b><sub><em>H</em></sub>(<em>E</em>) and
<b>P</b><sub>~<em>H</em></sub>(<em>E</em>) are known an experimenter
need not even know <em>E</em>'s probability to determine a value for
<b>P</b><sub><em>E</em></sub>(<em>H</em>) using Bayes' Theorem.</p>

<blockquote>
<table>
<tr>
<td valign="bottom"><b>(1.3)</b></td>
<td valign="bottom"><b>Bayes' Theorem</b> (2nd
 form).<sup>[<a href="notes.html#4" name="note-4">4</a>]</sup></td>
</tr>

<tr>
<td></td>
<td><b>P</b><sub><em>E</em></sub>(<em>H</em>) = 
<b>P</b>(<em>H</em>)<b>P</b><sub><em>H</em></sub>(<em>E</em>)
 <b>/</b> [<b>P</b>(<em>H</em>)<b>P</b><sub><em>H</em></sub>(<em>E</em>)
+ <b>P</b>(~<em>H</em>)<b>P</b><sub>~<em>H</em></sub>(<em>E</em>)]</td>
</tr>
</table>
</blockquote>

<p>
 In this guise Bayes' theorem is particularly useful for inferring
causes from their effects since it is often fairly easy to discern the
probability of an effect given the presence or absence of a putative
cause. For instance, physicians often screen for diseases of known
prevalence using diagnostic tests of recognized <em>sensitivity</em>
and <em>specificity</em>.  The sensitivity of a test, its "true
positive" rate, is the fraction of times that patients with the
disease test positive for it. The test's specificity, its "true
negative" rate, is the proportion of healthy patients who test
negative. If we let <em>H</em> be the event of a given patient having
the disease, and <em>E</em> be the event of her testing positive for
it, then the test's sensitivity and specificity are given by the
likelihoods <b>P</b><sub><em>H</em></sub>(<em>E</em>) and
<b>P<sub>~</sub></b><sub><em>H</em></sub>(<em>~E</em>), respectively,
and the "baseline" prevalence of the disease in the population is
<b>P</b>(<em>H</em>).  Given these inputs about the effects of the
disease on the outcome of the test, one can use (1.3) to determine the
probability of disease given a positive test.  For a more
detailed illustration of this process, see 
 <a href="supplement.html#1" name="s-1">Example 1</a> in the 
Supplementary Document "Examples, Tables, and Proof Sketches".</p>

<h2><a name="2">2. Special Forms of Bayes' Theorem</a></h2>

<p>

Bayes' Theorem can be expressed in a variety of forms that are useful
for different purposes. One version employs what Rudolf Carnap called
the <em>relevance quotient</em> or <em>probability ratio</em> (Carnap
1962, 466).  This is the factor <b><em>PR</em></b>(<em>H</em>,
<em>E</em>) =
<b>P</b><sub><em>E</em></sub>(<em>H</em>)<b>/P</b>(<em>H</em>)
by which <em>H</em>'s unconditional probability must be multiplied to
get its probability conditional on <em>E</em>. Bayes' Theorem is
equivalent to a simple symmetry principle for probability ratios.</p>

<blockquote>
<table>
<tr>
<td><b>(1.4)</b></td>
<td><b>Probability Ratio Rule</b>.</td>

</tr>

<tr>
<td></td>
<td><b><em>PR</em></b>(<em>H</em>, <em>E</em>) = 
<b><em>PR</em></b>(<em>E</em>, <em>H</em>)</td>

</tr>
</table>
</blockquote>

<p>
 The term on the right provides one measure of the degree to which
<em>H predicts E</em>.  If we think of <b>P</b>(<em>E</em>) as
expressing the "baseline" predictability of <em>E</em> given the
background information codified in <b>P</b>, and of
<b>P</b><sub><em>H</em></sub>(<em>E</em>) as <em>E</em>'s
predictability when <em>H</em> is added to this background, then
<b><em>PR</em></b>(<em>E</em>, <em>H</em>) captures the degree to
which knowing <em>H</em> makes <em>E</em> more or less predictable
relative to the baseline: <b><em>PR</em></b>(<em>E</em>, <em>H</em>) =
0 means that <em>H</em> categorically predicts ~<em>E</em>;
<b><em>PR</em></b>(<em>E</em>, <em>H</em>) = 1 means that adding
<em>H</em> does not alter the baseline prediction at all;
<b><em>PR</em></b>(<em>E</em>, <em>H</em>) =
1<b>/P</b>(<em>E</em>) means that <em>H</em> categorically
predicts <em>E</em>.  Since <b>P</b>(<em>E</em>)) =
<b>P</b><sub><b><em>T</em></b></sub>(<em>E</em>)) where
<b><em>T</em></b> is any truth of logic, we can think of (1.4) as
telling us that</p>

<blockquote>
 <em>The probability of a hypothesis conditional on a body of data is
equal to the unconditional probability of the hypothesis multiplied by
the degree to which the hypothesis surpasses a tautology as a
predictor of the data.</em>
 </blockquote>

<p>
 In our J. Doe example, <b><em>PR</em></b>(<em>H</em>, <em>E</em>) is
obtained by comparing the predictability of senior status given that
J. Doe died in 2000 to its predictability given no information
whatever about his or her mortality.  Dividing the former "prediction
term" by the latter yields <b><em>PR</em></b>(<em>H</em>, <em>E</em>) =
<b>P</b><sub><em>H</em></sub>(<em>E</em>)/<b>P</b>(<em>E</em>) =
0.57/0.06036 = 9.44.  Thus, as a predictor of senior status in 2000,
knowing that J. Doe died is more than nine times better than not
knowing whether she lived or died.</p>

<p>
 Another useful form of Bayes' Theorem is the <em>Odds Rule</em>.  In
the jargon of bookies, the "odds" of a hypothesis is its probability
divided by the probability of its negation: <b>O</b>(<em>H</em>) =
<b>P</b>(<em>H</em>)<b>/P</b>(~<em>H</em>). So, for example, a
racehorse whose odds of winning a particular race are 7-to-5 has a
7<b>/</b>12 chance of winning and a 5<b>/</b>12 chance of losing. To
understand the difference between odds and probabilities it helps to
think of probabilities as <em>fractions</em> of the distance between
the probability of a contradiction and that of a tautology, so that
<b>P</b>(<em>H</em>) = <em>p</em> means that <em>H</em> is <em>p</em>
times as likely to be true as a tautology. In contrast, writing
<b>O</b>(<em>H</em>) = [<b>P</b>(<em>H</em>) &minus;
<b>P</b>(<b><em>F</em></b>)]<b>/</b>[<b>P</b>(<b><em>T</em></b>)
&minus; <b>P</b>(<em>H</em>)]  (where <b><em>F</em></b> is some
logical contradiction) makes it clear that <b>O</b>(<em>H</em>)
expresses this same quantity as the ratio of the amount by which
<em>H</em>'s probability exceeds that of a contradiction to the
amount by which it is exceeded by that of a tautology. Thus, the
difference between "probability talk" and "odds talk" corresponds to
the difference between saying "we are two thirds of the way there" and
saying "we have gone twice as far as we have yet to go."</p>

<p>
 The analogue of the probability ratio is the <em>odds ratio</em>
<b><em>OR</em></b>(<em>H</em>, <em>E</em>) =
<b>O</b><sub><em>E</em></sub>(<em>H</em>)<b>/O</b>(<em>H</em>),
the factor by which <em>H</em>'s unconditional odds must be multiplied
to obtain its odds conditional on <em>E</em>. Bayes' Theorem is
equivalent to the following fact about odds ratios:</p>

<blockquote>
<table>
<tr>
<td><b>(1.5)</b></td>
<td><b>Odds Ratio Rule</b>.</td>
</tr>

<tr>
<td> </td>
 <td nowrap="nowrap"><b><em>OR</em></b>(<em>H</em>, <em>E</em>) =
<b>P</b><sub><em>H</em></sub>(<em>E</em>)<b>/P</b><sub><em>~H</em></sub>(<em>E</em>)</td>
 </tr>
</table>
</blockquote>

<p>
 Notice the similarity between (1.4) and (1.5). While each employs a
different way of <em>expressing</em> probabilities, each shows how
<em>its</em> expression for <em>H</em>'s probability conditional on
<em>E</em> can be obtained by multiplying <em>its</em> expression for
<em>H</em>'s unconditional probability by a factor involving inverse
probabilities.</p>

<p>
 The quantity <b><em>LR</em></b>(<em>H</em>, <em>E</em>) =
<b>P</b><sub><em>H</em></sub>(<em>E</em>)<b>/P</b><sub>~<em>H</em></sub>(<em>E</em>)
that appears in (1.5) is the <em>likelihood ratio</em> of <em>H</em>
given <em>E</em>. In testing situations like the one described in
Example 1, the likelihood ratio is the test's true positive rate
divided by its false positive rate: <b><em>LR</em></b> =
sensitivity<b>/</b>(1 &minus; specificity). As with the probability
ratio, we can construe the likelihood ratio as a measure of the degree
to which <em>H</em> predicts <em>E</em>. Instead of comparing
<em>E</em>'s probability given <em>H</em> with its unconditional
probability, however, we now compare it with its probability
conditional on ~<em>H</em>.  <b><em>LR</em></b>(<em>H</em>,
<em>E</em>) is thus the degree to which the hypothesis surpasses its
negation as a predictor of the data.  Once more, Bayes' Theorem tells
us how to factor conditional probabilities into unconditional
probabilities and measures of predictive power.</p>

<blockquote>
 <em>The odds of a hypothesis conditional on a body of data is equal
to the unconditional odds of the hypothesis multiplied by the degree
to which it surpasses its negation as a predictor of the data.</em>
</blockquote>

<p>
 In our running J. Doe example, <b><em>LR</em></b>(<em>H</em>,
<em>E</em>) is obtained by comparing the predictability of senior
status given that J.  Doe died in 2000 to its predictability given
that he or she lived out the year.  Dividing the former "prediction
term" by the latter yields <b><em>LR</em></b>(<em>H</em>, <em>E</em>)
=
<b>P</b><sub><em>H</em></sub>(<em>E</em>)/<b>P</b><sub>~<em>H</em></sub>(<em>E</em>)
= 0.57/0.056 = 10.12.  Thus, as a predictor of senior status in 2000,
knowing that J. Doe died is more than ten times better than knowing
that he or she lived.  </p>

<p>
 The similarities between the "probability ratio" and "odds ratio"
versions of Bayes' Theorem can be developed further if we express
<em>H</em>'s probability as a multiple of the probability of some
other hypothesis <em>H*</em> using the <em>relative probability</em>
function <b>B</b>(<em>H</em>, <em>H</em>*) =
<b>P</b>(<em>H</em>)<b>/P</b>(<em>H</em>*).  It should be clear
that <b>B</b> generalizes both <b>P</b> and <b>O</b> since
<b>P</b>(<em>H</em>) = <b>B</b>(<em>H</em>, <b><em>T</em></b>) and
<b>O</b>(<em>H</em>) = <b>B</b>(<em>H</em>, ~<em>H</em>). By comparing
the conditional and unconditional values of <b>B</b> we obtain the
<em>Bayes' Factor</em>:</p>

<blockquote>
 <b><em>BR</em></b>(<em>H</em>, <em>H</em>*; <em>E</em>) =
<b>B</b><sub><em>E</em></sub>(<em>H</em>,
<em>H</em>*)<b>/B</b>(<em>H</em>, <em>H</em>*) =
[<b>P</b><sub><em>E</em></sub>(<em>H</em>)<b>/P</b><sub><em>E</em></sub>(<em>H</em>*)]<b>/</b>
[<b>P</b>(<em>H</em>)<b>/P</b>(<em>H</em>*)].
 </blockquote>

<p>
 We can also generalize the likelihood ratio by setting
<b><em>LR</em></b>(<em>H</em>, <em>H</em>*; <em>E</em>) =
<b>P</b><sub><em>H</em></sub>(<em>E</em>)<b>/P</b><sub><em>H</em>*</sub>(<em>E</em>).
This compares <em>E</em>'s predictability on the basis of <em>H</em>
with its predictability on the basis of <em>H*</em>.  We can use these
two quantities to formulate an even more general form of Bayes'
Theorem.</p>

<blockquote>
<table>
<tr>
<td><b>(1.6)</b></td>
<td><b>Bayes' Theorem</b> (General Form)</td>
</tr>

<tr>
<td> </td>
 <td><b><em>BR</em></b>(<em>H</em>, <em>H</em>*; <em>E</em>) =
<b><em>LR</em></b>(<em>H</em>, <em>H</em>*; <em>E</em>)</td>
 </tr>
</table>
</blockquote>

<p>
 The message of (1.6) is this:</p>

<blockquote>
 <em>The ratio of probabilities for two hypotheses conditional on a
body of data is equal to the ratio their unconditional probabilities
multiplied by the degree to which the first hypothesis surpasses the
second as a predictor of the data.</em>
 </blockquote>

<p>
 The various versions of Bayes' Theorem differ only with respect to
the functions used to express unconditional probabilities
(<b>P</b>(<em>H</em>), <b>O</b>(<em>H</em>), <b>B</b>(<em>H</em>)) and
in the likelihood term used to represent predictive power
(<b><em>PR</em></b>(<em>E</em>, <em>H</em>),
<b><em>LR</em></b>(<em>H</em>, <em>E</em>),
<b><em>LR</em></b>(<em>H</em>, <em>H</em>*; <em>E</em>)).  In each
case, though, the underlying message is the same:</p>

<blockquote>
<em>conditional probability = unconditional probability &times;
 predictive power</em>
</blockquote>

<p>
 (1.2) &ndash; (1.6) are multiplicative forms of Bayes' Theorem that use
division to compare the disparities between unconditional and
conditional probabilities.  Sometimes these comparisons are best
expressed additively by replacing ratios with <em>differences</em>.
The following table gives the additive analogue of each ratio measure.</p>

<center>
<table border="1" width="100%">
<caption><b>Table 1</b></caption>
<tr>
<td align="center" bgcolor="#FFFFFF"><b>Ratio</b></td>
<td align="center" bgcolor="#FFFFFF"><b>Difference</b></td>
</tr>

<tr>
<td align="center" bgcolor="#CCCCCC"><em>Probability Ratio</em>&nbsp;
<br />
 <b><em>PR</em></b>(<em>H</em>, <em>E</em>)
= <b>P</b><sub><em>E</em></sub>(<em>H</em>)<b>/P</b>(<em>H</em>)</td>

<td align="center" bgcolor="#EEEEEE"><em>Probability Difference</em>
<br />
 <b><em>PD</em></b>(<em>H</em>, <em>E</em>) =
<b>P</b><sub><em>E</em></sub>(<em>H</em>) &minus;<b>
P</b>(<em>H</em>)</td> </tr>

<tr>
<td align="center" bgcolor="#CCCCCC"><em>Odds Ratio</em>&nbsp;
<br />
 <b><em>OR</em></b>(<em>H</em>, <em>E</em>) =
<b>O</b><sub><em>E</em></sub>(<em>H</em>)<b>/O</b>(<em>H</em>)</td>

<td align="center" bgcolor="#EEEEEE"><em>Odds Difference</em>&nbsp;
<br />
 <b><em>OD</em></b>(<em>H</em>, <em>E</em>) =
<b>O</b><sub><em>E</em></sub>(<em>H</em>) &minus;
<b>O</b>(<em>H</em>)</td>
 </tr>

<tr>
<td align="center" bgcolor="#CCCCCC"><em>Bayes' Factor</em>&nbsp;
<br />
 <b><em>BR</em></b>(<em>H</em>, <em>H</em>*; <em>E</em>) =
<b>B</b><sub><em>E</em></sub>(<em>H</em>,
<em>H</em>*)<b>/B</b>(<em>H</em>, <em>H</em>*)</td>

<td align="center" bgcolor="#EEEEEE"><em>Bayes' Difference</em>&nbsp;
<br />
 <b><em>BD</em></b>(<em>H</em>, <em>H</em>*; <em>E</em>) =
<b>B</b><sub><em>E</em></sub>(<em>H</em>, <em>H</em>*) &minus;
<b>B</b>(<em>H</em>, <em>H</em>*)</td>
 </tr>
</table>
</center>

<p>
 We can use Bayes' theorem to obtain additive analogues of (1.4) &ndash;
(1.6), which are here displayed along with their multiplicative
counterparts:</p>

<center>
<table border="1" width="100%">
<caption><b>Table 2</b></caption>
<tr>
<td align="center" bgcolor="#FFFFFF"></td>
<td align="center" bgcolor="#FFFFFF"><b>Ratio</b></td>

<td align="center" bgcolor="#FFFFFF"><b>Difference</b></td>
</tr>

<tr>
<td align="left" bgcolor="#FFFFFF">(1.4)</td>

<td align="left" bgcolor="#CCCCCC">
&nbsp;<b><em>PR</em></b>(<em>H</em>, <em>E</em>)
= <b><em>PR</em></b>(<em>E</em>, <em>H</em>)
= <b>P</b><sub><em>H</em></sub>(<em>E</em>)<b>/P</b>(<em>E</em>)</td>

<td align="left" bgcolor="#EEEEEE">
&nbsp;<b><em>PD</em></b>(<em>H</em>, <em>E</em>)
= <b>P</b>(<em>H</em>) [<b><em>PR</em></b>(<em>E</em>, <em>H</em>) &minus; 1]
</td>
</tr>

<tr>
<td align="left" bgcolor="#FFFFFF">(1.5)</td>
 <td align="left" bgcolor="#CCCCCC">
&nbsp;<b><em>OR</em></b>(<em>H</em>, <em>E</em>)
= <b><em>LR</em></b>(<em>H</em>, <em>E</em>)
= <b>P</b><sub><em>H</em></sub>(<em>E</em>)<b>/P</b><sub><em>~H</em></sub>(<em>E</em>)</td>
 <td align="left" bgcolor="#EEEEEE">
&nbsp;<b><em>OD</em></b>(<em>H</em>, <em>E</em>) = <b>O</b>(<em>H</em>)
[<b><em>OR</em></b>(<em>H</em>, <em>E</em>) &minus; 1]</td>
 </tr>

<tr>
<td align="left" bgcolor="#FFFFFF">(1.6)</td>
<td align="left" bgcolor="#CCCCCC">
 &nbsp;<b><em>BR</em></b>(<em>H</em>, <em>H</em>*; <em>E</em>) =
<b><em>LR</em></b>(<em>H</em>, <em>H</em>*; <em>E</em>) =
<b>P</b><sub><em>H</em></sub>(<em>E</em>)<b>/P</b><sub><em>H*</em></sub>(<em>E</em>)</td>

<td align="left" bgcolor="#EEEEEE">
&nbsp;<b><em>BD</em></b>(<em>H</em>, <em>H</em>*; <em>E</em>) =
<b>B</b>(<em>H</em>, <em>H</em>*) [<b><em>BR</em></b>(<em>H</em>,
<em>H</em>*; <em>E</em>) &minus; 1]</td>
 </tr>
 </table>
 </center>

<p>
 Notice how each additive measure is obtained by multiplying
<em>H</em>'s unconditional probability, expressed on the relevant
scale, <b>P</b>, <b>O</b> or <b>B</b>, by the associated
multiplicative measure diminished by 1.</p>

<p>
 While the results of this section are useful to anyone who employs
the probability calculus, they have a special relevance for
<em>subjectivist</em> or "Bayesian" approaches to statistics,
epistemology, and inductive
 inference.<sup>[<a href="notes.html#5" name="note-5">5</a>]</sup>
 Subjectivists lean heavily on conditional probabilities in their
theory of evidential support and their account of empirical
learning. Given that Bayes' Theorem is the single most important fact
about conditional probabilities, it is not at all surprising that it
should figure prominently in subjectivist methodology.</p>

<h2><a name="3">3. The Role of Bayes' Theorem in Subjectivist Accounts of Evidence</a></h2>

<p>

Subjectivists maintain that beliefs come in varying gradations of
strength, and that an ideally rational person's graded beliefs can be
represented by a <em>subjective probability function</em>
<b>P</b>. For each hypothesis <em>H</em> about which the person has a
firm opinion, <b>P</b>(<em>H</em>) measures her level of confidence
(or "degree of belief") in <em>H</em>'s
 truth.<sup>[<a href="notes.html#6" name="note-6">6</a>]</sup>
 Conditional beliefs are represented by conditional probabilities, so
that <b>P</b><sub><em>E</em></sub>(<em>H</em>) measures the person's
confidence in <em>H on the supposition that E is a
 fact</em>.<sup>[<a href="notes.html#7" name="note-7">7</a>]</sup></p>

<p>
 One of the most influential features of the subjectivist program is
its account of <em>evidential support</em>. The guiding ideas of this
<em>Bayesian confirmation theory</em> are these:</p>

<ul>

<li><em>Confirmational Relativity</em>.  Evidential relationships must
be relativized to individuals and their degrees of belief.</li>

<li><em>Evidence
 Proportionism.</em><sup>[<a href="notes.html#8" name="note-8">8</a>]</sup>
 A rational believer will proportion her confidence in a hypothesis
<em>H</em> to her <em>total evidence</em> for <em>H</em>, so that her
subjective probability for <em>H</em> reflects the overall balance of
her reasons for or against its truth.</li>

<li><em>Incremental
 Confirmation.</em><sup>[<a href="notes.html#9" name="note-9">9</a>]</sup>
 A body of data provides <em>incremental</em> evidence for <em>H</em>
to the extent that conditioning on the data raises <em>H</em>'s
probability.</li>

</ul>

<p> The first principle says that statements about evidentiary
relationships always make implicit reference to people and their
degrees of belief, so that, e.g., "<em>E</em> is evidence for
<em>H</em>" should really be read as "<em>E</em> is evidence for
<em>H</em> relative to the information encoded in the subjective
probability <b>P</b>".</p>

<p>
 According to evidence proportionism, a subject's level of confidence
in <em>H</em> should vary directly with the strength of her evidence
in favor of <em>H</em>'s truth.  Likewise, her level of confidence in
<em>H</em> conditional on <em>E</em> should vary directly with the
strength of her evidence for <em>H</em>'s truth when this evidence is
augmented by the supposition of <em>E</em>.  It is a matter of some
delicacy to say precisely what constitutes a person's
 evidence,<sup>[<a href="notes.html#10" name="note-10">10</a>]</sup>
 and to explain how her beliefs should be "proportioned" to it.
Nevertheless, the idea that incremental evidence is reflected in
disparities between conditional and unconditional probabilities only
makes sense if differences in subjective probability mirror
differences in <em>total</em> evidence.</p>

<p>
 An item of data provides a subject with <em>incremental</em> evidence
for or against a hypothesis to the extent that receiving the data
increases or decreases her total evidence for the truth of the
hypothesis.  When probabilities measure total evidence, the increment
of evidence that <em>E</em> provides for <em>H</em> is a matter of the
disparity between <b>P</b><sub><em>E</em></sub>(<em>H</em>) and
<b>P</b>(<em>H</em>).  When odds are used it is a matter of the
disparity between <b>O</b><sub><em>E</em></sub>(<em>H</em>) and
<b>O</b>(<em>H</em>). See
 <a href="supplement.html#2" name="s-2">Example 2</a> in the
supplementary document "Examples, Tables, and Proof Sketches", which
illustrates the difference between total and incremental evidence, and
explains the "baserate fallacy" that can result from failing to
properly distinguish the two.</p>

<p>
 It will be useful to distinguish two subsidiary concepts related to
total evidence.</p>

<ul>

<li>The <em>net evidence in favor of H</em> is the degree to which a
subject's total evidence in favor of <em>H</em> exceeds her total
evidence in favor of ~<em>H</em>.</li>

<li>The <em>balance of total evidence for H over H</em>* is the degree
to which a subject's total evidence in favor of <em>H</em> exceeds her
total evidence in favor of <em>H</em>*.</li>

</ul>

<p>
 The precise content of these notions will depend on how total
evidence is understood and measured, and on how disparities in total
evidence are characterized.  For example, if total evidence is given
in terms of probabilities and disparities are treated as ratios, then
the net evidence for <em>H</em> is
<b>P</b>(<em>H</em>)<b>/P</b>(~<em>H</em>).  If total evidence
is expressed in terms of odds and differences are used to express
disparities, then the net evidence for <em>H</em> will be
<b>O</b>(<em>H</em>) &minus; <b>O</b>(~<em>H</em>). Readers may
consult <a href="supplement.html#3" name="s-3">Table 3</a> (in 
the supplementary document) for a complete list of the possibilities.</p>

<p>
 As these remarks make clear, one can interpret <b>O</b>(<em>H</em>)
either as a measure of net evidence or as a measure of total evidence.
To see the difference, imagine that 750 red balls and 250 black balls
have been drawn at random and with replacement from an urn known to
contain 10,000 red or black balls.  Assuming that this is our only
evidence about the urn's contents, it is reasonable to set
<b>P</b>(<em>Red</em>) = 0.75 and <b>P</b>(~<em>Red</em>) = 0.25.  On
a probability-as-total-evidence reading, these assignments reflect
both the fact that we have a great deal of evidence in favor of
<em>Red</em> (namely, that 750 of 1,000 draws were red) and the fact
that we have also have some evidence against it (namely, that 250 of
the draws were black).  The <em>net</em> evidence for <em>Red</em> is
then the disparity between our total evidence for <em>Red</em> and our
total evidence against <em>Red</em>.  This can be expressed
multiplicatively by saying that we have seen three times as many red
draws as black draws, which is just to say that <b>O</b>(<em>Red</em>)
= 3.  Alternatively, we can use <b>O</b>(<em>Red</em>) as a measure of
the total evidence by taking our evidence for <em>Red</em> to be the
ratio of red to black draws, rather than the total number of red
draws, and our evidence for ~<em>Red</em> to be the ratio of black
balls to red balls, rather than the total number of black draws.
While the decision whether to use <b>O</b> as a measure total or net
evidence makes little difference to questions about the
<em>absolute</em> amount of total evidence for a hypothesis (since
<b>O</b>(<em>H</em>) is an increasing function of
<b>P</b>(<em>H</em>)), it can make a major difference when one is
considering the incremental <em>changes</em> in total evidence brought
about by conditioning on new information.</p>

<p>
 Philosophers interested in characterizing correct patterns of
inductive reasoning and in providing "rational reconstructions" of
scientific methodology have tended to focus on incremental evidence as
crucial to their enterprise.  When scientists (or ordinary folk) say
that <em>E</em> supports or confirms <em>H</em> what they generally
mean is that learning of <em>E</em>'s truth will increase the total
amount of evidence for <em>H</em>'s truth.  Since subjectivists
characterize total evidence in terms of subjective probabilities or
odds, they analyze incremental evidence in terms of changes in these
quantities.  On such views, the simplest way to characterize the
strength of incremental evidence is by making ordinal comparisons of
conditional and unconditional probabilities or odds.</p>

 <blockquote>
<table width="90%">
<tr>
<td><b>(2.1)</b></td>
<td><b>A Comparative Account of Incremental Evidence</b>.</td>
</tr>

<tr>
<td> </td>
<td>Relative to a subjective probability function <b>P</b>,
 <ul>
 <li><em>E</em> incrementally confirms (disconfirms, is irrelevant to)
<em>H</em> if and only if <b>P</b><sub><em>E</em></sub>(<em>H</em>) is
greater than (less than, equal to) <b>P</b>(<em>H</em>).</li>
 <li><em>H</em> receives a greater increment (or lesser decrement) of
evidential support from <em>E</em> than from <em>E*</em> if and only
if <b>P</b><sub><em>E</em></sub>(<em>H</em>) exceeds
<b>P</b><sub><em>E*</em></sub>(<em>H</em>).</li>
 </ul></td>
</tr>
</table>
</blockquote>

<p>
 Both these equivalences continue to hold with probabilities replaced
by odds.  So, this part of the subjectivist theory of evidence does
not depend on how total evidence is measured.</p>

<p>
 Bayes' Theorem helps to illuminate the content of (2.1) by making it
clear that <em>E</em>'s status as incremental evidence for <em>H</em>
is enhanced to the extent that <em>H</em> predicts <em>E</em>.  This
observation serves as the basis for the following conclusions about
incremental confirmation (which hold so long as 1  &gt; 
<b>P</b>(<em>H</em>), <b>P</b>(<em>E</em>)  &gt;  0).</p>

 <blockquote>
<table>
<tr>
<td valign="top"><b>(2.1a)</b>&nbsp;</td>
 <td valign="top">&nbsp;If <em>E</em> incrementally confirms
<em>H</em>, then <em>H</em> incrementally confirms <em>E</em>.</td>
 </tr>

<tr>
<td valign="top"><b>(2.1b)</b>&nbsp;</td>
 <td valign="top">&nbsp;If <em>E</em> incrementally confirms
<em>H</em>, then <em>E</em> incrementally disconfirms
~<em>H</em>.</td>
 </tr>

<tr>
 <td valign="top"><b>(2.1c)</b>&nbsp;</td> <td valign="top">&nbsp;If <em>H</em> entails <em>E</em>, then <em>E</em>
incrementally confirms <em>H</em>.</td>
 </tr>

<tr>
<td valign="top"><b>(2.1d)</b>&nbsp;</td>
 <td valign="top">&nbsp;If <b>P</b><sub><em>H</em></sub>(<em>E</em>) =
<b>P</b><sub><em>H</em></sub>(<em>E*</em>), then <em>H</em> receives
more incremental support from <em>E</em> than from <em>E*</em> if and
only if <em>E</em> is unconditionally less probable than
<em>E</em>*.</td>
 </tr>

<tr>
<td valign="top"><b>(2.1e)</b>&nbsp;</td>
 <td valign="top">&nbsp;<em>Weak Likelihood Principle</em>.
<em>E</em> provides incremental evidence for <em>H</em> if and only if
<b>P</b><sub><em>H</em></sub>(<em>E</em>) &gt;
<b>P</b><sub>~<em>H</em></sub>(<em>E</em>).  More generally, if
<b>P</b><sub><em>H</em></sub>(<em>E</em>) &gt;
<b>P</b><sub><em>H</em>*</sub>(<em>E</em>) and
<b>P</b><sub>~<em>H</em></sub>(~<em>E</em>) &ge;
<b>P</b><sub>~<em>H</em>*</sub>(~<em>E</em>), then <em>E</em> provides
more incremental evidence for <em>H</em> than for <em>H</em>*.</td>
 </tr>
</table>
</blockquote>

<p>
 (2.1a) tells us that incremental confirmation is a matter of
<em>mutual reinforcement</em>: a person who sees <em>E</em> as
evidence for <em>H</em> invests more confidence in the possibility
that both propositions are true than in either possibility in which
only one obtains.</p>

<p>
 (2.1b) says that relevant evidence must be capable of discriminating
between the truth and falsity of the hypothesis under test.</p>

<p>
 (2.1c) provides a subjectivist rationale for the
<em>hypothetico-deductive model of confirmation</em>. According to
this model, hypotheses are incrementally confirmed by any evidence
they entail.  While subjectivists reject the idea that evidentiary
relations can be characterized in a belief-independent manner &mdash;
Bayesian confirmation is <em>always</em> relativized to a person and
her subjective probabilities &mdash; they seek to preserve the basic
insight of the H-D model by pointing out that hypotheses are
incrementally supported by evidence they entail <em>for anyone who has
not already made up her mind about the hypothesis or the
evidence</em>.  More precisely, if <em>H</em> entails <em>E</em>, then
<b>P</b><sub><em>E</em></sub>(<em>H</em>) =
<b>P</b>(<em>H</em>)<b>/P</b>(<em>E</em>), which exceeds
<b>P</b>(<em>H</em>) whenever 1 &gt; <b>P</b>(<em>E</em>),
<b>P</b>(<em>H</em>) &gt; 0.  This explains why scientists so often
seek to design experiments that fit the H-D paradigm.  Even when
evidentiary relations are relativized to subjective probabilities,
experiments in which the hypothesis under test entails the data will
be regarded as evidentially relevant by <em>anyone</em> who has not
yet made up his mind about the hypothesis or the data. The
<em>degree</em> of incremental confirmation will vary among people
depending on their prior levels of confidence in <em>H</em> and
<em>E</em> , but everyone will agree that the data incrementally
supports the hypothesis to at least some degree.</p>

<p> 
 Subjectivists invoke (2.1d) to explain why scientists so often regard
improbable or surprising evidence as having more confirmatory
potential than evidence that is antecedently known. While it is not
true <em>in general</em> that improbable evidence has more confirming
potential, it is true that <em>E</em>'s incremental confirming power
relative to <em>H</em> varies inversely with <em>E</em>'s
unconditional probability <em>when the value of the inverse
probability</em> <b>P</b><sub><em>H</em></sub>(<em>E</em>) <em>is held
fixed</em>.  If <em>H</em> entails both <em>E</em> and <em>E</em>*,
say, then Bayes' Theorem entails that the least probable of the two
supports <em>H</em> more strongly.  For example, even if heart attacks
are invariably accompanied by severe chest pain and shortness of
breath, the former symptom is far better evidence for a heart attack
than the latter simply because severe chest pain is so much less
common than shortness of breath.</p>

<p>
 (2.1e) captures one core message of Bayes' Theorem for theories of
confirmation.  Let's say that <em>H</em> is <em>uniformly better</em>
than <em>H</em>* as predictor of <em>E</em>'s truth-value when (a)
<em>H</em> predicts <em>E</em> more strongly than <em>H</em>* does,
and (b) ~<em>H</em> predicts ~<em>E</em> more strongly than
~<em>H</em>* does.  According to the weak likelihood principle,
hypotheses that are uniformly better predictors of the data are better
supported by the data.  For example, the fact that little Johnny is a
Christian is better evidence for thinking that his parents are
Christian than for thinking that they are Hindu because (a) a far
higher proportion of Christian parents than Hindu have Christian
children, and (b) a far higher proportion of non-Christian parents
than non-Hindu parents have non-Christian children.</p>

<p>
 Bayes' Theorem can also be used as the basis for developing and
evaluating <em>quantitative</em> measures of evidential support. The
results listed in Table 2 entail that all four of the functions
<b><em>PR</em></b>, <b><em>OR</em></b>, <b><em>PD</em></b> and
<b><em>OD</em></b> agree with one another on the simplest question of
confirmation: Does <em>E</em> provide incremental evidence for
<em>H</em>?</p>

 <blockquote>
<table>
<tr>
<td valign="top"><b>(2.2)</b></td>
<td valign="top"><b>Corollary</b>.</td>
</tr>
<tr>
<td> </td>
 <td valign="top">Each of the following is equivalent to the assertion
that <em>E</em> provides incremental evidence in favor of <em>H</em>:
<b><em>PR</em></b>(<em>H</em>, <em>E</em>) &gt; 1,
<b><em>OR</em></b>(<em>H</em>, <em>E</em>) &gt; 1,
<b><em>PD</em></b>(<em>H</em>, <em>E</em>) &gt; 0,
<b><em>OD</em></b>(<em>H</em>, <em>E</em>) &gt; 0.</td>
 </tr>
</table>
</blockquote> 

<p>
 Thus, all four measures agree with the comparative account of
incremental evidence given in (2.1).</p>

<p>
 Given all this agreement it should not be surprising that
<b><em>PR</em></b>(<em>H</em>, <em>E</em>),
<b><em>OR</em></b>(<em>H</em>, <em>E</em>) and
<b><em>PD</em></b>(<em>H</em>, <em>E</em>), have all been proposed as
measures of the <em>degree</em> of incremental support that <em>E</em>
provides for
 <em>H</em>.<sup>[<a href="notes.html#11" name="note-11">11</a>]</sup>
 While <b><em>OD</em></b>(<em>H</em>, <em>E</em>) has not been
suggested for this purpose, we will consider it for reasons of
symmetry.  Some authors maintain that one or another of these
functions is the unique correct measure of incremental evidence;
others think it best to use a variety of measures that capture
different evidential relationships.  While this is not the place to
adjudicate these issues, we can look to Bayes' Theorem for help in
understanding what the various functions measure and in characterizing
the formal relationships among them.</p>

<p>
 All four measures agree in their conclusions about the
<em>comparative</em> amount of incremental evidence that different
items of data provide for a <em>fixed</em> hypothesis.  In particular,
they agree ordinally about the following concepts derived from
incremental evidence:</p>

<ul>

<li>The <em>effective increment of
 evidence</em><sup>[<a href="notes.html#12" name="note-12">12</a>]</sup>
 that <em>E</em> provides for <em>H</em> is the amount by which the
incremental evidence that <em>E</em> provides for <em>H</em> exceeds
the incremental evidence that ~<em>E</em> provides for <em>H</em>.
</li>

<li>The <em>differential</em> in the incremental evidence that
<em>E</em> and <em>E</em>* provide for <em>H</em> is the amount by
which the incremental evidence that <em>E</em> provides for <em>H</em>
exceeds the incremental evidence that <em>E</em>* provides for
<em>H</em>.</li>

</ul>

<p>
 Effective evidence is a matter of the degree to which a person's
total evidence for <em>H</em> depends on her opinion about <em>E</em>.
When <b>P</b><sub><em>E</em></sub>(<em>H</em>) and
<b>P</b><sub>~<em>E</em></sub>(<em>H</em>) (or
<b>O</b><sub><em>E</em></sub>(<em>H</em>) and
<b>O</b><sub>~<em>E</em></sub>(<em>H</em>)) are far apart the person's
belief about <em>E</em> has a great effect on her belief about
<em>H</em>: from her point of view, a great deal hangs on <em>E</em>'s
truth-value when it comes to questions about <em>H</em>'s truth-value.
A large differential in incremental evidence between <em>E</em> and
<em>E</em>* tells us that learning <em>E</em> increases the subject's
total evidence for <em>H</em> by a larger amount than learning
<em>E</em>* does.  Readers may consult
 <a href="supplement.html#4" name="s-4">Table 4</a> (in the
supplement) for quantitative measures of effective and
differential evidence.</p>

<p>
 The second clause of (2.1) tells us that <em>E</em> provides more
incremental evidence than <em>E</em>* does for <em>H</em> just in case
the probability of <em>H</em> conditional on <em>E</em> exceeds the
probability of <em>H</em> conditional on <em>E</em>*.  It is then a
simple step to show that all four measures of incremental support
agree ordinally on questions of effective evidence and of
differentials in incremental evidence.</p>

 <blockquote>
<table>
<tr>
<td valign="top"><b>(2.3)</b></td>
<td valign="top"><b>Corollary</b>.</td>
</tr>

<tr>
<td> </td>
 <td valign="top">For any <em>H</em>, <em>E</em>* and <em>E</em> with
positive probability, the following are equivalent:
 <ul>
 <li><em>E</em> provides more incremental evidence than <em>E</em>*
does for <em>H</em></li>
 <li><b><em>PR</em></b>(<em>H</em>, <em>E</em>) &gt;
<b><em>PR</em></b>(<em>H</em>, <em>E</em>*)</li>
 <li><b><em>OR</em></b>(<em>H</em>, <em>E</em>) &gt;
<b><em>OR</em></b>(<em>H</em>, <em>E</em>*)</li>
 <li><b><em>PD</em></b>(<em>H</em>, <em>E</em>) &gt;
<b><em>PD</em></b>(<em>H</em>, <em>E</em>*)</li>
 <li><b><em>OD</em></b>(<em>H</em>, <em>E</em>) &gt;
<b><em>OD</em></b>(<em>H</em>, <em>E</em>*)</li>
 </ul>
 </td>
</tr>
</table>
</blockquote> 

<p>
 The four measures of incremental support can disagree over the
<em>comparative</em> degree to which a single item of data
incrementally confirms two distinct hypotheses. 
 <a href="supplement.html#5" name="s-5">Example 3</a>,
 <a href="supplement.html#6" name="s-6">Example 4</a>, and
 <a href="supplement.html#7" name="s-7">Example 5</a>
 (in the supplement) show the various ways in which this
can happen.</p>

<p>
 All the differences between the measures have ultimately to do with
(a) whether the <em>total</em> evidence in favor of a hypothesis
should be measured in terms of probabilities or in terms of odds, and
(b) whether <em>disparities</em> in total evidence are best captured
as ratios or as differences.  Rows in the following table correspond
to different measures of total evidence.  Columns correspond to
different ways of treating disparities.</p>

<center>
<table border="1" cellspacing="1" width="80%">
<caption><b>Table 5</b>: Four measures of incremental evidence</caption>
<tr>
<td bgcolor="#FFFFFF"></td>
<td bgcolor="#FFFFFF">
<center><b>Ratio</b></center>
</td>
<td bgcolor="#FFFFFF">
<center><b>Difference</b></center>
</td>
</tr>

<tr>
<td><center><b>P</b> = Total</center></td>
<td bgcolor="#DDDDDD">
<center><b><em>PR</em></b>(<em>H</em>, <em>E</em>) =
 <b>P</b><sub><em>E</em></sub>(<em>H</em>)<b>/P</b>(<em>H</em>)</center>
</td>
<td bgcolor="#EEEEEE">
<center><b><em>PD</em></b>(<em>H</em>, <em>E</em>)
= <b>P</b><sub><em>E</em></sub>(<em>H</em>) &minus;<b>
P</b>(<em>H</em>)</center>
</td>
</tr>
<tr>

<td><center><b>O</b> = Total</center></td>
<td bgcolor="#DDDDDD">
<center><b><em>OR</em></b>(<em>H</em>, <em>E</em>) =
 <b>O</b><sub><em>E</em></sub>(<em>H</em>)<b>/O</b>(<em>H</em>)</center>
</td>
<td bgcolor="#EEEEEE">
<center><b><em>OD</em></b>(<em>H</em>, <em>E</em>)
= <b>O</b><sub><em>E</em></sub>(<em>H</em>) &minus;<b>
O</b>(<em>H</em>)</center></td>
</tr>
</table>
</center>

<p>
 Similar tables can be constructed for measures of net evidence and
measures of balances in total evidence.  See
 <a href="supplement.html#8" name="s-8">Table 5A</a> in the supplement.</p>

<p>
 We can use the various forms of Bayes' Theorem to clarify the
similarities and differences among these measures by rewriting each of
them in terms of likelihood ratios.</p>

<center>
<table border="1" cellspacing="1" width="90%">
 <caption><b>Table 6</b>: The four measures expressed in terms of
likelihood ratios</caption>
 <tr>
<td bgcolor="#FFFFFF"></td>
<td bgcolor="#FFFFFF">
<center><b>Ratio</b></center>
</td>
<td bgcolor="#FFFFFF">
<center><b>Difference</b></center>
</td>
</tr>

<tr>
<td><center><b>P</b> = Total</center></td>
<td bgcolor="#DDDDDD">
 <center><b><em>PR</em></b>(<em>H</em>, <em>E</em>) =
<b><em>LR</em></b>(<em>H</em>, <b><em>T</em></b>;
<em>E</em>)</center></td>
 <td bgcolor="#EEEEEE">
 <center><b><em>PD</em></b>(<em>H</em>, <em>E</em>) =
<b>P</b>(<em>H</em>)[<b><em>LR</em></b>(<em>H</em>, <b><em>T</em></b>;
<em>E</em>) &minus; 1]</center></td>
 </tr>
	
<tr>
<td><center><b>O</b> = Total</center></td>
<td bgcolor="#DDDDDD">
 <center><b><em>OR</em></b>(<em>H</em>, <em>E</em>) =
<b><em>LR</em></b>(<em>H</em>, ~<em>H</em>; <em>E</em>)</center></td>
<td bgcolor="#EEEEEE">
 <center><b><em>OD</em></b>(<em>H</em>, <em>E</em>)=
<b>O</b>(<em>H</em>)[<b><em>LR</em></b>(<em>H</em>, ~<em>H</em>;
<em>E</em>) &minus; 1]</center></td>
 </tr>
</table>
</center>

<p>
 This table shows that there are two differences between each
multiplicative measure and its additive counterpart.  First, the
likelihood term that appears in a given multiplicative measure is
diminished by 1 in its associated additive measure.  Second, in each
additive measure the diminished likelihood term is multiplied by an
expression for <em>H</em>'s probability: <b>P</b>(<em>H</em>) or
<b>O</b>(<em>H</em>), as the case may be.  The first difference
marks no distinction; it is due solely to the fact that the
multiplicative and additive measures employ a different zero point
from which to measure evidence.  If we settle on the point of
probabilistic independence <b>P</b><sub><em>E</em></sub>(<em>H</em>) =
<b>P</b>(<em>H</em>) as a natural common zero, and so subtract 1 from
each multiplicative
 measure,<sup>[<a href="notes.html#13" name="note-13">13</a>]</sup>
 then equivalent likelihood terms appear in both columns.</p>

<p>
 The real difference between the measures in a given row concerns the
effect of unconditional probabilities on relations of incremental
confirmation.  Down the right column, the degree to which <em>E</em>
provides incremental evidence for <em>H</em> is directly proportional
to <em>H</em>'s probability expressed in units of
<b>P</b>(<b><em>T</em></b>) or <b>P</b>(~<em>H</em>).  In the left
column, <em>H</em>'s probability makes no difference to the amount of
incremental evidence that <em>E</em> provides for <em>H</em> once
<b>P</b><sub><em>H</em></sub>(<em>E</em>) and either
<b>P</b>(<em>E</em>) or <b>P</b><sub>~<em>H</em></sub>(<em>E</em>) are
 fixed.<sup>[<a href="notes.html#14" name="note-14">14</a>]</sup>
 In light of Bayes' Theorem, then, the difference between the ratio
measures and then difference measures boils down to one question:</p>

<blockquote>
 <em>Does a given piece of data provide a greater increment of
evidential support for a more probable hypothesis than it does for a
less probable hypothesis when both hypotheses predict the data equally
well?</em>
 </blockquote> 

<p>The difference measures answer yes, the ratio measures answer no.</p>

<p>
 Bayes' Theorem can also help us understand the difference between
rows.  The measures within a given row agree about the role of
<em>predictability</em> in incremental confirmation.  In the top row
the incremental evidence that <em>E</em> provides for <em>H</em>
increases linearly with
<b>P</b><sub><em>H</em></sub>(<em>E</em>)<b>/P</b>(<em>E</em>),
whereas in the bottom row it increases linearly with
<b>P</b><sub><em>H</em></sub>(<em>E</em>)<b>/P</b><sub><em>~H</em></sub>(<em>E</em>).
Thus, when probabilities measure total evidence what matters is the
degree to which <em>H</em> exceeds <b><em>T</em></b> as a predictor of
<em>E</em>, but when odds measure total evidence it is the degree to
which <em>H</em> exceeds ~<em>H</em> as a predictor of <em>E</em> that
matters.</p>

<p>
 The central issue here concerns the status of the likelihood ratio.
While everyone agrees that it should play a leading role in any
quantitative theory of evidence, there are conflicting views about
precisely what evidential relationship it captures.  There are three
possible interpretations.</p>

<center>
<table border="1" cellspacing="1" width="100%">
 <caption><b>Table 7</b>: Three interpretations of the likelihood
ratio</caption>
 <tr>
<td valign="top" width="20%">Probability as total evidence reading</td>
<td valign="top">
 <ul>
 <li><b><em>PR</em></b>(<em>H</em>, <em>E</em>) measures incremental
change in total evidence.</li>
 <li><b><em>LR</em></b>(<em>H</em>, <em>E</em>) measures incremental
change in <em>net</em> evidence.</li>
 <li><b><em>LR</em></b>(<em>H</em>, <em>H</em>*, <em>E</em>) measures
incremental change in the balance of evidence that <em>E</em> provides
for <em>H</em> over <em>H</em>*</li>
 </ul>
 </td>
</tr>

<tr>
<td valign="top" width="20%">Odds as total evidence reading</td>
<td valign="top">
 <ul>
 <li><b><em>LR</em></b>(<em>H</em>, <em>E</em>) measures incremental
changes in total evidence.</li>
 <li><b><em>LR</em></b>(<em>H</em>, <em>E</em>)<sup>2</sup> measures
incremental change in net evidence.</li>
 <li><b><em>LR</em></b>(<em>H</em>, <em>H</em>*;
<em>E</em>)<b>/<em>LR</em></b>(~<em>H</em>, ~<em>H</em>*;
<em>E</em>) measures incremental change in the balance of evidence
that <em>E</em> provides for <em>H</em> over <em>H</em>*.</li>
 </ul>
 </td>
</tr>

<tr>
<td valign="top" width="20%">"Likelihoodist" reading</td>
<td valign="top">
 <ul>
 <li>Neither <b>P</b> nor <b>O</b> measures total evidence because
evidential relations are essentially <em>comparative</em>; they always
involve the balance of evidence.</li>
 <li><b><em>LR</em></b>(<em>H</em>, <em>E</em>) measures the balance
of evidence that <em>E</em> provides for <em>H</em> over
<em>H</em>*.</li>
 <li><b><em>LR</em></b>(<em>H</em>, <em>H</em>*; <em>E</em>) measures
the balance of evidence that <em>E</em> provides for <em>H</em> over
<em>H</em>*.</li>
 </ul>
</td>
</tr>
</table>
</center>

<p>
 On the first reading there is no conflict whatsoever between using
probability ratios and using likelihood ratios to measure evidence.
Once we get clear on the distinctions between total evidence, net
evidence and the balance of evidence, we see that each of
<b><em>PR</em></b>(<em>H</em>, <em>E</em>),
<b><em>LR</em></b>(<em>H</em>, <em>E</em>) and
<b><em>LR</em></b>(<em>H</em>, <em>H</em>*; <em>E</em>) measures an
important evidential relationship, but that the relationships they
measure are importantly different.</p>

<p>
 When odds measure total evidence neither
<b><em>PR</em></b>(<em>H</em>, <em>E</em>) nor
<b><em>LR</em></b>(<em>H</em>, <em>H</em>*; <em>E</em>) plays a
fundamental role in the theory of evidence.  Changes in the
probability ratio for <em>H</em> given <em>E</em> only indicate
changes in incremental evidence in the presence of information about
changes in the probability ratio for ~<em>H</em> given <em>E</em>.
Likewise, changes in the likelihood ratio for <em>H</em> and
<em>H</em>* given <em>E</em> only indicate changes in the balance of
evidence in light of information about changes in the likelihood ratio
for ~<em>H</em> and ~<em>H</em>* given <em>E</em>.  Thus, while each
of the two functions can figure as one component in a meaningful
measure of confirmation, neither tells us anything about incremental
evidence when taken by itself.</p>

<p>
 The third view, "likelihoodism," is popular among non-Bayesian
statisticians.  Its proponents deny evidence proportionism.  They
maintain that a person's subjective probability for a hypothesis
merely reflects her degree of uncertainty about its truth; it need not
be tied in any way to the amount of evidence she has in its
 favor.<sup>[<a href="notes.html#15" name="note-15">15</a>]</sup>
 It is likelihood ratios, not subjective probabilities, which capture
the "scientifically meaningful" evidential relations.  Here are two
classic statements of the position.</p>

<blockquote>
 All the information which the data provide concerning the relative
merits of two hypotheses is contained in the likelihood ratio of the
hypotheses on the data.  (Edwards 1972, 30)

<p>
 The &lsquo;evidential meaning&rsquo; of experimental results is characterized
fully by the likelihood function&hellip; Reports of experimental results in
scientific journals should in principle be descriptions of likelihood
functions. (Brinbaum 1962, 272)</p>
 </blockquote>

<p>
 On this view, everything that can be said about the evidential import
of <em>E</em> for <em>H</em> is embodied in the following
generalization of the weak likelihood principle:</p>

 <blockquote>
 <em>The</em> "<em>Law of Likelihood</em>".  If <em>H</em> implies that the
probability of <em>E</em> is <em>x</em>, while <em>H</em>* implies
that the probability of <em>E</em> is <em>x</em>*, then <em>E</em> is
evidence supporting <em>H</em> over <em>H</em>* if and only if
<em>x</em> exceeds <em>x</em>*, and the likelihood ratio,
<em>x</em><b>/</b><em>x</em>*, measures the strength of this support.
(Hacking 1965, 106-109), (Royall 1997, 3)
 </blockquote>

<p>
 The biostatistician Richard Royall is a particularly lucid defender
of likelihoodism (Royall 1997).  He maintains that any scientifically
respectable concept of evidence must analyze the evidential impact of
<em>E</em> on <em>H</em> solely in terms of likelihoods; it should not
advert to anyone's unconditional probabilities for <em>E</em> or
<em>H</em>.  This is supposed to be because likelihoods are both
better known and more objective than unconditional probabilities.
Royall argues strenuously against the idea that incremental evidence
can be measured in terms of the disparity between unconditional and
conditional probabilities.  Here is the gist of his complaint:</p>

<blockquote>
 Whereas [<b><em>LR</em></b>(<em>H</em>, <em>H</em>*; <em>E</em>)]
measures the support for one hypothesis <em>H</em> relative to a
specific alternative <em>H</em>*, without regard either to the prior
probabilities of the two hypotheses or to what other hypotheses might
also be considered, the law of changing probability [as measured by
<b><em>PR</em></b>(<em>H</em>, <em>E</em>)] measures support for
<em>H</em> relative to a specific prior distribution over <em>H</em>
and its alternatives... The law of changing probability is of limited
usefulness in scientific discourse because of its dependence on the
prior probability distribution, which is generally unknown and/or
personal.  Although you and I agree (on the basis of the law of
likelihood) that given evidence supports <em>H</em> over <em>H</em>*,
and <em>H</em>** over both <em>H</em> and <em>H</em>*, we might
disagree about whether it is evidence supporting <em>H</em> (on the
basis of the law of changing probability) purely on the basis of our
different judgments of the priori probability of <em>H</em>,
<em>H</em>*, and <em>H</em>**.  (Royall 1997, 10-11, with slight
changes in notation)
 </blockquote>

<p> Royall's point is that neither the probability ratio nor probability
difference will capture the sort of objective evidence required by
science because their values depend on the "subjective" terms
<b>P</b>(<em>E</em>) and <b>P</b>(<em>H</em>), and not just on the
"objective" likelihoods <b>P</b><sub><em>H</em></sub>(<em>E</em>) and
<b>P</b><sub>~<em>H</em></sub>(<em>E</em>).</p>

<p>
 Whether one agrees with this assessment will be a matter of
philosophical temperament, in particular of one's willingness to
tolerate subjective probabilities in one's account of evidential
relations.  It will also depend crucially on the extent to which one
is convinced that likelihoods are better known and more objective than
ordinary subjective probabilities.  Cases like the one envisioned in
the law of likelihood, where hypotheses <em>deductively entails</em> a
definite probability for the data, are relatively rare.  So, unless
one is willing to adopt a theory of evidence with a very restricted
range of application, a great deal will turn on how easy it is to
determine objective likelihoods in situations where the predictive
connection from hypothesis to data is itself the result of
<em>inductive</em> inferences.  However one comes down on these
issues, though, there is no denying that likelihood ratios will play a
central role in any probabilistic account of evidence.</p>

<p>
 In fact, the weak likelihood principle (2.1e) encapsulates a minimal
form of Bayesianism to which all parties can agree.  This is clearest
when it is restated in terms of likelihoods.</p>

 <blockquote>
<table>
<tr>
<td valign="top"><b>(2.1e)</b>&nbsp;</td>
 <td valign="top"><b>The Weak Likelihood Principle</b>. (expressed in
terms of likelihood ratios)</td>
 </tr>
<tr>
<td> </td>
 <td>If <b><em>LR</em></b>(<em>H</em>, <em>H</em>*; <em>E</em>)
&ge; 1 and <b><em>LR</em></b>(~<em>H</em>, ~<em>H</em>*;
~<em>E</em>) &ge; 1, with one inequality strict, then <em>E</em>
provides more incremental evidence for <em>H</em> than for <em>H</em>*
and ~<em>E</em> provides more incremental evidence for ~<em>H</em>
than for ~<em>H</em>*.</td>
 </tr>
</table>
</blockquote>

<p>
 Likelihoodists will endorse (2.1e) because the relationships
described in its antecedent depend only on inverse probabilities.
Proponents of both the "probability" and "odds" interpretations of
total evidence will accept (2.1e) because satisfaction of its
antecedent ensures that conditioning on <em>E</em> increases
<em>H</em>'s probability and its odds strictly more than those of
<em>H</em>*.  Indeed, the weak likelihood principle must be an
integral part of any account of evidential relevance that deserves the
title "Bayesian".  To deny it is to misunderstand the central message
of Bayes' Theorem for questions of evidence: namely, that hypotheses
are confirmed by data they predict.  As we shall see in the next
section, this "minimal" form of Bayesianism figures importantly into
subjectivist models of learning from experience.</p>

 <h2><a name="4">4. The Role of Bayes' Theorem in Subjectivist Models of Learning</a></h2>

<p>

Subjectivists think of learning as a process of <em>belief
revision</em> in which a "prior" subjective probability <b>P</b> is
replaced by a "posterior" probability <b>Q</b> that incorporates newly
acquired information.  This process proceeds in two stages. First,
some of the subject's probabilities are <em>directly altered</em> by
experience, intuition, memory, or some other <em>non-inferential</em>
learning process. Second, the subject "updates" the rest of her
opinions to bring them into line with her newly acquired knowledge.</p>

<p>
 Many subjectivists are content to regard the initial belief changes
as <em>sui generis</em> and independent of the believer's prior state
of opinion.  However, as long as the first phase of the learning
process is understood to be non-inferential, subjectivism can be made
compatible with an "externalist" epistemology that allows for
criticism of belief changes in terms the reliability of the causal
processes that generate them. It can even accommodate the thought that
the direct effect of experience might depend causally on the
believer's prior probability.</p>

<p>
 Subjectivists have studied the second, inferential phase of the
learning process in great detail. Here immediate belief changes are
seen as imposing constraints of the form "the posterior probability
<b>Q</b> has such-and-such properties." The objective is to discover
what sorts of constraints experience tends to impose, and to explain
how the person's <em>prior</em> opinions can be used to justify the
choice of a posterior probability from among the many that might
satisfy a given constraint. Subjectivists approach the latter problem
by assuming that the agent is justified in adopting whatever eligible
posterior <em>departs minimally</em> from her prior opinions. This is
a kind of "no jumping to conclusions" requirement. We explain it here
as a natural result of the idea that rational learners should
proportion their beliefs to the strength of the evidence they acquire.</p>

<p>
 The simplest learning experiences are those in which the learner
becomes certain of the truth of some proposition <em>E</em> about
which she was previously uncertain. Here the constraint is that all
hypotheses inconsistent with <em>E</em> must be assigned probability
zero. Subjectivists model this sort of learning as <em>simple
conditioning</em>, the process in which the prior probability of each
proposition <em>H</em> is replaced by a posterior that coincides with
the prior probability of <em>H</em> conditional on <em>E</em>.</p>

 <blockquote>
<table>
<tr>
<td valign="top"><b>(3.1)</b></td>
<td valign="top"><b>Simple Conditioning</b></td>
</tr>
<tr>
<td> </td>
 <td>If a person with a "prior" such that 0 &lt; <b>P</b>(<em>E</em>) &lt; 1
has a learning experience whose sole immediate effect is to raise her
subjective probability for <em>E</em> to 1, then her post-learning
"posterior" for any proposition <em>H</em> should be
<b>Q</b>(<em>H</em>) = <b>P</b><sub><em>E</em></sub>(<em>H</em>).</td>
 </tr>
</table>
</blockquote>

<p>
 In short, a rational believer who learns for certain that <em>E</em>
is true should factor this information into her doxastic system by
conditioning on it.</p>

<p>
 Though useful as an ideal, simple conditioning is not widely
applicable because it requires the learner to become absolutely
<em>certain</em> of <em>E</em>'s truth. As Richard Jeffrey has argued
(Jeffrey 1987), the evidence we receive is often too vague or
ambiguous to justify such "dogmatism."  On more realistic models, the
direct effect of a learning experience will be to <em>alter</em> the
subjective probability of some proposition without raising it to 1 or
lowering it to 0. Experiences of this sort are appropriately modeled
by what has come to be called <em>Jeffrey conditioning</em> (though
Jeffrey's preferred term is "probability kinematics").</p>

 <blockquote>
<table>
<tr>
<td valign="top"><b>(3.2)</b></td>
<td valign="top"><b>Jeffrey Conditioning</b></td>
</tr>
<tr>
<td> </td>
 <td>If a person with a prior such that 0 &lt; <b>P</b>(<em>E</em>) &lt; 1
has a learning experience whose sole immediate effect is to change her
subjective probability for <em>E</em> to <em>q</em>, then her
post-learning posterior for any <em>H</em> should be
<b>Q</b>(<em>H</em>) =
<em>q</em><b>P</b><sub><em>E</em></sub>(<em>H</em>) + (1 &minus;
<em>q</em>)<b>P</b><sub>~<em>E</em></sub>(<em>H</em>).</td>
 </tr>
</table>
</blockquote>

<p>
 Obviously, Jeffrey conditioning reduces to simple conditioning when
<em>q</em> = 1.</p>

<p>
 A variety of arguments for conditioning (simple or Jeffrey-style) can
be found in the literature, but we cannot consider them
 here.<sup>[<a href="notes.html#16" name="note-16">16</a>]</sup>
 There is, however, one sort of justification in which Bayes' Theorem
figures prominently. It exploits connections between belief revision
and the notion of incremental evidence to show that conditioning is
the <em>only</em> belief revision rule that allows learners to
correctly proportion their posterior beliefs to the new evidence they
receive.</p>

<p>
 The key to the argument lies in marrying the "minimal" version of
Bayesian expressed in the (2.1e) to a very modest "proportioning"
requirement for belief revision rules.</p>

 <blockquote>
<table>
<tr>
<td valign="top"><b>(3.3)</b></td>
<td valign="top"><b>The Weak Evidence Principle</b></td>
</tr>
<tr>
<td> </td>
 <td> If, relative to a prior <b>P</b>, <em>E</em> provides at least
as much incremental evidence for <em>H</em> as for <em>H</em>*, and if
<em>H</em> is antecedently more probable than <em>H</em>*, then
<em>H</em> should remain more probable than <em>H</em>* after any
learning experience whose sole immediate effect is to increase the
probability of <em>E</em>.</td>
 </tr>
</table>
</blockquote>

<p>
 This requires an agent to retain his views about the relative
probability of two hypotheses when he acquires evidence that supports
the more probable hypothesis more strongly. It rules out obviously
irrational belief revisions such as this: George is more confident
that the New York Yankees will win the American League Pennant than he
is that the Boston Rex Sox will win it, but he reverses himself when
he learns (only) that the Yankees beat the Red Sox in last night's
game.</p>

<p>
 Combining (3.3) with minimal Bayesianism yields the following:</p>

 <blockquote>
<table>
<tr>
<td valign="top"><b>(3.4)</b></td>
<td valign="top"><b>Consequence</b></td>
</tr>
<tr>
<td> </td>
 <td>If a person's prior is such that <b><em>LR</em></b>(<em>H</em>,
<em>H</em>*; <em>E</em>) &ge; 1, <b><em>LR</em></b>(~<em>H</em>,
~<em>H</em>*; ~<em>E</em>) &ge; 1, and <b>P</b>(<em>H</em>) &gt;
<b>P</b>(<em>H</em>*), then any learning experience whose sole
immediate effect is to raise her subjective probability for <em>E</em>
should result in a posterior such that <b>Q</b>(<em>H</em>) &gt;
<b>Q</b>(<em>H</em>*).</td>
 </tr>
</table>
</blockquote>

<p>
 On the reasonable assumption that <b>Q</b> is defined on the same set
of propositions over which <b>P</b> is defined, this condition
suffices to pick out simple conditioning as the <em>unique</em>
correct method of belief revision for learning experiences that make
<em>E</em> certain.  It picks out Jeffrey conditioning as the
<em>unique</em> correct method when learning merely alters one's
subjective probability for <em>E</em>.  The argument for these
conclusions makes use of the following two facts about probabilities.</p>

<blockquote>
<table>
<tr>
<td valign="top"><b>(3.5)</b></td>
<td valign="top"><b>Lemma</b></td>
</tr>

<tr>
<td> </td>
 <td>If <em>H</em> and <em>H</em>* both entail <em>E</em> when
<b>P</b>(<em>H</em>) &gt; <b>P</b>(<em>H</em>*), then
<b><em>LR</em></b>(<em>H</em>, <em>H</em>*; <em>E</em>) = 1 <br />and
<b><em>LR</em></b>(~<em>H</em>, ~<em>H</em>*; ~<em>E</em>) &gt;
1.</td>
 </tr>

<tr>
<td></td>
<td><a href="supplement.html#9" name="s-9">Proof Sketch</a></td>
</tr>
</table>

<table>
<tr>
<td valign="top"><b>(3.6)</b></td>
<td valign="top"><b>Lemma</b></td>
</tr>

<tr>
<td> </td>
 <td>Simple conditioning on <em>E</em> is the only rule for revising
subjective probabilities that yields a posterior with the following
properties for <em>any</em> prior such that <b>P</b>(<em>E</em>) &gt;
0:
<ol type="i">
<li><b>Q</b>(<em>E</em>) = 1.</li>
 <li><em>Ordinal Similarity</em>.  If <em>H</em> and <em>H</em>* both
entail <em>E</em>, then <b>P</b>(<em>H</em>) &ge;
<b>P</b>(<em>H</em>*) if and <br />only if <b>Q</b>(<em>H</em>) &ge;
<b>Q</b>(<em>H</em>*).</li>
</ol>
</td>
</tr>

<tr>
<td></td>
<td><a href="supplement.html#10" name="s-10">Proof Sketch</a></td>
</tr>
</table>

</blockquote>

<p>
 From here the argument for simple conditioning is a matter of using
(3.4) and (3.5) to establish ordinal similarity.  Suppose that
<em>H</em> and <em>H</em>* entail <em>E</em> and that
<b>P</b>(<em>H</em>) &gt; <b>P</b>(<em>H</em>*).  It follows from
(3.5) that <b><em>LR</em></b>(<em>H</em>, <em>H</em>*; <em>E</em>) = 1
and <b><em>LR</em></b>(~<em>H</em>, ~<em>H</em>*; ~<em>E</em>) &gt;
1. (3.4) then entails that any learning experience that raises
<em>E</em>'s probability must result in a posterior with
<b>Q</b>(<em>H</em>) &gt; <b>Q</b>(<em>H</em>*).  Thus, <b>Q</b> and
<b>P</b> are ordinally similar with respect to hypotheses that entail
<em>H</em>.  If we go on to suppose that the learning experience
raises <em>E</em>'s probability to 1, then (3.6) then guarantees that
<b>Q</b> arises from <b>P</b> by simple conditioning on <em>E</em>.</p>

<p>
 The case for Jeffrey conditioning is similarly direct.  Since the
argument for ordinal similarity did not depend at all on the
assumption that <b>Q</b>(<em>E</em>) = 1, we have really established</p>

 <blockquote>
<table>
<tr>
<td><b>(3.7)</b></td>
<td><b>Corollary</b></td>
</tr>
<tr>
<td> </td>
 <td>&bull; If <em>H</em> and <em>H</em>* entail <em>E</em>, then
<b>P</b>(<em>H</em>) &gt; <b>P</b>(<em>H</em>*) if and only if
<b>Q</b>(<em>H</em>) &gt; <b>Q</b>(<em>H</em>*).</td>
</tr>

<tr>
<td></td>
 <td>&bull; If <em>H</em> and <em>H</em>* entail ~<em>E</em>, then
<b>P</b>(<em>H</em>) &gt; <b>P</b>(<em>H</em>*) if and only if
<b>Q</b>(<em>H</em>) &gt; <b>Q</b>(<em>H</em>*).</td>
 </tr>
</table>
</blockquote>

<p>
 So, <b>Q</b> is ordinally similar to <b>P</b> both when restricted to
hypotheses that entail <em>E</em> and when restricted to hypotheses
than entail ~<em>E</em>. Moreover, since dividing by positive numbers
does not disturb ordinal relationships, it also follows that that
<b>Q</b><sub><em>E</em></sub> is ordinally similar to <b>P</b> when
restricted to hypotheses that entail <em>E</em>, and that
<b>Q</b><sub>~<em>E</em></sub> is ordinally similar to <b>P</b> when
restricted to hypotheses than entail ~<em>E</em>. Since
<b>Q</b><sub><em>E</em></sub>(<em>E</em>) = 1 =
<b>Q</b><sub>~<em>E</em></sub>(<em>E</em>), (3.6) then entails:</p>

 <blockquote>
<table>
<tr>
<td><b>(3.8)</b></td>
<td><b>Consequence</b></td>
</tr>
<tr>
<td> </td>
<td>
 For every proposition <em>H</em>,
<b>Q</b><sub><em>E</em></sub>(<em>H</em>) =
<b>P</b><sub><em>E</em></sub>(<em>H</em>) and
<b>Q</b><sub>~<em>E</em></sub>(<em>H</em>) =
<b>P</b><sub>~<em>E</em></sub>(<em>H</em>)
 </td>
</tr>
</table>
</blockquote>

<p>
 It is easy to show that (3.8) is necessary and sufficient for
<b>Q</b> to arise from <b>P</b> by Jeffrey conditioning on <em>E</em>.
Subject to the constraint <b>Q</b>(<em>E</em>) = <em>q</em>, it
guarantees that <b>Q</b>(<em>H</em>) =
<em>q</em><b>P</b><sub><em>E</em></sub>(<em>H</em>) + (1
&minus;<em>q</em>)<b>P</b><sub>~<em>E</em></sub>(<em>H</em>).</p>

<p>
 The general moral is clear.</p>

 <blockquote>
 <em>The basic Bayesian insight embodied in the weak likelihood
principle (2.1e) entails that simple and Jeffrey conditioning on
<em>E</em> are the </em>only<em> rational ways to revise beliefs in
response to a learning experience whose sole immediate effect is to
alter <em>E</em>'s probability.</em>
 </blockquote>

<p>
 While much more can be said about simple conditioning, Jeffrey
conditioning and other forms of belief revision, these remarks should
give the reader a sense of the importance of Bayes' Theorem in
subjectivist accounts of learning and evidential support. Though a
mathematical triviality, the Theorem's central insight &mdash; that a
hypothesis is supported by any body of data it renders probable &mdash; lies at the heart of all subjectivist approaches to epistemology, statistics, and inductive logic.</p>

</div>

<div id="bibliography">

<h2><a name="Bib">Bibliography</a></h2>

 <ul>

<li>Armendt, B. 1980. "Is There a Dutch Book Argument for Probability
Kinematics?", <em>Philosophy of Science</em> <b>47</b>, 583-588.</li>

<li>Bayes, T. 1764. "An Essay Toward Solving a Problem in the Doctrine
of Chances", <em>Philosophical Transactions of the Royal Society of
London</em> <b>53</b>, 370-418. 
 [<a href="https://web.archive.org/web/20190126111142/http://www.stat.ucla.edu/history/essay.pdf" target="other">Fascimile available online</a>: the original essay with an introduction by
 his friend Richard Price]</li>

<li>Birnbaum A. 1962. "On the Foundations of Statistical Inference",
<em>Journal of the American Statistical Association</em> <b>53</b>,
259-326.</li>

<li>Carnap, R. 1962. <em>Logical Foundations of Probability</em>, 2nd
edition. Chicago: University of Chicago Press.</li>

<li>Chihara, C. 1987. "Some Problems for Bayesian Confirmation
Theory", <em>British Journal for the Philosophy of Science</em>
<b>38</b>, 551-560.</li>

<li>Christensen, D. 1999. "Measuring Evidence", <em>Journal of
Philosophy</em> <b>96</b>, 437-61.</li>

<li>Dale, A. I. 1989. "Thomas Bayes: A Memorial", <em>The Mathematical
Intelligencer</em> <b>11</b>, 18-19.</li>

<li>----- 1999. <em>A History of Inverse Probability</em>, 2nd
edition. New York: Springer-Verlag.</li>

<li>Earman, J. 1992. <em>Bayes or Bust?</em> Cambridge, MA: MIT
Press.</li>

<li>Edwards, A. W. F. 1972. <em>Likelihood</em>. Cambridge: Cambridge
University Press.</li>

<li>Glymour, Clark. 1980. <em>Theory and Evidence</em>. Princeton:
Princeton University Press.</li>

<li>Hacking, Ian. 1965. <em>Logic of Statistical
Inference</em>. Cambridge: Cambridge University Press.</li>

<li>H&aacute;jek, A. 2003. "Interpretations of the Probability Calculus",
 in the <em>Stanford Encyclopedia of Philosophy</em>, (Summer 2003
Edition), Edward N. Zalta (ed.), URL =
 &lt;<a href="https://plato.stanford.edu/archives/sum2003/entries/probability-interpret/">https://plato.stanford.edu/archives/sum2003/entries/probability-interpret/</a>&gt;</li>

<li>Hammond, P. 1994. "Elementary non-Archimedean Representations for
of Probability for Decision Theory and Games," in P. Humphreys, ed.,
<em>Patrick Suppes: Scientific Philosopher, vol. 1</em>., Dordrecht:
Kluwer Publishers, 25-62.</li>

<li>Harper, W. 1976. "Rational Belief Change, Popper Functions and
Counterfactuals," in W. Harper and C. Hooker, eds., <em>Foundations of
Probability Theory, Statistical Inference, and Statistical Theories of
Science, vol. I</em>. Dordrecht: Reidel, 73-115.</li>

<li>Hartigan, J. A. 1983. <em>Bayes Theory</em>. New York:
Springer-Verlag.</li>

<li>Howson, Colin. 1985. "Some Recent Objections to the Bayesian
Theory of Support", <em>British Journal for the Philosophy of
Science</em>, <b>36</b>, 305-309.</li>

<li>Jeffrey, R. 1987. "Alias Smith and Jones: The Testimony of the
Senses", <em>Erkenntnis</em> <b>26</b>, 391-399.</li>

<li>----- 1992. <em>Probability and the Art of Judgment</em>. New
York: Cambridge University Press.</li>

<li>Joyce, J. M. 1999. <em>The Foundations of Causal Decision
Theory</em>. New York: Cambridge University Press.</li>

<li>Kahneman, D. and Tversky, A. 1973. "On the psychology of
prediction", <em>Psychological Review</em> <b>80</b>, 237-251.</li>

<li>Kaplan, M. 1996. <em>Decision Theory as
Philosophy</em>. Cambridge: Cambridge University Press.</li>

<li>Levi, I. 1985. "Imprecision and Indeterminacy in Probability
Judgment", <em>Philosophy of Science</em> <b>53</b>, 390-409.</li>

<li>Maher, P. 1996. "Subjective and Objective Confirmation",
<em>Philosophy of Science</em> <b>63</b>, 149-174.</li>

<li>McGee, V. 1994. "Learning the Impossible," in E. Eells and
B. Skyrms, eds., <em>Probability and Conditionals</em>. New York:
Cambridge University Press, 179-200.</li>

<li>Mortimer, Halina. 1988. <em>The logic of induction</em>, Ellis Horwood 
Series in Artificial Intelligence, New York; Halsted Press.</li>

<li>Nozick, R. 1981. <em>Philosophical Explanations</em>. Cambridge:
Harvard University Press.
</li>

<li>Renyi, A. 1955. "On a New Axiomatic Theory of Probability",
<em>Acta Mathematica Academiae Scientiarium Hungaricae</em> <b>6</b>,
285-335.</li>

<li>Royall, R. 1997. <em>Statistical Evidence: A Likelihood
Paradigm</em>. New York: Chapman &amp; Hall/CRC.</li>

<li>Skyrms, B. 1987. "Dynamic Coherence and Probability
Kinematics". <em>Philosophy of Science</em> <b>54</b>, 1-20.
</li>

<li>Sober, E. 2002. "Bayesianism &mdash; its Scope and Limits", in
Swinburne (2002), 21-38.</li>

<li>Sphon, W. 1986. "The Representation of Popper Measures",
<em>Topoi</em> <b>5</b>, 69-74.</li>

<li>Stigler, S. M. 1982. "Thomas Bayes' Bayesian Inference",
<em>Journal of the Royal Statistical Society, series A</em>
<b>145</b>, 250-258.</li>

<li>Swinburne, R. 2002. <em>Bayes' Theorem</em>. Oxford: Oxford
University Press (published for the British Academy).</li>

<li>Talbot, W. 2001. "Bayesian Epistemology",
 <em>Stanford Encyclopedia of Philosophy</em> (Fall
2001 Edition), Edward N. Zalta (ed.), URL =
 &lt;<a href="https://plato.stanford.edu/archives/fall2001/entries/epistemology-bayesian/">https://plato.stanford.edu/archives/fall2001/entries/epistemology-bayesian/</a>&gt;</li>

<li>Teller, P. 1976. "Conditionalization, Observation, and Change of
Preference", in W. Harper and C.A. Hooker, eds., <em>Foundations of
Probability Theory, Statistical Inference, and Statistical Theories of
Science</em>. Dordrecht: D. Reidel.
</li>

<li>Williamson, T. 2000. <em>Knowledge and its Limits</em>. Oxford:
Oxford University Press.</li>

<li>Van Fraassen, B.  1999. "A New Argument for
Conditionalization". <em>Topoi</em> <b>18</b>, 93-96.</li>

</ul>

</div>

<div id="academic-tools">

<h2><a id="Aca">Academic Tools</a></h2>

<blockquote>
<table>
<tr><td valign="top"><img src="../../symbols/sepman-icon.jpg" alt="sep man icon" /></td>
<td><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=bayes-theorem" target="other">How to cite this entry</a>.</td>
</tr>
<tr><td valign="top"><img src="../../symbols/sepman-icon.jpg" alt="sep man icon" /></td>
<td><a href="https://leibniz.stanford.edu/friends/preview/bayes-theorem/" target="other">Preview the PDF version of this entry</a> at the <a href="https://leibniz.stanford.edu/friends/" target="other">Friends of the SEP Society</a>.</td>
</tr>
<tr><td valign="top"><img src="../../symbols/inpho.png" alt="inpho icon" /></td>
<td><a href="https://www.inphoproject.org/entity?sep=bayes-theorem&amp;redirect=True" target="other">Look up topics and thinkers related to this entry</a>
 at the Internet Philosophy Ontology Project (InPhO).</td>
</tr>
<tr><td valign="top"><img src="../../symbols/pp.gif" alt="phil papers icon" /></td>
<td><a href="http://philpapers.org/sep/bayes-theorem/" target="other">Enhanced bibliography for this entry</a> at <a href="http://philpapers.org/" target="other">PhilPapers</a>, with links to its database.</td>
</tr>
</table>
</blockquote>

</div>

<div id="other-internet-resources">

<h2><a name="Oth">Other Internet Resources</a></h2>

<ul>

<li>Fitelson, B. 2001. <em>Studies in Bayesian Confirmation
Theory</em>, Ph.D. Dissertation, University of Wisconsin.  
[<a href="http://fitelson.org/thesis.pdf" target="other">Preprint in PDF available online</a>] (750K download)</li>

<!--LINK CHECKER COMMENTED OUT (Wed May 1 14:29:06 PDT 2019)

<li><a href="http://www.stat.ucla.edu/history/essay.pdf" target="other">Bayes' Original Essay</a>
 (in PDF) (UCLA Statistics 
 Department/<a href="http://www.stat.ucla.edu/history/" target="other">History of Statistics</a>)</li>

LINK CHECKER-->

<!-- COMMENTED OUT BY LINK CHECKER (Thu Oct  9 04:49:17 2008)
<li><a href="http://www.stat.ucla.edu/history/people/bayes.gif" target="other">A Portrait, perhaps of Thomas Bayes</a>
 (UCLA Statistics
 Department/<a href="http://www.stat.ucla.edu/history/" target="other">History of Statistics</a>)</li>

 -->
<!-- COMMENTED OUT BY LINK CHECKER (Thu Oct 25 08:26:11 2007)
<li><a href="http://astrosun.tn.cornell.edu/staff/loredo/bayes/" target="other">Bayesian Inference for the Physical Sciences</a>
 (Tom Loredo, Astronomy, Cornell)</li>

 -->
<!-- COMMENTED OUT BY LINK CHECKER (Tue Feb  1 03:35:22 2005)
<li><a href="http://www.stats.uwo.ca/faculty/bellhouse/bayesmss.pdf" target="other">Recently Discovered Manuscripts of Thomas Bayes</a>
 (David Bellhouse, Statistical and Actuarial Sciences, U. Western Ontario)</li>

 -->
<li><a href="http://www-groups.dcs.st-andrews.ac.uk/~history/Mathematicians/Bayes.html" target="other">A Short Biography of Thomas Bayes</a>
 (University of St. Andrews, MacTutor History of Mathematics Archive)</li>

<li><a href="http://www.bayesian.org/" target="other">The International Society for Bayesian Analysis (ISBA)</a></li>
</ul>

</div>

<div id="related-entries">

<h2><a name="Rel">Related Entries</a></h2>

<p>

 <a href="../epistemology-bayesian/index.html">epistemology: Bayesian</a> |
 <a href="../probability-interpret/index.html">probability, interpretations of</a>

</p>

</div>

</div><!-- #aueditable --><!--DO NOT MODIFY THIS LINE AND BELOW-->

<!-- END ARTICLE HTML -->

</div> <!-- End article-content -->

  <div id="article-copyright">
    <p>
 <a href="../../info.html#c">Copyright &copy; 2003</a> by

<br />
<a href="http://www-personal.umich.edu/~jjoyce/" target="other">James Joyce</a>
&lt;<a href="m&#97;ilto:jjoyce&#37;40umich&#37;2eedu"><em>jjoyce<abbr title=" at ">&#64;</abbr>umich<abbr title=" dot ">&#46;</abbr>edu</em></a>&gt;
    </p>
  </div>

</div> <!-- End article -->

<!-- NOTE: article banner is outside of the id="article" div. -->
<div id="article-banner" class="scroll-block">
  <div id="article-banner-content">
    <a href="../../fundraising/index.html">
    Open access to the SEP is made possible by a world-wide funding initiative.<br />
    The Encyclopedia Now Needs Your Support<br />
    Please Read How You Can Help Keep the Encyclopedia Free</a>
  </div>
</div> <!-- End article-banner -->

    </div> <!-- End content -->

    <div id="footer">

      <div id="footer-menu">
        <div class="menu-block">
          <h4><i class="icon-book"></i> Browse</h4>
          <ul role="menu">
            <li><a href="../../contents.html">Table of Contents</a></li>
            <li><a href="../../new.html">What's New</a></li>
            <li><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/random">Random Entry</a></li>
            <li><a href="../../published.html">Chronological</a></li>
            <li><a href="../../archives/index.html">Archives</a></li>
          </ul>
        </div>
        <div class="menu-block">
          <h4><i class="icon-info-sign"></i> About</h4>
          <ul role="menu">
            <li><a href="../../info.html">Editorial Information</a></li>
            <li><a href="../../about.html">About the SEP</a></li>
            <li><a href="../../board.html">Editorial Board</a></li>
            <li><a href="../../cite.html">How to Cite the SEP</a></li>
            <li><a href="../../special-characters.html">Special Characters</a></li>
            <li><a href="../../tools/index.html">Advanced Tools</a></li>
            <li><a href="../../contact.html">Contact</a></li>
          </ul>
        </div>
        <div class="menu-block">
          <h4><i class="icon-leaf"></i> Support SEP</h4>
          <ul role="menu">
            <li><a href="../../support/index.html">Support the SEP</a></li>
            <li><a href="../../support/friends.html">PDFs for SEP Friends</a></li>
            <li><a href="../../support/donate.html">Make a Donation</a></li>
            <li><a href="../../support/sepia.html">SEPIA for Libraries</a></li>
          </ul>
        </div>
      </div> <!-- End footer menu -->

      <div id="mirrors">
        <div id="mirror-info">
          <h4><i class="icon-globe"></i> Mirror Sites</h4>
          <p>View this site from another server:</p>
        </div>
        <div class="btn-group open">
          <a class="btn dropdown-toggle" data-toggle="dropdown" href="https://plato.stanford.edu/">
            <span class="flag flag-usa"></span> USA (Main Site) <span class="caret"></span>
            <span class="mirror-source">Philosophy, Stanford University</span>
          </a>
          <ul class="dropdown-menu">
            <li><a href="../../mirrors.html">Info about mirror sites</a></li>
          </ul>
        </div>
      </div> <!-- End mirrors -->
      
      <div id="site-credits">
        <p>The Stanford Encyclopedia of Philosophy is <a href="../../info.html#c">copyright &copy; 2021</a> by <a href="http://mally.stanford.edu/">The Metaphysics Research Lab</a>, Department of Philosophy, Stanford University</p>
        <p>Library of Congress Catalog Data: ISSN 1095-5054</p>
      </div> <!-- End site credits -->

    </div> <!-- End footer -->

  </div> <!-- End container -->

   <!-- NOTE: Script required for drop-down button to work (mirrors). -->
  <script>
    $('.dropdown-toggle').dropdown();
  </script>

</body>

<!-- Mirrored from seop.illc.uva.nl/entries/bayes-theorem/ by HTTrack Website Copier/3.x [XR&CO'2014], Wed, 22 Jun 2022 19:39:20 GMT -->
</html>
