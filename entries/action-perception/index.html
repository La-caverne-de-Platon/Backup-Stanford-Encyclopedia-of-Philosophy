<!DOCTYPE html>
<!--[if lt IE 7]> <html class="ie6 ie"> <![endif]-->
<!--[if IE 7]>    <html class="ie7 ie"> <![endif]-->
<!--[if IE 8]>    <html class="ie8 ie"> <![endif]-->
<!--[if IE 9]>    <html class="ie9 ie"> <![endif]-->
<!--[if !IE]> --> <html> <!-- <![endif]-->

<!-- Mirrored from seop.illc.uva.nl/entries/action-perception/ by HTTrack Website Copier/3.x [XR&CO'2014], Wed, 22 Jun 2022 19:36:18 GMT -->
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>
Action-based Theories of Perception (Stanford Encyclopedia of Philosophy)
</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="robots" content="noarchive, noodp" />
<meta property="citation_title" content="Action-based Theories of Perception" />
<meta property="citation_author" content="Briscoe, Robert" />
<meta property="citation_author" content="Grush, Rick" />
<meta property="citation_publication_date" content="2015/07/08" />
<meta name="DC.title" content="Action-based Theories of Perception" />
<meta name="DC.creator" content="Briscoe, Robert" />
<meta name="DC.creator" content="Grush, Rick" />
<meta name="DCTERMS.issued" content="2015-07-08" />
<meta name="DCTERMS.modified" content="2015-07-08" />

<!-- NOTE: Import webfonts using this link: -->
<link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,300,600,200&amp;subset=latin,latin-ext" rel="stylesheet" type="text/css" />

<link rel="stylesheet" type="text/css" media="screen,handheld" href="../../css/bootstrap.min.css" />
<link rel="stylesheet" type="text/css" media="screen,handheld" href="../../css/bootstrap-responsive.min.css" />
<link rel="stylesheet" type="text/css" href="../../css/font-awesome.min.css" />
<!--[if IE 7]> <link rel="stylesheet" type="text/css" href="../../css/font-awesome-ie7.min.css"> <![endif]-->
<link rel="stylesheet" type="text/css" media="screen,handheld" href="../../css/style.css" />
<link rel="stylesheet" type="text/css" media="print" href="../../css/print.css" />
<link rel="stylesheet" type="text/css" href="../../css/entry.css" />
<!--[if IE]> <link rel="stylesheet" type="text/css" href="../../css/ie.css" /> <![endif]-->
<script type="text/javascript" src="../../js/jquery-1.9.1.min.js"></script>
<script type="text/javascript" src="../../js/bootstrap.min.js"></script>

<!-- NOTE: Javascript for sticky behavior needed on article and ToC pages -->
<script type="text/javascript" src="../../js/jquery-scrolltofixed-min.js"></script>
<script type="text/javascript" src="../../js/entry.js"></script>

<!-- SEP custom script -->
<script type="text/javascript" src="../../js/sep.js"></script>
</head>

<!-- NOTE: The nojs class is removed from the page if javascript is enabled. Otherwise, it drives the display when there is no javascript. -->
<body class="nojs article" id="pagetopright">
<div id="container">
<div id="header-wrapper">
  <div id="header">
    <div id="branding">
      <div id="site-logo"><a href="../../index.html"><img src="../../symbols/sep-man-red.png" alt="SEP logo" /></a></div>
      <div id="site-title"><a href="../../index.html">Stanford Encyclopedia of Philosophy</a></div>
    </div>
    <div id="navigation">
      <div class="navbar">
        <div class="navbar-inner">
          <div class="container">
            <button class="btn btn-navbar collapsed" data-target=".collapse-main-menu" data-toggle="collapse" type="button"> <i class="icon-reorder"></i> Menu </button>
            <div class="nav-collapse collapse-main-menu in collapse">
              <ul class="nav">
                <li class="dropdown open"><a id="drop1" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-book"></i> Browse</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop1">
                    <li><a href="../../contents.html">Table of Contents</a></li>
                    <li><a href="../../new.html">What's New</a></li>
                    <li><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/random">Random Entry</a></li>
                    <li><a href="../../published.html">Chronological</a></li>
                    <li><a href="../../archives/index.html">Archives</a></li>
                  </ul>
                </li>
                <li class="dropdown open"><a id="drop2" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-info-sign"></i> About</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop2">
                    <li><a href="../../info.html">Editorial Information</a></li>
                    <li><a href="../../about.html">About the SEP</a></li>
                    <li><a href="../../board.html">Editorial Board</a></li>
                    <li><a href="../../cite.html">How to Cite the SEP</a></li>
                    <li><a href="../../special-characters.html">Special Characters</a></li>
                    <li><a href="../../tools/index.html">Advanced Tools</a></li>
                    <li><a href="../../contact.html">Contact</a></li>
                  </ul>
                </li>
                <li class="dropdown open"><a id="drop3" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-leaf"></i> Support SEP</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop3">
                    <li><a href="../../support/index.html">Support the SEP</a></li>
                    <li><a href="../../support/friends.html">PDFs for SEP Friends</a></li>
                    <li><a href="../../support/donate.html">Make a Donation</a></li>
                    <li><a href="../../support/sepia.html">SEPIA for Libraries</a></li>
                  </ul>
                </li>
              </ul>
            </div>
          </div>
        </div>
      </div>
    </div>
    <!-- End navigation -->
    
    <div id="search">
      <form id="search-form" method="get" action="https://seop.illc.uva.nl/search/searcher.py">
        <input type="search" name="query" placeholder="Search SEP" />
        <div class="search-btn-wrapper"><button class="btn search-btn" type="submit"><i class="icon-search"></i></button></div>
      </form>
    </div>
    <!-- End search --> 
    
  </div>
  <!-- End header --> 
</div>
<!-- End header wrapper -->

<div id="content">

<!-- Begin article sidebar -->
<div id="article-sidebar" class="sticky">
  <div class="navbar">
    <div class="navbar-inner">
      <div class="container">
        <button class="btn btn-navbar" data-target=".collapse-sidebar" data-toggle="collapse" type="button"> <i class="icon-reorder"></i> Entry Navigation </button>
        <div id="article-nav" class="nav-collapse collapse-sidebar in collapse">
          <ul class="nav">
            <li><a href="#toc">Entry Contents</a></li>
            <li><a href="#Bib">Bibliography</a></li>
            <li><a href="#Aca">Academic Tools</a></li>
            <li><a href="https://leibniz.stanford.edu/friends/preview/action-perception/">Friends PDF Preview <i class="icon-external-link"></i></a></li>
            <li><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=action-perception">Author and Citation Info <i class="icon-external-link"></i></a> </li>
            <li><a href="#pagetopright" class="back-to-top">Back to Top <i class="icon-angle-up icon2x"></i></a></li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</div>
<!-- End article sidebar --> 

<!-- NOTE: Article content must have two wrapper divs: id="article" and id="article-content" -->
<div id="article">
<div id="article-content">

<!-- BEGIN ARTICLE HTML -->


<div id="aueditable"><!--DO NOT MODIFY THIS LINE AND ABOVE-->

<h1>Action-based Theories of Perception</h1><div id="pubinfo"><em>First published Wed Jul 8, 2015</em></div>

<div id="preamble">

<p>Action is a means of acquiring perceptual information about the
environment. Turning around, for example, alters your spatial
relations to surrounding objects and, hence, which of their properties
you visually perceive. Moving your hand over an object&rsquo;s surface
enables you to feel its shape, temperature, and texture. Sniffing and
walking around a room enables you to track down the source of an unpleasant
smell. Active or passive movements of the body can also generate
useful sources of perceptual information (Gibson 1966, 1979). The
pattern of optic flow in the retinal image produced by forward
locomotion, for example, contains information about the direction in
which you are heading, while motion parallax is a &ldquo;cue&rdquo;
used by the visual system to estimate the relative distances of
objects in your field of view. In these uncontroversial ways and
others, perception is instrumentally dependent on action. According to
an explanatory framework that Susan Hurley
(1998) dubs the
&ldquo;Input-Output Picture&rdquo;, the dependence of perception on
action is <em>purely</em> instrumental:</p>

<blockquote><p> Movement can alter sensory inputs and so result in
different perceptions&hellip; changes in output are merely a means to
changes in input, on which perception depends directly. (1998:
342)</p> </blockquote>

<p>The action-based theories of perception, reviewed in this entry,
challenge the Input-Output Picture. They maintain that perception can
also depend in a noninstrumental or <em>constitutive</em> way on
action (or, more generally, on capacities for object-directed motor control). This
position has taken many different forms in the history of philosophy
and psychology. Most action-based theories of perception in the last
300 years, however, have looked to action in order to explain how
vision, in particular, acquires either all or some of
its <em>spatial representational content</em>. Accordingly, these are
the theories on which we shall focus here.</p>

<p>We begin in <a href="#EarActBasThe">Section 1</a> by discussing
George Berkeley&rsquo;s <em>Towards a New Theory of Vision</em>
(1709), the historical <em>locus classicus</em> of action-based
theories of perception, and one of the most influential texts on
vision ever written. Berkeley argues that the basic or
&ldquo;proper&rdquo; deliverance of vision is not an arrangement of
voluminous objects in three-dimensional space, but rather a
two-dimensional manifold of light and color. We then turn to a
discussion of Lotze, Helmholtz, and the <em>local sign</em>
doctrine. The &ldquo;local signs&rdquo; were felt cues for the mind to
know what sort of spatial content to imbue visual experience with. For
Lotze, these cues were &ldquo;inflowing&rdquo; kinaesthetic feelings
that result from actually moving the eyes, while, for Helmholtz, they
were &ldquo;outflowing&rdquo; motor commands sent to move the
eyes.</p>

<p>In <a href="#SenConThe">Section 2,</a> we discuss sensorimotor
contingency theories, which became prominent in the 20<sup>th</sup>
century. These views maintain that an ability to predict the sensory
consequences of self-initiated actions is necessary for
perception. Among the motivations for this family of theories is the
problem of <em>visual direction constancy</em>&mdash;why do objects
appear to be stationary even though the locations on the retina to
which they reflect light change with every eye movement?&mdash;as well
as experiments on adaptation to optical rearrangement devices (ORDs)
and sensory substitution.</p>

<p><a href="#MotComEffReaThe">Section 3</a> examines two other
important 20<sup>th</sup> century theories. According to what we shall
call the <strong>motor component theory</strong>, efference copies
generated in the oculomotor system and/or proprioceptive feedback from
eye-movements are used together with incoming sensory inputs to
determine the spatial attributes of perceived
objects. <strong>Efferent readiness theories</strong>, by contrast,
look to the particular ways in which perceptual
states <em>prepare</em> the observer to move and act in relation to
the environment. The <strong>modest readiness theory</strong>, as we
shall call it, claims that the way an object&rsquo;s spatial
attributes are represented in visual experience can be modulated by
one or another form of covert action planning. The <strong>bold
readiness theory</strong> argues for the stronger claim that
perception <em>just is</em> covert readiness for action.</p>

<p>In <a href="#SkiThe">Section 4,</a> we move to
the <strong>disposition theory</strong>, most influentially
articulated by Gareth Evans (1982, 1985), but more recently defended
by Rick Grush (2000, 2007). Evans&rsquo; theory is, at its core, very
similar to the bold efferent readiness theory. There are some notable
differences, though. Evans&rsquo; account is more finely articulated
in some philosophical respects. It also does not posit a reduction of
perception to behavioral dispositions, but rather posits that certain
complicated relations between perceptual input and behavioral provide
spatial content. Grush proposes a very specific theory that is like
Evans&rsquo; in that it does not posit a reduction, but unlike
Evans&rsquo; view, does not put behavioral dispositions and sensory
input on an undifferentiated footing.</p>

</div>

<div id="toc">
<!--Entry Contents-->
<ul>
<li><a href="#EarActBasThe">1. Early Action-Based Theories</a>
 <ul>
 <li><a href="#MovTouNewTheVis">1.1 Movement and Touch in the <em>New Theory Of Vision</em></a></li>
 <li><a href="#ObjBerThe">1.2 Objections to Berkeley&rsquo;s Theory</a></li>
 <li><a href="#LotHelLocSigDoc">1.3 Lotze, Helmholtz, and the Local Sign Doctrine</a></li>
 </ul></li>

<li><a href="#SenConThe">2. Sensorimotor Contingency Theories</a>
 <ul>

 <li><a href="#EffVisDirCon">2.1 Efference and Visual Direction Constancy</a>
 <ul>
 <li><a href="#ObjEffCopThe">2.1.1 Objections to the Efference Copy Theory</a></li>
 <li><a href="#AltEffCopThe">2.1.2 Alternatives to the Efference Copy Theory</a></li>
 </ul></li>

 <li><a href="#ReaThe">2.2 The Reafference Theory</a>
 <ul>
 <li><a href="#OhInvWorEarExpOptRea">2.2.1 Oh, Inverted World: Early Experiments on Optical Rearrangement</a></li>
 <li><a href="#Str">2.2.2 Stratton</a></li>
 <li><a href="#Hel">2.2.3 Helmholtz</a></li>
 <li><a href="#HelExpPriAda">2.2.4 Held&rsquo;s Experiments On Prism Adaptation</a></li>
 <li><a href="#ChaReaThe">2.2.5 Challenges to the Reafference Theory</a></li>
 <li><a href="#ProChaThe">2.2.6 The Proprioceptive Change Theory</a></li>
 </ul></li>

 <li><a href="#EnaApp">2.3 The Enactive Approach</a>
 <ul>
 <li><a href="#SomQueAboPPro">2.3.1 Some questions about P-properties</a></li>
 <li><a href="#EviForEnaApp">2.3.2 Evidence for the Enactive Approach</a></li>
 <li><a href="#ChaEnaApp">2.3.2 Challenges to the Enactive Approach</a></li>
 </ul></li>
 </ul></li>

<li><a href="#MotComEffReaThe">3. Motor Component and Efferent Readiness Theories</a>
 <ul>
 <li><a href="#MotComTheEmbVisPer">3.1 The Motor Component Theory (Embodied Visual Perception)</a></li>
 <li><a href="#EffReaThe">3.2 The Efferent Readiness Theory</a>
 <ul>
 <li><a href="#ModReaThe">3.2.1 The Modest Readiness Theory</a></li>
 <li><a href="#BolReaThe">3.2.2 The Bold Readiness Theory</a></li>
 </ul></li>
 </ul></li>

<li><a href="#SkiThe">4. Skill/Disposition Theories</a></li>

<li><a href="#Bib">Bibliography</a></li>
<li><a href="#Aca">Academic Tools</a></li>
<li><a href="#Oth">Other Internet Resources</a></li>
<li><a href="#Rel">Related Entries</a></li>

</ul>

<!--Entry Contents-->
<hr />

</div>

<div id="main-text">

<h2><a id="EarActBasThe">1. Early Action-Based Theories</a></h2>

<p>Two doctrines dominate philosophical and psychological discussions
of the relationship between action and space perception from the
18<sup>th</sup> to the early 20<sup>th</sup> century. The <strong>first</strong>
is that the immediate objects of sight are two-dimensional manifolds
of light and color, lacking perceptible extension in
depth. The <strong>second</strong> is that vision must be
&ldquo;educated&rdquo; by the sense of touch&mdash;understood as
including both kinaesthesis and proprioceptive position sense&mdash;if
the former is to acquire its apparent outward, three-dimensional
spatial significance. The relevant learning process is associationist:
normal vision results when tangible ideas of distance (derived from
experiences of unimpeded movement) and solid shape (derived from
experiences of contact and differential resistance) are elicited by
the visible ideas of light and color with which they have been
habitually associated. The widespread acceptance of both doctrines
owes much to the influence of George Berkeley&rsquo;s <em>New Theory
of Vision</em> (1709).</p>

<p>The Berkeleyan approach looks to action in order to explain how
depth is &ldquo;added&rdquo; to a phenomenally two-dimensional visual
field. The spatial ordering of the visual field itself, however, is
taken to be immediately given in experience (Hatfield &amp; Epstein
1979; Falkenstein 1994; but see Grush 2007). Starting in the
19<sup>th</sup> century, a number of theorists, including Johann
Steinbuch (1770&ndash;1818), Hermann Lotze (1817&ndash;1881), Hermann
von Helmholtz (1821&ndash;1894), Wilhelm Wundt (1832&ndash;1920), and
Ernst Mach (1838&ndash;1916), argued that <em>all</em> abilities for
visual spatial localization, including representation of up/down and
left/right direction within the two-dimensional visual field, depend
on motor factors, in particular, gaze-directing movements of the eye
(Hatfield 1990: chaps. 4&ndash;5). This idea is the basis of the
&ldquo;local sign&rdquo; doctrine, which we examine
in <a href="#EnaApp">Section 2.3</a>.</p>

<h3><a id="MovTouNewTheVis">1.1 Movement and Touch in the <em>New Theory Of Vision</em></a></h3>

<p>There are three principal respects in which motor action is central
to Berkeley&rsquo;s project in the <em>New Theory of Vision</em>
(1709). First, Berkeley argues that visual experiences convey
information about three-dimensional space only to the extent that they
enable perceivers to anticipate the tactile consequences of actions
directed at surrounding objects. In &sect;45 of the <em>New
Theory,</em> Berkeley writes:</p>

<blockquote> <p> &hellip;I say, neither distance, nor things placed at
a distance are themselves, or their ideas, truly perceived by
sight&hellip;. whoever will look narrowly into his own thoughts, and
examine what he means by saying, he sees this or that thing at a
distance, will agree with me, that what he sees only suggests to his
understanding, that after having passed a certain distance, to be
measured by the motion of his body, which is perceivable by touch, he
shall come to perceive such and such tangible ideas which have been
usually connected with such and such visible ideas. </p></blockquote>

<p>And later in the <em>Treatise Concerning the Principles of Human
Knowledge</em> (1734: &sect;44):</p>

<blockquote> <p> &hellip;in strict truth the ideas of sight, when we
apprehend by them distance and things placed at a distance, do not
suggest or mark out to us things actually existing at a distance, but
only admonish us what ideas of touch will be imprinted in our minds at
such and such distances of time, and in consequence of such or such
actions. &hellip;[V]isible ideas are the language whereby the
governing spirit &hellip; informs us what tangible ideas he is about
to imprint upon us, in case we excite this or that motion in our own
bodies.</p></blockquote>

<p>The view Berkeley defends in these passages has recognizable
antecedents in Locke&rsquo;s <em>Essay Concerning Human
Understanding</em> (1690: Book II, Chap. 9,
&sect;&sect;8&ndash;10). There Locke maintained that the immediate
objects of sight are &ldquo;flat&rdquo; or lack outward depth; that
sight must be coordinated with touch in order to mediate judgments
concerning the disposition of objects in three-dimensional space; and
that visible ideas &ldquo;excite&rdquo; in the mind movement-based
ideas of distance through an associative process akin to that whereby
words suggest their meanings: the process is </p>

<blockquote><p> performed so constantly, and so quick, that we take
that for the perception of our sensation, which is an <em>idea</em>
formed by our judgment. </p></blockquote>

<p>
A long line of philosophers&mdash;including Condillac (1754), Reid
(1785), Smith (1811), Mill (1842, 1843), Bain (1855, 1868), and Dewey
(1891)&mdash;accepted this view of the relation between sight and
touch.</p>

<p>The second respect in which action plays a prominent role in
the <em>New Theory</em> is teleological. Sight not only derives its
three-dimensional spatial significance from bodily movement, its
purpose is to help us engage in such movement <em>adaptively</em>:</p>

<blockquote> <p> &hellip;the proper objects of vision constitute an
universal language of the Author of nature, whereby we are instructed
how to regulate our actions, in order to attain those things, that are
necessary to the preservation and well-being of our bodies, as also to
avoid whatever may be hurtful and destructive of them. It is by their
information that we are principally guided in all the transactions and
concerns of life. (1709: &sect;147)</p></blockquote>

<p>Although Berkeley does not explain <em>how</em> vision instructs us
in regulating our actions, the answer is reasonably clear from the
preceding account of depth perception: seeing an object or scene can
elicit tangible ideas that directly motivate self-preserving
action. The tactual ideas associated with a rapidly looming ball in
the visual field, for example, can directly motivate the subject to
shift position defensively or to catch it before being struck. </p>

<p>The third respect in which action is central to the <em>New
Theory</em> is psychological. Tangible ideas of distance are elicited
not only by (1) visual or &ldquo;pictorial&rdquo; depth cues such as
object&rsquo;s degree of blurriness (objects appear increasingly
&ldquo;confused&rdquo; as they approach the observer), but also by
kinaesthetic, muscular sensations resulting from (2) changes in the
vergence angle of the eyes (1709: &sect;16) and (3) accommodation of
the lens (1709: &sect;27). Like many contemporary theories of spatial
vision, the Berkeleyan account thus acknowledges an important role for
oculomotor factors in our perception of distance.</p>

<h3><a id="ObjBerThe">1.2 Objections to Berkeley&rsquo;s Theory</a></h3>

<p>Critics of Berkeley&rsquo;s theory in the 18<sup>th</sup> and
19<sup>th</sup> centuries (for reviews, see Bain 1868; Smith 2000;
Atherton 2005) principally targeted three claims:</p>

<dl class="sentag">
<dt>(a)</dt><dd>that &ldquo;distance, of it self and immediately, cannot be seen&rdquo; (Berkeley 1709: &sect;1);</dd>
<dt>(b)</dt><dd>that sight depends on learned connections with experiences of movement and touch for its outward, spatial significance; and</dd>
<dt>(c)</dt><dd>that &ldquo;habitual connexion&rdquo;, i.e., association, would by itself enable touch to &ldquo;educate&rdquo; vision in the manner required by (b).</dd>
</dl>

<p>Most philosophers and perceptual psychologists now concur with
Armstrong&rsquo;s (1960) assessment that the &ldquo;single
point&rdquo; argument for claim (a)&mdash;&ldquo;distance being a line
directed end-wise to the eye, it projects only one point in the fund
of the eye, which point remains invariably the same, whether the
distance be longer or shorter&rdquo; (Berkeley 1709: &sect;2)&mdash;conflates
spatial properties of the retinal image with those of the objects of
sight (also see Condillac 1746/2001: 102; Abbott 1864: chap. 1). In
contrast with claim (a), we should note, both contemporary
&ldquo;ecological&rdquo; and information-processing approaches in
vision science assume that the spatial representational contents of
visual experience are robustly three-dimensional: vision is no less a
distance sense than touch.</p>

<p>Three sorts of objections targeted on claim (b) were
prominent. First, it is not evident to introspection that visual
experiences reliably elicit tactile and kinaesthetic images as
Berkeley suggests. As Bain succinctly formulates this objection: </p>

<blockquote><p> In perceiving distance, we are not conscious of
tactual feelings or locomotive reminiscences; what we see is a visible
quality, and nothing more. (1868: 194)</p></blockquote>

<p>Second, sight is often the refractory party when conflicts with
touch arise. Consider the experience of seeing a three-dimensional
scene in a painting: &ldquo;I know, without any doubt&rdquo;, writes
Condillac,</p>

<blockquote><p> that it is painted on a flat surface; I have touched
it, and yet this knowledge, repeated experience, and all the judgments
I can make do not prevent me from seeing convex figures. Why does this
appearance persist? (1746/2001: I, &sect;6, 3)</p></blockquote>

<p>Last, vision in many animals does not need tutoring by touch before
it is able to guide spatially directed movement and action. Cases in
which non-human neonates respond adaptively to the distal sources of
visual stimulation </p>

<blockquote><p> imply that external objects are seen to be
so&hellip;. They prove, at least, the possibility that the opening of
the eye may be at once followed by the perception of external objects
as such, or, in other words, by the perception or sensation of
outness. (Bailey 1842: 30; for replies, see Smith 1811:
385&ndash;390)</p></blockquote>

<p>
Here it would be in principle possible for a proponent of
Berkeley&rsquo;s position to maintain that, at least for such animals,
the connection between visual ideas and ideas of touch is innate and
not learned (see Stewart 1829: 241&ndash;243; Mill 1842:
106&ndash;110). While this would abandon Berkeley&rsquo;s empiricism
and associationism, it would maintain the claim that vision provides
depth information only because its ideas are connected to tangible
ideas.</p>

<p>Regarding claim (c), many critics denied that the supposed
&ldquo;habitual connexion&rdquo; between vision and touch actually
obtains. Suppose that the novice perceiver sees a remote tree at
time<sub>1</sub> and walks in its direction until she makes contact
with it at time<sub>2</sub>. The problem is that the perceiver&rsquo;s
initial visual experience of the tree at time<sub>1</sub> is not
temporally contiguous with the locomotion-based experience of the
tree&rsquo;s distance completed at time<sub>2</sub>. Indeed, at
time<sub>2</sub> the former experience no longer exists. &ldquo;The
association required&rdquo;, Abbott thus writes, </p>

<blockquote><p> cannot take place, for the simple reason that the
ideas to be associated cannot co-exist. We cannot at one and the same
moment be looking at an object five, ten, fifty yards off, and be
achieving our last step towards it. (1864: 24)</p></blockquote>

<p>Finally, findings from perceptual psychology have more recently
been leveled against the view that vision is educated by
touch. Numerous studies of how subjects respond to lens-, mirror-, and
prism-induced distortions of visual experience (Gibson 1933; Harris
1965, 1980; Hay <em>et al.</em> 1965; Rock &amp; Harris 1967) indicate
that not only is sight resistant to correction from touch, it will
often dominate or &ldquo;capture&rdquo; the latter when intermodal
conflicts arise. This point will be discussed in greater depth
in <a href="#MotComEffReaThe">Section 3</a> below.</p>

<h3><a id="LotHelLocSigDoc">1.3 Lotze, Helmholtz, and the Local Sign Doctrine</a></h3>

<p>Like Berkeley, Hermann Lotze (1817&ndash;1881) and Hermann von
Helmholtz (1821&ndash;1894) affirm the role played by active movement
and touch in the genesis of three-dimensional visuospatial
awareness:</p>

<blockquote> <p> &hellip;there can be no possible sense in speaking of
any other truth of our perceptions other than <em>practical</em>
truth. Our perceptions of things cannot be anything other than
symbols, naturally given signs for things, which we have learned to
use in order to control our motions and actions. When we have learned
to read those signs in the proper manner, we are in a condition to use
them to orient our actions such that they achieve their intended
effect; that is to say, <em>that new sensations arise in an expected
manner</em> (Helmholtz 2005 [1924]: 19, our
emphasis). </p></blockquote>

<p>Lotze and Helmholtz go further than Berkeley in maintaining that
bodily movement also plays a role in the construction of the
two-dimensional visual field, taken for granted by most previous
accounts of vision (but for exceptions, see Hatfield 1990: ch. 4).</p>

<p>The problem of two-dimensional spatial localization, as Lotze and
Helmholtz understand it, is the problem of assigning a unique,
eye-relative (or &ldquo;oculocentric&rdquo;) direction to every point
in the visual field. Lotze&rsquo;s commitment to
mind-body dualism precluded looking to any physical
or anatomical spatial ordering in the visual system for a solution to
this problem (Lotze 1887 [1879]: &sect;&sect;276&ndash;77). Rather,
Lotze maintains that every discrete visual impression is attended by a
&ldquo;special extra sensation&rdquo; whose phenomenal character
varies as a function of its origin on the retina. Collectively, these
extra sensations or &ldquo;local signs&rdquo; constitute a
&ldquo;system of graduated, qualitative tokens&rdquo; (1887 [1879]:
&sect;283) that bridge the gap between the spatial structure of the
nonconscious retinal image and the spatial structure represented in
conscious visual awareness.</p>

<p>What sort of sensation, however, is suited to play the
individuating role attributed to a local sign? Lotze appeals to
kinaesthetic sensations that accompany gaze-directing movements of the eyes (1887 [1879]:
&sect;&sect;284&ndash;86). If <em>P</em> is the location on the retina
stimulated by a distal point <em>d</em> and <em>F</em> is the fovea,
then <em>PF</em> is the arc that must be traversed in order to align
the direction of gaze with <em>d</em>. As the eye moves through
arc <em>PF</em>, its changing position gives rise to a corresponding
series of kinaesthetic
sensations <em>p</em><sub>0</sub>, <i>p</i><sub>1</sub>, <i>p</i><sub>2</sub>,
&hellip;<i>p</i><sub><i>n</i></sub>, and it is this consciously
experienced series, unique to <em>P</em>, that
constitutes <em>P&rsquo;s</em> local sign. By contrast, if <em>Q</em>
were rather the location on the retina stimulated by <em>d</em>, then
the eye&rsquo;s foveating movement through arc <em>QF</em> would
elicit a different series of kinaesthetic
sensations <em>k</em><sub>0</sub>, <i>k</i><sub>1</sub>, <i>k</i><sub>2</sub>,
&hellip;<i>k</i><sub><i>n</i></sub> unique to <em>Q</em>.</p>

<p>Importantly, Lotze allows that retinal stimulation need not
trigger an overt movement of the eye. Rather, even in the absence of
the corresponding saccade, stimulating point <em>P</em> will elicit
kinaesthetic sensation <em>p</em><sub>0</sub>, and this sensation
will, in turn, recall from memory the rest of the series with which it
is associated <em>p</em><sub>1</sub>,
&hellip;<em>p<sub>n</sub></em>. </p>

<blockquote><p> Accordingly, though there is no movement of the eye,
there arises the recollection of something, greater or smaller, that
must be accomplished if the stimuli at <em>P</em> and <em>Q</em>,
which arouse only a weak sensation, are to arouse sensations of the
highest degree of strength and clearness. (1887 [1879]:
&sect;285)</p></blockquote>

<p>
In this way, Lotze accounts for our ability to perceive multiple
locations in the visual field at the same time.</p>

<p>Helmholtz 2005 [1924]
fully accepts the need for local signs in two-dimensional spatial
localization, but makes an important modification to Lotze&rsquo;s
theory. In particular, he maintains that local signs are not feelings
that originate in the adjustment of the ocular musculature, i.e., a
form of afferent, sensory &ldquo;inflow&rdquo; from the eyes, but
rather feelings of innervation (<em>Innervationsgef&uuml;hlen</em>)
produced by the effort of the will (<em>Willensanstrengung</em>) to
move the eyes, i.e., a form of efferent, motor
&ldquo;outflow&rdquo;. In general, to each perceptible location in the
visual field there is an associated readiness or impulse of the will
(<em>Willensimpuls</em>) to move eyes in the manner required in order
to fixate it. As Ernst Mach later formulates Helmholtz&rsquo;s view:
&ldquo;The will to perform movements of the eyes, or the innervation
to the act, is itself the space sensation&rdquo; (Mach 1897 [1886]:
59).</p>

<p>Helmholtz favored a motor outflow version of the local sign
doctrine for two main reasons. First, he was skeptical that afferent
registrations of eye position are precise enough to play the role
assigned to them by Lotze&rsquo;s theory (2005 [1924]:
47&ndash;49). Recent
research has shown that proprioceptive inflow from ocular muscular
stretch receptors does in fact play a quantifiable role in estimating
direction of gaze, but efferent outflow is normally the more heavily
weighted source of information (Bridgeman 2010; see
 <a href="#">Section 2.1.1</a> below).</p>

<p>Second, attempting a saccade when the eyes are paralyzed or
otherwise immobilized results in an apparent shift of the visual scene
in the same direction (Helmholtz 2005 [1924]: 205&ndash;06; Mach 1897
[1886]: 59&ndash;60). This finding would make sense if efferent
signals to the eye are used to determine the direction of gaze: the
visual system &ldquo;infers&rdquo; that perceived objects are moving
because they would have to be in order for retinal stimulation to
remain constant despite the change in eye direction predicted on the
basis of motor outflow.</p>

<p>Although Helmholtz was primarily concerned to show that &ldquo;our
judgments as to the direction of the visual axis are simply the result
of the effort of will involved in trying to alter the adjustment of
the eyes&rdquo; (2005 [1924]: 205&ndash;06), the evidence he adduces also implies that efferent
signals play a critical role in our perception of stability in the
world across saccadic eye movements. In the next section, we trace the
influence of this idea on theories in the 20<sup>th</sup> century.</p>

<h2><a id="SenConThe">2. Sensorimotor Contingency Theories</a></h2>

<p>Action-based accounts of perception proliferate diversely in
20<sup>th</sup> century. In this section, we focus on the reafference
theory of Richard Held and the more recent enactive approach of
J. Kevin O&rsquo;Regan and Alva No&euml;. Central to both accounts is
the view that perception and perceptually guided action depend on
abilities to anticipate the sensory effects of bodily movements. To
be a perceiver it is necessary to have knowledge of what O&rsquo;Regan
and No&euml; call the <em>laws of sensorimotor
contingency</em>&mdash;&ldquo;the structure of the rules governing the
sensory changes produced by various motor actions&rdquo;
(O&rsquo;Regan &amp; No&euml; 2001: 941).</p>

<p>We start with two sources of motivation for theories that make
knowledge of sensorimotor contingencies necessary and/or sufficient
for spatially contentful perceptual experience. The first is the idea
that the visual system exploits <em>efference copy</em>, i.e., a copy
of the outflowing saccade command signal, in order to distinguish
changes in visual stimulation caused by movement of the eye from those
caused by object movement. The second is a long line of experiments,
first performed by Stratton and Helmholtz in the 19<sup>th</sup> century,
on how subjects adapt to lens-, mirror-, and prism-induced
modifications of visual experience. We follow up with objections to
these theories and alternatives.</p>

<h3><a id="EffVisDirCon">2.1 Efference and Visual Direction Constancy</a></h3>

<p>The problem of visual direction constancy (VDC) is the problem of
how we perceive a stable world despite variations in visual
stimulation caused by saccadic eye movements. When we execute a
saccade, the image of the world projected on the retina rapidly
displaces in the direction of rotation, yet the directions of
perceived objects appear constant. Such perceptual stability is
crucial for ordinary visuomotor interaction with surrounding the
environment. As Bruce Bridgeman writes,</p>

<blockquote><p> Perceiving a stable visual world establishes the platform on which all other visual
function rests, making possible judgments about the positions and
motions of the self and of other objects. (2010: 94)</p></blockquote>

<p>The problem of VDC divides into two questions (MacKay 1973): First,
which sources of <em>information</em> are used to determine whether
the observer-relative position of an object has changed between
fixations? Second, how are relevant sources of
information <em>used</em> by the visual system to achieve this
function?</p>

<p>The historically most influential answer to the first question is
that the visual system has access to a copy of the efferent or
&ldquo;outflowing&rdquo; saccade command signal. These signals carry
information specifying the direction and magnitude of eye movements
that can be used to compensate for or &ldquo;cancel out&rdquo;
corresponding displacements of the retinal image.</p>

<p>In the 19<sup>th</sup> century, Bell (1823), Purkyn&#283; (1825), and
Hering (1861 [1990]), Helmholtz (2005 [1924]), and Mach (1897 [1886])
deployed the efference copy theory to illuminate a variety
of experimental findings, e.g., the tendency in subjects with partially
paralyzed eye muscles to perceive movement of the visual scene when
attempting to execute a saccade (for a review, see Bridgeman 2010.)
The theory&rsquo;s most influential formulation, however, came from
Erich von Holst and Horst Mittelst&auml;dt in the early
1950s. According to what they dubbed the &ldquo;reafference
principle&rdquo; (von Holst &amp; Mittelst&auml;dt 1950; von Holst
1954), the visual system exploits a copy of motor directives to the
eye in order to distinguish between <em>exafferent</em> visual
stimulation, caused by changes in the world, and <em>reafferent</em>
visual stimulation, caused by changes in the direction of gaze:</p>

<blockquote> <p> Let us imagine an active CNS sending out orders, or
&ldquo;commands&rdquo; &hellip; to the effectors and receiving signals
from its sensory organs. Signals that predictably come when nothing
occurs in the environment are necessarily a result of its own
activity, i.e., are <em>reafferences</em>. All signals that come when
no commands are given are <em>exafferences</em> and signify changes in
the environment or in the state of the organism caused by external
forces. &hellip; The difference between that which is to be expected
as the result of a command and the totality of what is reported by the
sensory organs is the proportion of exafference&hellip;. It is only
this difference to which there are compensatory reflexes; only this
difference determines, for example during a moving glance at movable
objects, the actually perceived direction of visual objects. This,
then, is the solution that we propose, which we have termed the
&ldquo;reafference principle&rdquo;: distinction of reafference and
exafference by a comparison of the total afference with the
system&rsquo;s state&mdash;the
&ldquo;command&rdquo;. (Mittelst&auml;dt
1971; translated by
Bridgeman <em>et al.</em> 1994: 251).</p></blockquote>

<p>It is only when the displacement of the retinal image differs from
the displacement predicted on the basis of the efference copy, i.e.,
when the latter fails to &ldquo;cancel out&rdquo; the former, that
subjects experience a change of some sort in the perceived scene
(see <a href="#fig1">Figure 1</a>). The relevant upshot is that VDC
has an essential motoric component: the apparent stability of an
object&rsquo;s eye-relative position in the world depends on the
perceiver&rsquo;s ability to integrate incoming retinal signals with
extraretinal information concerning the magnitude and direction of
impending eye movements.</p>

<div class="figure avoid-breaks" id="fig1">

<img src="fig1.png" width="450" alt="[Three parts to the image, the first, labeled 'a.', has at the top an apple and at the bottom an eyeball looking straight up with an arrow going from the bottom of the eyeball to the apple; the arrow is labeled EC=0 and the eyeball, A=0. The second, labeled 'b.', is like the first except the eyeball is looking slightly clockwise of straight up and the arrow follows the line of sight; a second arrow goes from the apple to the bottom of the eyeball; the eyeball is labeled A=-10; the first arrow, EC=+10 (there two equations line up horizontally with A=0 and EC=0 respectively from the first part). The third part is not labeled and consists of a circle divided into quarters with a '+' in the top quarter and a '-' in the bottom quarter. The equation 'EC=+10' in part b has an arrow going from it to the '+' quadrant of the circle. The equation 'A=-10' from part b has an arrow going from it to the '-' quadrant of the circle. From the right side of the circle is an arrow that points to an equation 'EA=EC+A=0'; the arrow is labeled 'Comparator'. ]" />

<p style="line-height:1.3em;margin-top:1ex"><span class="figlabel">Figure 1:</span> (a) When the eye is stationary, both efference copy (EC) and afference produced by displacement of the retinal image (A) are absent. (b) Turning the eye 10&deg; to the right results in a corresponding shift of the retinal image. Since the magnitude of the eye movement specified by EC and the magnitude of retinal image displacement cancel out, no movement in the world or &ldquo;exafference&rdquo; (EA) is registered.</p>
</div>

<h4><a id="ObjEffCopThe">2.1.1 Objections to the Efference Copy Theory</a></h4>

<p>The foregoing solution to the problem of VDC faces challenges on
multiple, empirical fronts. <strong>First</strong>, there is evidence
that proprioceptive signals from the extraocular muscles make a
non-trivial contribution to estimates of eye position, although the
gain of efference copy is approximately 2.4 times greater (Bridgeman
&amp; Stark 1991). <strong>Second</strong>, in the <em>autokinetic
effect</em>, a fixed luminous dot appears to wander when the field of
view is dark and thus completely unstructured. This finding is
inconsistent with theories according to which retinotopic location and
efference copy are the sole determinants of eye-relative
direction. <strong>Third</strong>, the hypothesized compensation
process, if psychologically real, would be highly inaccurate since
subjects fail to notice displacements of the visual world up to 30% of
total saccade magnitude (Bridgeman <em>et al.</em> 1975), and the
locations of flashed stimuli are systematically misperceived when
presented near the time of a saccade (Deubel
2004). <strong>Last</strong>, when image displacements concurrent with
a saccade are large, but just below threshold for
detection, <em>visually attended</em> objects appear to
&ldquo;jump&rdquo; or &ldquo;jiggle&rdquo; against a stable background
(Brune and L&uuml;cking 1969; Bridgeman 1981). Efference copy
theories, however, as Bridgeman observes,</p>

<blockquote><p> do not allow the possibility that parts of the image
can move relative to one another&mdash;the visual world is conceived
as a monolithic object. The observation would seem to eliminate all
efference copy and related theories in a single stroke. (2010:
102)</p></blockquote>



<h4><a id="AltEffCopThe">2.1.2 Alternatives to the Efference Copy Theory</a></h4>

<p>The <em>reference object</em> theory of Deubel and Bridgeman denies
that efference copy is used to &ldquo;cancel out&rdquo; displacements
of the retinal image caused by saccadic eye-movements (Deubel <em>et al.</em>
2002; Deubel 2004;
Bridgeman 2010). According to
this theory, visual attention shifts to the saccade target and a small number
of other objects in its vicinity (perhaps four or fewer) before eye
movement is initiated. Although little visual scene information is
preserved from one fixation to the next, the features of these objects
as well as precise information about their presaccadic, eye-relative
locations is preserved. After the eye has landed, the visual system
searches for the target or one of its neighbors within a limited
spatial region around the landing site. If the postsaccadic
localization of this &ldquo;landmark&rdquo; object succeeds, the world
appears to be stable. If this object is not found, however,
displacement is perceived. On this approach, efference copy does not
directly support VDC. Rather, the role of efference copy is to
maintain an estimate of the direction of gaze, which can be integrated
with incoming retinal stimulation to determine the static,
observer-relative locations of perceived objects. For a recent,
philosophically oriented discussion, see Wu 2014.</p>

<p>A related alternative to the von Holst-Mittelst&auml;dt model is
the <em>spatial remapping</em> theory of Duhamel and Colby
(Duhamel <em>et al.</em> 1992; Colby <em>et al.</em> 1995). The role
of saccade efference copy on this theory is to initiate an updating of
the eye-relative locations of a small number of attended or otherwise
salient objects. When post-saccadic object locations are sufficiently
congruent with the updated map, stability is perceived. Single-cell
and fMRI studies show that neurons at various stages in the
visual-processing hierarchy exploit a copy of the saccade command
signal in order to shift their receptive field locations in the
direction of an impending eye movement microseconds before its
initiation (Merriam &amp; Colby 2005; Merriam <em>et al.</em>
2007). Efference copy indicating an impending saccade 20&deg; to the
right, in effect, tells relevant neurons: </p>

<blockquote><p> If you are now firing in response to an
item <em>x</em> in your receptive field, then stop firing
at <em>x</em>. If there is currently an item <em>y</em> in the region
of oculocentric visual space that would be coincident with your
receptive field after a saccade 20&deg; to the right, then start
firing at <em>y</em>. </p></blockquote>

<p>
Such putative updating responses are strongest in parietal cortex and
at higher levels in visual processing (V3A and hV4) and weakest at
lower levels (V1 and V2).</p>

<h3><a id="ReaThe">2.2 The Reafference Theory</a></h3>

<p>In 1961, Richard Held proposed that the reafference principle could
be used to construct a general &ldquo;neural model&rdquo; of
perception and perceptually guided action. Held&rsquo;s
<em>reafference theory</em> goes beyond the account of
von Holst and Mittelst&auml;dt in three main
ways. <strong>First</strong>, information about movement parameters
specified by efference copy is not simply summated with reafferent
stimulation. Rather, subjects are assumed to acquire knowledge of
the <em>specific sensory consequences</em> of different bodily
movements. This knowledge is contained in a hypothesized
&ldquo;correlational storage&rdquo; area and used to determine whether
or not the reafferent stimulations that result from a given type of
action match those that resulted in the past (Held 1961:
30). <strong>Second</strong>, the reafference theory is not
limited to eye movements, but extends to &ldquo;any motor system that
can be a source of reafferent visual
stimulation&rdquo;. <strong>Third</strong>, knowledge of the way
reafferent stimulation depends on self-produced movement is used for
purposes of sensorimotor control: planning and controlling
object-directed actions in the present depends on access to
information concerning the visual consequences of performing such
actions in the past.</p>

<h4><a id="OhInvWorEarExpOptRea">2.2.1 Oh, Inverted World: Early Experiments on Optical Rearrangement</a></h4>

<p>The reafference theory was also significantly motivated by studies
of how subjects adapt to devices that alter the relationship between
the distal visual world and sensory input by rotating, reversing, or
laterally displacing the retinal image (for helpful guides to the
literature on this topic, see Rock 1966; Howard &amp; Templeton 1966;
Epstein 1967; and Welch 1978). We will refer to these as optical
rearrangement devices (or <strong>ORDs</strong> for short).</p>

<!--pdf include

<div class="figure avoid-breaks" id="fig2">

<img src="fig2.png" width="300" alt= "[a line drawing of a man standing and looking up at about a 45 degree angle. Above him is a horizontal line labeled at the left end 'A' and right end 'B'. A second line goes from the 'B' end at about a -60 degree angle to point approximately horizontal to the man's neck that point is labeled 'D'. To the right of D is the dotted line drawing of a horizontal man, head closest to D; feet labeled 'E'. Fromt the first man's eyes is a short line, labeled 'C', going up at about a 45 degree angle approximately in the direction of the point labeled 'B'.]" />

<p  style="line-height:1.3em;margin-top:1ex"><span class="figlabel">Figure 2:</span> The apparatus designed by Stratton (1899). Stratton saw a view of his own body from the perspective of mirror AB, worn above his head</p> </div>
pdf include-->

<h4><a id="Str">2.2.2 Stratton</a></h4>

<p>The American psychologist George Stratton conducted two
experiments using a lens system that effected an 180&ordm;
rotation of the retinal image in his right eye (his left eye was kept
covered). The first experiment involved wearing the device for 21.5
hours over the course of three days (1896); the second experiment
involved wearing the device for 81.5 hours over the course of 8 days
(1897a,b). In both cases, Stratton kept a detailed diary of how his
visual, imaginative, and proprioceptive experiences underwent
modification as a consequence of inverted vision. In 1899, he
performed a lesser-known but equally dramatic three-day experiment,
using a pair of mirrors that presented his eyes with a view of his own
body from a position in space directly above his head
(<a href="#fig2">Figure 2</a>).</p>

<!--pdf exclude begin-->

<div class="figure avoid-breaks" id="fig2">

<img src="fig2.png" width="300" alt="[a line drawing of a man standing and looking up at about a 45 degree angle. Above him is a horizontal line labeled at the left end 'A' and right end 'B'. A second line goes from the 'B' end at about a -60 degree angle to point approximately horizontal to the man's neck that point is labeled 'D'. To the right of D is the dotted line drawing of a horizontal man, head closest to D; feet labeled 'E'. Fromt the first man's eyes is a short line, labeled 'C', going up at about a 45 degree angle approximately in the direction of the point labeled 'B'.]" />

<p style="line-height:1.3em;margin-top:1ex"><span class="figlabel">Figure 2:</span> The apparatus designed by Stratton (1899). Stratton saw a view of his own body from the perspective of mirror AB, worn above his head.</p> </div>
<!--pdf exclude end-->

<p>In both experiments, Stratton reported a brief period of initial
visual confusion and breakdown in visuomotor skill: </p>

<blockquote><p> Almost all movements performed under the direct
guidance of sight were laborious and embarrassed. Inappropriate
movements were constantly made; for instance, in order to move my hand
from a place in the visual field to some other place which I had
selected, the muscular contraction which would have accomplished this
if the normal visual arrangement had existed, now carried my hand to
an entirely different place. (1897a: 344)</p></blockquote>

<p>
Further bewilderment was caused by a &ldquo;swinging&rdquo; of the
visual field with head movements as well as jarring discord between
where things were respectively seen and <em>imagined</em> to be: </p>

<blockquote><p> Objects lying at the moment outside the visual field
(things at the side of the observer, for example) were at first
mentally represented as they would have appeared in normal
vision&hellip;. The actual present perception remained in this way
entirely isolated and out of harmony with the larger whole made up by
[imaginative] representation. (1896: 615)</p></blockquote>

<p>After a seemingly short period of adjustment, Stratton reported a
gradual re-establishment of harmony between the deliverances of sight
and touch. By the end of his experiments on inverted vision, it was
not only possible for Stratton to perform many visuomotor actions
fluently and without error, the visual world often appeared to him to be
&ldquo;right side up&rdquo; (1897a: 358) and &ldquo;in normal
position&rdquo; (1896: 616). Just what this might <em>mean</em> will
be discussed below in <a href="#">Section
2.2.6</a>.</p>

<h4><a id="Hel">2.2.3 Helmholtz</a></h4>

<p>Another influential experiment was performed by Helmholtz (2005
[1924]: &sect;29), who practiced reaching to targets while wearing
prisms that displaced the retinal image 16&ndash;18&deg; to the
left. The initial tendency was to reach too far in the direction of
lateral displacement. After a number of trials, however, reaching
gradually regained its former level of accuracy. Helmholtz made two
additional discoveries. First, there was an <em>intermanual transfer
effect</em>: visuomotor adaptation to prisms extended to his
non-exposed hand. Second, immediately after removing the prisms from
his eyes, errors were made in the opposite direction, i.e., when
reaching for a target, Helmholtz now moved his hand too far to the
right. This <em>negative after-effect</em> is now standardly used as a
measure of adaptation to lateral displacement.</p>

<p>Stratton and Helmholtz&rsquo;s findings catalyzed a research
tradition on ORD adaptation that experienced its heyday in the 1960s
and 1970s. Two questions dominated studies conducted during this
period. First, what are the necessary and sufficient conditions for
adaptation to occur? In particular, which sources
of <em>information</em> do subjects use when adapting to the various
perceptual and sensorimotor discrepancies caused by ORDs? Second,
just <em>what</em> happens when subjects adapt to perceptual
rearrangement? What is the &ldquo;end product&rdquo; of the relevant
form of perceptual learning?</p>

<h4><a id="HelExpPriAda">2.2.4 Held&rsquo;s Experiments On Prism Adaptation</a></h4>

<p>Held&rsquo;s answer to the first question is that subjects must
receive visual feedback from active movement, i.e., <em>reafferent
visual stimulation</em>, in order for significant and stable
adaptation to occur (Held &amp; Hein 1958; Held 1961; Held &amp;
Bossom 1961). Evidence for this conclusion came from experiments in
which participants wore laterally displacing prisms during both active
and passive movement conditions. In the active movement condition, the
subject moved her visible hand back and forth along a fixed arc in
synchrony with a metronome. In the passive movement condition, the
subject&rsquo;s hand was passively moved at the same rate by the
experimenters. Although the overall pattern of visual stimulation was
identical in both conditions, adaptation was reported only when
subjects engaged in self-movement. Reafferent stimulation, Held
and Bossom concluded on the basis of this and other studies,</p>

<blockquote><p> is the source of ordered contact with the environment
which is responsible for both the stability, under typical conditions,
and the adaptability, to certain atypical conditions, of
visual-spatial performance. (1961: 37)</p></blockquote>

<p>Held&rsquo;s answer to the second question is couched in terms of
the reafference theory: subjects adapt to ORDs only when they have
relearned the sensory consequences of their bodily movements. In the
case of adaptation to lateral displacement, they must relearn the way
retinal stimulations vary as a function of reaching for targets at
different body-relative locations. This relearning is assumed to
involve an updating of the mappings from motor output to reafferent
sensory feedback in the hypothesized "correlational storage" module
mentioned above.</p>

<h4><a id="ChaReaThe">2.2.5 Challenges to the Reafference Theory</a></h4>

<p>The reafference theory faces a number of
objections. <strong>First</strong>, the theory is an extension of von
Holst and Mittelst&auml;dt&rsquo;s reafference principle, according to
which efference copy is used to cancel out shifts of the retinal image
caused by saccadic eye movements. The latter was specifically intended
to explain why we do not experience object displacement in the world
whenever we change the direction of gaze. There is nothing, at first
blush, however, that is analogous to the putative need for
&ldquo;cancellation&rdquo; or &ldquo;discounting&rdquo; of the retinal
image in the case of prism adaptation. As Welch puts it, &ldquo;There
is no visual position constancy here, so why should a model originally
devised to explain this constancy be appropriate?&rdquo; (1978:
16).</p>

<p><strong>Second</strong>, the reafference theory fails to explain
just how stored efference-reafference correlations are supposed to
explain visuomotor control. How does having the ability to anticipate
the retinal stimulations that would caused by a certain type of hand
movement enable one actually to perform the movement in question?
Without elaboration, all that Held&rsquo;s theory seems to explain is
why subjects are surprised when reafferences generated by their
movements are non-standard (Rock 1966: 117).</p>

<p><strong>Third</strong>, adaptation to ORDs, contrary to the theory,
is not restricted to situations in which subjects receive reafferent
visual feedback, but may also take place when subjects receive
feedback generated by passive effector or whole-body movement (Singer
&amp; Day 1966; Templeton <em>et al.</em> 1966; Fishkin
1969). Adaptation is even possible in the complete absence of motor
action (Howard <em>et al.</em> 1965; Kravitz &amp; Wallach
1966).</p>

<p>In general, the extent to which adaptation occurs depends not on
the availability of reafferent stimulation, but rather on the presence
of either of two related kinds of information concerning &ldquo;the
presence and nature of the optical rearrangement&rdquo; (Welch 1978:
24). Following Welch, we shall refer to this view as the
&ldquo;information hypothesis&rdquo;.</p>

<p>One source of information present in a displaced visual array
concerns the veridical directions of objects from the observer (Rock
1966: chaps. 2&ndash;4). Normally, when engaging in forward
locomotion, the perceived radial direction of an object straight ahead
of the observer&rsquo;s body remains constant while the perceived
radial directions of objects to either side undergo constant
change. This pattern also obtains when the observer wears prisms that
displace the retinal image to side. Hence, &ldquo;an object seen
through prisms which retains the same radial direction as we approach
must be seen to be moving in toward the sagittal plane&rdquo; (Rock
1966: 105). On Rock&rsquo;s view, at least some forms of adaptation to
ORDs can be explained by our ability to detect and exploit such
invariant sources of spatial informational in locomotion-generated
patterns of optic flow.</p>

<p>Another related source of information for adaptation derives from
the <em>conflict</em> between seen and proprioceptively experienced
limb position (Wallach 1968; Ularik &amp; Canon 1971). When this
discrepancy is made conspicuous, proponents of the information
hypothesis have found that passively moved (Melamed <em>et al.</em>
1973), involuntarily moved (Mather &amp; Lackner 1975), and even
immobile subjects (Kravitz &amp; Wallach 1966) exhibit significant
adaption. Although self-produced bodily movement is not necessary for
adaptation to occur, it provides subjects with especially salient
information about the discrepancy between sight and touch (Moulden
1971): subjects are able proprioceptively to determine the location of
a moving limb much more accurately than a stationary or passively
moved limb. It is the enhancement of the visual-proprioceptive
conflict rather than reafferent <em>visual</em> stimulation, on this
interpretation, that explains why active movement yields more
adaptation than passive movement in Held&rsquo;s experiments.</p>

<h4><a id="ProChaThe">2.2.6 The Proprioceptive Change Theory</a></h4>

<p>A <strong>final objection</strong> to the reafference theory
concerns the <em>end product</em> of adaptation to ORDs. According to
the theory, adaptation occurs when subjects learn new rules of
sensorimotor dependence that govern how actions affect sensory
inputs. There is a significant body of evidence, however, that much,
if not all, adaptation rather occurs at the proprioceptive
level. Stratton, summarizing the results of his experiment on
mirror-based optical rearrangement, wrote:</p>

<blockquote> <p> &hellip;the principle stated in an earlier
paper&mdash;<em>that in the end we would feel a thing to be wherever
we constantly saw it</em>&mdash;can be justified in a wider sense than
I then intended it to be taken&hellip;. We may now, I think, safely
include differences of distance as well, and assert that the spatial
coincidence of touch and sight does not require that an object in a
given tactual position should appear visually in any particular
direction or at any particular distance. In whatever place the tactual
impression&rsquo;s visual counterpart regularly appeared, this would
eventually seem the only appropriate place for it to appear in. If we
were always to see our bodies a hundred yards away, we would probably
also feel them there. (1899: 498, our emphasis)</p></blockquote>

<p>On this interpretation, the plasticity revealed by ORDs is
primarily proprioceptive and kinaesthetic, rather than
visual. Stratton&rsquo;s world came to look &ldquo;right side
up&rdquo; (1897b: 469) after adaptation to the inverted retinal image
because things were <em>felt</em> where they were visually perceived
to be&mdash;not because, his &ldquo;entire visual field flipped
over&rdquo; (Kuhn 2012 [1962]: 112). This is clear from the absence of a visual <em>negative
aftereffect</em> when Stratton finally removed his inverting lenses at
the end of his eight-day experiment: </p>

<blockquote><p> The visual arrangement was immediately recognized as
the old one of pre-experimental days; yet the reversal of everything
from the order to which I had grown accustomed during the past week,
gave the scene a surprising, bewildering air which lasted for several
hours. It was hardly the feeling, though, that things were upside
down. (1897b: 470)</p></blockquote>

<p>
Moreover, Stratton reported changes in <em>kinaesthesis</em> during
the course of the experiment consistent with the alleged
proprioceptive shift: </p>

<blockquote><p> when one was most at home in the unusual
experience <em>the head seemed to be moving in the very opposite
direction from that which the motor sensations themselves would
suggest</em>. (1907: 156)</p></blockquote>

<p>On this view, the end product of adaptation to an ORD is a
recalibration of proprioceptive position sense at one or more points
of articulation in the body (see the entry on
 <a href="../bodily-awareness/index.html">bodily awareness</a>). As
you practice reaching for a target while wearing laterally displacing
prisms, for example, the muscle spindles, joint receptors, and Golgi
tendon organs in your shoulder and arm continue to generate the same
patterns of action potentials as before, but the proprioceptive and
kinaesthetic <em>meaning</em> assigned to them by their
&ldquo;consumers&rdquo; in the brain undergoes change: whereas before
they signified that your arm was moving along one path through the
seven-dimensional space of possible arm configurations (the human arm
has seven degrees of freedom: three at the wrist, one at the elbow,
and three at the shoulder), they gradually come to signify that it is
moving along a different path in that kinematic space, namely, the one
consistent with the prismatically distorted visual feedback you are
receiving. Similar recalibrations are possible with respect to sources
of information for head and eye position. After adapting to laterally
displacing prisms, signals from receptors in your neck that previously
signified the alignment of your head and torso, for example, may come
to signify that your head is turned slightly to the side. For
discussion, see Harris 1965, 1980 and Welch 1978: chap. 3.</p>

<h3><a id="EnaApp">2.3 The Enactive Approach</a></h3>

<p>The enactive approach defended by J. Kevin O&rsquo;Regan and Alva
No&euml; (O&rsquo;Regan &amp; No&euml; 2001; No&euml; 2004, 2005, 2010;
O&rsquo;Regan 2011) is best viewed as an extension of the reafference
theory. According to the enactive approach, spatially contentful,
world-presenting perceptual experience depends on implicit knowledge
of the way sensory stimulations vary as a function of bodily
movement. &ldquo;Over the course of life&rdquo;, O&rsquo;Regan and
No&euml; write, </p>

<blockquote><p> a person will have encountered myriad visual
attributes and visual stimuli, and each of these will have particular
sets of sensorimotor contingencies associated with it. Each such set
will have been recorded and will be latent, potentially available for
recall: the brain thus has mastery of all these sensorimotor
sets. (2001: 945)</p></blockquote>

<p>
To see an object <em>o</em> as having the location and shape
properties it has it is necessary (1) to receive sensory stimulations
from <em>o</em> and (2) to use those stimulations in order to retrieve
the set of sensorimotor contingencies associated with <em>o</em> on
the basis of past encounters. In this sense, seeing is a
&ldquo;two-step&rdquo; process (No&euml; 2004: 164). It is important
to emphasize, however, that the enactive approach distances itself
from the idea that vision is functionally dedicated, in whole or in
part, to the <em>guidance</em> of spatially directed actions:
&ldquo;Our claim&rdquo;, No&euml; writes, </p>

<blockquote><p> is that seeing depends on an appreciation of the
sensory effects of movement (not, as it were, on the practical
significance of sensation)&hellip;. Actionism is not committed to the
general claim that seeing is a matter of knowing how to act in respect
of or in relation to the things we see. (No&euml; 2010:
249)</p></blockquote>

<p>The enactive approach also has strong affinities with
the <strong>sense-data</strong> tradition. According to No&euml;, an
object&rsquo;s visually apparent shape is the shape of the 2D patch
that would occlude the object on a plane perpendicular to the line of
sight, i.e., the shape of the patch projected by the object on the
frontal plane in accordance with the laws of linear
perspective. No&euml; calls this the object&rsquo;s
&ldquo;perspectival shape&rdquo; (P-shape). An object&rsquo;s visually
apparent size, in turn, is the size of the patch projected by the
object on the frontal plane. No&euml; calls this the object&rsquo;s
&ldquo;perspectival size&rdquo; (P-size). Appearances are
&ldquo;perceptually basic&rdquo; (No&euml; 2004: 81) because in order
to see an object&rsquo;s actual spatial properties it is necessary
both to see its 2D P-properties and to understand how they would vary
(undergo transformation) with changes in one&rsquo;s point of
view. This conception of what it is to perceive objects as voluminous
space-occupiers is closely to akin to views defended by Russell
(1918), Broad (1923), and Price (1950). It also worth mentioning that
the enactive approach has strong affinities to views in the
phenomenological tradition that are beyond the scope of this entry
(but for discussion, see Thompson 2005; Hickerson 2007; and
the entry on <a href="../phenomenology/index.html">phenomenology</a>).</p>

<h4><a id="SomQueAboPPro">2.3.1 Some questions about P-properties</a></h4>

<p>Assessment of the enactive approach is complicated by questions
concerning the nature of P-properties. First, there is a tendency on the
part of its main proponents to speak interchangeably of consciously
perceived P-properties (or &lsquo;looks&rsquo;), on the one hand, and
proximal sensory stimulations, on the other. No&euml;, e.g.,
writes:</p>

<blockquote><p> The sensorimotor profile of an object is the way
its <em>appearance</em> changes as you move with respect to it
(strictly speaking, it is the way <em>sensory stimulation</em> varies
as you move). (2004: 78, our emphasis)</p></blockquote>

<p>It is far from clear how these different characterizations are to be
related, however (Briscoe 2008; Kiverstein 2010). P-properties,
according to the enactive approach, are distal, relational properties
of the objects we see: &ldquo;If there is a mind/world divide&hellip;
then P-properties are on the world side of the divide&rdquo; (2004:
83). Moreover, No&euml; clearly assumes that they are visible:
&ldquo;P-properties are themselves objects of sight, that is, things
that we see&rdquo; (2004: 83). Sensory stimulations, by contrast, are
proximal, subpersonal vehicles of visual perception. They are not
objects of sight. Quite different, if not incommensurable, notions
of <em>sensorimotor profile</em> and, so, of <em>sensorimotor
knowledge</em> would thus seem to be implied by the two
characterizations.</p>

<p>There is also an ambiguity with the &ldquo;-motor&rdquo; in
&ldquo;sensorimotor knowledge&rdquo;. On the one hand, No&euml; argues
that perception is active in the sense that perceivers require
knowledge of the proximal, sensory effects of movement. E.g., in order
to see an object&rsquo;s shape and size it is necessary to have
certain anticipations concerning the way in which retinal stimulations
caused by the object would vary as a function of her point of
view. &ldquo;This perspectival aspect&rdquo;, No&euml; writes,
&ldquo;marks the place of action in perception&rdquo; (No&euml; 2004:
34). On this conception there is no commitment to the view that vision
is <em>for</em> the guidance of action, that vision constitutively has
something to do with adapting animal behavior to the spatial layout of
the distal environment (No&euml; 2004: 18&ndash;19). Rather, vision is
active in the sense that it involves learned expectations concerning
the ways in which sensory stimulations would be
&ldquo;perturbed&rdquo; by possible bodily movements (No&euml; 2010:
247&ndash;248).</p>

<p>On the other hand, No&euml; adverts to a more world-engaging
conception of sensorimotor knowledge in order to explain our visual
experience of P-properties: </p>

<blockquote><p> variation in looks reveals how things are. But what of
the looks themselves, what of P-properties? Do we see <em>them</em> by
seeing how <em>they</em> look? This would threaten to lead to infinite
regress&hellip;. (2004: 87)</p></blockquote>

<p>
The solution to the regress problem is that seeing an object&rsquo;s
P-properties involves a kind of practical know-how. A tilted plate,
e.g., looks elliptical and small from here because one has to move
one&rsquo;s hand in a certain way in order to indicate its shape and
size in the visual field (2004: 89). Whereas seeing an object&rsquo;s
intrinsic properties, according to the enactive approach, requires
knowledge of the way P-properties would vary as a function of
movement, seeing P-properties involves knowing how one would need to
move one&rsquo;s body in relation to what one sees in order to achieve
a certain goal.</p>

<p>While this seems to suggest that the first kind of sensorimotor
knowledge is asymmetrically dependent on the latter, No&euml;
maintains that just the opposite is the case. &ldquo;I do not wish to
argue&rdquo;, he writes,</p>

<blockquote><p> that to experience something as having a certain
[P-shape] is to experience it as affording a range of possible
movements; rather I want to suggest that one experiences it as having
a certain P-shape, and so as affording possible movements, only
insofar as, in encountering it, one is able to draw on one&rsquo;s
appreciation of the sensorimotor patterns mediating (or that might be
mediating) your relation to it. (2004: 90)</p></blockquote>

<p>
The problem with this suggestion, however, is that it leads the
enactive approach directly back to the explanatory regress that the
second, affordance-detecting kind of sensorimotor knowledge was
introduced to avoid.</p>


<h4><a id="EviForEnaApp">2.3.2 Evidence for the Enactive Approach</a></h4>

<p>The enactive approach rests its case on three main sources of
empirical support. The <strong>first</strong> derives from experiments
with optical rearrangement devices (ORDs), discussed
in <a href="#ReaThe">Section 2.2</a> above. Hurley and No&euml; (2003)
maintain that adaptation to ORDs only occurs when subjects relearn the
systematic patterns of interdependence between active movement and
reafferent visual stimulation. Moreover, contrary to the
proprioceptive change theory of Stratton, Harris, and Rock, Hurley and
No&euml; argue that the end product of adaptation to inversion and
reversal of the retinal image is genuinely visual in nature: during
the final stage of adaptation, visual experience &ldquo;rights
itself&rdquo;.</p>

<p>In <a href="#ReaThe">Section 2.2</a> above, we reviewed empirical
evidence against the view that active movement and corresponding
reafferent stimulation are necessary for adaptation to
ORDs. Accordingly, we will focus here on Hurley and No&euml;&rsquo;s
objections to the proprioceptive-change theory. According to the
latter, &ldquo;what is actually modified [by the adaptation process]
is the interpretation of nonvisual information about positions of body
parts&rdquo; (Harris 1980: 113). Once intermodal harmony is restored,
the subject will again be able to perform visuomotor actions without
error or difficulty, and she will again feel at home in the visually
perceived world.</p>

<p>Hurley and No&euml; do not contest the numerous sources of empirical
and introspective evidence that Stratton, Harris, and Rock adduce for
the proprioceptive-change theory. Rather they reject the theory on the
basis of what they take to be an untoward epistemic implication
concerning adaptation to left-right reversal: </p>

<blockquote><p> while rightward things <em>really</em> look and feel
leftward to you, they come to <em>seem</em> to look and feel
rightward. So the true qualities of your experience are no longer
self-evident to you. (2003: 155)</p></blockquote>

<p>The proprioceptive-change theory, however, does not imply such
radical introspective error. According to proponents of the theory,
experience normalizes after adaptation to reversal not because things
that really look leftward &ldquo;seem to look rightward&rdquo; (what
this might mean is enigmatic at best), but rather because the subjects
eventually become familiar with the way things look when
reversed&mdash;much as ordinary subjects can learn to read
mirror-reversed writing fluently (Harris 1965: 435&ndash;36). Things
seem &ldquo;normal&rdquo; after adaptation, in other words, because
subjects are again able to cope with the visually perceived world in a
fluent and unreflective manner.</p>

<p>A <strong>second</strong> line of evidence for the enactive approach
comes from well-known experiments on <strong>tactile-visual sensory
substitution (TVSS)</strong> devices that transform outputs from a
low-resolution video camera into a matrix of vibrotactile stimulation
on the skin of one&rsquo;s back (Bach-y-Rita 1972, 2004) or
electrotactile stimulation on the surface of one&rsquo;s tongue
(Sampaio <em>et al.</em> 2001).</p>

<p>At first, blind subjects equipped with a TVSS device experience its
outputs as purely tactile. After a short time, however, many subjects
cease to notice the tactile stimulations themselves and instead report
having quasi-visual experiences of the objects arrayed in space in
front of them. Indeed, with a significant amount of supervised
training, blind subjects can learn to discriminate spatial properties
such as shape, size, and location and even to perform simple
&ldquo;eye&rdquo;-hand coordination tasks such as catching or batting
a ball. A main finding of relevance in early experiments was that
subjects learn to &ldquo;see&rdquo; by means of TVSS only when they
have active control over movement of the video camera. Subjects who
receive visual input passively&mdash;and therefore lack any knowledge of
how (or whether) the camera is moving&mdash;experience only
meaningless, tactile stimulation.</p>

<p>Hurley and No&euml; argue that passively stimulated subjects do not
learn to &ldquo;see&rdquo; by means of sensory substitution because
they are unable to learn the laws of sensorimotor contingency that
govern the prosthetic modality: </p>

<blockquote><p> active movement is required in order for the subject
to acquire practical knowledge of the change from sensorimotor
contingencies characteristic of touch to those characteristic of
vision and the ability to exploit this change skillfully. (Hurley
&amp; No&euml; 2003: 145)</p></blockquote>

<p>An alternative explanation, however, is that subjects who do not
control camera movement&mdash;and who are not otherwise attuned to how
the camera is moving&mdash;are simply unable to extract
any <em>information</em> about the structure of the distal scene from
the incoming pattern of sensory stimulations. In consequence they do
not engage in &ldquo;distal attribution&rdquo; (Epstein <em>et al.</em>
1986; Loomis 1992; Siegel
&amp; Warren 2010): they do not perceive <em>through</em> the changing
pattern of proximal stimulation to a spatially external scene in the
environment. For development of this alternative explanation in the
context of Bayesian perceptual psychology, see Briscoe
forthcoming.</p>

<p>A <strong>final</strong> source of evidence for the enactive
approach comes from studies of visuomotor development in the absence
of normal, reafferent visual stimulation. Held &amp; Hein 1963
performed an experiment in which pairs of kittens were harnessed to a
carousel in a small, cylindrical chamber. One of the kittens was able
to engage in free circumambulation while wearing a harness. The other
kitten was suspended in the air in a metal gondola whose motions were
driven by the first harnessed kitten. When the first kitten walked,
both kittens moved and received identical visual stimulation. However,
only the first kitten received reafferent visual feedback as the
result of self-movement. Held and Hein reported that
only <em>mobile</em> kittens developed normal depth
perception&mdash;as evidenced by their unwillingness to step over the
edge of a visual cliff, blinking reactions to looming objects, and
visually guided paw placing responses. No&euml; (2004) argues that
this experiment supports the enactive approach: in order to develop
normal visual depth perception it is necessary to learn how motor
outputs lead to changes to visual inputs.</p>

<p>There are two main reasons to be skeptical of this
assessment. <strong>First</strong>, there is evidence that passive
transport in the gondola may have disrupted the development of the
kittens&rsquo; innate visual paw placing responses (Ganz 1975:
206). <strong>Second</strong>, the fact that passive kittens were
prepared to walk over the edge of a visual cliff does not show that
their visual experience of <em>depth</em> was abnormal. Rather, as
Jesse Prinz (2006)
argues, it may only indicate that they &ldquo;did not have enough
experience walking on edges to anticipate the bodily affordances of
the visual world&rdquo;.</p>

<h4><a id="ChaEnaApp">2.3.2 Challenges to the Enactive Approach</a></h4>

<p>The enactive approach confronts objections on multiple fronts. We
focus on just three of them here (but see Block 2005; Prinz 2006;
Briscoe 2008; Clark 2009: chap. 8; and Block
2012). <strong>First</strong>, the approach is essentially an
elaboration of Held&rsquo;s reafference theory and, as such, faces
many of the same empirical obstacles. Evidence, for example, that
active movement <em>per se</em> is not necessary for perceptual
adaptation to optical rearrangement
(<a href="#OhInvWorEarExpOptRea">Section 2.2.1</a>) is at variance
with predictions made by the reafference theory and the enactive
approach alike.</p>

<p>A <strong>second</strong> line of criticism targets the alleged
perceptual priority of P-properties. According to the enactive
approach, P-properties are &ldquo;perceptually basic&rdquo; (No&euml;
2004: 81) because in order to see an object&rsquo;s intrinsic, 3D
spatial properties it is necessary to see its 2D P-properties and to
understand how they would undergo transformation with variation in
one&rsquo;s point of view. When we view a tilted coin, critics argue,
however, we do <em>not</em> see something that looks&mdash;in either
an epistemic or non-epistemic sense of &ldquo;looks&rdquo;&mdash;like
an upright ellipse. Rather, we see what looks like a disk that is
partly nearer and partly farther away from us. In general, the
apparent shapes of the objects we perceive are not 2D but have
extension in depth (Austin 1962; Gibson 1979; Smith 2000; Schwitzgebel
2006; Briscoe 2008; Hopp 2013).</p>

<p>Support for this objection comes from work in mainstream vision
science. In particular, there is abundant empirical evidence that an
object&rsquo;s 3D shape is specified by sources of spatial information
in the light reflected or emitted from the object&rsquo;s surfaces to
the perceiver&rsquo;s eyes as well as by oculomotor factors (for
reviews, see Cutting &amp; Vishton 1995; Palmer 1999; and Bruce <em>et
al.</em> 2003). Examples include binocular disparity, vergence,
accommodation, motion parallax, texture gradients, occlusion, height
in the visual field, relative angular size, reflections, and
shading. That such shape-diagnostic information having once been
processed by the visual system is not lost in conscious visual
experience of the object is shown by standard psychophysical methods
in which experimenters manipulate the availability of different
spatial depth cues and gauge the perceptual effects. Objects, for
example, look somewhat flattened under uniform illumination conditions
that eliminate shadows and highlights, and egocentric distances are
underestimated for objects positioned beyond the operative range of
binocular disparity, accommodation, and vergence. Results of such
experimentation show that observers can literally see the difference
made by the presence or absence of a certain cue in the light
available to the eyes (Smith 2000; Briscoe 2008).</p>

<p>According to the influential dual systems model (DSM) of visual
processing (Milner &amp; Goodale 1995/2006; Goodale &amp; Milner
2004), visual consciousess and visuomotor control are supported by
functionally and anatomically distinct visual subsystems (these are
the <em>ventral</em> and <em>dorsal</em> information processing
streams, respectively). In particular, proponents of the DSM maintain
that the contents of visual experience are not used by motor
programming areas in the primate brain:</p>

<blockquote><p>The visual information used by the dorsal stream for
programming and on-line control, according to the model, is
not <em>perceptual</em> in nature &hellip;[I]t cannot be accessed
consciously, even in principle. In other words, although we may be
conscious of the actions we perform, the visual information used to
program and control those actions can never be experienced. (Milner
&amp; Goodale 2008: 775&ndash;776)</p></blockquote>

<p>A <strong>final</strong> criticism of the enactive approach is that
it is empirically falsified by evidence for the DSM (see the
commentaries on O&rsquo;Regan &amp; No&euml;
2001; Clark 2009:
chap. 8; and the essays collected in Gangopadhyay <em>et al.</em>
2010): the bond it posits between what we see and what we do is much
too tight to comport with what neuroscience has to tells us about
their functional relations.</p>

<p>The enactivist can make two points in reply to this
objection. First, experimental findings indicate that there are a
number of contexts in which information present in conscious vision is
utilized for purposes of motor programming (see Briscoe 2009 and
Briscoe &amp; Schwenkler forthcoming). Action and perception are not as sharply dissociated as
proponents of DSM sometimes claim.</p>

<p>Second, the enactive approach, as emphasized above, rejects the
idea that the function of vision is to <em>guide</em> actions. It </p>

<blockquote><p> does not claim that visual awareness depends on
visuomotor skill, if by &ldquo;visuomotor skill&rdquo; one means the
ability to make use of vision to reach out and manipulate or
grasp. Our claim is that seeing depends on an appreciation of the
sensory effects of movement (not, as it were, on the practical
significance of sensation). (No&euml; 2010: 249)</p></blockquote>

<p>
Since the enactive approach is not committed to the idea that seeing
depends on knowing how to act in relation to what we see, it is not
threatened by empirical evidence for a functional dissociation between
visual awareness and visually guided action.</p>

<!--pdf include  
 <br />  
 <br />   
 <br />   
pdf include-->


<h2><a id="MotComEffReaThe">3. Motor Component and Efferent Readiness Theories</a></h2>

<p>At this point, it should be clear that the claim that perception
is <em>active</em> or <em>action-based</em> is far from
unambiguous. Perceiving may implicate action in the sense that it is
taken constitutively to involve associations with touch (Berkeley
1709), kinaesthetic feedback from changes in eye position (Lotze 1887
[1879]), consciously experienced &ldquo;effort of the will&rdquo;
(Helmholtz 2005 [1924]), or
knowledge of the way reafferent sensory stimulation varies as a
function of movement (Held 1961; O&rsquo;Regan &amp; No&euml; 
2001; Hurley &amp;
No&euml; 2003).</p>

<p>In this section, we shall examine two additional conceptions of the
role of action in perception. According to the <strong>motor component
theory</strong>, as we shall call it, efference copies generated in
the oculomotor system and/or proprioceptive feedback from
eye-movements are used in tandem with incoming sensory inputs to
determine the spatial attributes of perceived objects (Helmholtz 2005 [1924]; Mack 1979;
Shebilske 1984, 1987; Ebenholtz 2002). <strong>Efferent readiness
theories</strong>, by contrast, appeal to the particular ways in which
perceptual states <em>prepare</em> the observer to move and act in
relation to the environment. The <strong>modest readiness
theory</strong>, as we shall call it, claims that the way an
object&rsquo;s spatial attributes are represented in visual experience
is sometimes modulated by one or another form of covert action
planning (Festinger <em>et al.</em> 1967; Coren 1986; Vishton <em>et
al.</em> 2007). The <strong>bold readiness theory</strong> argues for
the stronger, constitutive claim that, as J.G. Taylor puts its,
&ldquo;perception and multiple simultaneous readiness for action are
one and the same thing&rdquo; (1968: 432).</p>

<!--pdf include  
 <br />  
 <br />   
 <br />   
pdf include-->

<h3><a id="MotComTheEmbVisPer">3.1 The Motor Component Theory (Embodied Visual Perception)</a></h3>

<p>As pointed out in <a href="#EviForEnaApp">Section 2.3.2</a>, there
are numerous, independently variable sources of information about the
spatial layout of the environment in the light sampled by the eye. In
many cases, however, processing of stimulus information requires or is
optimized by recruiting sources of auxiliary information from outside
the visual system. These may be directly integrated with incoming
visual information or used to change the weighting assigned to one or
another source of optical stimulus information (Shams &amp; Kim 2010;
Ernst 2012).</p>

<p>An importantly different recruitment strategy involves combining
visual input with non-perceptual information originating in the
body&rsquo;s motor control systems, in particular, efference copy,
and/or proprioceptive feedback from active movement
(kinaesthesis). The <strong>motor component theory,</strong> as we
shall call it, is premised on evidence for such <em>motor-modal</em>
processing.</p>

<p>The motor component theory can be made more concrete by examining
three situations in which the spatial contents of visual experience
are modulated by information concerning recently initiated or
impending bodily movements:</p>

<ol type="a">

<li><strong>Apparent direction:</strong> The retinal image produced by
an object is ambiguous with respect to the object&rsquo;s direction in
the absence of extraretinal information concerning the orientation of
the eye relative to the head. While there is evidence that
proprioceptive inflow from muscle spindles in the extraocular muscles
is used to encode eye position, as Sherrington 1918 proposed,
outflowing <em>efference copy</em> is generally regarded as the more
heavily weighted source of information (Bridgeman &amp; Stark
1991). The problem of visual direction constancy was discussed in
detail in <a href="#EffVisDirCon">Section 2.1</a> above.</li>

<li><strong>Apparent distance and size:</strong> When an object is at
close range, its distance in depth from the perceiver can be
determined on the basis of three variables: (1) the distance between
the perceiver&rsquo;s eyes, (2) the vergence angle formed by the line
of sight from each eye to the object, and (3) the direction of
gaze. Information about (1) is updated in the course of development as
the perceiver&rsquo;s body grows. Information about (2) and (3), which
vary from one moment to the next, is obtained from efference copy of
the motor command to fixate the object as well as proprioceptive
feedback from the extraocular muscles. Since an object&rsquo;s
apparent size is a function of its perceived distance from the
perceiver and the angle it subtends on the retina (Emmert 1881),
information about (2) and (3) can thus modulate visual size perception
(Mon-Williams <em>et al.</em> 1997).</li>

<li><strong>Apparent motion:</strong> In the most familiar case of
motion perception, the subject visually tracks a moving target, e.g.,
a bird in flight, against a stable background using <em>smooth
pursuit</em> eye movements. As Bridgeman <em>et al.</em> 1994 note,
smooth pursuit &ldquo;reverses the movement conditions on the retina:
the tracked object sweeps across the retina very little, while the
background undergoes a brisk motion&rdquo; (p. 255). Nonetheless, it
is the target that appears to be in motion while the environment
appears to be stationary. There is evidence that the visual system is
able to compensate for pursuit induced retinal motion by means of
efference-based information about the changing direction of gaze (for
a review, see Furman &amp; Gur 2012). This has been used to explain
the travelling moon illusion (Post &amp; Leibowitz 1985:
637). Neuropsychological findings indicate that failure to integrate
efference-based information about eye movement leads to a breakdown in
perceived background stability during smooth pursuit (Haarmeier <em>et
al.</em> 1997; Nakamura &amp; Colby 2002; Fischer <em>et al.</em>
2012).</li>
</ol>

<p>The motor component theory is a version of the view that perception
is embodied in the sense of Prinz 2009 (see
the entry on <a href="../embodied-cognition/index.html">embodied cognition</a>).
 Prinz explains that</p>

<blockquote><p>embodied mental capacities, are ones that depend on
mental representations or processes that relate to the
body&hellip;. Such representations and processes come in two forms:
there are representations and processes that represent or respond to
body, such as a perception of bodily movement, and there are
representations and processes that affect the body, such as motor
commands. (2009: 420; for relevant discussion of various senses of
embodiment, see Alsmith and Vignemount 2012)</p></blockquote>

<p>
The three examples presented above provide empirical support for the
thesis that visual perception is embodied in this sense. For
additional examples, see Ebenholtz 2002: chap. 4.</p>

<h3><a id="EffReaThe">3.2 The Efferent Readiness Theory</a></h3>

<p>Patients with frontal lobe damage sometimes exhibit pathological
&ldquo;utilization behaviour&rdquo; (Lhermitte 1983) in which the
sight of an object automatically elicits behaviors typically
associated with it, such as automatically pouring water into a glass and
drinking it whenever a bottle of water and a glass are present
(Frith <em>et al.</em> 2000: 1782). That normal subjects often do not
automatically perform actions afforded by a perceived object, however, does not mean
that they do not plan, or imaginatively rehearse, or otherwise
represent them. (On the contrary, recent neuroscientific findings
suggest that merely perceiving an object often covertly prepares the motor
system to engage with it in a certain manner. For overviews, see
Jeannerod 2006 and Rizzolatti 2008.)</p>

<p>Efferent readiness theories are based on the idea that covert
preparation for action is &ldquo;an integral part of the perceptual
process&rdquo; and not &ldquo;merely a <em>consequence</em> of the
perceptual process that has preceded it&rdquo; (Coren 1986:
394). According to the <strong>modest readiness theory</strong>, as we
shall call it, covert motor preparation can sometimes influence the
way an object&rsquo;s spatial attributes are represented in perceptual
experience. The <strong>bold readiness theory</strong>, by contrast,
argues for the stronger, constitutive claim that to perceive an
object&rsquo;s spatial properties <em>just is</em> to be prepared or
ready to act in relation to the object in certain ways (Sperry
1952; Taylor 1962, 1965,
1968).</p>

<h4><a id="ModReaThe">3.2.1 The Modest Readiness Theory</a></h4>

<p>A number of empirical findings motivate the modest readiness
theory. Festinger <em>et al.</em> 1967 tested the view that visual
contour perception is </p>

<blockquote><p> determined by the particular sets of preprogrammed
efferent instructions that are activated by the visual input into a
state of readiness for immediate use. (p. 34)</p></blockquote>

<p>
Contact lenses that produce curved retinal input were placed on the
right eye of three observers, who were instructed to scan a
horizontally oriented line with their left eye covered for 40
minutes. The experimenters reported that there was an average of 44%
adaptation when the line was physically straight but retinally curved,
and an average of 18% adaptation when the line was physically curved
but retinally straight (see Miller &amp; Festinger 1977, however, for
conflicting results).</p>

<p>An elegantly designed set of experiments by Coren 1986 examined the
role of efferent readiness in the visual perception of direction and
extent. Coren&rsquo;s experiments support the hypothesis that the
spatial parameter controlling the length of a saccade is not the
angular direction of the target relative to the line of sight, but
rather the direction of the center of gravity (COG) of all the stimuli
in its vicinity (Coren &amp; Hoenig 1972; Findlay
1982). Importantly, </p>

<blockquote><p> the bias arises from the computation of the saccade
that <em>would</em> be made and, hence, is held in readiness, rather
than the saccade actually emitted. (Coren 1986: 399)</p></blockquote>

<p>The COG bias is illustrated in <a href="#fig3">Figure 3</a>. In
the <strong>first row (top)</strong>, there are no extraneous stimuli
near the saccade target. Hence, the saccade from the point of fixation to
the target is unbiased. In the <strong>second row</strong>, by
contrast, the location of an extraneous stimulus (&times;) results in
a saccade from the point of fixation that undershoots its target, while in
the <strong>third row</strong> the saccade overshoots its
target. In the <strong>fourth row</strong>, changing the location of
the extraneous stimulus eliminates the COG bias: because the
extraneous stimulus is near the point of fixation rather than the saccade
target, the saccade is accurate.</p>


<div class="figure avoid-breaks" id="fig3">
<img src="fig3.png" width="200" alt="[Two columns of 4 dots each, each pair of dots on the same horizontal. The left column has the words 'Fixation Point' at the top and a blue arrow pointing from those words to the top of the column. The right column has the words 'Saccade Target' and a similar blue arrow. The top (or first) pair of dots has an arrow curving from the left dot to the right dot. The second pair as a 'x' to the left of the right dot and an arrow curving from the left dot to a point between the 'x' and the right dot. The third pair has a 'x' to the right of the right dot and an arrow curving from the left dot to a point between the right dot and the 'x'. The fourth pair as a 'x' to the left of the left dot and an arrow curving from the left dot to the right dot.]" />


<p style="line-height:1.3em;margin-top:1ex"><span class="figlabel">Figure 3:</span> 
The effect of starting eye position on saccade programming (after Coren 1986: 405)</p>
</div>


<p>The COG bias is evolutionarily adaptive: eye movements will bring
both the saccade target as well as nearby objects into high acuity
vision, thereby maximizing the amount of information obtained with
each saccade. Motor preparation or &ldquo;efferent readiness&rdquo; to
execute an undershooting or overshooting saccade, Coren found,
however, can also give rise to a corresponding <em>illusion of
extent</em> (1986: 404&ndash;406). Observers, e.g., will perceptually
underestimate the length of the distance between the point of fixation
and the saccade target when there is an extraneous stimulus on the
near side of the target (as in the second row
of <a href="#fig3">Figure 3</a>) and will perceptually overestimate
the length of the distance when there is an extraneous stimulus on the
far side of the target (as in the third row of <a href="#fig3">Figure
3</a>).</p>

<p>According to Coren, the well known M&uuml;ller-Lyer illusion can be
explained within this framework. The outwardly turned wings in
M&uuml;ller-Lyer display shift the COG outward from each vertex, while
the inwardly turned wings in this figure shift the COG inward. This
influences both saccade length from vertex to vertex as well as the
apparent length of the central line segments. The influence of COG on
efferent readiness to execute eye movements, Coren argues (1986:
400&ndash;403), also explains why the line segments in the
M&uuml;ller-Lyer display can be replaced with small dots while leaving
the illusion intact as well as the effects of varying wing length and
wing angle on the magnitude of the illusion.</p>

<h4><a id="BolReaThe">3.2.2 The Bold Readiness Theory</a></h4>

<p>The modest readiness theory holds that the way an
object&rsquo;s spatial attributes are represented in visual experience
is sometimes modulated by one or another form of covert action
planning. The <strong>bold readiness theory</strong> argues for a
stronger, constitutive claim: to perceive an object&rsquo;s spatial
properties <em>just is</em> to be prepared or ready to act in relation
to the object in certain ways. We begin by examining
J.G. Taylor&rsquo;s &ldquo;behavioral theory&rdquo; of perception
(Taylor 1962, 1965, 1968).</p>

<p>Taylor&rsquo;s behavioral theory of perception identifies
the conscious experience of seeing an object&rsquo;s spatial
properties with the passive activation of a specific set of learned or
&ldquo;preprogrammed&rdquo; motor routines:</p>

<blockquote> <p> [P]erception is a state of multiple simultaneous
readiness for actions directed to the objects in the environment that
are acting on the receptor organs at any one moment. The actions in
question have been acquired by the individual in the course of his
life and have been determined by the reinforcing contingencies in the
environment in which he grew up. What determines the content of
perception is not the properties of the sensory transducers that are
operated on by stimulus energies from the environment, but <em>the
properties of the behaviour conditioned to those stimulus
energies</em>&hellip;. (1965: 1, our emphasis)</p></blockquote>

<p>According to Taylor&rsquo;s theory, sensory stimulation gives rises
to spatially contentful visual experience as a consequence of
associative, reinforcement learning: we perceive an object as having
the spatial attribute <em>G</em> when the types of proximal sensory
stimulation caused by the object have been conditioned to the
performance of actions sensitive to <em>G</em> (1962: 42). The
conscious experience of seeing an object&rsquo;s distance,
e.g., is constituted by the subject&rsquo;s learned readiness to
perform specific whole body and limb movements that were reinforced
when the subject previously received stimulation from objects at the
same remove. In general, differences in the spatial content of a
visual experience are identified with differences in the
subject&rsquo;s state of &ldquo;multiple simultaneous readiness&rdquo;
to interact with the objects represented in the experience.</p>

<p>The main problem with Taylor&rsquo;s theory is one that besets
behaviorist theories of perception in general: it assumes that for any
visible spatial property <em>G</em>, there will be some distinctive
set of behavioral responses that are constitutive of perceiving the
object as having <em>G</em>. The problem with this assumption, as
Mohan Matthen (1988) puts it, </p>

<blockquote><p> there is no such thing as <em>the</em> proper
response, or even a range of functionally appropriate responses, to
what perception tells us. (p. 20, see also Hurley 2001:
17)</p></blockquote>

<h2><a id="SkiThe">4. Skill/Disposition Theories</a></h2>

<p>The last approach we shall discuss has roots in, and similarities
to, many of the proposals covered above, but is most closely aligned
with the bold readiness theory. We will follow Grush (2007) in calling
this approach the <em>disposition theory</em> (see Grush 2007: 394,
for discussion of the name). The primary proponent of this position is
Gareth Evans, whose work on spatial representation focused on
understanding how we manage to perceive objects as occupying locations
in egocentric space.</p>

<p>The starting point of Evans&rsquo; theory is that the
subject&rsquo;s perceptual systems have isolated a channel of sensory
input, an &ldquo;information link&rdquo;, through which she receives
information about the object. The information link by itself does not
allow the subject to know the location of this object. Rather, it is
when the information link is able to induce in the subject appropriate
kinds of behavioral dispositions that it becomes imbued with spatial
import:</p>

<blockquote> <p> The subject hears the sound as coming from
such-and-such a position, but how is the position to be specified?
Presumably in <em>egocentric</em> terms (he hears the sound as up, or
down, to the right or to the left, in front or behind). These terms
specify the position of the sound in relation to the observer&rsquo;s
own body; and they derive their meaning in part from their complicated
connections with the subject&rsquo;s <em>actions</em>. (Evans 1982:
155)</p></blockquote>

<p>This is not a version of a motor theory (e.g., Poincar&eacute;
1907: 71). The behavioral responses in question are <em>not</em> to be
understood as raw patterns of motor activations, or even muscular
sensations. Such a reduction would face challenges anyway, since for
any location in egocentric space, there are an infinite number of
kinematic configurations (movements) that would, for example, effect a
grasp to that location; and for any kinematic configuration, there are
an infinite number of dynamic profiles (temporal patterns of muscular
force) that would yield that configuration. The behavioral responses
in question are <em>overt environmental behavior</em>:</p>

<blockquote> <p> It may well be that the input-output connections can
be finitely stated only if the output is described in explicitly
spatial terms (e.g., &lsquo;extending the arm&rsquo;, &lsquo;walking
forward two feet&rsquo;, etc.). If this is so, it would rule out the
reduction of the egocentric spatial vocabulary to a muscular
vocabulary. But such a reduction is certainly not needed for the point
being urged here, which is that the spatial information embodied in
auditory perception is specifiable only in a vocabulary whose terms
derive their meaning partly from being linked with bodily
actions. Even given an irreducibility, it would remain the case that
possession of such information is directly manifestable in behaviour
issuing from no calculation; it is just that there would be
indefinitely many ways in which the manifestation can occur. (Evans
1982: 156)</p></blockquote>

<p>Also, on this proposal, all modalities are in the same boat. As
such the disposition theory is more ambitious than most of the
theories already discussed, which are limited to vision. Not only is
there no reduction of perceptual spatial content to a &ldquo;muscular
vocabulary&rdquo;, there is also no reduction of the spatial content
of some perceptual modalities to that of one or more others&mdash;as
there was for Berkeley, who sought to reduce the spatial content of
vision to that of touch, and whose program forced a distinction
between two spaces, visual space and tangible space:</p>

<blockquote> <p> The spatial content of auditory and
tactual-kinaesthetic perceptions must be specified in the same
terms&mdash;egocentric terms. &hellip; It is a consequence of this
that perceptions from both systems will be used to build up a unitary
picture of the world. There is only one egocentric space, because
there is only one behavioural space. (Evans 1982:
160)</p></blockquote>

<p>Relatedly, for Evans it is not even the case that spatial
perceptual content, for all modalities, is being <em>reduced</em> to
behavioral dispositions. Rather, perceptual inputs and behavioral
outputs <em>jointly and holistically</em> yield a single behavioral
space:</p>

<blockquote> <p> Egocentric spatial terms are the terms in which the
content of our spatial experiences would be formulated, and those in
which our immediate behavioural plans would be expressed. This duality
is no coincidence: an egocentric space can exist only for an animal in
which a complex network of connections exists between perceptual input
and behavioural output. A perceptual input&mdash;even if, in some
loose sense, it encapsulates spatial information (because it belongs
to a range of inputs which vary systematically with some spatial
facts)&mdash;cannot have a spatial significance for an organism except
in so far as it has a place in such a complex network of input-output
connections. (Evans 1982: 154)</p>

<p> Egocentric spatial terms and spatial descriptions of bodily
movement would, on this view, form a structure familiar to
philosophers under the title &ldquo;holistic&rdquo;. (Evans 1982: 156,
fn. 26)</p></blockquote>

<p>This last point and the associated quotes address a common
misconception of the disposition theory. It would be easy to read the
theory as providing a proposal of the following sort: <em>A creature
gets sensory information from a stimulus, and the problem is to
determine where that stimulus is located in egocentric space; the
solution is that features of that sensory episode induce dispositions
to behavior targeting some egocentric location</em>. While this sort
of thing is indeed a problem, it is relatively superficial. Any
creature facing <em>this</em> problem must already have the capacity
to grasp egocentric spatial location contents, and the problem is
which of these ready-at-hand contents it should assign to the
stimulus. But the disposition theory is addressing a deeper question:
in virtue of what does this creature have a capacity to grasp
egocentric spatial contents to begin with? The answer is that the
creature must have a rich set of interconnections between sensory
inputs (and their attendant information links) and dispositions for
behavioral outputs.</p>

<p>Rick Grush (2000, 2007) has adopted Evans&rsquo; theory, and
attempted to clarify and expand upon it, particularly in three areas:
first, the distinction between the disposition theory and other
approaches; second, the neural implementation of the disposition
theory; and finally the specific kinds of dispositions that are
relevant for the issue of spatial experience.</p>

<p>The theory depends on behavioral dispositions. Grush (2007) argues
that there are two distinctions that need to be made: first, the
organism might possess i) knowledge of what the consequences (bodily,
environmental, or sensory) of a given action will be; or ii) knowledge
of which motor commands will bring about a given desired end state
(of the body, environment, or sensory channels) (Grush 2007: 408). I
might be able to recognize that a series of moves someone shows me
will force my grandmaster opponent into checkmate (knowledge of the
first sort, the consequences of a given set of actions), and yet not
have been anywhere near the skill level to have come up with that
series of moves on my own (knowledge of the second sort, what actions
will achieve a desired effect). Sensorimotor contingency theorists
appeal to knowledge of the first sort&mdash;though as was discussed
in <a href="#SomQueAboPPro">Section 2.3.1</a>, No&euml; flirts with
appealing to knowledge of the second sort to explain the perceptual
grasp of P-shapes; to the extent he does, he is embracing a
disposition theoretic account of P-shapes. Disposition theorists, and
bold readiness theorists (<a href="#">Section
3.2.2</a>) appeal to
knowledge of the second sort. These are the dispositions of the
disposition theory: given some goal, the organism is disposed to
execute certain actions.</p>

<p>This leads to the second distinction,
between <em>type-specifying</em> and <em>detail-specifying</em>
dispositions. Grush (2007: 393) maintains that only the latter are
directly relevant for spatial perception. A type-specifying
disposition is a disposition to execute some <em>type</em> of behavior
with respect to an object or place. For example, an organism might be
disposed to grasp, bite, flee, or foveate some object. This sort of
disposition is not relevant to the spatial content of the experience
on the disposition theory. Rather, what are relevant are
detail-specifying dispositions: the specifics of how I am disposed to
act to execute any of these behavior types. When reaching to grab the
cup to take a drink (type), do I move my hand like so (straight ahead,
say), or like such (off to the right)? When I want to foveate or
orient towards (behavior type) the ant crawling up the wall, do a I
move my head and eyes like <em>this</em>, or like <em>that</em>?</p>

<p>This latter distinction allows the disposition theory to answer one
of the main objections to the bold readiness theory (described at the
end of section <a href="#BolReaThe">3.2.2</a>) that there is no single
special disposition connected to perceiving any given object. That is
true of type-specifying dispositions, but not of detail-specifying
dispositions. Given the ant&rsquo;s location there is indeed a very
limited range of detail specifying dispositions that will allow me to
foveate it (though this might require constraints on possible actions,
such as <em>minimum jerk</em> or other such constraints).</p>

<p>Grush (2007; 2009) has proposed a detailed implementation of the disposition
theory in terms of neural information processing. The proposal
involves more mathematics than is appropriate here, and so a quick
qualitative description will have to suffice (for more detail, see
Grush 2007; 2009). The basic idea is that relevant cortical areas learn
sets of basis functions which, to put it <em>very</em> roughly, encode
equivalence classes of combinations of sensory and postural signals
(for discussion, see Pouget <em>et al.</em> 2002). For example, many
combinations of eye orientation and location of stimulation on the
retina correspond to a visual stimulus that is directly in front of
the head. Sorting such bodily postural information (not just eye
orientation, but any postural information that affects sensation,
which is most) and sensory condition pairs into useful equivalence
classes is the first half of the job.</p>

<p>What this does is encode incoming information in a way that renders
it ready to be of use in guiding behavior, since the equivalence
classes are precisely those for which a given kind of motor program is
appropriate. The next part corresponds to how this information, so
represented, can be used to produce the details of such a motor
program. For every <em>type</em> of action in a creature&rsquo;s
behavioral repertoire (grasp, approach, avoid, foveate, bite, etc.)
its motor areas have a set of linear coefficients, easily implemented
as a set of neural connection strengths, and when these are applied to
a set of basis function values, a detailed behavior is specified. For
example, when a creature senses an object <em>O</em><sub>1</sub>, a
set of basis function values <em>B</em><sub>1</sub> for that stimulus
is produced. If the creature decides to execute overt
action <em>A</em><sub>1</sub>, then the <em>B</em><sub>1</sub> basis
function values are multiplied by the coefficient corresponding
to <em>A</em><sub>1</sub>. The result is an instance of behavior
type <em>A</em><sub>1</sub> executed with respect to
object <em>O</em><sub>1</sub>. If the creature had decide instead to
execute action <em>A</em><sub>2</sub>, with respect
to <em>O</em><sub>1</sub>, the <em>B</em><sub>1</sub> basis function
values would have been multiplied by the <em>A</em><sub>2</sub> set of
coefficients, and the result would be a motor behavior
executing <em>A</em><sub>2</sub> on object <em>O</em><sub>1</sub>.</p>

<p>Accordingly, the disposition theory has a very different account of
what is happening with sensory substitution devices than Susan Hurley and Alva
No&euml; (see <a href="#ChaEnaApp">Section 2.3.2</a> above). On the
disposition theory, what allows the user of such a device to have
spatial experience is not the ability to anticipate how the sensory
input will change upon execution of movement as the sensorimotor
contingency theory would have it. Rather, it is that the
subject&rsquo;s brain has learned to take these sensory inputs
together with postural signals to produce sets of basis functions that
poise the subject to act with respect to the object that is causing
the sensory signals (see Grush 2007: 406).</p>

<p>One objection to disposition theories is what Hurley has called <em>The Myth of the
Giving</em>:</p>

<blockquote> <p> To suppose that &hellip; the content of intentions
can be taken as unproblematically primitive in explaining how the
content of experience is possible, is to succumb to the myth of the
giving. (Hurley 1998: 241)</p></blockquote>

<p>The idea behind this objection is that one is simply shifting
the debt from one credit card to another when one takes as problematic
the spatial content of perception, and then appeals to motor behavior
as the supplier of this content. For then, of course, the question
will be: Whence the spatial content of motor behavior?</p>

<p>The disposition theory, however, does not posit any such unilateral
reduction (though Taylor&rsquo;s bold readiness theory arguably does,
see <a href="#BolReaThe">Section 3.2.2</a> above). As discussed above,
Evans explicitly claims that the behavioral space is holistically
determined by both behavior and perception. And on Grush&rsquo;s
account spatial content is implemented in the construction of basis
function values, and these values coordinate <em>transitions</em> from
perceptual input to behavioral output. As such, they are highly
analogous to inferences whose conditions of application are given in
sensory-plus-postural terms and whose consequences of application
manifest in behavioral terms. The import of the states that represent
these basis function values is no more narrowly motor than the meaning
of a conditional can be identified with its consequent (or its
antecedent, for that matter) in isolation.</p>

<p>Another very common objection, one that is often leveled at many
forms of motor theory, has to do with the fact that even paralyzed
people, with very few possibilities for action, seem capable in many
cases of normal spatial perception. Such objections would, at a minimum,
place significant pressure on any views that explain perceptual
content by appeal to actual behavior. It is also easy to see how even
hypothetical behavior would be called into question in such cases,
since in many such cases behavior is not physically
possible. Grush&rsquo;s theory (2007), right or wrong, has something
specific to say about this objection. Since spatial content is taken
to be manifested in the production of basis function values in the
cortex, the prediction is that any impairments manifesting farther
down the chain, the brain stem or spinal cord, for example, need have
no direct effect on spatial content. So long as the relevant brain
areas have the wherewithal to produce sets of basis function values
suitable for constructing a motor sequence (if multiplied by the
action-type-specific coefficients), then the occasioning perceptual
episode will have spatial content.</p>

</div>

<div id="bibliography">

<h2><a id="Bib">Bibliography</a></h2>



<ul class="hanging"> 

<li>Abbott, T.K., 1864, <em>Sight and Touch: An Attempt to Disprove
the Received (or Berkeleian) Theory of Vision</em>, London: Longman
&amp; Co.</li>

<li>Alsmith, A. and F. de Vignemont, 2012, &ldquo;Embodying the Mind
and Representing the Body&rdquo;, <em>Review of Philosophy and
Psychology</em>, 3(1): 1&ndash;13.</li>

<li>Armstrong, D.M., 1960, <em>Berkeley's theory of vision</em>,
Parkville: Melbourne University Press.</li>

<li>Atherton, M., 2005, &ldquo;Berkeley&rsquo;s Theory of Vision and
Its Reception&rdquo;, in <em>The Cambridge Companion to Berkeley</em>,
New York: Cambridge University Press, pp. 94&ndash;124.</li>

<li>Austin, J.L., 1962, <em>Sense and Sensibilia</em>, Oxford:
Clarendon.</li>

<li>Bach-y-Rita, P., 1972, <em>Brain Mechanisms in Sensory
Substitution</em>, New York: Academic Press.</li>

<li>&ndash;&ndash;&ndash;, 2004, &ldquo;Tactile Sensory Substitution
Studies&rdquo;, <em>Annals of the New York Academy of Sciences</em>,
1013: 83&ndash;91.</li>

<li>Bach-y-Rita, P. and S.W. Kercel, 2003, &ldquo;Sensory Substitution
and the Human&ndash;Machine Interface&rdquo;, <em>Trends in Cognitive
Sciences</em>, 7(12): 541&ndash;546.</li>

<li>Bailey, S., 1842, <em>A Review of Berkeley&rsquo;s Theory of
Vision, Designed to Show the Unsoundness of That Celebrated
Speculation</em>, London: James Ridgway.</li>

<li>Bain, A., 1855, <em>The Senses and the Intellect</em>, New York:
Appleton.</li>

<li>&ndash;&ndash;&ndash;, 1868, <em>Mental and Moral Science</em>,
London: Longmans, Green, and Co.</li>

<li>Bell, C., 1823, &ldquo;Idea of a New Anatomy of the Brain&rdquo;,
in <em>Francois Magendie, Charles Bell and the Course of the Spinal
Nerves</em>, P. Cranefield (ed.), Mt. Kisco, NY: Futura, 1974.</li>

<li>Berkeley, G., 1709, &ldquo;An Essay Towards a New Theory of
Vision&rdquo;, in <em>Berkeley: Philosophical Writings</em>, D. Clarke
(ed.), Cambridge: Cambridge University Press, 2008.</li>

<li>&ndash;&ndash;&ndash;, 1734, <em>A Treatise Concerning the
Principles of Human Knowledge</em>, K. Winkler (ed.), Indianapolis:
Hackett, 1982.</li>

<li>Block, N., 2005, &ldquo;Review of <em>Action in
Perception</em>&rdquo;, <em>Journal of Philosophy</em>, 102:
259&ndash;272.</li>

<li>&ndash;&ndash;&ndash;, 2012, &ldquo;Discussion of J. Kevin
O&rsquo;Regan&rsquo;s <em>Why Red Doesn&rsquo;t Sound Like a Bell:
Understanding the Feel of Consciousness</em>&rdquo;, <em>Review of
Philosophy and Psychology</em>, 3: 89&ndash;108.</li>

<li>Bridgeman, B., 1981, &ldquo;Cognitive Factors in Subjective
Stabilization of the Visual World&rdquo;, <em>Acta Psychologica</em>,
48: 111&ndash;121.</li>

<li>&ndash;&ndash;&ndash;, 2010, &ldquo;Space Constancy: The Rise and
Fall of Perceptual Compensation&rdquo;, in <em>Space and Time in
Perception and Action</em>, pp. 94&ndash;108.</li>

<li>Bridgeman, B., D. Hendry, and L. Stark, 1975, &ldquo;Failure to
Detect Displacement of the Visual World During Saccadic Eye
Movements&rdquo;, <em>Vision Res</em>, 15: 719&ndash;722.</li>

<li>Bridgeman, B. and L. Stark, 1991, &ldquo;Ocular Proprioception and
Efference Copy in Registering Visual Direction&rdquo;, <em>Vision
Res</em>, 31: 1903&ndash;1913.</li>

<li>Bridgeman B, A.H.C. van der Heijden, and B. Velichkovsky, 1994,
&ldquo;A Theory of Visual Stability Across Saccadic Eye
Movements&rdquo;, <em>Behavioral and Brain Sciences</em>, 17:
247&ndash;292.</li>

<li>Briscoe, R., 2008, &ldquo;Vision, Action, and
Make-Perceive&rdquo;, <em>Mind and Language</em>, 23:
457&ndash;497.</li>

<li>&ndash;&ndash;&ndash;, 2009, &ldquo;Egocentric Spatial
Representation in Action and Perception&rdquo;, <em>Philosophy and
Phenomenological Research</em>, 79: 423&ndash;460.</li>

<li>&ndash;&ndash;&ndash;, forthcoming, &ldquo;Bodily Action and
Distal Attribution in Sensory Substitution&rdquo;, in <em>Sensory
Substitution and Augmentation</em>, F. Macpherson
(ed.), <em>Proceedings of the British Academy</em>, Oxford: Oxford
University Press.</li>

<li>Briscoe, R. and J. Schwenkler, forthcoming, &ldquo;Conscious
Vision in Action&rdquo;, to appear in <em>Cognitive Science</em>.</li>

<li>Broad, C.D., 1923, <em>Scientific Thought</em>, C.K. Ogden (ed.),
New York: Harcourt, Brace.</li>

<li>Bruce, V., P. Greene, and M. Georgeson, 2003, <em>Visual
Perception: Physiology, Psychology and Ecology</em>, London:
Psychology Press, 4th edition.</li>

<li>Brune, F. and C.H. L&uuml;cking, 1969, &ldquo;<em>Okulomotorik,
Bewegungswahrnehmung and Raumkonstanz der
Sehdinge</em>&rdquo;, <em>Der Nervenarzt</em>, 40: 692&ndash;700</li>

<li>Clark, A., 2009, <em>Supersizing the Mind</em>, Oxford: Oxford
University Press.</li>

<li>Colby, C.L., J. Duhamel, and M.E. Goldberg, 1995,
&ldquo;Oculocentric Spatial Representation in Parietal
Cortex&rdquo;, <em>Cerebral Cortex</em>, 5: 470&ndash;481.</li>

<li>Colby, C.L. and M.E. Goldberg, 1992, &ldquo;The Updating of the
Representation of Visual Space in Parietal Cortex by Intended Eye
Movements&rdquo;, <em>Science</em>, 255(5040): 90&ndash;92.</li>

<li>Condillac, E., 1746, <em>Essay on the Origin of Human
Knowledge</em>, H. Aarsleff (ed.), Cambridge: Cambridge University
Press, 2001.</li>

<li>&ndash;&ndash;&ndash;, 1754, <em>Treatise on the Sensations</em>,
G. Carr (trans.), London: Favil, 1930.</li>

<li>Coren, S., 1986, &ldquo;An Efferent Component in the Visual
Perception of Direction and Extent&rdquo;, <em>Psychological
Review</em>, 93(4): 391&ndash;410.</li>

<li>Coren, S. and P. Hoenig, 1972, &ldquo;Effect of Non-Target Stimuli
upon the Length of Voluntary Saccades&rdquo;, <em>Perceptual and Motor
Skills</em>, 34: 499&ndash;508.</li>

<li>Cutting, J.E. and P.M. Vishton, 1995, &ldquo;Perceiving Layout and
Knowing Distances&rdquo;, in <em>Perception of Space and Motion</em>,
W. Epstein and S. Rogers (eds.), San Diego, CA: Academic Press,
pp. 69&ndash;117.</li>

<li>Deubel, H., 2004, &ldquo;Localization of Targets Across Saccades:
Role of Landmark Objects&rdquo;, <em>Visual Cognition</em>,
11(2&ndash;3): 173&ndash;202.</li>

<li>Deubel, H., W.X. Schneider, and B. Bridgeman, 2002,
&ldquo;Transsaccadic Memory of Position and Form&rdquo;, <em>Progress
in Brain Research</em>, 140: 165&ndash;180.</li>

<li>Dewey, J., 1891, <em>Psychology</em>, New York: American Book
Company.</li>

<li>Duhamel, J., C. Colby, and M. E. Goldberg, 1992, &ldquo;The
Updating of the Representation of Visual Space in Parietal Cortex by
Intended Eye Movements&rdquo;, <em>Science</em>, 255:
90&ndash;92.</li>

<li>Ebenholtz, S., 2002, <em>Oculomotor Systems and Perception</em>,
Cambridge: Cambridge University Press.</li>

<li>Emmert, E., 1881, &ldquo;<em>Gr&ouml;&szlig;enverh&auml;ltnisse
der Nachbilder</em>&rdquo;, <em>Klinische Monatsbl&auml;tter f&uuml;r
Augenheilkunde und f&uuml;r augen&auml;rztliche Fortbildung</em>, 19:
443&ndash;450.</li>

<li>Epstein, W., 1967, <em>Varieties of Perceptual Learning</em>, New
York: McGraw Hill.</li>

<li>Epstein, W., B. Hughes, S.L. Schneider, and P. Bach-y-Rita, 1986,
&ldquo;Is There Anything Out There? A Study of Distal Attribution in
Response to Vibrotactile Stimulation&rdquo;, <em>Perception</em>, 15:
275&ndash;284</li>

<li>Ernst, M., 2012, &ldquo;Optimal Multisensory Integration:
Assumptions and Limits&rdquo;, in <em>The New Handbook of Multisensory
Processing</em>, B. Stein, (ed.), Cambridge, MA: MIT Press,
pp. 527&ndash;544.</li>

<li>Evans, G., 1982, <em>The Varieties of Reference</em>, Oxford:
Oxford University Press.</li>

<li>&ndash;&ndash;&ndash;, 1985, &ldquo;Molyneux&rsquo;s
Question&rdquo;, in <em>The Collected Papers of Gareth Evans</em>,
A. Phillips (ed.), London: Oxford University Press.</li>

<li>Falkenstein, L., 1994, &ldquo;Intuition and Construction in
Berkeley's Account of Visual Space&rdquo;, <em>Journal of the History
of Philosophy</em>, 32(1): 63&ndash;84.</li>

<li>Festinger, L., C.A. Burnham, H. Ono, and D. Bamber, 1967,
&ldquo;Efference and the Conscious Experience of
Perception&rdquo;, <em>Journal of Experimental Psychology
Monographs</em>, 74(4, Pt 2): 1&ndash;36.</li>

<li>Findlay, J.M., 1982, &ldquo;Global Visual Processing for Saccadic
Eye Movements&rdquo;, <em>Vision Research</em>, 22(8):
1033&ndash;1045.</li>

<li>Fischer, E., H.H. B&uuml;lthoff, N.K. Logothetis, and A. Bartels,
2012, &ldquo;Human Areas V3A and V6 Compensate for Self-Induced Planar
Visual Motion&rdquo;, <em>Neuron</em>, 73(6): 1228&ndash;1240.</li>

<li>Fishkin, S., 1969, &ldquo;Passive vs. Active Exposure and Other
Variables Related to the Occurrence of Hand Adaptation to Lateral
Displacement&rdquo;, <em>Perceptual and Motor Skills</em>, 29:
291&ndash;297.</li>

<li>Frith, C.D. and D.M. Wolpert, 2000, &ldquo;Abnormalities in the
Awareness and Control of Action&rdquo;, <em>Philosophical Transactions
of the Royal Society B: Biological Sciences</em>, 355(1404):
1771&ndash;1788.</li>

<li>Furman, M. and M. Gur, 2012, &ldquo;And Yet it Moves: Perceptual
Illusions and Neural Mechanisms of Pursuit Compensation During Smooth
Pursuit Eye Movements&rdquo;, <em>Neuroscience &amp; Biobehavioral
Reviews</em>, 36(1): 143&ndash;151.</li>

<li>Gangopadhyay, N., M. Madary, and F. Spicer, 2010, <em>Perception,
Action, and Consciousness: Sensorimotor Dynamics and Two Visual
Systems</em>, Oxford: Oxford University Press.</li>

<li>Ganz, L., 1975, &ldquo;Orientation in Visual Space by Neonates and
its Modification by Visual Deprivation&rdquo;, in <em>The
Developmental Neuropsychology of Sensory Deprivation</em>, A. Riesen
(ed.), New York: Academic Press, pp. 169&ndash;210.</li>

<li>Gibson, J.J., 1933, &ldquo;Adaptation, After-Effect and Contrast
in the Perception of Curved Lines&rdquo;, <em>Journal of Experimental
Psychology</em>, 16(1): 1&ndash;31.</li>

<li>&ndash;&ndash;&ndash;, 1966, <em>The Senses Considered as
Perceptual Systems</em>, Boston, MA: Houghton Mifflin.</li>

<li>&ndash;&ndash;&ndash;, 1979, <em>The Ecological Approach to Visual
Perception</em>, Boston, MA: Houghton Mifflin.</li>

<li>Goodale, M.A. and A.D. Milner, 2004, <em>Sight Unseen: An
Exploration of Conscious and Unconscious Vision</em>, Oxford: Oxford
University Press.</li>

<li>Grush, R., 2000, &ldquo;Self, World and Space: The Meaning and
Mechanisms of Ego- and Allocentric Spatial
Representation&rdquo;, <em>Brain and Mind</em>, 1: 59&ndash;92.</li>

<li>&ndash;&ndash;&ndash;, 2007, &ldquo;Skill Theory v2.0:
Dispositions, Emulation, and Spatial
Perception&rdquo;, <em>Synthese</em>, 159: 389&ndash;416.</li>

<li>&ndash;&ndash;&ndash;, 2009, &ldquo;Space, time, and
objects&rdquo;, <em>The Oxford Handbook of Philosophy and
Neuroscience</em>, John Bickle(ed), New York, NY: Oxford University
Press, pp. 311&ndash;345.</li>

<li>Haarmeier, T., Thier, P., Repnow, M. and D. Petersen, 1997,
&ldquo;False Perception of Motion in a Patient Who Cannot Compensate
for Eye Movements&rdquo;, <em>Nature</em>, 389: 849&ndash;851.</li>

<li>Harris, C.S., 1965, &ldquo;Perceptual Adaptation to Inverted,
Reversed, and Displaced Vision&rdquo;, <em>Psychological Review</em>,
72(6): 419&ndash;444.</li>

<li>&ndash;&ndash;&ndash;, 1980, &ldquo;Insight or Out of Sight? Two
Examples of Perceptual Plasticity in the Human
Adult&rdquo;, <em>Visual Coding and Adaptability</em>, C.S. Harris
(ed.), pp. 95&ndash;149.</li>

<li>Hatfield, G.C., 1990, <em>The Natural and the Normative: Theories
of Spatial Perception from Kant to Helmholtz</em>, Cambridge, MA: MIT
Press.</li>

<li>Hatfield, G.C. and W. Epstein, 1979, &ldquo;The Sensory Core and
the Medieval Foundations of Early Modern Perceptual
Theory&rdquo;, <em>Isis</em>, 70(3): 363&ndash;384.</li>

<li>Hay, J.C., H.L. Pick, Jr., and K. Ikeda, 1965, &ldquo;Visual
Capture Produced by Prism Spectacles&rdquo;, <em>Psychonomic
Science</em>, 2: 215&ndash;216.</li>

<li>Hein, A. and R. Held, 1962, &ldquo;A Neural Model for Labile
Sensorimotor Coordinations&rdquo;, in <em>Biological Prototypes and
Synthetic Systems</em> (Volume 1), E. Bernard and M. Kare (eds.), New
York: Plenum Press, pp. 71&ndash;74.</li>

<li>Held, R., 1961, &ldquo;Exposure-History as a Factor in Maintaining
Stability of Perception and Coordination&rdquo;, <em>The Journal of

Nervous and Mental Disease</em>, 132(1): 26&ndash;32.</li>

<li>&ndash;&ndash;&ndash;, 1965, &ldquo;Plasticity in Sensory-Motor
Systems&rdquo;, <em>Scientific American</em>, 213: 84&ndash;94.</li>

<li>Held, R. and J. Bossom, 1961, &ldquo;Neonatal Deprivation and
Adult Rearrangement: Complementary Techniques for Analyzing Plastic
Sensory-Motor Coordinations&rdquo;, <em>Journal of Comparative and
Physiological Psychology</em>, 54(1): 33&ndash;37.</li>

<li>Held, R. and A. Hein, 1958, &ldquo;Adaptation of Disarranged
Hand-Eye Coordination Contingent upon Re-Afferent
Stimulation&rdquo;, <em>Perceptual and Motor Skills</em>, 8:
87&ndash;90.</li>

<li>&ndash;&ndash;&ndash;, 1963, &ldquo;Movement-Produced Stimulation
in the Development of Visually Guided Behavior&rdquo;, <em>Journal of
Comparative and Physiological Psychology</em>, 56: 872&ndash;876.</li>

<li>Helmholtz, H, 2005 [1924], <em>Treatise on Physiological
Optics</em> (Volume 3), New York: Dover.</li>

<li>Hering, E., 1861, <em>Beitr&auml;ge zur Physiologie</em> (Volume
1), Leipzig: Engelman. (Reissued with an introduction by B. Bridgeman,
Berlin: Springer, 1990).</li>

<li>Hickerson, R., 2007, &ldquo;Perception as Knowing How to Act: Alva
No&euml;&rsquo;s <em>Action In
Perception</em>&rdquo;, <em>Philosophical Psychology</em>, 20(4):
505&ndash;517.</li>

<li>von Holst, E., 1954, &ldquo;Relations Between the Central Nervous
System and the Peripheral Organs&rdquo;, <em>The British Journal of
Animal Behaviour</em>, 2(3): 89&ndash;94.</li>

<li>von Holst, E. and H. Mittelst&auml;dt, 1950, &ldquo;<em>Das
Reafferenzprinzip, Wechselwirkungen zwischen Zerntalnervensystem und
Peripherie</em>&rdquo;, <em>Naturwissenschaften</em>, 27:
464&ndash;476.</li>

<li>Hopp, W., 2013, &ldquo;No Such Look: Problems with the Dual
Content Theory&rdquo;, <em>Phenomenology and the Cognitive
Sciences</em>, 12(4): 813&ndash;833.</li>

<li>Howard, I.P., B. Craske, and W.B. Templeton, 1965,
&ldquo;Visuomotor Adaptation to Discordant Exafferent
Stimulation&rdquo;, <em>Journal of Experimental Psychology</em>,
70(2): 189&ndash;191.</li>

<li>Howard, I.P. and W.B. Templeton, 1966, <em>Human Spatial
Orientation</em>, New York: Wiley.</li>

<li>Hurley, S.L., 1998, <em>Consciousness in Action</em>, Cambridge,
MA: Harvard University Press.</li>

<li>Hurley, S.L. and A. No&euml;, 2003, &ldquo;Neural Plasticity and
Consciousness&rdquo;, <em>Biology and Philosophy</em>, 18:
131&ndash;168.</li>

<li>Jeannerod, M., 2006, <em>Motor Cognition: What Actions Tell the
Self</em>, Oxford: Oxford University Press.</li>

<li>Kiverstein, J., 2010, &ldquo;Sensorimotor Knowledge and the
Contents of Experience&rdquo;, in Gangopadhyay et al. 2010:
257&ndash;274.</li>

<li>Kravitz, J. and H. Wallach, 1966, &ldquo;Adaptation to Displaced
Vision Contingent upon Vibrating Stimulation&rdquo;, <em>Psychonomic
Science</em>, 6: 465&ndash;466.</li>

<li>Kuhn, T.S., 2012 [1962], <em>The Structure of Scientific
Revolutions</em>, Chicago: University of Chicago Press.</li>

<li>Lhermitte, F., 1983, &ldquo;Utilization Behaviour and its Relation
to Lesions of the Frontal Lobes&rdquo;, <em>Brain</em>, 106(2):
237&ndash;255.</li>

<li>Locke, J., 1690, <em>An Essay Concerning Human Understanding</em>,
P. Nidditch (ed.), New York: Oxford University Press, 1979.</li>

<li>Loomis, J.M., 1992, &ldquo;Distal Attribution and
Presence&rdquo;, <em>Presence: Teleoperators and Virtual
Environments</em>, 1(1): 113&ndash;119.</li>

<li>Lotze, H., 1887 [1879], <em>Metaphysics, in Three Books: Ontology,
Cosmology, and Psychology</em> (Volume 2), B. Bosanquet (trans.),
Oxford: Clarendon.</li>

<li>Mach, E., 1897 [1886], <em>Contributions to the Analysis of the
Sensations</em>, C.M. Williams (trans.), Chicago: Open Court,
1897.</li>

<li>Mack, A., 1979, &ldquo;Non-Visual Determinants of
Perception&rdquo;, <em>Behavioral and Brain Sciences</em>, 2(1):
75&ndash;76.</li>

<li>MacKay, D.M., 1973, &ldquo;Visual Stability and Voluntary Eye
Movements&rdquo;, in <em>Central Processing of Visual Information A:
Integrative Functions and Comparative Data</em>, Berlin: Springer,
pp. 307&ndash;331.</li>

<li>Mandik, P., 2005, &ldquo;Action-Oriented Representation&rdquo;,
in <em>Cognition and the Brain: The Philosophy and Neuroscience
Movement</em>, K. Akins and A. Brook (eds.), Cambridge: Cambridge
University Press.</li>

<li>Mather, J. and J. Lackner, 1975, &ldquo;Adaptation to Visual
Rearrangement Elicited by Tonic Vibration
Reflexes&rdquo;, <em>Experimental Brain Research</em>, 24:
103&ndash;105.</li>

<li>Matthen, M., 1988, &ldquo;Biological Functions and Perceptual
Content&rdquo;, <em>Journal of Philosophy</em>, 85: 5&ndash;27.</li>

<li>Melamed, L., M. Halay, and J. Gildow, 1973, &ldquo;Effect of
External Target Presence on Visual Adaptation with Active and Passive
Movement&rdquo;, <em>Journal of Experimental Psychology</em>, 98:
125&ndash;130.</li>

<li>Merriam, E.P. and C. Colby, 2005, &ldquo;Active Vision in Parietal
and Extrastriate Cortex&rdquo;, <em>The Neuroscientist</em>, 11:
484&ndash;493.</li>

<li>Merriam, E.P., C.R. Genovese, and C.L. Colby, 2007,
&ldquo;Remapping in Human Visual Cortex&rdquo;, <em>Journal of
Neurophysiology</em>, 97(2): 1738&ndash;1755.</li>

<li>Mill, J.S., 1842, &ldquo;Bailey on Berkeley&rsquo;s Theory of
Vision&rdquo;, <em>Westminster Review</em>, 38: 318&ndash;336.</li>

<li>&ndash;&ndash;&ndash;, 1843, &ldquo;Rejoinder to
Mr. Bailey&rsquo;s Reply&rdquo;, <em>Westminster Review</em>, 39:
491&ndash;494.</li>

<li>Miller, J. and L. Festinger, 1977, &ldquo;Impact of Oculomotor
Retraining on the Visual Perception of Curvature&rdquo;, <em>Journal
of Experimental Psychology: Human Perception and Performance</em>,
3(2): 187&ndash;200.</li>

<li>Milner, A.D. and M.A. Goodale, 1995, <em>The Visual Brain in
Action</em>, Oxford: Oxford University Press, 2<sup>nd</sup> edition,
2006.</li>

<li>&ndash;&ndash;&ndash;, 2008, &ldquo;Two Visual Systems
Re-viewed&rdquo;, <em>Neuropsychologia</em>, 46: 774&ndash;785.</li>

<li>Mittelst&auml;dt, H., 1971, <em>Reafferenzprinzip&mdash;Apologie
und Kritik</em>, in <em>Vortr&auml;ge der Erlanger
Physiologentagung</em>, Berlin: Springer, pp. 161&ndash;171.</li>

<li>Mon-Williams, M., J.R. Tresilian, A. Plooy, J.P. Wann, and
J. Broerse, 1997, &ldquo;Looking at the Task in Hand: Vergence Eye
Movements and Perceived Size, &ldquo; <em>Experimental Brain
Research</em>, 117(3): 501&ndash;506.</li>

<li>Moulden, B., 1971, &ldquo;Adaptation to Displaced Vision:
Reafference is a Special Case of the Cue-Discrepancy
Hypothesis&rdquo;, <em>The Quarterly Journal of Experimental
Psychology</em>, 23: 113&ndash;117.</li>

<li>Nakamura, K. and C. Colby, 2002, &ldquo;Updating of the Visual
Representation in Monkey Striate and Extrastriate Cortex during
Saccades&rdquo;, <em>Proceedings of the National Academy of
Sciences</em>, 99(6): 4026&ndash;4031.</li>

<li>No&euml;, A., 2004, <em>Action in Perception</em>, Cambridge, MA:
MIT Press.</li>

<li>&ndash;&ndash;&ndash;, 2005, &ldquo;Real
Presence&rdquo;, <em>Philosophical Topics</em>, 33:
235&ndash;264.</li>

<li>&ndash;&ndash;&ndash;, 2009, <em>Out of our Heads</em>, New York:
Hill and Wang.</li>

<li>&ndash;&ndash;&ndash;, 2010, &ldquo;Vision without
Representation&rdquo;, in Gangopadhyay et al. 2010::
245&ndash;256.</li>

<li>O&rsquo;Regan, J.K., 2011, <em>Why Red Doesn&rsquo;t Sound Like a
Bell: Explaining the Feel of Consciousness</em>, Oxford: Oxford
University Press.</li>

<li>O&rsquo;Regan, J.K. and A. No&euml;, 2001, &ldquo;A Sensorimotor
Account of Vision and Visual Consciousness&rdquo;, <em>Behavioral and
Brain Sciences</em>, 24: 939&ndash;973.</li>

<li>Palmer, S.E., 1999, <em>Vision Science: Photons to
Phenomenology</em>, Cambridge, MA: MIT Press.</li>

<li>Poincar&eacute;, H., 1907, <em>La Science et
L'Hypoth&eacute;se</em>, Paris: Flammarion.</li>

<li>Post, R.B. and H.W. Leibowitz, 1985, &ldquo;A Revised Analysis of
the Role of Efference in Motion
Perception&rdquo;, <em>Perception</em>, 14(5): 631&ndash;643.</li>

<li>Pouget, A., S. Deneve, and J.-R., Duhamel, 2002, &ldquo;A
Computational Perspective on the Neural Basis of Multisensory Spatial
Representation&rdquo;, <em>Nature Reviews: Neuroscience</em>, 3:
741&ndash;747.</li>

<li>Price, H.H., 1950, <em>Perception</em>, London: Methuen,
2<sup>nd</sup> edition.</li>

<li>Prinz, J.J., 2006, &ldquo;Putting the Brakes on Enactive
Perception&rdquo;, <em>Psyche</em>, 12: 1&ndash;19.</li>

<li>&ndash;&ndash;&ndash;, 2009, &ldquo;Is Consciousness
Embodied?&rdquo; in <em>The Cambridge Handbook of Situated
Cognition</em>, P. Robbins and M. Aydede (eds.), Cambridge: Cambridge
University Press, pp. 419&ndash;436.</li>

<li>Purkyn&#283;, J., 1825, &ldquo;<em>&Uuml;ber die Scheinbewegungen,
welche im subjectiven Umfang des Gesichtsinnes
vorkommen</em>&rdquo;, <em>Bulletin der naturwessenschaftlichen
Sektion der Schlesischen Gesellschaft</em>, 4: 9&ndash;10.</li>

<li>Reid, T., 1785, <em>Essays on the Intellectual Powers of Man</em>,
Cambridge, MA: MIT Press, 1969.</li>

<li>Rizzolatti, G., 2008, <em>Mirrors in the Brain</em>, New York:
Oxford University Press.</li>

<li>Rock, I., 1966, <em>The Nature of Perceptual Adaptation</em>, New
York: Basic Books.</li>

<li>Rock, I. and C.S. Harris, 1967, &ldquo;Vision and
Touch&rdquo;, <em>Scientific American</em>, 216: 96&ndash;107.</li>

<li>Russell, B., 1918, &ldquo;The Philosophy of Logical
Atomism&rdquo;, in <em>Logic and Knowledge</em>, London: Allen and
Unwin, 1956, pp. 177&ndash;281.</li>

<li>Sampaio, E., S. Maris, and P. Bach-y-Rita, 2001, &ldquo;Brain
Plasticity: &lsquo;Visual&rsquo; Acuity of Blind Persons via the
Tongue&rdquo;, <em>Brain Research</em>, 908: 204&ndash;207.</li>

<li>Schwitzgebel, E., 2006, &ldquo;Do Things Look
Flat?&rdquo; <em>Philosophy &amp; Phenomenological Research</em>, 72:
589&ndash;599.</li>

<li>Shams, L. and R. Kim, 2010, &ldquo;Crossmodal Influences on Visual
Perception&rdquo;, <em>Physics of Life Reviews</em>, 7(3):
269&ndash;284.</li>

<li>Shebilske, W.L., 1984, &ldquo;Context Effects and Efferent Factors
in Perception and Cognition&rdquo;, in <em>Cognition and Motor
Processes</em>, W. Prinz and A.F. Sanders (eds.), Berlin:
Springer-Verlag, pp. 99&ndash;119.</li>

<li>&ndash;&ndash;&ndash;, 1987, &ldquo;An Ecological Efference
Mediation Theory of Natural Event Perception&rdquo;,
in <em>Perspectives on Perception and Actions</em>, H. Heuer and
A.F. Sanders (eds.), Hillsdale, NJ: Erlbaum, pp. 195&ndash;213.</li>

<li>Sherrington, C.S., 1918, &ldquo;Observations on the Sensual Role
of the Proprioceptive Nerve Supply of the Extrinsic Ocular
Muscles&rdquo;, <em>Brain</em>, 41: 332&ndash;343.</li>

<li>Siegle, J.H. and W.H. Warren, 2010, &ldquo;Distal Attribution and
Distance Perception in Sensory
Substitution&rdquo;, <em>Perception</em>, 39(2): 208&ndash;223.</li>

<li>Singer, G. and R. Day, 1966, &ldquo;Spatial Adaptation and
Aftereffect with Optically Transformed Vision: Effects of Active and
Passive Responding and the Relationship between Test and Exposure
Responses&rdquo;, <em>Journal of Experimental Psychology</em>, 71:
725&ndash;731.</li>

<li>Smith, A., 1811, <em>The Works of Adam Smith</em> (Volume 5),
D. Stewart. (ed.), London: T. Cadell and W. Davies.</li>

<li>Smith, A.D., 2000, &ldquo;Space and Sight&rdquo;, <em>Mind</em>,
109: 481&ndash;518.</li>

<li>Sperry, R.W., 1952, &ldquo;Neurology and the Mind-Brain
Problem&rdquo;, <em>American Scientist</em>, 291&ndash;312.</li>

<li>Stewart, D., 1829, <em>Elements of the Philosophy of the Human
Mind</em>, in <em>The Collected Works of Dugald Stewart</em> (Volume
2), W. Hamilton (ed.), Westmead, UK: Gregg International Publishers,
1971.</li>

<li>Stratton, G.M., 1896, &ldquo;Some Preliminary Experiments on
Vision without Inversion of the Retinal
Image&rdquo;, <em>Psychological Review</em>, 3: 611&ndash;617.</li>

<li>&ndash;&ndash;&ndash;, 1897(a and b), &ldquo;Vision Without
Inversion of the Retinal Image&rdquo;, <em>Psychological Review</em>,
4(4): 341&ndash;360 and 4(5)463&ndash;481.</li>

<li>&ndash;&ndash;&ndash;, 1899, &ldquo;The Spatial Harmony of Touch
and Sight&rdquo;, <em>Mind</em>, 8: 492&ndash;505.</li>

<li>&ndash;&ndash;&ndash;, 1907, &ldquo;Eye-Movements and Visual
Direction&rdquo;, <em>Psychological Bulletin</em>, 4:
155&ndash;158.</li>

<li>Taylor, J.G., 1962, <em>The Behavioral Basis of Perception</em>,
New Haven, CT: Yale University Press.</li>

<li>&ndash;&ndash;&ndash;, 1965, &ldquo;The Behavioral Basis of
Perceived Size and Distance&rdquo;, <em>Canadian Journal of
Psychology</em>, 19(1): 1&ndash;14.</li>

<li>&ndash;&ndash;&ndash;, 1968, &ldquo;Perception as a Function of
Behaviour&rdquo;, <em>Studies in Logic and the Foundations of
Mathematics</em>, 52: 431&ndash;436.</li>

<li>Templeton, W., I. Howard, and A. Lowman, 1966, &ldquo;Passively
Generated Adaptation to Prismatic Distortion&rdquo;, <em>Perceptual
and Motor Skills</em>, 22: 140&ndash;142.</li>

<li>Thompson, E., 2005, &ldquo;Sensorimotor Subjectivity and the
Enactive Approach to Experience&rdquo;, <em>Phenomenology and the
Cognitive Sciences</em>, 4(4): 407&ndash;427.</li>

<li>Uhlarik, J.J. and L.K. Canon, 1971, &ldquo;Influence of Concurrent
and Terminal Exposure Conditions on the Nature of Perceptual
Adaptation&rdquo;, <em>Journal of Experimental Psychology</em>, 91:
233&ndash;239.</li>

<li>Vishton, P.M., N.J. Stephens, L.A. Nelson, S.E. Morra,
K.L. Brunick, and J.A. Stevens, 2007, &ldquo;Planning to Reach for an
Object Changes How the Reacher Perceives It&rdquo;, <em>Psychological
Science</em>, 18: 713&ndash;719.</li>

<li>Wallach, H., 1968, &ldquo;Informational Discrepancy as a Basis of
Perceptual Adaptation&rdquo;, in <em>The Neuropsychology of Spatially
Oriented Behaviour</em>, S. Friedman (ed.), Homewood, IL: Dorsey,
pp. 209&ndash;230.</li>

<li>Welch, R., 1978, <em>Perceptual Modification: Adapting to Altered
Sensory Environments</em>, New York: Academic Press.</li>

<li>Wu, W., 2014, &ldquo;Against Division: Consciousness, Information
and the Visual Streams&rdquo;, <em>Mind &amp; Language</em>, 29(4):
383&ndash;406.</li>

</ul>

</div>

<div id="academic-tools">

<h2><a id="Aca">Academic Tools</a></h2>

<blockquote>
<table class="vert-top">
<tr>
<td><img src="../../symbols/sepman-icon.jpg" alt="sep man icon" /></td>
<td><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=action-perception" target="other">How to cite this entry</a>.</td>
</tr>

<tr>
<td><img src="../../symbols/sepman-icon.jpg" alt="sep man icon" /></td>
<td><a href="https://leibniz.stanford.edu/friends/preview/action-perception/" target="other">Preview the PDF version of this entry</a> at the
 <a href="https://leibniz.stanford.edu/friends/" target="other">Friends of the SEP Society</a>.</td>
</tr>

<tr>
<td><img src="../../symbols/inpho.png" alt="inpho icon" /></td>
<td><a href="https://www.inphoproject.org/entity?sep=action-perception&amp;redirect=True" target="other">Look up topics and thinkers related to this entry</a>
 at the Internet Philosophy Ontology Project (InPhO).</td>
</tr>

<tr>
<td><img src="../../symbols/pp.gif" alt="phil papers icon" /></td>
<td><a href="http://philpapers.org/sep/action-perception/" target="other">Enhanced bibliography for this entry</a>
at <a href="http://philpapers.org/" target="other">PhilPapers</a>, with links to its database.</td>
</tr>

</table>
</blockquote>

</div>



<div id="other-internet-resources">

<h2><a id="Oth">Other Internet Resources</a></h2>

<ul>

<li><a href="http://philpapers.org/browse/spatial-experience/" target="other">Spatial Experience</a>
  at Philpapers.org.</li>

</ul>

</div>

<div id="related-entries">

<h2><a id="Rel">Related Entries</a></h2>

<p>

 <a href="../bodily-awareness/index.html">bodily awareness</a> |
 <a href="../embodied-cognition/index.html">cognition: embodied</a> |
 <a href="../phenomenology/index.html">phenomenology</a>

</p>

</div>

<div id="acknowledgments">

<h3>Acknowledgments</h3>

<p>We would like to thank Jason Winning for helping to compose the
bibliography and proofreading. We are also grateful to Adrian Alsmith,
John Schwenkler, and an anonymous referee for comments that resulted
in many improvements.</p>

</div>

</div><!-- #aueditable --><!--DO NOT MODIFY THIS LINE AND BELOW-->

<!-- END ARTICLE HTML -->

</div> <!-- End article-content -->

  <div id="article-copyright">
    <p>
 <a href="../../info.html#c">Copyright &copy; 2015</a> by

<br />
Robert Briscoe
&lt;<a href="m&#97;ilto:rbriscoe&#37;40gmail&#37;2ecom"><em>rbriscoe<abbr title=" at ">&#64;</abbr>gmail<abbr title=" dot ">&#46;</abbr>com</em></a>&gt;<br />
<a href="http://rickgrush.net/" target="other">Rick Grush</a>
&lt;<a href="m&#97;ilto:rgrush&#37;40ucsd&#37;2eedu"><em>rgrush<abbr title=" at ">&#64;</abbr>ucsd<abbr title=" dot ">&#46;</abbr>edu</em></a>&gt;
    </p>
  </div>

</div> <!-- End article -->

<!-- NOTE: article banner is outside of the id="article" div. -->
<div id="article-banner" class="scroll-block">
  <div id="article-banner-content">
    <a href="../../fundraising/index.html">
    Open access to the SEP is made possible by a world-wide funding initiative.<br />
    The Encyclopedia Now Needs Your Support<br />
    Please Read How You Can Help Keep the Encyclopedia Free</a>
  </div>
</div> <!-- End article-banner -->

    </div> <!-- End content -->

    <div id="footer">

      <div id="footer-menu">
        <div class="menu-block">
          <h4><i class="icon-book"></i> Browse</h4>
          <ul role="menu">
            <li><a href="../../contents.html">Table of Contents</a></li>
            <li><a href="../../new.html">What's New</a></li>
            <li><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/random">Random Entry</a></li>
            <li><a href="../../published.html">Chronological</a></li>
            <li><a href="../../archives/index.html">Archives</a></li>
          </ul>
        </div>
        <div class="menu-block">
          <h4><i class="icon-info-sign"></i> About</h4>
          <ul role="menu">
            <li><a href="../../info.html">Editorial Information</a></li>
            <li><a href="../../about.html">About the SEP</a></li>
            <li><a href="../../board.html">Editorial Board</a></li>
            <li><a href="../../cite.html">How to Cite the SEP</a></li>
            <li><a href="../../special-characters.html">Special Characters</a></li>
            <li><a href="../../tools/index.html">Advanced Tools</a></li>
            <li><a href="../../contact.html">Contact</a></li>
          </ul>
        </div>
        <div class="menu-block">
          <h4><i class="icon-leaf"></i> Support SEP</h4>
          <ul role="menu">
            <li><a href="../../support/index.html">Support the SEP</a></li>
            <li><a href="../../support/friends.html">PDFs for SEP Friends</a></li>
            <li><a href="../../support/donate.html">Make a Donation</a></li>
            <li><a href="../../support/sepia.html">SEPIA for Libraries</a></li>
          </ul>
        </div>
      </div> <!-- End footer menu -->

      <div id="mirrors">
        <div id="mirror-info">
          <h4><i class="icon-globe"></i> Mirror Sites</h4>
          <p>View this site from another server:</p>
        </div>
        <div class="btn-group open">
          <a class="btn dropdown-toggle" data-toggle="dropdown" href="https://plato.stanford.edu/">
            <span class="flag flag-usa"></span> USA (Main Site) <span class="caret"></span>
            <span class="mirror-source">Philosophy, Stanford University</span>
          </a>
          <ul class="dropdown-menu">
            <li><a href="../../mirrors.html">Info about mirror sites</a></li>
          </ul>
        </div>
      </div> <!-- End mirrors -->
      
      <div id="site-credits">
        <p>The Stanford Encyclopedia of Philosophy is <a href="../../info.html#c">copyright &copy; 2021</a> by <a href="http://mally.stanford.edu/">The Metaphysics Research Lab</a>, Department of Philosophy, Stanford University</p>
        <p>Library of Congress Catalog Data: ISSN 1095-5054</p>
      </div> <!-- End site credits -->

    </div> <!-- End footer -->

  </div> <!-- End container -->

   <!-- NOTE: Script required for drop-down button to work (mirrors). -->
  <script>
    $('.dropdown-toggle').dropdown();
  </script>

</body>

<!-- Mirrored from seop.illc.uva.nl/entries/action-perception/ by HTTrack Website Copier/3.x [XR&CO'2014], Wed, 22 Jun 2022 19:36:19 GMT -->
</html>
