<!DOCTYPE html>
<!--[if lt IE 7]> <html class="ie6 ie"> <![endif]-->
<!--[if IE 7]>    <html class="ie7 ie"> <![endif]-->
<!--[if IE 8]>    <html class="ie8 ie"> <![endif]-->
<!--[if IE 9]>    <html class="ie9 ie"> <![endif]-->
<!--[if !IE]> --> <html> <!-- <![endif]-->

<!-- Mirrored from seop.illc.uva.nl/entries/decision-theory/ by HTTrack Website Copier/3.x [XR&CO'2014], Wed, 22 Jun 2022 19:44:07 GMT -->
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>
Decision Theory (Stanford Encyclopedia of Philosophy)
</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="robots" content="noarchive, noodp" />
<meta property="citation_title" content="Decision Theory" />
<meta property="citation_author" content="Steele, Katie" />
<meta property="citation_author" content="Stef&aacute;nsson, H. Orri" />
<meta property="citation_publication_date" content="2015/12/16" />
<meta name="DC.title" content="Decision Theory" />
<meta name="DC.creator" content="Steele, Katie" />
<meta name="DC.creator" content="Stef&aacute;nsson, H. Orri" />
<meta name="DCTERMS.issued" content="2015-12-16" />
<meta name="DCTERMS.modified" content="2020-10-09" />

<!-- NOTE: Import webfonts using this link: -->
<link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,300,600,200&amp;subset=latin,latin-ext" rel="stylesheet" type="text/css" />

<link rel="stylesheet" type="text/css" media="screen,handheld" href="../../css/bootstrap.min.css" />
<link rel="stylesheet" type="text/css" media="screen,handheld" href="../../css/bootstrap-responsive.min.css" />
<link rel="stylesheet" type="text/css" href="../../css/font-awesome.min.css" />
<!--[if IE 7]> <link rel="stylesheet" type="text/css" href="../../css/font-awesome-ie7.min.css"> <![endif]-->
<link rel="stylesheet" type="text/css" media="screen,handheld" href="../../css/style.css" />
<link rel="stylesheet" type="text/css" media="print" href="../../css/print.css" />
<link rel="stylesheet" type="text/css" href="../../css/entry.css" />
<!--[if IE]> <link rel="stylesheet" type="text/css" href="../../css/ie.css" /> <![endif]-->
<script type="text/javascript" src="../../js/jquery-1.9.1.min.js"></script>
<script type="text/javascript" src="../../js/bootstrap.min.js"></script>

<!-- NOTE: Javascript for sticky behavior needed on article and ToC pages -->
<script type="text/javascript" src="../../js/jquery-scrolltofixed-min.js"></script>
<script type="text/javascript" src="../../js/entry.js"></script>

<!-- SEP custom script -->
<script type="text/javascript" src="../../js/sep.js"></script>
</head>

<!-- NOTE: The nojs class is removed from the page if javascript is enabled. Otherwise, it drives the display when there is no javascript. -->
<body class="nojs article" id="pagetopright">
<div id="container">
<div id="header-wrapper">
  <div id="header">
    <div id="branding">
      <div id="site-logo"><a href="../../index.html"><img src="../../symbols/sep-man-red.png" alt="SEP logo" /></a></div>
      <div id="site-title"><a href="../../index.html">Stanford Encyclopedia of Philosophy</a></div>
    </div>
    <div id="navigation">
      <div class="navbar">
        <div class="navbar-inner">
          <div class="container">
            <button class="btn btn-navbar collapsed" data-target=".collapse-main-menu" data-toggle="collapse" type="button"> <i class="icon-reorder"></i> Menu </button>
            <div class="nav-collapse collapse-main-menu in collapse">
              <ul class="nav">
                <li class="dropdown open"><a id="drop1" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-book"></i> Browse</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop1">
                    <li><a href="../../contents.html">Table of Contents</a></li>
                    <li><a href="../../new.html">What's New</a></li>
                    <li><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/random">Random Entry</a></li>
                    <li><a href="../../published.html">Chronological</a></li>
                    <li><a href="../../archives/index.html">Archives</a></li>
                  </ul>
                </li>
                <li class="dropdown open"><a id="drop2" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-info-sign"></i> About</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop2">
                    <li><a href="../../info.html">Editorial Information</a></li>
                    <li><a href="../../about.html">About the SEP</a></li>
                    <li><a href="../../board.html">Editorial Board</a></li>
                    <li><a href="../../cite.html">How to Cite the SEP</a></li>
                    <li><a href="../../special-characters.html">Special Characters</a></li>
                    <li><a href="../../tools/index.html">Advanced Tools</a></li>
                    <li><a href="../../contact.html">Contact</a></li>
                  </ul>
                </li>
                <li class="dropdown open"><a id="drop3" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-leaf"></i> Support SEP</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop3">
                    <li><a href="../../support/index.html">Support the SEP</a></li>
                    <li><a href="../../support/friends.html">PDFs for SEP Friends</a></li>
                    <li><a href="../../support/donate.html">Make a Donation</a></li>
                    <li><a href="../../support/sepia.html">SEPIA for Libraries</a></li>
                  </ul>
                </li>
              </ul>
            </div>
          </div>
        </div>
      </div>
    </div>
    <!-- End navigation -->
    
    <div id="search">
      <form id="search-form" method="get" action="https://seop.illc.uva.nl/search/searcher.py">
        <input type="search" name="query" placeholder="Search SEP" />
        <div class="search-btn-wrapper"><button class="btn search-btn" type="submit"><i class="icon-search"></i></button></div>
      </form>
    </div>
    <!-- End search --> 
    
  </div>
  <!-- End header --> 
</div>
<!-- End header wrapper -->

<div id="content">

<!-- Begin article sidebar -->
<div id="article-sidebar" class="sticky">
  <div class="navbar">
    <div class="navbar-inner">
      <div class="container">
        <button class="btn btn-navbar" data-target=".collapse-sidebar" data-toggle="collapse" type="button"> <i class="icon-reorder"></i> Entry Navigation </button>
        <div id="article-nav" class="nav-collapse collapse-sidebar in collapse">
          <ul class="nav">
            <li><a href="#toc">Entry Contents</a></li>
            <li><a href="#Bib">Bibliography</a></li>
            <li><a href="#Aca">Academic Tools</a></li>
            <li><a href="https://leibniz.stanford.edu/friends/preview/decision-theory/">Friends PDF Preview <i class="icon-external-link"></i></a></li>
            <li><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=decision-theory">Author and Citation Info <i class="icon-external-link"></i></a> </li>
            <li><a href="#pagetopright" class="back-to-top">Back to Top <i class="icon-angle-up icon2x"></i></a></li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</div>
<!-- End article sidebar --> 

<!-- NOTE: Article content must have two wrapper divs: id="article" and id="article-content" -->
<div id="article">
<div id="article-content">

<!-- BEGIN ARTICLE HTML -->


<div id="aueditable"><!--DO NOT MODIFY THIS LINE AND ABOVE-->

<h1>Decision Theory</h1><div id="pubinfo"><em>First published Wed Dec 16, 2015; substantive revision Fri Oct 9, 2020</em></div>

<div id="preamble">

<p>
Decision theory is concerned with the reasoning underlying an
agent&rsquo;s choices, whether this is a mundane choice between taking
the bus or getting a taxi, or a more far-reaching choice about whether
to pursue a demanding political career. (Note that &ldquo;agent&rdquo;
here stands for an entity, usually an individual person, that is
capable of deliberation and action.) Standard thinking is that what an
agent chooses to do on any given occasion is completely determined by
her beliefs and desires or values, but this is not uncontroversial, as
will be noted below. In any case, decision theory is as much a theory
of beliefs, desires and other relevant attitudes as it is a theory of
choice; what matters is how these various attitudes (call them
&ldquo;preference attitudes&rdquo;) cohere together.</p>

<p>
The focus of this entry is normative decision theory. That is, the
main question of interest is what criteria an agent&rsquo;s preference
attitudes <em>should</em> satisfy in <em>any generic</em>
circumstances. This amounts to a minimal account of
<em>rationality</em>, one that sets aside more substantial questions
about appropriate desires and reasonable beliefs, given the situation
at hand. The key issue for a minimal account is the treatment of
uncertainty. The orthodox normative decision theory, <em>expected
utility (EU) theory</em>, essentially says that, in situations of
uncertainty, one should prefer the option with greatest
<em>expected</em> desirability or value. (Note that in this context,
&ldquo;desirability&rdquo; and &ldquo;value&rdquo; should be
understood as desirability/value <em>according to the agent in
question</em>.) This simple maxim will be the focus of much of our
discussion.</p>

<p>
The structure of this entry is as follows: Section 1 discusses the
basic notion of &ldquo;preferences over prospects&rdquo;, which lies
at the heart of decision theory. Section 2 describes the development
of normative decision theory in terms of ever more powerful and
flexible measures of preferences. Section 3 discusses the two
best-known versions of EU theory. Section 4 considers the broader
significance of EU theory for practical action, inference, and
valuing. Section 5 turns to prominent challenges to EU theory, while
Section 6 addresses sequential decisions, and how this richer setting
bears on debates about rational preferences.</p>
</div>

<div id="toc">
<!--Entry Contents-->

<ul>

 <li><a href="#WhaPreOvePro">1. What are <em>preferences</em> over <em>prospects</em>?</a></li>
 
 <li><a href="#UtiMeaPre">2. Utility measures of preference</a>
 
<ul>

 <li><a href="#OrdUti">2.1 Ordinal utilities</a></li>
 
 <li><a href="#CarUti">2.2 Cardinalizing utility</a></li>
 
 <li><a href="#VNMRepThe">2.3 The von Neumann and Morgenstern (vNM) representation theorem</a></li>
 </ul></li>

 <li><a href="#MakReaDec">3. Making real decisions</a>
 
<ul>

 <li><a href="#SavThe">3.1 Savage&rsquo;s theory</a></li>
 
 <li><a href="#JefThe">3.2 Jeffrey&rsquo;s theory</a></li>
 </ul></li>

 <li><a href="#BroSigEUThe">4. Broader significance of Expected Utility (EU) theory</a>
 
<ul>

 <li><a href="#RatBel">4.1 On rational belief</a></li>
 
 <li><a href="#RatDes">4.2 On rational desire</a></li>
 </ul></li>

 <li><a href="#ChaEUThe">5. Challenges to EU theory</a>
 
<ul>

 <li><a href="#SepRisRegAtt">5.1 On risk and regret attitudes</a></li>
 
 <li><a href="#ComVagBelDes">5.2 On completeness: Vague beliefs and desires</a></li>
 
 <li><a href="#UnAw">5.3 Unawareness</a></li>
 </ul></li>

 <li><a href="#SeqDec">6. Sequential decisions</a>
 
<ul>

 <li><a href="#WasUlyRat">6.1 Was Ulysses rational? </a></li>
 
 <li><a href="#EUAxiRev">6.2 The EU axioms revisited</a></li>
 </ul></li>

 <li><a href="#ConRem">7. Concluding remarks</a></li>
 
 <li><a href="#Bib">Bibliography</a></li>
 
 <li><a href="#Aca">Academic Tools</a></li>
 
 <li><a href="#Oth">Other Internet Resources</a></li>
 
 <li><a href="#Rel">Related Entries</a></li>
 </ul>
<!--Entry Contents-->

<hr />
</div>

<div id="main-text">

<h2><a id="WhaPreOvePro">1. What are <em>preferences</em> over <em>prospects</em>?</a></h2>

<p>
The two central concepts in decision theory are <em>preferences</em>
and <em>prospects</em> (or equivalently, <em>options</em>). Roughly
speaking, when we (in this entry) say that an agent
&ldquo;prefers&rdquo; the &ldquo;option&rdquo; \(A\) over \(B\) we
mean that the agent takes \(A\) to be more desirable or choice-worthy
than \(B\). This rough definition makes clear that preference is a
comparative attitude. Beyond this, there is room for argument about
what preferences over options actually amount to, or in other words,
what it is about an agent (perhaps oneself) that concerns us when we
talk about his/her preferences over options. This section considers
some elementary issues of interpretation that set the stage for
introducing (in the next section) the decision tables and expected
utility rule that for many is the familiar subject matter of decision
theory. Further interpretive questions regarding preferences and
prospects will be addressed later, as they arise.</p>

<p>
Let us nonetheless proceed by first introducing basic candidate
properties of (rational) preference over options and only afterwards
turning to questions of interpretation. As noted above, preference
concerns the comparison of options; it is a relation between options.
For a domain of options we speak of an agent&rsquo;s <em>preference
ordering</em>, this being the ordering of options that is generated by
the agent&rsquo;s preference between any two options in that
domain.</p>

<p>
In what follows, \(\preceq\) represents a <em>weak</em> preference
relation. So \(A\preceq B\) means that the agent we are interested in
considers option \(B\) to be at least as preferable as option \(A\).
From the weak preference relation we can define the <em>strict</em>
preference relation, \(\prec\), as follows: \(A\prec B\Leftrightarrow
A\preceq B \ \&amp; \ \neg (B\preceq A)\), where \(\neg X\) means
&ldquo;it is not the case that \(X\)&rdquo;. The indifference
relation, \(\sim\), is defined as: \(A\sim B \Leftrightarrow A\preceq
B \ \&amp; \ B\preceq A\). This represents that the agent we are
interested in considers \(A\) and \(B\) to be equally preferable.</p>

<p>
We say that \(\preceq\) <em>weakly orders</em> a set \(S\) of options
whenever it satisfies the following two conditions:</p>

<p class="indent" id="axiom1">
<strong>Axiom 1</strong> (Completeness)
<br />
For any \(A, B\in S\): either \(A\preceq B\) or \(B\preceq A\).</p>

<p class="indent" id="axiom2">
<strong>Axiom 2</strong> (Transitivity)
<br />
For any \(A, B, C\in S\): if \(A\preceq B\) and \(B\preceq C\) then
\(A\preceq C\).</p>

<p>
The above can be taken as a preliminary characterisation of rational
preference over options. Even this limited characterisation is
contentious, however, and points to divergent interpretations of
&ldquo;preferences over prospects/options&rdquo;.</p>

<p>
Start with the Completeness axiom, which says that an agent can
compare, in terms of the weak preference relation, all pairs of
options in \(S\). Whether or not Completeness is a plausible
rationality constraint depends both on what sort of options are under
consideration, and how we interpret preferences over these options. If
the option set includes all kinds of states of affairs, then
Completeness is not immediately compelling. For instance, it is
questionable whether an agent should be able to compare the option
whereby two additional people in the world are made literate with the
option whereby two additional people reach the age of sixty. If, on
the other hand, all options in the set are quite similar to each
other, say, all options are investment portfolios, then Completeness
is more compelling. But even if we do not restrict the kinds of
options under consideration, the question of whether or not
Completeness should be satisfied turns on the meaning of preference.
For instance, if preferences merely represent choice behaviour or
choice dispositions, as they do according to the &ldquo;revealed
preference theory&rdquo; popular amongst economists (see Sen 1973),
then Completeness is automatically satisfied, on the assumption that a
choice must inevitably be made. By contrast, if preferences are
understood rather as mental attitudes, typically considered judgments
about whether an option is better or more desirable than another, then
the doubts about Completeness alluded to above are pertinent (for
further discussion, see Mandler 2001).</p>

<p>
Most philosophers and decision theorists subscribe to the latter
interpretation of preference as a kind of judgment that explains, as
opposed to being identical with, choice dispositions and resultant
choice behaviour (see, e.g., Hausman 2011a, 2011b; Dietrich and List,
2016a &amp; 2016b; Bradley 2017; although see also Thoma 2020b and
Vredenburgh 2020 for recent defences of &ldquo;revealed preference
theory&rdquo;, at least in the context of empirical economics).
Moreover, many hold that Completeness is not rationally required,
since they think that rationality makes demands only on the judgments
an agent actually holds, but says nothing of whether a judgement must
be held in the first place. Nevertheless, following Richard Jeffrey
(1983), most decision theorists suggest that rationality requires that
preferences be <em>coherently extendible</em>. This means that even if
your preferences are not complete, it should be possible to complete
them without violating any of the conditions that are rationally
required, in particular Transitivity.</p>

<p>
This brings us to the
 <a href="#axiom2">Transitivity axiom</a>,
 which says that if an option \(B\) is weakly preferred to \(A\), and
\(C\) weakly preferred to \(B\), then \(C\) is weakly preferred to
\(A\). A recent challenge to Transitivity turns on heterogeneous sets
of options, as per the discussion of Completeness above. But here a
different interpretation of preference is brought to bear on the
comparison of options. The idea is that preferences, or judgments of
desirability, may be responsive to a salience condition. For example,
suppose that the most salient feature when comparing cars \(A\) and
\(B\) is how fast they can be driven, and \(B\) is no worse than \(A\)
in this regard, yet the most salient feature when comparing cars \(B\)
and \(C\) is how safe they are, and that \(C\) is no worse than \(B\)
in this regard. Furthermore, when comparing \(A\) and \(C\), the most
salient feature is their beauty. In such a case, some argue (e.g.,
Temkin 2012) that there is no reason why Transitivity should be
satisfied with respect to the preferences concerning \(A\), \(B\) and
\(C\). Others (e.g., Broome 1991a) argue that Transitivity is part of
the very meaning of the betterness relation (or objective comparative
desirability); if rational preference is a judgment of betterness or
desirability, then Transitivity is non-negotiable. With respect to the
car example, Broome would argue that the desirability of a fully
specified option should not vary, simply in virtue of what other
options it is compared with. Either the choice context affects how the
agent perceives the option at hand, in which case the description of
the option should reflect this, or else the choice context does not
affect the option. Either way, Transitivity should be satisfied.</p>

<p>
There is a more straightforward defence of Transitivity in preference;
a defence that hinges on the sure losses that may befall anyone who
violates the axiom. This is the so-called <em>money pump</em> argument
(see Davidson et. al. 1955 for an early argument of this sort, but for
recent discussion and revision of this argument, see Gustafsson 2010
&amp; 2013). It is based on the assumption that if you find \(X\) at
least as desirable as \(Y\), then you should be happy to trade the
latter for the former. Suppose you violate Transitivity; for you:
\(A\preceq B\), \(B\preceq C\) but \(C\prec A\). Moreover, suppose you
presently have \(A\). Then you should be willing to trade \(A\) for
\(B\). The same goes for \(B\) and \(C\): you should be willing to
trade \(B\) for \(C\). You strictly prefer \(A\) to \(C\), so you
should be willing to trade in \(C\) plus some sum \(\$x\) for \(A\).
But now you are in the same situation as you started, having \(A\) and
neither \(B\) nor \(C\), except that you have lost \(\$x\)! So in a
few steps, each of which was consistent with your preferences, you
find yourself in a situation that is clearly worse, by your own
lights, than your original situation. The picture is made more
dramatic if we imagine that the process could be repeated, turning you
into a &ldquo;money pump&rdquo;. Hence, the argument goes, there is
something (instrumentally) irrational about your intransitive
preferences. If your preferences were transitive, then you would not
be vulnerable to choosing a dominated option and serving as a money
pump. Therefore, your preferences should be transitive.</p>

<p>
While the aforementioned controversies have not been settled, the
following assumptions will be made in the remainder of this entry: i)
the objects of preference may be heterogeneous prospects,
incorporating a rich and varied domain of properties, ii) preference
between options is a judgment of comparative desirability or
choice-worthiness, and iii) preferences satisfy both Completeness and
Transitivity (although the former condition will be revisited in
 <a href="#ChaEUThe">Section 5</a>).
 The question that now arises is whether there are further general
constraints on rational preference over options.</p>

<h2><a id="UtiMeaPre">2. Utility measures of preference</a></h2>

<p>
In our continuing investigation of rational preferences over
prospects, the numerical <em>representation</em> (or
<em>measurement</em>) of preference orderings will become important.
The numerical measures in question are known as <em>utility
functions</em>. The two main types of utility function that will play
a role are the <em>ordinal</em> utility function and the more
information-rich <em>interval-valued</em> (or <em>cardinal</em>)
utility function.</p>

<h3><a id="OrdUti">2.1 Ordinal utilities</a></h3>

<p>
It turns out that as long as the set of prospects/options, \(S\), is
finite, any weak order of the options in \(S\) can be represented by
an ordinal utility function. To be precise, let us say that \(u\) is a
<em>utility function</em> with domain \(S\). We say that the function
\(u\) <em>represents</em> the preference \(\preceq\) between the
options in \(S\) just in case:</p> 

\[\tag{1}\text{For any}\ A, B \in S: u(A)\leq u(B) \Leftrightarrow A\preceq B\]

<p>
Another way to put this is that, when the above holds, the preference
relation can be represented as <em>maximising utility</em>, since it
always favours option with higher utility.</p>

<p>
The only information contained in an ordinal utility representation is
how the agent whose preferences are being represented orders options,
from least to most preferable. This means that if \(u\) is an ordinal
utility function that represents the ordering \(\preceq\), then any
utility function \(u'\) that is an ordinal transformation of
\(u\)&mdash;that is, any transformation of \(u\) that also satisfies
the biconditional in (1)&mdash;represents \(\preceq\) just as well as
\(u\) does. Hence, we say that an ordinal utility function is
<em>unique only up to ordinal transformations</em>.</p>

<p>
The result referred to above can be summarised as follows:</p>

<p class="indent" id="theorem1">
<strong>Theorem 1</strong> (Ordinal representation). Let \(S\) be a
finite set, and \(\preceq\) a weak preference relation on \(S\). Then
there is an ordinal utility function that represents \(\preceq\) just
in case \(\preceq\) is complete and transitive.</p>

<p>
This theorem should not be too surprising. If \(\preceq\) is complete
and transitive over \(S\), then the options in \(S\) can be put in an
order, from the most to the least preferred, where some options may
fall in the same position (if they are deemed equally desirable) but
where there are no cycles, loops, or gaps.
 <a href="#theorem1">Theorem 1</a>
 just says that we can assign numbers to the options in \(S\) in a way
that represents this order. (For a simple proof of Theorem 1, except
for a strict rather than a weak preference relation, consult Peterson
2009: 95.)</p>

<p>
Note that ordinal utilities are not very mathematically
&ldquo;powerful&rdquo;, so to speak. It does not make sense, for
instance, to compare the probabilistic expectations of different sets
of ordinal utilities. For example, consider the following two pairs of
prospects: the elements of the first pair are assigned ordinal
utilities of 2 and 4, while those in the second pair are assigned
ordinal utilities of 0 and 5. Let us specify a &ldquo;flat&rdquo;
probability distribution in each case, such that each element in the
two pairs corresponds to a probability of 0.5. Relative to this
probability assignment, the expectation of the first pair of ordinal
utilities is 3, which is larger than 2.5, the expectation of the
second pair. Yet when we transform the ordinal utilities in a
permissible way&mdash;for instance by increasing the highest utility
in the second pair from 5 to 10&mdash;the ordering of expectations
reverses; now the comparison is between 3 and 5. The significance of
this point will become clearer in what follows, when we turn to the
comparative evaluation of lotteries and risky choices. An
interval-valued or cardinal utility function is necessary for
evaluating lotteries/risky prospects in a consistent way. By the same
token, in order to construct or conceptualise a cardinal utility
function, one typically appeals to preferences over lotteries.
(Although see Alt 1936 for a &ldquo;risk-free&rdquo; construction of
cardinal utility, that is, one that does not appeal to lotteries.)</p>

<h3><a id="CarUti">2.2 Cardinalizing utility</a></h3>

<p>
In order to get a cardinal (interval-valued) utility representation of
a preference ordering&mdash;i.e., a measure that represents not only
how an agent orders the options but also says something about the
desirabilistic &ldquo;distance&rdquo; between options&mdash;we need a
richer setting; the option set and the corresponding preference
ordering will need to have more structure than for an ordinal utility
measure. One such account, owing to John von Neumann and Oskar
Morgenstern (1944), will be cashed out in detail below. For now, it is
useful to focus on the kind of option that is key to understanding and
constructing a cardinal utility function:
 lotteries.<sup>[<a href="notes.html#note-1" id="ref-1">1</a>]</sup></p>
 
<p>
Consider first an ordering over three regular options, e.g., the three
holiday destinations Amsterdam, Bangkok and Cardiff, denoted \(A\),
\(B\) and \(C\) respectively. Suppose your preference ordering is
\(A\prec B \prec C\). This information suffices to ordinally represent
your judgement; recall that any assignment of utilities is then
acceptable as long as \(C\) gets a higher value than \(B\) which gets
a higher value than \(A\). But perhaps we want to know more than can
be inferred from such a utility function&mdash;we want to know how
much \(C\) is preferred over \(B\), compared to how much \(B\) is
preferred over \(A\). For instance, it may be that Bangkok is
considered almost as desirable as Cardiff, but Amsterdam is a long way
behind Bangkok, relatively speaking. Or else perhaps Bangkok is only
marginally better than Amsterdam, compared to the extent to which
Cardiff is better than Bangkok. This kind of information about the
relative distance between options, in terms of strength of preference
or desirability, is precisely what is given by an interval-valued
utility function. The problem is how to ascertain this
information.</p>

<p>
To solve this problem, Ramsey (1926) and later von Neumann and
Morgenstern (hereafter vNM) made the following suggestion: we
construct a new option, a <em>lottery</em>, \(L\), that has \(A\) and
\(C\) as its possible &ldquo;prizes&rdquo;, and we figure out what
chance the lottery must confer on \(C\) for you to be indifferent
between this lottery and a holiday in Bangkok. The basic idea is that
your judgment about Bangkok, relative to Cardiff on the one hand and
Amsterdam on the other, can be measured by the riskiness of the
lottery \(L\) involving Cardiff and Amsterdam that you deem equally
desirable as Bangkok. For instance, if you are indifferent between
Bangkok and a lottery that provides a very low chance of winning a
trip to Cardiff, then you evidently do not regard Bangkok to be much
better than Amsterdam, vis-&agrave;-vis Cardiff; for you, even a small
improvement on Amsterdam, i.e., a lottery with a small chance of
Cardiff rather than Amsterdam, is enough to match Bangkok.</p>

<p>
The above analysis presumes that lotteries are evaluated in terms of
their <em>expected</em> choice-worthiness or desirability. That is,
the desirability of a lottery is effectively the sum of the chances of
each prize multiplied by the desirability of that prize. Consider the
following example: Suppose you are indifferent between the lottery and
the holiday in Bangkok when the chance of the lottery resulting in a
holiday in Cardiff is \(3/4\). Call this particular lottery \(L'\).
The idea is that Bangkok is therefore three quarters of the way up a
desirability scale that has Amsterdam at the bottom and Cardiff at the
top. If we stipulate that \(u(A)=0\) and \(u(C)=1\), then
\(u(B)=u(L')=3/4\). This corresponds to the <em>expected</em>
desirability&mdash;or, as it is usually called, the <em>expected
utility</em>&mdash;of the lottery, since \(1/4\cdot 0 + 3/4\cdot 1 =
3/4 = u(L')\). That is, the desirability of the lottery is a
probability weighted sum of the utilities of its prizes, where the
weight on each prize is determined by the probability that the lottery
results in that prize.</p>

<p>
We thus see that an interval-valued utility measure over options can
be constructed by introducing lottery options. As the name suggests,
the interval-valued utility measure conveys information about the
relative sizes of the intervals between the options according to some
desirability scale. That is, the utilities are unique after we have
fixed the starting point of our measurement and the unit scale of
desirability. In the above example, we could have, for instance,
assigned a utility value of 1 to \(A\) and 5 to \(C\), in which case
we would have had to assign a utility value of 4 to \(B\), since 4 is
3/4 of the way between 1 and 5. In other words, once we have assigned
utility values to \(A\) and \(C\), the utility of \(L'\) and thus
\(B\) has been determined. Let us call this second utility function
\(u'\). It is related to our original function as follows: \(u'=4\cdot
u +1\). This relationship always holds between two such functions: If
\(u\) is an interval-valued utility function that represents a
preference ordering, \(\preceq\), and \(u'\) is another utility
function that also represents this same preference ordering, then
there are constants \(a\) and \(b\), where \(a\) must be positive,
such that \(u'=a\cdot u + b\). This is to say that interval-valued
utility functions are <em>unique only up to positive linear
transformation</em>.</p>

<p>
Before concluding this discussion of measuring utility, two related
limitations regarding the information such measures convey should be
mentioned. First, since the utilities of options, whether ordinal or
interval-valued, can only be determined <em>relative</em> to the
utilities of other options, there is no such thing as the
<em>absolute</em> utility of an option, at least not without further
 assumptions.<sup>[<a href="notes.html#note-2" id="ref-2">2</a>]</sup>
 Second, by the same reasoning, neither interval-valued nor ordinal
utility measures, as discussed here, are <em>interpersonally
commensurable</em> with respect to levels and units of utility. By way
of a quick illustration, suppose that both you and I have the
preference ordering described above over the holiday options: \(A\prec
B \prec C\). Suppose too that, as per the above, we are both
indifferent between \(B\) and the lottery \(L'\) that has a \(3/4\)
chance of yielding \(C\) and a \(1/4\) chance of yielding \(A\). Can
we then say that granting me Cardiff and you Bangkok would amount to
the same amount of &ldquo;total desirability&rdquo; as granting you
Cardiff and me Bangkok? We are not entitled to say this. Our shared
preference ordering is, for instance, consistent with me finding a
vacation in Cardiff a dream come true while you just find it the best
of a bad lot. Moreover, we are not even entitled to say that the
difference in desirability between Bangkok and Amsterdam is the same
for you as it is for me. According to me, the desirability of the
three options might range from living hell to a dream come true, while
according to you, from bad to quite bad; both evaluations are
consistent with the above preference ordering. In fact, the same might
hold for our preferences over <em>all</em> possible options, including
lotteries: even if we shared the same total preference ordering, it
might be the case that you are just of a negative
disposition&mdash;finding no option that great&mdash;while I am very
extreme&mdash;finding some options excellent but others a sheer
torture. Hence, utility functions, whether interval-valued or ordinal,
do not allow for meaningful interpersonal comparisons. (Elster and
Roemer 1993 contains a number of papers discussing these issues; see
also the entry on
 <a href="../social-choice/index.html">social choice theory</a>.)</p>
 
<h3><a id="VNMRepThe">2.3 The von Neumann and Morgenstern (vNM) representation theorem</a></h3>

<p>
The last section provided an interval-valued utility representation of
a person&rsquo;s preferences over lotteries, on the assumption that
lotteries are evaluated in terms of expected utility. Some might find
this a bit quick. Why should we assume that people evaluate lotteries
in terms of their expected utilities? The vNM theorem effectively
shores up the gaps in reasoning by shifting attention back to the
preference relation. In addition to Transitivity and Completeness, vNM
introduce further principles governing rational preferences over
lotteries, and show that an agent&rsquo;s preferences can be
represented as maximising expected utility whenever her preferences
satisfy these principles.</p>

<p>
Let us first define, in formal terms, the expected utility of a
lottery: Let \(L_i\) be a lottery from the set \(\bL\) of lotteries,
and \(O_{ik}\) the outcome, or prize, of lottery \(L_i\) that arises
with probability \(p_{ik}\). The expected utility of \(L_i\) is then
defined as:</p>

<div class="indent">

<p id="vnmequation">
<strong>The vNM equation.</strong></p> 

\[EU(L_i) \mathbin{\dot{=}} \sum_k u(O_{ik}) \cdot p_{ik}\]

</div>

<p>
The assumption made earlier can now be formally stated:</p>
\begin{equation}\tag{2} \text{For any}\ L_i, L_j\in \bL: L_i\preceq
L_j\Leftrightarrow EU(L_i)\leq EU(L_j) \end{equation}

<p>
When the above holds, we say that there is an expected utility
function that represents the agent&rsquo;s preferences; in other
words, the agent can be represented as <em>maximising expected
utility</em>.</p>

<p>
The question that vNM address is: What sort of preferences can be thus
represented? To answer this question, we must return to the underlying
preference relation \(\preceq\) over the set of options, in this case
involving lotteries. The vNM theorem requires the set \(\bL\) of
lotteries to be rather extensive: it is closed under
&ldquo;probability mixture&rdquo;, that is, if \(L_i, L_j\in \bL\),
then compound lotteries that have \(L_i\) and \(L_j\) as possible
prizes are also in \(\bL\). (Another technical assumption, that will
not be discussed in detail, is that compound lotteries can always be
reduced, in accordance with the laws of probability, to simple
lotteries that only involve basic prizes.)</p>

<p>
A basic rationality constraint on the preference relation has already
been discussed&mdash;that it weakly orders the options (i.e.,
satisfies Transitivity and Completeness). The following notation will
be used to introduce the two additional vNM axioms of preference:
\(\{pA, (1-p)B\}\) denotes a lottery that results either in \(A\),
with probability \(p\), or \(B\), with probability \(1-p\), where
\(A\) and \(B\) can be final outcomes but can also be lotteries.</p>

<div class="indent">

<p id="axiom3">
<strong>Axiom 3</strong> (Continuity)
<br />
Suppose \(A\preceq B\preceq C\). Then there is a \(p\in [0,1]\) such
that:</p> 

  \[\{pA, (1-p)C\}\sim B\]

<p id="axiom4">
<strong>Axiom 4</strong> (Independence)
<br />
Suppose \(A\preceq B\). Then for any \(C\), and any \(p\in
[0,1]\):</p> 

\[\{pA, (1-p)C\}\preceq \{pB, (1-p)C\}\]

</div>

<p>
Continuity implies that no outcome \(A\) is so bad that you would not
be willing to take some gamble that might result in you ending up with
that outcome, but might otherwise result in you ending up with an
outcome (\(C\)) that you find to be a marginal improvement on your
status quo (\(B\)), provided that the chance of \(A\) is small enough.
Intuitively, Continuity guarantees that an agent&rsquo;s evaluations
of lotteries are appropriately sensitive to the probabilities of the
lotteries&rsquo; prizes.</p>

<p>
Independence implies that when two alternatives have the same
probability for some particular outcome, our evaluation of the two
alternatives should be independent of our opinion of that outcome.
Intuitively, this means that preferences between lotteries should be
governed only by the features of the lotteries that differ; the
commonalities between the lotteries should be effectively ignored.
</p>

<p>
Some people find the
 <a href="#axiom3">Continuity axiom</a>
 an unreasonable constraint on rational preference. Is there any
probability \(p\) such that you would be willing to accept a gamble
that has that probability of you losing your life and probability
\((1-p)\) of you gaining $10? Many people think there is not. However,
the very same people would presumably cross the street to pick up a
$10 bill they had dropped. But that is just taking a gamble that has a
very small probability of being killed by a car but a much higher
probability of gaining $10! More generally, although people rarely
think of it this way, they constantly take gambles that have minuscule
chances of leading to imminent death, and correspondingly very high
chances of some modest reward.</p>

<p>
Independence seems a compelling requirement of rationality, when
considered in the abstract. Nevertheless, there are famous examples
where people often violate Independence without seeming irrational.
These examples involve <em>complementarities</em> between the possible
lottery outcomes. A particularly well-known such example is the
so-called <em>Allais Paradox</em>, which the French economist Maurice
Allais (1953) first introduced in the early 1950s. The paradox turns
on comparing people&rsquo;s preferences over two pairs of lotteries
similar to those given in Table 1. The lotteries are described in
terms of the prizes that are associated with particular numbered
tickets, where one ticket will be drawn randomly (for instance,
\(L_1\) results in a prize of $2500 if one of the tickets numbered
2&ndash;34 is drawn).</p>

<div class="figure avoid-break">

<table class="cellpad-med-dense two-rules nocaption">
<tr>
  <td>&nbsp;</td>
  <td>1</td>
  <td>2&ndash;34</td>
  <td>35&ndash;100</td> </tr>
<tr>
  <td>\(L_1\)</td>
  <td>$0</td>
  <td>$2500</td>
  <td>$2400</td> </tr>
<tr>
  <td>\(L_2\)</td>
  <td>$2400</td>
  <td>$2400</td>
  <td>$2400</td> </tr>
</table>

<table class="cellpad-med-dense two-rules">
<tr>
  <td>&nbsp;</td>
  <td>1</td>
  <td>2&ndash;34</td>
  <td>35&ndash;100</td> </tr>
<tr>
  <td>\(L_3\)</td>
  <td>$0</td>
  <td>$2500</td>
  <td>$0</td> </tr>
<tr>
  <td>\(L_4\)</td>
  <td>$2400</td>
  <td>$2400</td>
  <td>$0</td> </tr>
</table>

<p class="center">
<span class="figlabel">Table 1.</span> Allais&rsquo; paradox</p>
</div>

<p>
In this situation, many people strictly prefer \(L_2\) over \(L_1\)
but also \(L_3\) over \(L_4\) (as evidenced by their choice behaviour,
as well as their testimony), a pair of preferences which will be
referred to as <em>Allais&rsquo;
 preferences</em>.<sup>[<a href="notes.html#note-3" id="ref-3">3</a>]</sup>
 A common way to rationalise Allais&rsquo; preferences, is that in the
first choice situation, the risk of ending up with nothing when one
could have had $2400 for sure does not justify the increased chance of
a higher prize. In the second choice situation, however, the minimum
one stands to gain is $0 no matter which choice one makes. Therefore,
in that case many people do think that the slight extra risk of $0 is
worth the chance of a better prize.</p>

<p>
While the above reasoning may seem compelling, Allais&rsquo;
preferences conflict with the
 <a href="#axiom4">Independence axiom</a>.
 The following is true of both choice situations: whatever choice you
make, you will get the same prize if one of the tickets in the last
column is drawn. Therefore, Independence implies that both your
preference between \(L_1\) and \(L_2\) and your preference between
\(L_3\) and \(L_4\) should be independent of the prizes in that
column. But when you ignore the last column, \(L_1\) becomes identical
to \(L_3\) and \(L_2\) to \(L_4\). Hence, if you prefer \(L_2\) over
\(L_1\) but \(L_3\) over \(L_4\), there seems to be an inconsistency
in your preference ordering. And there is definitely a violation of
Independence (given how the options have been described; an issue to
which we return in
 <a href="#SepRisRegAtt">Section 5.1</a>).
 As a result, the pair of preferences under discussion cannot be
represented as maximising expected utility. (Thus the
&ldquo;paradox&rdquo;: many people think that Independence is a
requirement of rationality, but nevertheless also want to claim that
there is nothing irrational about Allais&rsquo; preferences.)</p>

<p>
Decision theorists have reacted in different ways to Allais&rsquo;
Paradox. This issue will be revisited in
 <a href="#SepRisRegAtt">Section 5.1</a>,
 when challenges to EU theory will be discussed. The present goal is
simply to show that Continuity and Independence are compelling
constraints on rational preference, although not without their
detractors. The result vNM proved can be summarised thus:</p>

<p class="indent" id="theorem2">
<strong>Theorem 2</strong> (von Neumann-Morgenstern)
<br />
Let \(\bO\) be a finite set of outcomes, \(\bL\) a set of
corresponding lotteries that is closed under probability mixture and
\(\preceq\) a weak preference relation on \(\bL\). Then \(\preceq\)
satisfies axioms 1&ndash;4 if and only if there exists a function
\(u\), from \(\bO\) into the set of real numbers, that is unique up to
positive linear transformation, and relative to which \(\preceq\) can
be represented as maximising expected utility.</p>

<p>
David Kreps (1988) gives an accessible illustration of the proof of
this theorem.</p>

<h2><a id="MakReaDec">3. Making real decisions</a></h2>

<p>
The vNM theorem is a very important result for measuring the strength
of a rational agent&rsquo;s preferences over sure options (the
lotteries effectively facilitate a cardinal measure over sure
options). But this does not get us all the way to making rational
decisions in the real world; we do not yet really have a decision
theory. The theorem is limited to evaluating options that come with a
probability distribution over outcomes&mdash;a situation decision
theorists and economists often describe as &ldquo;choice under
risk&rdquo; (Knight 1921).</p>

<p>
In most ordinary choice situations, the objects of choice, over which
we must have or form preferences, are not like this. Rather,
decision-makers must consult <em>their own</em> probabilistic beliefs
about whether one outcome or another will result from a specified
option. Decisions in such circumstances are often described as
&ldquo;choices under uncertainty&rdquo; (Knight 1921). For example,
consider the predicament of a mountaineer deciding whether or not to
attempt a dangerous summit ascent, where the key factor for her is the
weather. If she is lucky, she may have access to comprehensive weather
statistics for the region. Nevertheless, the weather statistics differ
from the lottery set-up in that they do not <em>determine</em> the
probabilities of the possible outcomes of attempting versus not
attempting the summit on a particular day. Not least, the mountaineer
must consider how confident she is in the data-collection procedure,
whether the statistics are applicable to the day in question, and so
on, when assessing her options in light of the weather.</p>

<p>
Some of the most celebrated results in decision theory address, to
some extent, these challenges. They consist in showing what conditions
on preferences over &ldquo;real world options&rdquo; suffice for the
existence of a pair of utility <em>and</em> probability functions
relative to which the agent can be represented as maximising expected
utility. The standard interpretation is that, just as the utility
function represents the agent&rsquo;s desires, so the probability
function represents her beliefs. The theories are referred to
collectively as <em>subjective expected utility (SEU) theory</em> as
they concern an agent&rsquo;s preferences over prospects that are
characterised entirely in terms of her own beliefs and desires (but we
will continue to use the simpler label <em>EU theory</em>). In this
section, two of these results will be briefly discussed: that of
Leonard Savage (1954) and Richard Jeffrey (1965).</p>

<p>
Note that these EU decision theories apparently prescribe two things:
(a) you should have consistent preference attitudes, and (b) you
should prefer the means to your ends, or at least you should prefer
the means that you assess will <em>on average</em> lead to your ends
(cf. Buchak 2016). The question arises: What is the relationship
between these prescriptions? The <em>EU representation theorems</em>
that will be outlined shortly seem to show that, despite appearances,
the two prescriptions are actually just one: anyone who has consistent
attitudes prefers the means to her ends, and vice versa. But the
puzzle remains that there are many ways to have consistent preference
attitudes, and surely not all of these amount to preferring the means
to one&rsquo;s <em>own true</em> ends. This puzzle is worth bearing in
mind when appraising EU theory in its various guises; it will come up
again later.</p>

<h3><a id="SavThe">3.1 Savage&rsquo;s theory</a></h3>

<p>
Leonard Savage&rsquo;s decision theory, as presented in his (1954)
<em>The Foundations of Statistics</em>, is without a doubt the
best-known normative theory of choice under uncertainty, in particular
within economics and the decision sciences. In the book Savage
presents a set of axioms constraining preferences over a set of
options that guarantee the existence of a pair of probability and
utility functions relative to which the preferences can be represented
as maximising expected utility. Nearly three decades prior to the
publication of the book, Frank P. Ramsey (1926) had actually proposed
that a different set of axioms can generate more or less the same
result. Nevertheless, Savage&rsquo;s theory has been much more
influential than Ramsey&rsquo;s, perhaps because Ramsey neither gave a
full proof of his result nor provided much detail of how it would go
(Bradley 2004). Savage&rsquo;s result will not be described here in
full detail. However, the ingredients and structure of his theorem
will be laid out, highlighting its strengths and weaknesses.</p>

<p>
The options or prospects in Savage&rsquo;s theory are similar to
lotteries, except that the possible outcomes do not come with
probabilities but rather depend on whether a particular state of the
world is actual. Indeed, the primitives in Savage&rsquo;s theory are
 <em>outcomes</em><sup>[<a href="notes.html#note-4" id="ref-4">4</a>]</sup>
 and <em>states (of the world)</em>. The former are the good or bad
states of affairs that ultimately affect and matter to an agent, while
the latter are the features of the world that the agent has no control
over and which are the locus of her uncertainty about the world. Sets
of states are called <em>events</em>. This distinction between
outcomes and states serves to neatly separate desire and belief: the
former are, according to Savage&rsquo;s theory, the target of desire,
while the latter are the target of belief.</p>

<p>
The lottery-like options over which the agent has preferences are a
rich set of <em>acts</em> that effectively amount to all the possible
assignments of outcomes to states of the world. That is, acts are
functions from the state space to the outcome space, and the
agent&rsquo;s preference ordering is taken to be defined over all such
possible functions. Some of these acts will look quite sensible:
consider the act that assigns to the event &ldquo;it rains&rdquo; the
outcome &ldquo;miserable wet stroll&rdquo; and assigns to the event
&ldquo;it does not rain&rdquo; the outcome &ldquo;very comfortable
stroll&rdquo;. This is apparently the act of going for a stroll
without one&rsquo;s umbrella. Other Savage acts will not look quite so
sensible, such as the <em>constant act</em> that assigns to both
&ldquo;it rains&rdquo; and &ldquo;it does not rain&rdquo; the same
outcome &ldquo;miserable wet stroll&rdquo;. (Note that the constant
acts provide a way of including sure outcomes within the preference
ordering.) The problem with this act (and many others) is that it does
not correspond to anything that an agent could even in principle
choose to do or
 perform.<sup>[<a href="notes.html#note-5" id="ref-5">5</a>]</sup></p>
 
<p>
Savage&rsquo;s act/state(event)/outcome distinction can be naturally
represented in tabular form, with rows serving as acts that yield a
given outcome for each state/event column. Table 2 depicts the two
acts mentioned above plus a third one that the decision maker might
care about: the acts i) &ldquo;go for stroll without umbrella&rdquo;,
ii) &ldquo;go for stroll with umbrella&rdquo;, and iii) the bizarre
constant act. Of course, the set of acts required for Savage&rsquo;s
theorem involve even more acts that account for all the possible
combinations of states and outcomes.</p>

<div class="figure avoid-break">

<table class="cellpad-med-dense two-rules smaller">
<tr>
  <td>&nbsp;</td>
  <td>no rain</td>
  <td>rain</td> </tr>
<tr>
  <td>stroll without umbrella</td>
  <td>very comfortable stroll</td>
  <td>miserable wet stroll</td> </tr>
<tr>
  <td>stroll with umbrella</td>
  <td>comfortable stroll</td>
  <td>comfortable stroll</td> </tr>
<tr>
  <td>constant act</td>
  <td>miserable wet stroll</td>
  <td>miserable wet stroll</td> </tr>
</table>

<p class="center">
<span class="figlabel">Table 2.</span> Savage-style decision table</p>
</div>

<p>
Before discussing Savage&rsquo;s axioms, let us state the result that
they give rise to. The following notation will be used: \(f\), \(g\),
etc, are various acts, i.e., functions from the set \(\bS\) of states
of the world to the set \(\bO\) of outcomes, with \(\bF\) the set of
these functions. \(f(s_i)\) denotes the outcome of \(f\) when state
\(s_i\in\bS\) is actual. The expected utility of \(f\), according to
Savage&rsquo;s theory, denoted \(U(f)\), is given by:</p>

<div class="indent">

<p>
Savage&rsquo;s equation
<br />
\(U(f)=\sum_i u(f(s_i))\cdot P(s_i)\) </p>
</div>

<p>
The result Savage proved can be stated as
 follows:<sup>[<a href="notes.html#note-6" id="ref-6">6</a>]</sup></p>
 
<div class="indent" id="theorem3">
<strong>Theorem 3</strong> (Savage).
<br />
Let \(\preceq\) be a weak preference relation on \(\bF\). If
\(\preceq\) satisfies Savage&rsquo;s axioms, then the following holds:

<ul>

<li>

<p>
The agent&rsquo;s confidence in the actuality of the states in \(\bS\)
can be represented by a <em>unique</em> (and finitely additive)
probability function, \(P\);</p></li>

<li>

<p>
the strength of her desires for the ultimate outcomes in \(\bO\) can
be represented by a utility function, \(u\), that is unique up to
positive linear transformation;</p></li>

<li>

<p>
and the pair \((P, u)\) gives rise to an expected utility function,
\(U\), that represents her preferences for the alternatives in
\(\bF\); i.e., for any \(f, g\in\bF\):</p> 

\[f\preceq g\Leftrightarrow U(f)\leq U(g)\]

 </li>
</ul>
</div>

<p>
The above result may seem remarkable; in particular, the fact that a
person&rsquo;s preferences can determine a unique probability function
that represents her beliefs. On a closer look, however, it is evident
that some of our beliefs can be determined by examining our
preferences. Suppose you are offered a choice between two lotteries,
one that results in you winning a nice prize if a coin comes up heads
but getting nothing if the coin comes up tails, another that results
in you winning the same prize if the coin comes up tails but getting
nothing if the coin comes up heads. Then assuming that the
desirability of the prize (and similarly the desirability of no prize)
is independent of how the coin lands, your preference between the two
lotteries should be entirely determined by your comparative beliefs
for the two ways in which the coin can land. For instance, if you
strictly prefer the first lottery to the second, then that suggests
you consider heads more likely than tails.</p>

<p>
The above observation suggests that one can gauge an agent&rsquo;s
comparative beliefs, and perhaps more, from her preferences. Savage
went one step further than this, and <em>defined</em> comparative
beliefs in terms of preferences. To state Savage&rsquo;s definition,
let \(\wcbrel\) be a weak comparative belief relation, defined on the
set \(\bS\) of states of the world. (\(\cbrel\) and \(\wcbsim\) are
defined in terms of \(\wcbrel \) in the usual way.)</p>

<div class="indent" id="definition1">

<p>
<strong>Definition 1</strong> (Comparative Belief).
<br />
Suppose \(E\) and \(F\) are two events (i.e., subsets of \(\bS\)).
Suppose \(X\) and \(Y\) are two outcomes and \(f\) and \(g\) two acts,
with the following properties:</p>

<ul>

<li>\(f(s_i)=X\) for all \(s_i\in E\), but \(f(s_i)=Y\) for all
\(s_i\not\in E\),</li>

<li>\(g(s_i)=X\) for all \(s_i\in F\), but \(g(s_i)=Y\) for all
\(s_i\not\in F\),</li>

<li>\(Y\preceq X\).</li>
</ul>

<p>
Then \(E \wcbrel F\Leftrightarrow f\preceq g\).</p>
</div>

<p>
Definition 1 is based on the simple observation that one would
generally prefer to stake a good outcome on a more rather than less
probable event. But the idea that this <em>defines</em> comparative
beliefs might seem questionable. We could, for instance, imagine
people who are instrumentally irrational, and as a result fail to
prefer \(g\) to \(f\), even when the above conditions all hold and
they find \(F\) more likely than \(E\). Moreover, this definition
raises the question of how to define the comparative beliefs of those
who are indifferent between <em>all</em> outcomes (Eriksson and
H&aacute;jek 2007). Perhaps no such people exist (and Savage&rsquo;s
 <a href="#axiomP5">axiom P5</a>
 indeed makes clear that his result does not pertain to such people).
Nevertheless, it seems a definition of comparative beliefs should not
preclude that such people, if existent, have <em>strict</em>
comparative beliefs. Savage suggests that this definition of
comparative beliefs is plausible in light of his axiom P4, which will
be stated below. In any case, it turns out that when a person&rsquo;s
preferences satisfy Savage&rsquo;s axioms, we can read off her
preferences a comparative belief relation that can be represented by a
(unique) probability function.</p>

<p>
Without further ado, let us state Savage&rsquo;s axioms in turn. These
are intended as constraints on an agent&rsquo;s preference relation,
\(\preceq\), over a set of acts, \(\bF\), as described above. The
first of Savage&rsquo;s axioms is the basic ordering axiom.</p>

<p class="indent" id="axiomP1">
<strong>P1</strong>. (Ordering)
<br />
The relation \(\preceq\) is complete and transitive.</p>

<p>
The next axiom is reminiscent of vNM&rsquo;s Independence axiom. We
say that alternative \(f\) &ldquo;agrees with&rdquo; \(g\) in event
\(E\) if, for any state in event \(E\), \(f\) and \(g\) yield the same
outcome.</p>

<div class="indent" id="axiomP2">

<p>
<strong>P2</strong>. (Sure Thing Principle)
<br />
If \(f\), \(g\), and \(f'\), \(g'\) are such that:</p>

<ul>

<li>\(f\) agrees with \(g\) and \(f'\) agrees with \(g'\) in event
\(\neg E\),</li>

<li>\(f\) agrees with \(f'\) and \(g\) agrees with \(g'\) in event
\(E\),</li>

<li>and \(f\preceq g\),</li>
</ul>

<p>
then \(f'\preceq g'\).</p>
</div>

<p>
The idea behind the Sure Thing Principle (STP) is essentially the same
as that behind Independence: since we should be able to evaluate each
outcome independently of other possible outcomes, we can safely ignore
states of the world where two acts that we are comparing result in the
same outcome. Putting the principle in tabular form may make this more
apparent. The setup involves four acts with the following form: </p>

<table class="cellpad-med-dense two-rules centered avoid-break">
<tr>
  <td>&nbsp;</td>
  <td>\(E\)</td>
  <td>\(\neg E\)</td> </tr>
<tr>
  <td>\(f\)</td>
  <td><i>X</i></td>
  <td><i>Z</i></td> </tr>
<tr>
  <td>\(g\)</td>
  <td><i>Y</i></td>
  <td><i>Z</i></td> </tr>
<tr>
  <td>\(f'\)</td>
  <td><i>X</i></td>
  <td><i>W</i></td> </tr>
<tr>
  <td>\(g'\)</td>
  <td><i>Y</i></td>
  <td><i>W</i></td> </tr>
</table>

<p>
The intuition behind the STP is that if \(g\) is weakly preferred to
\(f\), then that must be because the consequence \(Y\) is considered
at least as desirable as \(X\), which by the same reasoning implies
that \(g'\) is weakly preferred to \(f'\).</p>

<p>
Savage also requires that the desirability of an outcome be
independent of the state in which it occurs, as this is necessary for
it to be possible to determine a comparative belief relation from an
agent&rsquo;s preferences. To formalise this requirement, Savage
introduces the notion of a <em>null</em> event, defined as
follows:</p>

<p class="indent" id="definition2">
<strong>Definition 2</strong> (Null)
<br />
Event <em>E</em> is null just in case for any alternatives
\(f,g\in\bF\), \(f\sim g\) given <em>E</em>.</p>

<p>
The intuition is that null events are those events an agent is certain
will not occur. If and only if an agent is certain that \(E\) will not
occur, then it is of indifference to her what the acts before her
yield under \(E\). The following axiom then stipulates that knowing
what state is actual does not affect the preference ordering over
<em>outcomes</em>:</p>

<p class="indent" id="axiomP3">
<strong>P3</strong>. (State Neutrality)
<br />
If \(f(s_i)=X\) and \(g(s_i)=Y\) whenever \(s_i\in E\) and \(E\) is
not null, then \(f\preceq g\) given \(E\) just in case \(X\preceq
Y\).</p>

<p>
The next axiom is also necessary for it to be possible to determine a
comparative belief relation from an agent&rsquo;s preferences. Above
it was suggested that by asking you to stake a prize on whether a coin
comes up heads or tails, it can be determined which of these events,
heads or tails, you find more likely. But that suggestion is only
plausible if the size of the prize does not affect your judgement of
the relative likelihood of these two events. That assumption is
captured by the next axioms. Since the axiom is rather complicated it
will be stated in tabular form:</p>

<div class="indent" id="axiomP4">

<p>
<strong>P4</strong>. Consider the following acts:</p>

<table class="cellpad-med-dense two-rules centered">
<tr>
  <td>&nbsp;</td>
  <td>\(E\)</td>
  <td>\(\neg E\)</td> </tr>
<tr>
  <td>\(f\) &nbsp;</td>
  <td>\(X\)</td>
  <td>\(X'\)</td> </tr>
<tr>
  <td>\(g\) &nbsp;</td>
  <td>\(Y\)</td>
  <td>\(Y'\)</td> </tr>
</table>

<table class="cellpad-med-dense two-rules centered">
<tr>
  <td>&nbsp;</td>
  <td>\(F\)</td>
  <td>\(\neg F\)</td> </tr>
<tr>
  <td>\(f'\)</td>
  <td>\(X\)</td>
  <td>\(X'\)</td> </tr>
<tr>
  <td>\(g'\)</td>
  <td>\(Y\)</td>
  <td>\(Y'\)</td> </tr>
</table>

<p>
Now suppose:</p> 

\[\begin{align}
X' &amp;\preceq X, \\
Y' &amp;\preceq Y,  \\
f' &amp;\preceq f
\end{align}\]

<p>
Then</p> 

\[g'\preceq g.\]

</div>

<p>
Less formally (and stated in terms of strict preference), the idea is
that if you prefer to stake the prize \(X\) on \(f\) rather than
\(f'\), you must consider \(E\) more probable than \(F\). Therefore,
you should prefer to stake the prize \(Y\) on \(g\) rather than \(g'\)
since the prize itself does not affect the probability of the
events.</p>

<p>
The next axiom is arguably not a rationality requirement, but one of
Savage&rsquo;s &ldquo;structural axioms&rdquo; (Suppes 2002). An agent
needs to have some variation in preference for it to be possible to
read off her comparative beliefs from her preferences; and, more
generally, for it to be possible to represent her as maximising
expected utility. To this end, the next axiom simply requires that
there be some alternatives between which the agent is not
indifferent:</p>

<p class="indent" id="axiomP5">
<strong>P5</strong>.
<br />
There are some \(f,g\in\bF\) such that \(f\prec g\).</p>

<p>
When these five axioms are satisfied, the agent&rsquo;s preferences
give rise to a comparative belief relation, \(\wcbrel \), which has
the property of being a <em>qualitative probability</em> relation,
which is necessary for it to be possible to represent \(\wcbrel \) by
a probability function. In other words, \(\wcbrel \) satisfies the
following three conditions, for any events \(E\), \(F\) and \(G\):</p>

<ol>

<li>

<p>
\(\wcbrel \) is transitive and complete,</p></li>

<li>

<p>
if \(E\cap G=\emptyset=F\cap G\), then \(E \wcbrel F\Leftrightarrow
E\cup G \wcbrel F\cup G\),</p></li>

<li>

<p>
\(\emptyset \wcbrel E,\) &nbsp; \(\emptyset \cbrel \bS\)</p></li>
</ol>

<p>
Being a qualitative probability relation is, however, not sufficient
to ensure the possibility of probabilistic representation. To ensure
this possibility, Savage added the following structural axiom:</p>

<div class="indent" id="axiomP6">

<p>
<strong>P6</strong>. (Non-atomicity)
<br />
Suppose \(f\prec g\). Then for <em>any</em> \(X\in\bO\), there is a
finite partition, \(\{E_1, E_2, &hellip; E_m\}\), of \(\bS\) such
that:</p>

<ul>

<li> \(f'(s_i)=X\) for any \(s_i\in E_j\), but \(f'(s_i)=f(s_i)\) for
any \(s_i\not\in E_j\),</li>

<li> \(g'(s_i)=X\) for any \(s_i\in E_j\), but \(g'(s_i)=g(s_i)\) for
any \(s_i\not\in E_j\),</li>

<li> \(f'\prec g\) and \(f\prec g'\).</li>
</ul>
</div>

<p>
Like the Continuity axiom of vNM, Non-Atomicity implies that no matter
how bad an outcome \(X\) is, if \(g\) is already preferred to \(f\),
then if we add \(X\) as one of the possible outcomes of
\(f\)&mdash;thereby constructing a new alternative \(f'\)&mdash;\(g\)
will still be preferred to the modified alternative as long as the
probability of \(X\) is sufficiently small. In effect, Non-Atomicity
implies that \(\bS\) contains events of arbitrarily small probability.
It is not too difficult to imagine how that could be satisfied. For
instance, any event \(F\) can be partitioned into two equiprobable
sub-events according to whether some coin would come up heads or tails
if it were tossed. Each sub-event could be similarly partitioned
according to the outcome of the second toss of the same coin, and so
on.</p>

<p>
Savage showed that whenever these six axioms are satisfied, the
comparative belief relation can be represented by a <em>unique</em>
probability function. Having done so, he could rely on the vNM
representation theorem to show that an agent who satisfies all six
 axioms<sup>[<a href="notes.html#note-7" id="ref-7">7</a>]</sup>
 can be represented as maximising expected utility, relative to a
unique probability function that plausibly represents the
agent&rsquo;s beliefs over the states and a cardinal utility function
that plausibly represents the agent&rsquo;s desires for ultimate
outcomes (recall the statement of Savage&rsquo;s theorem
 above).<sup>[<a href="notes.html#note-8" id="ref-8">8</a>]</sup>
 Savage&rsquo;s own proof is rather complicated, but Kreps (1988)
provides a useful illustration of it.</p>

<p>
There is no doubt that Savage&rsquo;s <em>expected utility
representation theorem</em> is very powerful. There are, however, two
important questions to ask about whether Savage achieves his aims: 1)
Does Savage characterise <em>rational preferences</em>, at least in
the generic sense? And 2) Does Savage&rsquo;s theorem tell us how to
make rational decisions in the real world? Savage&rsquo;s theory has
problems meeting these two demands, taken together. Arguably the core
weakness of the theory is that its various constraints and assumptions
pull in different directions when it comes to constructing realistic
decision models, and furthermore, at least one constraint (notably,
the Sure Thing Principle) is only plausible under decision modelling
assumptions that are supposed to be the output, not the input, of the
theory.</p>

<p>
One well recognised decision-modelling requirement for Savage&rsquo;s
theory is that outcomes be maximally specific in every way that
matters for their evaluation. If this were not the case, the axiom of
State Neutrality, for instance, would be a very implausible
rationality constraint. Suppose we are, for example, wondering whether
to buy cocoa or lemonade for the weekend, and assume that how good we
find each option depends on what the weather will be like. Then we
need to describe the outcomes such that they include the state of the
weather. For if we do not, the desirability of the outcomes will
depend on what state is actual. Since lemonade is, let us suppose,
better on hot days than cold, an outcome like &ldquo;I drink lemonade
this weekend&rdquo; would be more or less desirable depending on
whether it occurs in a state where it is hot or cold. This would be
contrary to the axiom of State Neutrality. Therefore, the appropriate
outcomes in this case are those of the form &ldquo;I drink lemonade
this weekend in hot weather&rdquo;. (Of course, this outcome must be
split into even more fine-grained outcomes if there are yet further
features that would affect the choice at hand, such as sharing the
drink with a friend who loves lemonade versus sharing the drink with a
friend who loves hot cocoa, and so on.)</p>

<p>
The fact that the outcomes in the above case must be specific enough
to contain the state of the weather may seem rather innocuous.
However, this requirement exacerbates the above-mentioned problem that
many of the options/acts that Savage requires for his representation
theorem are nonsensical, in that the semantic content of state/outcome
pairs is contradictory. Recall that the domain of the preference
ordering in Savage&rsquo;s theory amounts to <em>every</em> function
from the set of states to the set of outcomes (what Broome 1991a
refers to as the <em>Rectangular Field Assumption</em>). So if
&ldquo;I drink lemonade this weekend in hot weather&rdquo; is one of
the outcomes we are working with, and we have partitioned the set of
states according to the weather, then there must, for instance, be an
act that has this outcome in the state where it is cold! The more
detailed the outcomes (as required for the plausibility of State
Neutrality), the less plausible the Rectangular Field Assumption. This
is an internal tension in Savage&rsquo;s framework. Indeed, it is
difficult to see how/why a rational agent can/should form preferences
over nonsensical acts (although see Dreier 1996 for an argument that
this is not such an important issue). Without this assumption,
however, the agent&rsquo;s preference ordering will not be adequately
rich for Savage&rsquo;s rationality constraints to yield the EU
representation
 result.<sup>[<a href="notes.html#note-9" id="ref-9">9</a>]</sup></p>
 
<p>
The axiom in Savage&rsquo;s theory that has received most attention is
the Sure Thing Principle. It is not hard to see that this principle
conflicts with Allais&rsquo; preferences for the same reason these
preferences conflict with Independence (recall
 <a href="#VNMRepThe">Section 2.3</a>).
 Allais&rsquo; challenge will be discussed again later. For now, our
concern is rather the Sure Thing Principle vis-&agrave;-vis the
internal logic of Savage&rsquo;s theory. To begin with, the Sure Thing
Principle, like State Neutrality, exacerbates concerns about the
Rectangular Field Assumption. This is because the Sure Thing Principle
is only plausible if outcomes are specific enough to account for any
sort of dependencies between outcomes in different states of the
world. For instance, if the fact that one could have chosen a
risk-free alternative&mdash;and thereby guaranteed an acceptable
outcome&mdash;makes a difference to the desirability of receiving
nothing after having taken a risk (as in Allais&rsquo; problem), then
that has to be accounted for in the description of the outcomes. But
again, if we account for such dependencies in the description of the
outcomes, we run into the problem that there will be acts in the
preference ordering that are nonsensical (see, e.g., Broome 1991a: ch.
5).</p>

<p>
There is a further internal problem with Savage&rsquo;s theory
associated with the Sure Thing Principle: the principle is only
reasonable when the decision model is constructed such that there is
probabilistic independence between the acts an agent is considering
and the states of the world that determine the outcomes of these acts.
Recall that the principle states that if we have four options with the
following form: </p>

<table class="cellpad-med-dense two-rules centered">
<tr>
  <td>&nbsp;</td>
  <td>\(E\)</td>
  <td>\(\neg E\)</td> </tr>
<tr>
  <td>\(f\)</td>
  <td><i>X</i></td>
  <td><i>Z</i></td> </tr>
<tr>
  <td>\(g\)</td>
  <td><i>Y</i></td>
  <td><i>Z</i></td> </tr>
<tr>
  <td>\(f'\)</td>
  <td><i>X</i></td>
  <td><i>W</i></td> </tr>
<tr>
  <td>\(g'\)</td>
  <td><i>Y</i></td>
  <td><i>W</i></td> </tr>
</table>

<p>
then if \(g\) is weakly preferred to \(f\), \(g'\) must be weakly
preferred to \(f'\). Suppose, however, that there is probabilistic
dependency between the states of the world and the alternatives we are
considering, and that we find \(Z\) to be better than both \(X\) and
\(Y\), and we also find \(W\) to be better than both \(X\) and \(Y\).
Moreover, suppose that \(g\) makes \(\neg E\) more likely than \(f\)
does, and \(f'\) makes \(\neg E\) more likely than \(g'\) does. Then
it seems perfectly reasonable to prefer \(g\) over \(f\) but \(f'\)
over \(g'\).</p>

<p>
Why is the requirement of probabilistic independence problematic? For
one thing, in many real-world decision circumstances, it is hard to
frame the decision model in such a way that states are intuitively
probabilistically independent of acts. For instance, suppose an agent
enjoys smoking, and is trying to decide whether to quit or not. How
long she lives is amongst the contingencies that affect the
desirability of smoking. It would be natural to partition the set of
states according to how long the agent lives. But then it is obvious
that the options she is considering could, and arguably should, affect
how likely she finds each state of the world, since it is well
recognised that life expectancy is reduced by smoking. Savage would
thus require an alternative representation of the decision
problem&mdash;the states do not reference life span directly, but
rather the agent&rsquo;s physiological propensity to react in a
certain way to smoking.</p>

<p>
Perhaps there is always a way to contrive decision models such that
acts are intuitively probabilistically independent of states. But
therein lies the more serious problem. Recall that Savage was trying
to formulate a way of determining a rational agent&rsquo;s beliefs
from her preferences over acts, such that the beliefs can ultimately
be represented by a probability function. If we are interested in
real-world decisions, then the acts in question ought to be
recognisable options for the agent (which we have seen is
questionable). Moreover, now we see that one of Savage&rsquo;s
rationality constraints on preference&mdash;the Sure Thing
Principle&mdash;is plausible only if the modelled acts are
probabilistically independent of the states. In other words, this
independence must be built into the decision model if it is to
facilitate appropriate measures of belief and desire. But this is to
assume that we already have important information about the beliefs of
the agent whose attitudes we are trying to represent; namely what
state-partitions she considers probabilistically independent of her
acts.</p>

<p>
The above problems suggest there is a need for an alternative theory
of choice under uncertainty. Richard Jeffrey&rsquo;s theory, which
will be discuss next, avoids all of the problems that have been
discussed so far. But as we will see, Jeffrey&rsquo;s theory has
well-known problems of its own, albeit problems that are not
insurmountable.</p>

<h3><a id="JefThe">3.2 Jeffrey&rsquo;s theory</a></h3>

<p>
Richard Jeffrey&rsquo;s expected utility theory differs from
Savage&rsquo;s in terms of both the <em>prospects</em> (i.e., options)
under consideration and the <em>rationality constraints on
preferences</em> over these prospects. The distinct advantage of
Jeffrey&rsquo;s theory is that real-world decision problems can be
modelled just as the agent perceives them; the plausibility of the
rationality constraints on preference do not depend on decision
problems being modelled in a particular way. We first describe the
prospects or decision set-up and the resultant expected utility rule,
before turning to the pertinent rationality constraints on preferences
and the corresponding theorem.</p>

<p>
Unlike Savage, Jeffrey does not make a distinction between the objects
of instrumental and non-instrumental desire (acts and outcomes
respectively) and the objects of belief (states of the world). Rather,
Jeffrey assumes that <em>propositions</em> describing states of
affairs are the objects of both desire and belief. On first sight,
this seems unobjectionable: just as we can have views about whether it
will in fact rain, we can also have views about how desirable that
would be. The uncomfortable part of this setup is that acts, too, are
just propositions&mdash;they are ordinary states of affairs about
which an agent has both beliefs and desires. Just as the agent has a
preference ordering over, say, possible weather scenarios for the
weekend, she has a preference ordering over the possible acts that she
may perform, and in neither case is the most preferred state of
affairs necessarily the most likely to be true. In other words, the
only thing that picks out acts as special is their substantive
content&mdash;these are the propositions that the agent has the power
to choose/make true in the given situation. It is as if the agent
assesses her own options for acting from, rather, a third-person
perspective. If one holds that a decision model should convincingly
represent the subjective perspective of the agent in question, this is
arguably a weakness of Jeffrey&rsquo;s theory, although it may be one
without
 consequence.<sup>[<a href="notes.html#note-10" id="ref-10">10</a>]</sup></p>
 
<p>
Before proceeding, a word about propositions may be helpful: they are
abstract objects that can be either true or false, and are commonly
identified with sets of possible worlds. A possible world can be
thought of as an abstract representation of how things are or could be
(Stalnaker 1987; see also entry on
 <a href="../possible-worlds/index.html">possible worlds</a>).
 The proposition that it rains at time \(t\), for example, is just the
set of all worlds where it rains at time \(t\). And this particular
proposition is true just in case the actual world happens to be a
member of the set of all worlds where it rains at time \(t\). </p>

<p>
The basic upshot of Jeffrey&rsquo;s theory is that the desirability of
a proposition, including one representing acts, depends both on the
desirabilities of the different ways in which the proposition can be
true, and the relative probability that it is true in these respective
ways. To state this more precisely, \(p\), \(q\), etc., will denote
propositional variables. Let \(\{p_1, p_2, &hellip;, p_n\}\) be one
amongst many finite partitions of the proposition \(p\); that is, sets
of mutually incompatible but jointly exhaustive ways in which the
proposition \(p\) can be realised. For instance, if \(p\) is the
proposition that it is raining, then we could partition this
proposition very coarsely according to whether we go to the beach or
not, but we could also partition \(p\) much more finely, for instance
according to the precise millimetres-per-hour amount of rain. The
desirability of \(p\) according to Jeffrey, denoted \(Des(p)\), is
given by:</p>

<p class="indent">
<strong>Jeffrey&rsquo;s equation.</strong>
<br />
\(Des(p)=\sum_i Des(p_i)\cdot P(p_i\mid p)\) </p>

<p>
This is effectively a <em>conditional</em> expected utility formula
for evaluating \(p\). As noted, a special case is when the content of
\(p\) is such that it is recognisably something the agent can choose
to make true, i.e., an act.</p>

<p>
One important difference between Jeffrey&rsquo;s desirability formula
and Savage&rsquo;s expected utility formula, is that there is no
distinction made between desirability and &ldquo;expected&rdquo;
desirability, unlike what has to be done in Savage&rsquo;s theory,
where there is a clear distinction between utility, measuring an
agent&rsquo;s fundamental desires for ultimate outcomes, and expected
utility, measuring an agent&rsquo;s preferences over uncertain
prospects or acts. This disanalogy is due to the fact that there is no
sense in which the \(p_i\)s that \(p\) is evaluated in terms of need
to be ultimate outcomes; they can themselves be thought of as
uncertain prospects that are evaluated in terms of their different
possible realisations.</p>

<p>
Another important thing to notice about Jeffrey&rsquo;s way of
calculating desirability, is that it does not assume probabilistic
independence between the alternative that is being evaluated, \(p\),
and the possible ways, the \(p_i\)s, that the alternative may be
realised. Indeed, the probability of each \(p_i\) is explicitly
conditional on the \(p\) in question. When it comes to evaluating
acts, this is to say (in Savage&rsquo;s terminology) that the
probabilities for the possible state-outcome pairs for the act are
conditional on the act in question. Thus we see why the agent can
describe her decision problem just as she sees it; there is no
requirement that she identify a set of states (in Jeffrey&rsquo;s
case, this would be a partition of the proposition space that is
orthogonal to the act partition) such that the states are
appropriately fine-grained and probabilistically independent of the
acts.</p>

<p>
It should moreover be evident, given the discussion of the Sure Thing
Principle (STP) in
 <a href="#SavThe">Section 3.1</a>,
 that Jeffrey&rsquo;s theory does not have this axiom. Since states
may be probabilistically dependent on acts, an agent can be
represented as maximising the value of Jeffrey&rsquo;s desirability
function while violating the STP. Moreover, unlike Savage&rsquo;s,
Jeffrey&rsquo;s representation theorem does not depend on anything
like the Rectangular Field Assumption. The agent is not required to
have preferences over artificially constructed acts or propositions
that turn out to be nonsensical, given the interpretation of
particular states and outcomes. In fact, only those propositions the
agent considers to be possible (in the sense that she assigns them a
probability greater than zero) are, according to Jeffrey&rsquo;s
theory, included in her preference ordering.</p>

<p>
Of course, we still need certain structural assumptions in order to
prove a representation theorem for Jeffrey&rsquo;s theory. In
particular, the set \(\Omega\), on which the preference ordering
\(\preceq\) is defined, has to be an <em>atomless Boolean algebra</em>
of propositions, from which the impossible propositions, denoted
\(\bot\), have been removed. A Boolean algebra is just a set of e.g.
propositions or sentences that is closed under the classical logical
operators and negation. An algebra is atomless just in case all of its
elements can be partitioned into finer elements. The assumption that
\(\Omega\) is atomless is thus similar to Savage&rsquo;s
 <a href="#axiomP6">P6</a>,
 and can be given a similar justification: any way \(p_i\) in which
\(p\) can be true can be partitioned into two further propositions
according to how some coin would land if tossed.</p>

<p>
So under what conditions can a preference relation \(\preceq\) on the
set \(\Omega\) be represented as maximising desirability? Some of the
required conditions on preference should be familiar by now and will
not be discussed further. In particular, \(\preceq\) has to be
transitive, complete and continuous (recall our discussion in
 <a href="#VNMRepThe">Section 2.3</a>
 of vNM&rsquo;s Continuity preference axiom).</p>

<p>
The next two conditions are, however, not explicitly part of the two
representation theorems that have been considered so far:</p>

<div class="indent">

<p>
<strong>Averaging</strong>
<br />
If \(p,\ q\in \Omega\) are mutually incompatible, then</p> 

\[p\preceq q\Leftrightarrow p\preceq p\cup q\preceq q\]

<p>
<strong>Impartiality</strong>
<br />
Suppose \(p,\ q\in \Omega\) are mutually incompatible and \(p\sim q\).
Then if \(p\cup r\sim q\cup r\) for <em>some</em> \(r\) that is
mutually incompatible with both \(p\) and \(q\) and is such that
\(\neg(r\sim p)\), then \(p\cup r\sim q\cup r\) for <em>every</em>
such \(r\).</p>
</div>

<p>
Averaging is the distinguishing rationality condition in
Jeffrey&rsquo;s theory. It can actually be seen as a weak version of
Independence and the Sure Thing Principle, and it plays a similar role
in Jeffrey&rsquo;s theory. But it is not directly inconsistent with
Allais&rsquo; preferences, and its plausibility does not depend on the
type of probabilistic independence that the STP implies. The postulate
requires that no proposition be strictly better or worse than all of
its possible realisations, which seems to be a reasonable requirement.
When \(p\) and \(q\) are mutually incompatible, \(p\cup q\) implies
that either \(p\) or \(q\) is true, but not both. Hence, it seems
reasonable that \(p\cup q\) should be neither strictly more nor less
desirable than both \(p\) and \(q\). Suppose one of \(p\) or \(q\) is
more desirable than the other. Then since \(p\cup q\) is compatible
with the truth of either the more or the less desirable of the two,
\(p\cup q\)&rsquo;s desirability should fall strictly between that of
\(p\) and that of \(q\). However, if \(p\) and \(q\) are equally
desirable, then \(p\cup q\) should be as desirable as each of the
two.</p>

<p>
The intuitive appeal of Impartiality, which plays a similar role in
Jeffrey&rsquo;s theory as P4 does in Savage&rsquo;s, is not as great
as that of Averaging. Jeffrey himself admitted as much in his comment:
</p>

<blockquote>

<p>
The axiom is there because we need it, and it is justified by our
antecedent belief in the plausibility of the result we mean to deduce
from it. (1965: 147) </p>
</blockquote>

<p>
Nevertheless, it does seem that an argument can be made that any
reasonable person will satisfy this axiom. Suppose you are indifferent
between two propositions, \(p\) and \(q\), that cannot be
simultaneously true. And suppose now we find a proposition \(r\), that
is pairwise incompatible with both \(p\) and \(q\), and which you find
more desirable than both \(p\) and \(q\). Then if it turns out that
you are indifferent between \(p\) joined with \(r\) and \(q\) joined
with \(r\), that must be because you find \(p\) and \(q\) equally
probable. Otherwise, you would prefer the union that contains the one
of \(p\) and \(q\) that you find less probable, since that gives you a
higher chance of the more desirable proposition \(r\). It then follows
that for any other proposition \(s\) that satisfies the aforementioned
conditions that \(r\) satisfies, you should also be indifferent
between \(p\cup s\) and \(q\cup s\), since, again, the two unions are
equally likely to result in \(s\).</p>

<p>
The first person to prove a theorem stating sufficient conditions for
a preference relation to be representable as maximising the value of a
Jeffrey-desirability function was actually not Jeffrey himself, but
the mathematician Ethan Bolker (1966, 1967). He proved the following
result (recall the definition of a &ldquo;desirability measure&rdquo;
given
 above):<sup>[<a href="notes.html#note-11" id="ref-11">11</a>]</sup></p>
 
<p class="indent" id="theorem4">
<strong>Theorem 4</strong> (Bolker)
<br />
Let \(\Omega\) be a complete and atomless Boolean algebra of
propositions, and \(\preceq\) a continuous, transitive and complete
relation on \(\Omega \setminus \bot \), that satisfies Averaging and
Impartiality. Then there is a desirability measure on \(\Omega
\setminus \bot \) and a probability measure on \(\Omega\) relative to
which \(\preceq\) can be represented as maximising desirability.</p>

<p>
Unfortunately, Bolker&rsquo;s representation theorem does not yield a
result anywhere near as unique as Savage&rsquo;s. Even if a
person&rsquo;s preferences satisfy all the conditions in
Bolker&rsquo;s theorem, then it is neither guaranteed that there will
be just one probability function that represents her beliefs nor that
the desirability function that represents her desires will be unique
up to a positive linear transformation (unless her preferences are
unbounded). Even worse, the same preference ordering satisfying all
these axioms could be represented as maximising desirability relative
to two probability functions that do not even agree on how to order
propositions according to their
 probability.<sup>[<a href="notes.html#note-12" id="ref-12">12</a>]</sup></p>
 
<p>
For those who think that the only way to determine a person&rsquo;s
comparative beliefs is to look at her preferences, the lack of
uniqueness in Jeffrey&rsquo;s theory is a big problem. Indeed, this
may be one of the main reasons why economists have largely ignored
Jeffrey&rsquo;s theory. Economists have traditionally been skeptical
of any talk of a person&rsquo;s desires and beliefs that goes beyond
what can be established by examining the person&rsquo;s preferences,
which they take to be the only attitude that is directly revealed by a
person&rsquo;s behaviour. For these economists, it is therefore
unwelcome news if we cannot even in principle determine the
comparative beliefs of a rational person by looking at her
preferences.</p>

<p>
Those who are less inclined towards behaviourism might, however, not
find this lack of uniqueness in Bolker&rsquo;s theorem to be a
problem. James Joyce (1999), for instance, thinks that Jeffrey&rsquo;s
theory gets things exactly right in this regard, since one should not
expect that reasonable conditions imposed on a person&rsquo;s
preferences would suffice to determine a unique probability function
representing the person&rsquo;s beliefs. It is only by imposing overly
strong conditions, as Savage does, that we can achieve this. However,
if uniqueness is what we are after, then we can, as Joyce points out,
supplement the Bolker-Jeffrey axioms with certain conditions on the
agent&rsquo;s comparative belief relation (e.g. those proposed by
Villegas 1964) that, together with the Bolker-Jeffrey axioms, ensure
that the agent&rsquo;s preferences can be represented by a unique
probability function and a desirability function that is unique up to
a positive linear transformation.</p>

<p>
Instead of adding specific belief-postulates to Jeffrey&rsquo;s
theory, as Joyce suggests, one can get the same uniqueness result by
enriching the set of prospects. Richard Bradley (1998) has, for
instance, shown that if one extends the Boolean algebra in
Jeffrey&rsquo;s theory to indicative conditionals, then a preference
relation on the extended domain that satisfies the Bolker-Jeffrey
axioms (and some related axioms that specifically apply to
conditionals) will be representable as maximising desirability, where
the probability function is unique and the desirability function is
unique up to a positive linear transformation.</p>

<h2><a id="BroSigEUThe">4. Broader implications of Expected Utility (EU) theory</a></h2>

<p>
It was noted from the outset that EU theory is as much a theory of
rational choice, or overall preferences amongst acts, as it is a
theory of rational belief and desire. This section expands, in turn,
on the epistemological and evaluative commitments of EU theory.</p>

<h3><a id="RatBel">4.1 On rational belief</a></h3>

<p>
Some refer to EU theory as <em>Bayesian decision theory</em>. This
label brings to the forefront the commitment to <em>probabilism</em>,
i.e., that beliefs may come in degrees which, on pain of
irrationality, can be represented numerically as probabilities. So
there is a strong connection between EU theory and probabilism, or
more generally between rational preference and rational belief. (The
finer details of rational preference and associated rational belief
are not the focus here; challenges to EU theory on this front are
addressed in
 <a href="#ChaEUThe">Section 5</a>
 below.)</p>

<p>
Some take the connection between rational preference and rational
belief to run very deep indeed. At the far end of the spectrum is the
position that the very meaning of belief involves preference. Indeed,
recall this manoeuvre in Savage&rsquo;s theory, discussed earlier in
 <a href="#SavThe">Section 3.1</a>.
 Many question the plausibility, however, of equating comparative
belief with preferences over specially contrived prospects. A more
moderate position is to regard these preferences as entailed by, but
not identical with, the relevant comparative beliefs. Whether or not
beliefs merely ground or are defined in terms of preference, there is
a further question as to whether the only justification for rational
belief having a certain structure (say, conforming to the probability
calculus) is a pragmatic one, i.e., an argument resting on the
agent&rsquo;s preferences being otherwise inconsistent or
self-defeating. A recent defender of this kind of pragmatism (albeit
cast in more general terms) is Rinard (e.g., 2017). Others contend
that accounts of rational belief can and should be ultimately
justified on epistemic grounds; Joyce (1998), for instance, offers a
non-pragmatic justification of probabilism that rests on the notion of
overall &ldquo;distance from the truth&rdquo; of one&rsquo;s beliefs.
(For further developments of this position, see the entry on
 <a href="../epistemic-utility/index.html">epistemic utility arguments for probabilism</a>.)</p>
 
<p>
Notwithstanding these finer disputes, Bayesians agree that pragmatic
considerations play a significant role in managing beliefs. One
important way, at least, in which an agent can interrogate her degrees
of belief is to reflect on their pragmatic implications. Furthermore,
whether or not to seek more evidence is a pragmatic issue; it depends
on the &ldquo;value of information&rdquo; one expects to gain with
respect to the decision problem at hand. The idea is that seeking more
evidence is an action that is choice-worthy just in case the expected
utility of seeking further evidence before making one&rsquo;s decision
is greater than the expected utility of making the decision on the
basis of existing evidence. This reasoning was made prominent in a
paper by Good (1967), where he proves that one should always seek
&ldquo;free evidence&rdquo; that may have a bearing on the decision at
hand. (Precursors of this theorem can be found in Ramsey 1990,
published posthumously, and Savage 1954.) Note that the theorem
assumes the standard Bayesian learning rule known as
&ldquo;conditionalisation&rdquo;, which requires that when one&rsquo;s
learning experience has the form of coming to know some proposition
(to which one had assigned positive probability) for sure, one&rsquo;s
new degrees of belief should be equal to one&rsquo;s old degrees of
belief conditional on the proposition that now has probability one.
Indeed, the fact that conditionalisation plays a crucial role in
Good&rsquo;s result about the non-negative value of free evidence is
taken by some as providing some justification for this learning
rule.</p>

<p>
So EU theory or Bayesian decision theory underpins a powerful set of
epistemic norms. It has been taken as the appropriate account of
scientific inference, giving rise to a school of statistical inference
and experimental design and inviting formal interpretations of key
concepts like &ldquo;evidence&rdquo;, &ldquo;evidential
support&rdquo;, &ldquo;induction&rdquo; versus
&ldquo;abduction&rdquo;, and the bearing of &ldquo;coherence&rdquo;
and &ldquo;explanatory power&rdquo; on truth (see the relevant
 <a href="#Rel">related entries</a>).
 The major competitor to Bayesianism, as regards scientific inference,
is arguably the collection of approaches known as Classical or Error
statistics, which deny the sense of &ldquo;degrees of support&rdquo;
(probabilistic or otherwise) conferred on a hypothesis by evidence.
These approaches focus instead on whether a hypothesis has survived
various &ldquo;severe tests&rdquo;, and inferences are made with an
eye to the long-run properties of tests as opposed to how they perform
in any single case, which would require decision-theoretic reasoning
(see the entry on
 <a href="../statistics/index.html">philosophy of statistics</a>).</p>
 
<h3><a id="RatDes">4.2 On rational desire</a></h3>

<p>
EU theory takes a stance on the structure of rational desire too. In
this regard, the theory has been criticised on opposing fronts. We
consider first the criticism that EU theory is too permissive with
respect to what may influence an agent&rsquo;s desires. We then turn
to the opposing criticism: that when it comes to desire, EU theory is
not permissive enough.</p>

<p>
The worry that EU theory is too permissive with respect to desire is
related to the worry that the theory is <em>unfalsifiable</em>. The
worry is that apparently irrational preferences by the lights of EU
theory can always be construed as rational, under a suitable
description of the options under consideration. As discussed in
 <a href="#WhaPreOvePro">Section 1</a>
 above, preferences that seem to violate Transitivity can be construed
as consistent with this axiom so long as the options being compared
vary in their description depending on, amongst other things, the
other options under consideration. The same goes for preferences that
seem to violate Separability or Independence (of the contribution of
each outcome to the overall value of an option), discussed further in
 <a href="#SepRisRegAtt">Section 5.1</a>
 below. One might argue that this is the right way to describe such
agents&rsquo; preferences. After all, an apt model of preference is
supposedly one that captures, in the description of final outcomes and
options, everything that matters to an agent. In that case, however,
EU theory is effectively vacuous or impotent as a standard of
rationality to which agents can aspire. Moreover, it stretches the
notion of what are genuine properties of outcomes that can reasonably
confer value or be desirable for an agent.</p>

<p>
There are two ways one can react to the idea that an agent&rsquo;s
preferences are necessarily consistent with EU theory, with the
above-mentioned implications for what the agent may desire:</p>

<ul>

<li>

<p>
One can resist the claim, asserting that there are additional
constraints on the <em>content</em> of an agent&rsquo;s preferences.
On the one hand there may be empirical constraints whereby the content
of preferences is determined by some tradeoff between fit and
simplicity in representing the agent&rsquo;s greater &ldquo;web&rdquo;
of preference attitudes. On the other hand there may be normative
constraints with respect to what sorts of outcomes an agent may
reasonably discriminate (for relevant discussion, see Tversky 1975;
Broome 1991a &amp; 1993; Pettit 1993; Dreier 1996; Guala 2006;
Vredenburgh 2020).</p></li>

<li>

<p>
One can alternatively embrace the claim, interpreting EU theory not as
a standard against which an agent may pass or fail, but rather as an
organising principle that enables the characterisation of an
agent&rsquo;s desires as well as her beliefs (see esp. Guala
2008).</p></li>
</ul>

<p>
Either way, it may yet be argued that EU theory does not go far enough
in structuring an agent&rsquo;s preference attitudes so that we may
understand the <em>reasons</em> for these preference attitudes.
Dietrich and List (2013 &amp; 2016a) have proposed a more general
framework that fills this lacuna. In their framework, preferences
satisfying some minimal constraints are representable as dependent on
the bundle of properties in terms of which each option is perceived by
the agent in a given context. Properties can, in turn, be categorised
as either <em>option properties</em> (which are intrinsic to the
outcome), <em>relational properties</em> (which concern the outcome in
a particular context), or <em>context properties</em> (which concern
the context of choice itself). Such a representation permits more
detailed analysis of the reasons for an agent&rsquo;s preferences and
captures different kinds of context-dependence in an agent&rsquo;s
choices. Furthermore, it permits explicit restrictions on what counts
as a legitimate reason for preference, or in other words, what
properties legitimately feature in an outcome description; such
restrictions may help to clarify the normative commitments of EU
theory.</p>

<p>
There are also less general models that offer templates for
understanding the reasons underlying preferences. For instance, the
<em>multiple criteria</em> decision framework (see, for instance,
Keeney and Raiffa 1993) takes an agent&rsquo;s overall preference
ordering over options to be an aggregate of the set of preference
orderings corresponding to all the pertinent dimensions of value.
Under certain assumptions, the overall or aggregate preference
ordering is compatible with EU theory. One might otherwise seek to
understand the role of time, or the temporal position of goods, on
preferences. To this end, outcomes are described in terms of
temporally-indexed bundles of goods, or <em>consumption streams</em>
(for an early model of this kind see Ramsey 1928; a later influential
treatment is Koopmans 1960). There may be systematic structure to an
agent's preferences over these consumption streams, over and above the
structure imposed by the EU axioms of preference. For instance, the
aforementioned authors considered and characterised preferences that
exhibit <em>exponential time discounting</em>.</p>

<p>
Let&rsquo;s turn now to the opposing kind of criticism: that the
limited constraints that EU theory imposes on rational preference and
desire are nonetheless overly restrictive. Here the focus will be on
the compatibility of EU theory with prominent ethical positions
regarding the choice-worthiness of acts, as well as meta-ethical
positions regarding the nature of value and its relationship to
belief.</p>

<p>
One may well wonder whether EU theory, indeed decision theory more
generally, is neutral with respect to normative ethics, or whether it
is compatible only with <em>ethical consequentialism</em>, given that
the ranking of an act is fully determined by the utility of its
possible outcomes. Such a model seems at odds with
<em>nonconsequentialist</em> ethical theories for which the
choice-worthiness of acts purportedly depends on more than the moral
value of their consequences. The model does not seem able to
accommodate basic deontological notions like agent relativity,
absolute prohibitions or permissible and yet suboptimal acts.</p>

<p>
An initial response, however, is that one should not read too much
into the formal concepts of decision theory. The utility measure over
acts and outcomes is simply a convenient way to represent an ordering,
and leaves much scope for different ways of identifying and evaluating
outcomes. Just as an agent&rsquo;s utility function need not be
insensitive to ethical considerations in general (a common
misconception due to the prevalence of selfish preferences in economic
models; see, for instance, Sen 1977), nor need it be insensitive to
specifically nonconsequentialist or deontological ethical
considerations. It all depends on how acts and their outcomes are
distinguished and evaluated. For starters, the character of an act may
feature as a property of all its possible outcomes. Moreover, whether
some event befalls or is perpetrated by the deciding agent or rather
someone else may be relevant. That an act involves lying, say, can be
referenced in all possible outcomes of the act, and furthermore this
lying on the part of the deciding agent can be distinguished from the
lying of others. In general, acts and their outcomes can be
distinguished according to whatever matters morally, be it a complex
relational property to do with how and when the act is chosen, by
whom, and/or in what way some state of affairs results from the act.
For early discussions on how a wide range of ethical properties can be
accommodated in the description of acts and outcomes, see, for
instance, Sen (1982), Vallentyne (1988), Broome (1991b) and Dreier
(1993). This idea has since been embraced by others associated with
the so-called &ldquo;consequentializing&rdquo; program, including
Louise (2004) and Portmore (2007). The idea is that the normative
advice of putatively nonconsequentialist ethical theories can be
represented in terms of a ranking of acts/outcomes corresponding to
some value function, as per consequentialist ethical theories (see too
Colyvan et al. 2010).</p>

<p>
A sticking point for reconciling decision theory with all forms of
nonconsequentialism is the difficulty in accommodating <em>absolute
prohibitions</em> or <em>side constraints</em> (see Oddie and Milne
1999; Jackson and Smith 2006). For instance, suppose there is a moral
prohibition against killing an innocent person, whatever else is at
stake. Perhaps such a constraint is best modelled in terms of a
lexical ranking and corresponding value function, whereby the
killing-innocents status of an act/outcome takes priority in
determining its relative rank/value. But this has counterintuitive
implications in the face of risk since very many acts will have some
chance, however small, of killing an innocent. The lesson here may
simply be that the theories in question require development; any
mature ethical theory owes us an account of how to act under risk or
uncertainty. What is arguably a more compelling challenge for the
reconciliation of decision theory and nonconsequentialism is the
accommodation of &ldquo;agent-centred options&rdquo; and associated
&ldquo;supererogation&rdquo;. Portmore (e.g., 2007) and Lazar (e.g.,
2017) offer proposals to this effect, which appeal (in different ways)
to the moral ranking of acts/outcomes as distinct from the personal
costs to the agent of pursuing these acts/outcomes.</p>

<p>
To the extent that decision theory can be reconciled with the full
range of ethical theories, should we say that there are no meaningful
distinctions between these theories? Brown (2011) and Dietrich and
List (2017) demonstrate that in fact the choice-theoretic
representation of ethical theories better facilitates distinctions
between them; terms like &ldquo;(non)consequentialism&rdquo; can be
precisely defined, albeit in debatable ways. More generally, we can
catalogue theories in terms of the kinds of properties (whether
intrinsic or in some sense relational) that distinguish acts/outcomes
and also in terms of the nature of the ranking of acts/outcomes that
they yield (whether transitive, complete, continuous and so on). This
also serves to reveal departures from EU theory.</p>

<p>
Indeed, some of the most compelling counterexamples to EU axioms of
preference rest on ethical considerations. Recall our earlier
discussion of the basic Ordering axioms in
 <a href="#WhaPreOvePro">Section 1</a>.
 The Transitivity axiom has been challenged by appeal to
ethically-motivated examples of preference cycles (see Temkin 2012).
The notion of a non-continuous lexical ordering was mentioned above in
relation to ethical side constraints. The dispensability of the
Completeness axiom, too, is often motivated by appeal to examples
involving competing ethical values that are difficult to tradeoff
against each other, like average versus total welfare. Other
suggestive examples against Completeness involve competing notions of
personal welfare (see, e.g., Levi 1986; Chang 2002). Must a rational
agent have a defined preference between, say, two career options that
pull in different directions as regards opportunities for creative
self-expression versus community service (perhaps a career as a dancer
versus a career as a doctor in remote regions)? Note that some of
these challenges to EU theory are discussed in more depth in
 <a href="#ChaEUThe">Section 5</a>
 below.</p>

<p>
Finally, we turn to the potential meta-ethical commitments of EU
theory. David Lewis (1988, 1996) famously employed EU theory to argue
against <em>anti-Humeanism</em>, the position that we are sometimes
moved entirely by our beliefs about what would be good, rather than by
our desires as the Humean claims. He formulated the anti-Humean theory
as postulating a necessary connection between, on the one hand, an
agent&rsquo;s desire for any proposition \(A\), and, on the other
hand, her belief in a proposition about \(A\)&rsquo;s goodness; and
claimed to prove that when such a connection is formulated in terms of
EU theory, the agent in question will be dynamically incoherent.
Several people have criticised Lewis&rsquo;s argument. For instance,
Broome (1991c), Byrne and H&aacute;jek (1997) and H&aacute;jek and
Pettit (2004) suggest formulations of anti-Humeanism that are immune
to Lewis&rsquo; criticism, while Stef&aacute;nsson (2014) and Bradley
and Stef&aacute;nsson (2016) argue that Lewis&rsquo; proof relies on a
false assumption. Nevertheless, Lewis&rsquo; argument no doubt
provoked an interesting debate about the sorts of connections between
belief and desire that EU theory permits. There are, moreover, further
questions of meta-ethical relevance that one might investigate
regarding the role and structure of desire in EU theory. For instance,
Jeffrey (1974) and Sen (1977) offer some preliminary investigations as
to whether the theory can accommodate <em>higher-order</em>
desires/preferences, and if so, how these relate to first-order
desires/preferences.</p>

<h2><a id="ChaEUThe">5. Challenges to EU theory</a></h2>

<p>
Thus far the focus has been on prominent versions of the standard
theory of rational choice: EU theory. This section picks up on some
key criticisms of EU theory that have been developed into alternative
accounts of rational choice. The proposed innovations to the standard
theory are distinct and so are discussed separately, but they are not
necessarily mutually exclusive. Note that we do not address all
criticisms of EU theory that have inspired alternative accounts of
rational choice. Two major omissions of this sort (for want of space
and also because they have been thoroughly addressed in alternative
entries of this encyclopedia) are i) the problem of causal anomalies
and the development of causal decision theory (see the entry on
 <a href="../decision-causal/index.html">causal decision theory</a>),
 and ii) the problem of infinite state spaces and the development of
alternatives like &ldquo;relative expectation theory&rdquo; (see the
entries on
 <a href="../rationality-normative-utility/index.html">normative theories of rational choice: expected utility theory</a>
 and
 <a href="../paradox-stpetersburg/index.html">the St. Petersburg paradox</a>).</p>
 
<h3><a id="SepRisRegAtt">5.1 On risk and regret attitudes</a></h3>

<p>
Expected utility theory has been criticised for not allowing for value
interactions between outcomes in different, mutually incompatible
states of the world. For instance, recall that when deciding between
two risky options you should, according to Savage&rsquo;s version of
the theory, ignore the states of the world where the two options
result in the same outcome. That seems very reasonable if we can
assume <em>separability</em> between outcomes in different states of
the world, i.e., if the contribution that an outcome in one state of
the world makes towards the overall value of an option is independent
of what other outcomes the option might result in. For then identical
outcomes (with equal probabilities) should cancel each other out in a
comparison of two options, which would entail that if two options
share an outcome in some state of the world, then when comparing the
options, it does not matter what that shared outcome is.</p>

<p>
The Allais paradox, discussed in
 <a href="#VNMRepThe">Section 2.3</a>
 above, is a classic example where the aforementioned separability
seems to fail. For ease of reference, the options that generate the
paradox are reproduced as Table 3. Recall from
 <a href="#VNMRepThe">Section 2.3</a>
 that people tend to prefer \(L_2\) over \(L_1\) and \(L_3\) over
\(L_4\)&mdash;an attitude that has been called <em>Allais&rsquo;
preferences</em>&mdash;in violation of expected utility theory. The
violation occurs precisely because the contributions that some of
these outcomes make towards the overall value of an option is not
independent of the other outcomes that the option can have. Compare
the extra chance of outcome $0 that \(L_1\) has over \(L_2\) with the
same extra chance of $0 that \(L_3\) has over \(L_4\). Many people
think that this extra chance counts more heavily in the first
comparison than the latter, i.e., that an extra 0.01 chance of $0
contributes a greater negative value to \(L_1\) than to \(L_3\). Some
explain this by pointing out that the <em>regret</em> one would
experience by winning nothing when one could have had $2400 for
sure&mdash;i.e., when choosing \(L_1\) over \(L_2\) and the first
ticket is drawn&mdash;is much greater than the regret one would
experience by winning nothing when the option one turned down also had
a high chance of resulting in $0&mdash;such as when choosing \(L_3\)
over \(L_4\) (see, e.g., Loomes and Sugden 1982). But whether or not
the preference in question should be explained by the potential for
regret, it would seem that the desirability of the $0-outcome depends
on what could (or would) otherwise have been; in violation of the
aforementioned assumption of separability. (See Thoma 2020a for a
recent extensive discussion of this assumption.) </p>

<div class="figure avoid-break">

<table class="cellpad-med-dense two-rules nocaption">
<tr>
  <td>&nbsp;</td>
  <td>1</td>
  <td>2&ndash;34</td>
  <td>35&ndash;100</td> </tr>
<tr>
  <td>\(L_1\)</td>
  <td>$0</td>
  <td>$2500</td>
  <td>$2400</td> </tr>
<tr>
  <td>\(L_2\)</td>
  <td>$2400</td>
  <td>$2400</td>
  <td>$2400</td> </tr>
</table>

<table class="cellpad-med-dense two-rules">
<tr>
  <td>&nbsp;</td>
  <td>1</td>
  <td>2&ndash;34</td>
  <td>35&ndash;100</td> </tr>
<tr>
  <td>\(L_3\)</td>
  <td>$0</td>
  <td>$2500</td>
  <td>$0</td> </tr>
<tr>
  <td>\(L_4\)</td>
  <td>$2400</td>
  <td>$2400</td>
  <td>$0</td> </tr>
</table>

<p class="center">
<span class="figlabel">Table 3.</span> Allais&rsquo; paradox</p>
</div>

<p>
Various attempts have been made to make Allais&rsquo; preferences
compatible with some version of expected utility theory. A common
response is to suggest that the choice problem has been incorrectly
described. If it really is rational to evaluate $0 differently
depending on which lottery it is part of, then perhaps this should be
accounted for in the description of the outcomes (Broome 1991a). For
instance, we could add a variable to the $0 outcome that \(L_1\) might
result in to represent the extra regret or risk associate with that
outcome compared to the $0 outcomes from the other lotteries (as done
in
 <a href="#table4">Table 4</a>).
 If we do that, Allais&rsquo; preferences are no longer inconsistent
with EU theory. The simplest way to see this is to note that when we
ignore the state of the world where the options that are being
compared have the same outcome (i.e., when we ignore the last column
in Table 4), \(L_1\) is no longer identical to \(L_3\), which means
that the Independence axiom of von Neumann and Morgenstern (and
Savage&rsquo;s Sure Thing Principle) no longer requires that one
prefer \(L_2\) over \(L_1\) only if one prefers \(L_4\) over
\(L_3\).</p>

<div class="figure avoid-break" id="table4">

<table class="cellpad-med-dense two-rules nocaption">
<tr>
  <td>&nbsp;</td>
  <td>1</td>
  <td>2&ndash;34</td>
  <td>35&ndash;100</td> </tr>
<tr>
  <td>\(L_1\)</td>
  <td>$0 + \(\delta\)</td>
  <td>$2500</td>
  <td>$2400</td> </tr>
<tr>
  <td>\(L_2\)</td>
  <td>$2400</td>
  <td>$2400</td>
  <td>$2400</td> </tr>
</table>

<table class="cellpad-med-dense two-rules">
<tr>
  <td>&nbsp;</td>
  <td>1</td>
  <td>2&ndash;34</td>
  <td>35&ndash;100</td> </tr>
<tr>
  <td>\(L_3\)</td>
  <td>$0</td>
  <td>$2500</td>
  <td>$0</td> </tr>
<tr>
  <td>\(L_4\)</td>
  <td>$2400</td>
  <td>$2400</td>
  <td>$0</td> </tr>
</table>

<p class="center">
<span class="figlabel">Table 4.</span> Allais&rsquo; paradox
re-described</p>
</div>

<p>
The above &ldquo;re-description strategy&rdquo; could be employed
whenever the value and/or contribution of an outcome depends on other
possible outcomes: just describe the outcomes in a way that accounts
for this dependency. But more worryingly, the strategy could be
employed whenever one comes across <em>any</em> violation of expected
utility theory or other theories of rationality (as discussed in
 <a href="#RatDes">Section 4.2</a>).
 </p>

<p>
Lara Buchak (2013) has recently developed a decision theory that can
accommodate Allais&rsquo; preferences without re-describing the
outcomes. On Buchak&rsquo;s interpretation, the explanation for
Allais&rsquo; preferences is not the different <em>value</em> that the
outcome $0 has depending on what lottery it is part of. The outcome
itself has the same value. However, the <em>contribution</em> that $0
makes towards the overall value of an option partly depends on what
other outcomes are possible, she suggests, which reflects the fact
that the option-risk that the possibility of $0 generates depends on
what other outcomes the option might result in. To accommodate
Allais&rsquo; preferences (and other intuitively rational attitudes to
risk that violate EU theory), Buchak introduces a <em>risk
function</em> that represents people&rsquo;s willingness to trade
chances of something good for risks of something bad. And she shows
that if an agent satisfies a particular set of axioms, which is
essentially Savage&rsquo;s except that the Sure Thing Principle is
replaced with a strictly weaker one, then the agent&rsquo;s
preferences can be represented as maximising <em>risk weighted
expected utility</em>; which is essentially Savage-style expected
utility weighted by a risk function.</p>

<p>
Bradley and Stef&aacute;nsson (2017) also develop a new decision
theory partly in response to the Allais paradox. But unlike Buchak,
they suggest that what explains Allais&rsquo; preferences is that the
value of wining nothing from a chosen lottery partly depends on what
would have happened had one chosen differently. To accommodate this,
they extend the Boolean algebra in Jeffrey&rsquo;s decision theory to
<em>counterfactual</em> propositions, and show that Jeffrey&rsquo;s
extended theory can represent the value-dependencies one often finds
between counterfactual and actual outcomes. In particular, their
theory can capture the intuition that the (un)desirability of winning
nothing partly depends on whether or not one was guaranteed to win
something had one chosen differently. Therefore, their theory can
represent Allais&rsquo; preferences as maximising the value of an
extended Jeffrey-desirability function.</p>

<p>
Stef&aacute;nsson and Bradley (2019) suggest yet another way of
accounting for Allais&rsquo; preferences in an extension of
Jeffrey&rsquo;s decision theory; this time extended to <em>chance
propositions</em>, that is, propositions describing objective
probability distributions. The general idea is that the desirability
of a particular increase or decrease in the chance of some
outcome&mdash;for instance, in the Allais case, a 0.01 increase in the
chance of the $0-outcome&mdash;might depend on what the chances were
before the increase or decrease. Stef&aacute;nsson and Bradley&rsquo;s
extension of Jeffrey&rsquo;s theory to chance propositions is also
motivated by the fact that standard decision theories do not
distinguish between risk aversion with respect to some good and
attitudes to quantities of that good (which is found problematic by,
for instance, Hansson 1988, Rabin 2000, and Buchak 2013).</p>

<h3><a id="ComVagBelDes">5.2 On completeness: Vague beliefs and desires</a></h3>

<p>
As noted in
 <a href="#BroSigEUThe">Section 4</a>,
 criticisms of the EU requirement of a complete preference ordering
are motivated by both epistemic and desire/value considerations. On
the value side, many contend that a rational agent may simply find two
options <em>incomparable</em> due to their <em>incommensurable</em>
qualities. (Here a prominent usage of these terms will be followed,
whereby particular options may be described as incomparable in value,
while general properties or dimensions of value may be described as
incommensurable.) As in, the agent&rsquo;s evaluations of the
desirability of sure options may not be representable by any precise
utility function. Likewise, on the belief side, some contend (notably,
Joyce 2010 and Bradley 2017) that the evidence may be such that it
does not commit a rational agent to precise degrees of belief
measurable by a unique probability function.</p>

<p>
There are various alternative, &ldquo;fuzzier&rdquo; representations
of desire and belief that might be deemed more suitable. Halpern
(2003), for instance, investigates different ways of conceptualising
and representing epistemic uncertainty, once we depart from
probabilities. Presumably there are also various ways to represent
uncertain desire. Here the focus will be on just one proposal that is
popular amongst philosophers: the use of <em>sets</em> of probability
and utility functions to represent uncertainty in belief and desire
respectively. This is a minimal generalisation of the standard EU
model, in the sense that probability and utility measures still
feature. Roughly, the more severe the epistemic uncertainty, the more
probability measures over the space of possibilities needed to
conjointly represent the agent&rsquo;s beliefs. This notion of
rational belief is referred to as <em>imprecise probabilism</em> (see
the entry on
 <a href="../imprecise-probabilities/index.html">imprecise probabilities</a>).
 Likewise, the more severe the evaluative uncertainty, the more
utility measures over the space of sure options needed to conjointly
represent the agent&rsquo;s desires. Strictly speaking, we should not
treat belief and desire separately, but rather talk of the
agent&rsquo;s incomplete preferences being represented by a set of
probability and utility pairs. Recall the requirement that incomplete
preferences be <em>coherently extendible</em> (refer back to
 <a href="#WhaPreOvePro">Section 1</a>);
 on this representation, all the probability-utility pairs amount to
candidate extensions of the incomplete preferences.</p>

<p>
The question then arises: Is there a conservative generalisation of
the EU decision rule that can handle sets of probability and utility
pairs? Contender decision rules are standardly framed in terms of
choice functions that take as input some set of feasible options and
return as output a non-empty set of admissible choices that is a
subset of the feasible options. A basic constraint on these choice
functions is that they respect the agent&rsquo;s preferences in cases
where options are in fact comparable. That is, if all pairs of
probability and utility functions characterising the agent&rsquo;s
attitudes agree on the ranking of two options, then these particular
options should be ranked accordingly. The relevant constraint on
choice functions is that &ldquo;EU-dominated options&rdquo; are not
admissible choices, i.e., if an option has lower expected utility than
another option according to all pairs of probability and utility
functions, then the former dominated option is not an admissible
choice. Note that Levi (1986) has a slightly more restrictive
condition on admissibility: if an option does not have maximum EU for
at least one pair of probability and utility functions, then it is not
admissible. In ordinary cases where sets of probability and utility
functions are closed convex sets, however, Levi&rsquo;s condition is
equivalent to the aforementioned one that rules out EU-dominated
options (Schervish et al. 2003).</p>

<p>
The treatment of genuinely incomparable options (those surviving the
above admissibility test and yet are not such that the agent is
indifferent) is where the real controversies begin. See Bradley (2017)
for extensive discussion of the various ways to proceed. A
consideration that is often appealed to in order to discriminate
between incomparable options is caution. The Maxmin-EU rule, for
instance, recommends picking the action with greatest minimum expected
utility (see Gilboa and Schmeidler 1989; Walley 1991). The rule is
simple to use, but arguably much too cautious, paying no attention at
all to the full spread of expected utilities. The \(\alpha\)-Maxmin
rule, by contrast, recommends taking the action with the greatest
\(\alpha\)-weighted sum of the minimum and maximum expected utilities
associated with it. The relative weights for the minimum and maximum
expected utilities can be thought of as reflecting either the decision
maker&rsquo;s pessimism in the face of uncertainty or else her degree
of caution (see Binmore 2009).</p>

<p>
There are more complicated choice rules that depend on a richer
representation of uncertainty involving a notion of
<em>confidence</em>. For instance, Klibanoff et al. (2005) propose a
rule whereby choices are made between otherwise incomparable options
on the basis of confidence-weighted expected utility. It presupposes
that weights can be assigned to the various expected utilities
associated with an act, reflecting the agent&rsquo;s confidence in the
corresponding probability and utility pairs. There are alternative
rules that appeal to confidence even in the absence of precise
cardinal weights. G&auml;rdenfors and Sahlin (1982), for instance,
suggest simply excluding from consideration any probability (and
utility) functions that fall below a confidence threshold, and then
applying the Maxmin-EU rule based on the remainder. Hill&rsquo;s
(2013) choice theory is somewhat similar, although confidence
thresholds for probability and utility pairs are allowed to vary
depending on the choice problem (and the term &ldquo;confidence&rdquo;
is itself used differently). There are further proposals whereby acts
are compared in terms of how much uncertainty they can tolerate (which
again depends on levels of confidence) and yet still be a satisfactory
option (see, e.g., Ben-Haim 2001). These rules are compelling, but
they do raise a host of difficult questions regarding how to interpret
and measure the extra subjective attitudes that play a role, like
&ldquo;amount of confidence in a belief/desire&rdquo; and
&ldquo;satisfactory level of desirability&rdquo;.</p>

<h3><a id="UnAw">5.3 Unawareness</a></h3>

<p>
There has been recent interest in yet a further challenge to expected
utility theory, namely, the challenge from <em>unawareness</em>. In
fact, unawareness presents a challenge for all extant normative
theories of choice. To keep things simple, we shall however focus on
Savage&rsquo;s expected utility theory to illustrate the challenge
posed by unawareness.</p>

<p>
As the reader will recall, Savage takes for granted a set of possible
outcomes \(\bO\), and another set of possible states of the world
\(\bS\), and defines the set of acts, \(\bF\), as the set of all
functions from \(\bS\) to \(\bO\). Moreover, his representation
theorem has been interpreted as justifying the claim that a rational
person always performs the act in \(\bF\) that maximises expected
utility, relative to a probability measure over \(\bS\) and a utility
measure over \(\bO\). </p>

<p>
Now, Savage&rsquo;s theory is neutral about how to interpret the
states in \(\bS\) and the outcomes in \(\bO\). For instance, the
theory is consistent with interpreting \(\bS\) and \(\bO\) as
respectively the sets of <em>all logically possible</em> states and
outcomes, but it is also consistent with interpreting \(\bS\) and
\(\bO\) as respectively the sets of states and outcomes <em>that some
modeller recognises</em>, or the sets of states and outcomes <em>that
the decision-maker herself recognises</em>. </p>

<p>
If the theory is meant to describe the reasoning of a decision-maker,
the first two interpretations would seem inferior to the third. The
problem with the first two interpretations is that the decision-maker
might be <em>unaware</em> of some of the logically possible states and
outcomes, as well as some of the states and outcomes that the modeller
is aware of. (Having said that, one may identify the states and
outcomes that the agent is unaware of by reference to those of which
the modeller is aware.)</p>

<p>
When it comes to (partially) unaware decision-makers, an important
distinction can be made between on the one hand what we might call
&ldquo;unawareness of unawareness&rdquo;&mdash;that is, a situation
where a decision-maker does not realise that there might be some
outcome or state that they are unaware of&mdash;and on the other hand
&ldquo;awareness of unawareness&rdquo;&mdash;that is, a situation
where a decision-maker at least suspects that there is some outcome or
state of which they are unaware. </p>

<p>
From the perspective of decision-making, unawareness of unawareness is
not of much interest. After all, if one is not even aware of the
possibility that one is unaware of some state or outcome, then that
unawareness cannot play any role in one&rsquo;s reasoning about what
to do. However, decision-theoretic models have been proposed for how a
rational person responds to <em>growth</em> in awareness (that is
meant to apply even to people who previously were unaware of their
unawareness). In particular, economists Karni and Vier&oslash; (2013,
2015) have recently extended standard Bayesian conditionalisation to
such learning events. Their theory, <em>Reverse Bayesianism</em>,
informally says that awareness growth should not affect the ratios of
probabilities of the states/outcomes that the agent was aware of
before the growth. Richard Bradley (2017) defends a similar principle
in the context of the more general Jeffrey-style framework, and so
does Roussos (2020); but the view is criticised by Steele and
Stef&aacute;nsson (forthcoming-a, forthcoming-b) and by Mahtani
(forthcoming).</p>

<p>
In contrast, awareness of unawareness would seem to be of great
interest from the perspective of decision-making. If you suspect that
there is some possible state, say, that you have not yet entertained,
and some corresponding outcome, the content of which you are unaware,
then you might want to at least come to some view about how likely you
expect this state to be, and how good or bad you expect the
corresponding outcome to be, before you make a decision.</p>

<p>
A number of people have suggested models to represent agents who are
aware of their unawareness (e.g., Walker &amp; Dietz 2013, Piermont
2017, Karni &amp; Vier&oslash; 2017). Steele and Stef&aacute;nsson
(forthcoming-b) argue that there may not be anything especially
distinctive about how a decision-maker reasons about states/outcomes
of which she is aware she is unaware, in terms of the confidence she
has in her judgments and how she manages risk. That said, the way she
arrives at such judgments of probability and desirability is worth
exploring further. Grant and Quiggin (2013a, 2013b), for instance,
suggest that these judgments are made based on induction from past
situations where one experienced awareness growth.</p>

<p>
In general, the literature on unawareness has been rapidly growing.
Bradley (2017) and Steele and Stef&aacute;nsson (forthcoming-b) are
new in-depth treatments of this topic within philosophy. Schipper
maintains a bibliography on unawareness, mostly with papers in
economics and computer science, at
\url{http://faculty.econ.ucdavis.edu/faculty/schipper/unaw.htm}. </p>

<h2><a id="SeqDec">6. Sequential decisions</a></h2>

<p>
The decision theories of Savage and Jeffrey, as well as those of their
critics, apparently concern a single or &ldquo;one shot only&rdquo;
decision; at issue is an agent&rsquo;s preference ordering, and
ultimately her choice of act, at a particular point in time. One may
refer to this as a <em>static</em> decision problem. The question
arises as to whether this framework is adequate for handling more
complex scenarios, in particular those involving a series or sequence
of decisions; these are referred to as <em>sequential</em> decision
problems.</p>

<p>
On paper, at least, static and sequential decision models look very
different. The static model has familiar tabular or <em>normal</em>
form, with each row representing an available act/option, and columns
representing the different possible states of the world that yield a
given outcome for each act. The sequential decision model, on the
other hand, has tree or <em>extensive</em> form (such as in
 <a href="#fig1">Figure 1</a>).
 It depicts a series of anticipated choice points, where the branches
extending from a choice point represent the options at that choice
point. Some of these branches lead to further choice points, often
after the resolution of some uncertainty due to new evidence.</p>

<p>
These basic differences between static and sequential decision models
raise questions about how, in fact, they relate to each other:</p>

<ul>

<li>

<p>
Do static and sequential decision models depict the same kind of
decision problem? If so, what is the static counterpart of a
sequential decision model?</p></li>

<li>

<p>
Does the sequential decision setting reveal any further
(dis)advantages of EU theory? More generally does this setting shed
light on normative theories of choice?</p></li>
</ul>

<p>
These questions turn out to be rather controversial. They will be
addressed in turn, after the scene has been set with an old story
about Ulysses.</p>

<h3><a id="WasUlyRat">6.1 Was Ulysses rational? </a></h3>

<p>
A well-known sequential decision problem is the one facing Ulysses on
his journey home to Ithaca in Homer&rsquo;s great tale from antiquity.
Ulysses must make a choice about the manner in which he will sail past
an island inhabited by sweet-singing sirens. He can choose to sail
unrestrained or else tied to the mast. In the former case, Ulysses
will later have the choice, upon hearing the sirens, to either
continue sailing home to Ithaca or to stay on the island indefinitely.
In the latter case, he will not be free to make further choices and
the ship will sail onwards to Ithaca past the sweet-singing sirens.
The final outcome depends on what sequence of choices Ulysses makes.
Ulysses&rsquo; decision problem is represented in tree (or extensive)
form in
 <a href="#fig1">Figure 1</a>
 (where the two boxes represent choice points for Ulysses).</p>

<div class="figure avoid-break" id="fig1">
<img src="dt-fig1.png" alt="" />

<p class="center">
<span class="figlabel">Figure 1.</span> Ulysses&rsquo; decision
problem</p>
</div>

<p>
We are told that, before embarking, Ulysses would most prefer to
freely hear the sirens and return home to Ithaca. The problem is that
Ulysses predicts his future self will not comply: if he sails
unrestrained, he will later be seduced by the sirens and will not in
fact continue home to Ithaca but will rather remain on the island
indefinitely. Ulysses therefore reasons that it would be better to be
tied to the mast, because he would prefer the shame and discomfort of
being tied to the mast and making it home to remaining on the
sirens&rsquo; island forever.</p>

<p>
It is hard to deny that Ulysses makes a wise choice in being tied to
the mast. Some hold, however, that Ulysses is nevertheless not an
exemplary agent, since his present self must play against his future
self who will be unwittingly seduced by the sirens. While Ulysses is
rational <em>at the first choice node</em> by static decision
standards, we might regard him irrational <em>overall</em> by
sequential decision standards, understood in terms of the relative
value of sequences of choices. The sequence of choices that Ulysses
inevitably pursues is, after all, suboptimal. It would have been
better were he able to sail unconstrained and continue on home to
Ithaca. This sequence could have been achieved if Ulysses were
continuously rational <em>over the extended time period</em>; say, if
at all times he were to act as an EU maximiser, and change his beliefs
and desires only in accordance with Bayesian norms (variants of
standard <em>conditionalisation</em>). On this reading, sequential
decision models introduce considerations of rationality-over-time.</p>

<p>
While rationality-over-time may have import in assessing an
agent&rsquo;s preferences and norms for changing these preferences
(one can read the discussion in
 <a href="#EUAxiRev">Section 6.2</a>
 below in this way), there remains the important question of how an
agent should act in light of her preferences at <em>any given point in
time</em>. To this end, the sequential decision model can be
fruitfully viewed as a tool for helping determine rational choice at a
particular time, just like the static decision model. The sequential
decision tree is effectively a way of visualising the temporal series
of choices and learning events that an agent <em>believes</em> she
will confront in the future, depending on what part of the decision
tree she will find herself. The key question, then, is: How should an
agent choose amongst her initial options in light of her projected
decision tree? This question has generated a surprising amount of
controversy. Three major approaches to negotiating sequential decision
trees have appeared in the literature. These are the
<em>na&iuml;ve</em> or <em>myopic</em> approach, the
<em>sophisticated</em> approach and the <em>resolute</em> approach.
These will be discussed in turn; it will be suggested that the
disputes may not be substantial but rather indicate subtle differences
in the interpretation of sequential decision models.</p>

<p>
The so-called na&iuml;ve approach to negotiating sequential decisions
serves as a useful contrast to the other two approaches. The
na&iuml;ve agent assumes that any path through the decision tree is
possible, and so sets off on whichever path is optimal, given his/her
present attitudes. For instance, a na&iuml;ve Ulysses would simply
presume that he has three overall strategies to choose from: either
ordering the crew to tie him to the mast, or issuing no such order and
later stopping at the sirens&rsquo; island, or issuing no such order
and later sticking to his course. Ulysses prefers the outcome
associated with the latter combination, and so he initiates this
strategy by not ordering the crew to restrain him. Table 5 presents
the static counterpart of na&iuml;ve Ulysses&rsquo; decision problem.
In effect, this decision model does not take into account
Ulysses&rsquo; present knowledge of his future preferences, and hence
advises that he pursue an option that is predicted to be
impossible.</p>

<div class="figure avoid-break">

<table class="cellpad-med-dense two-rules smaller">
<tr>
  <td>Act</td>
  <td>Outcome</td></tr>
<tr>
  <td>order tying to mast</td>
  <td>reach home, some humiliation</td></tr>
<tr>
  <td>sail unconstrained then stay with sirens </td>
  <td>life with sirens</td></tr>
<tr>
  <td>sail unconstrained then home to Ithaca </td>
  <td>reach home, no humiliation</td></tr>
</table>

<p class="center">
<span class="figlabel">Table 5.</span> Na&iuml;ve Ulysses&rsquo;
decision problem</p>
</div>

<p>
There is no need to labour the point that the na&iuml;ve approach to
sequential choice is aptly named. The hallmark of the sophisticated
approach, by contrast, is its emphasis on backwards planning: the
sophisticated chooser does not assume that all paths through the
decision tree, or in other words, all possible combinations of choices
at the various choice nodes, will be possible. The agent considers,
rather, what he/she will be inclined to choose at later choice nodes
when he/she gets to the temporal position in question. Sophisticated
Ulysses would take note of the fact that, if he reaches the island of
the sirens unrestrained, he will want to stop there indefinitely, due
to the transformative effect of the sirens&rsquo; song on his
preferences. This is then reflected in the static representation of
the decision problem, as per Table 6. The states here concern
Ulysses&rsquo; future preferences, once he reaches the island. Since
the second state has (by assumption) probability zero, the acts are
decided on the basis of the first state, so Ulysses wisely chooses to
be tied to the mast.</p>

<div class="figure avoid-break">

<table class="cellpad-med-dense two-rules smaller" id="table6">
<tr>
  <td>Act</td>
  <td>later choose sirens \( (p = 1)\)</td>
  <td>later choose Ithaca \( (p = 0)\)</td></tr>
<tr>
  <td>order tying to mast </td>
  <td>home, some humiliation </td>
  <td>home, some humiliation</td></tr>
<tr>
  <td>sail unconstrained </td>
  <td>life with sirens </td>
  <td>home, no humiliation</td></tr>
</table>

<p class="center">
<span class="figlabel">Table 6.</span> Sophisticated Ulysses&rsquo;
decision problem</p>
</div>

<p>
Resolute choice deviates from sophisticated choice only under certain
conditions that are not fulfilled by Ulysses, given his inexplicable
change in attitudes. Defenders of resolute choice typically defend
decision theories and associated preferences that violate the
Independence axiom/Sure-Thing Principle (notably McClennen 1990 and
Machina 1989; see also Rabinowicz 1995 and Buchak 2013 for
discussion), and appeal to resolute choice to make these preferences
more palatable in the sequential-decision context (to be discussed
further in
 <a href="#EUAxiRev">Section 6.2</a>
 below). According to resolute choice, in appropriate contexts, the
agent should at all choice points stick to the strategy that was
initially deemed best. The question is whether this advice makes
sense, given the standard interpretation of a sequential decision
model. What would it mean for an agent to choose against her
preferences in order to fulfill a previously-selected plan? That would
seem to defy the very notion of preference. Of course, an agent may
place considerable importance on honouring previous commitments. Any
such integrity concerns, however, should arguably be reflected in the
specification of outcomes and thus in the agent&rsquo;s preferences at
the time in question. This is quite different from choosing out of
step with one&rsquo;s all-things-considered preferences at a time.</p>

<p>
Defenders of resolute choice may have in mind a different
interpretation of sequential decision models, whereby future
&ldquo;choice points&rdquo; are not really points at which an agent is
free to choose according to her preferences at the time. If so, this
would amount to a subtle shift in the question or problem of interest.
In what follows, the standard interpretation of sequential decision
models will be assumed, and accordingly, it will be assumed that
rational agents pursue the sophisticated approach to choice (as per
Levi 1991, Maher 1992, Seidenfeld 1994, amongst others).</p>

<h3><a id="EUAxiRev">6.2 The EU axioms revisited</a></h3>

<p>
We have seen that sequential decision trees can help an agent like
Ulysses take stock of the consequences of his current choice, so that
he can better reflect on what to do <em>now</em>. The literature on
sequential choice is primarily concerned, however, with more ambitious
questions. The sequential-decision setting effectively offers new ways
to &ldquo;test&rdquo; theories of rational preference and norms for
preference (or belief and desire) change. The question is whether an
agent&rsquo;s decision theory in this broad sense is shown to be
<em>dynamically inconsistent</em> or self-defeating.</p>

<p>
Skyrms&rsquo; (1993) &ldquo;diachronic Dutch book&rdquo; argument for
conditionalisation can be read in this way. The agent is assumed to
have EU preferences and to take a sophisticated (backwards reasoning)
approach to sequential decision problems. Skyrms shows that any such
agent who plans to learn in a manner at odds with conditionalisation
will make self-defeating choices in some specially contrived
sequential decision situations. A conditionalising agent, by contrast,
will never make choices that are self-defeating in this way. The kind
of &ldquo;self-defeating choices&rdquo; at issue here are ones that
yield a sure loss. That is, the agent chooses a strategy that is
surely worse, by her own lights, than another strategy that she might
otherwise have chosen, if only her learning rule was such that she
would choose differently at one or more future decision nodes.</p>

<p>
A similar &ldquo;dynamic consistency&rdquo; argument can be used to
defend EU preferences in addition to learning in accordance with
conditionalisation (see Hammond 1976, 1977, 1988b,c). It is assumed,
as before, that the agent takes a sophisticated approach to sequential
decision problems. Hammond shows that only a fully Bayesian agent can
plan to pursue any path in a sequential decision tree that is deemed
optimal at the initial choice node. This makes the Bayesian agent
unique in that she will never make &ldquo;self-defeating
choices&rdquo; on account of her preferences and norms for preference
change. She will never choose a strategy that is worse by her own
lights than another strategy that she might otherwise have chosen, if
only her preferences were such that she would choose differently at
one or more future decision nodes.</p>

<p>
Hammond&rsquo;s argument for EU theory, and the notion of dynamic
consistency that it invokes, has been criticised from different
quarters, both by those who defend theories that violate the
Independence axiom but retain the Completeness and Transitivity (i.e.,
Ordering) axioms of EU theory, and those who defend theories that
violate the latter (for discussion, see Steele 2010). The approach
taken by some defenders of Independence-violating theories (notably,
Machina 1989 and McClennen 1990) has already been alluded to: They
reject the assumption of sophisticated choice underpinning the dynamic
consistency arguments. Seidenfeld (1988a,b, 1994, 2000a,b) rather
rejects Hammond&rsquo;s notion of dynamic consistency in favour of a
more subtle notion that discriminates between theories that violate
Ordering and those that violate Independence alone; the former, unlike
the latter, pass Seidenfeld&rsquo;s test that turns on future decision
nodes where the agent is indifferent between the best options. This
argument too is not without its critics (see McClennen 1988, Hammond
1988a, Rabinowicz 2000).</p>

<p>
Note that the costs of any departure from EU theory are well
highlighted by Al-Najjar and Weinstein (2009), in particular the
possibility of aversion to free information and aversion to
opportunities for greater choice in the future. Kadane et al. (2008)
and Bradley and Steele (2016) focus on the sure loss that is
associated with paying to avoid free evidence. But see Buchak (2010,
2013) for nuanced discussion of this issue in relation to epistemic
versus instrumental rationality.</p>

<h2><a id="ConRem">7. Concluding remarks</a></h2>

<p>
Let us conclude by summarising the main reasons why decision theory,
as described above, is of philosophical interest. First, normative
decision theory is clearly a (minimal) theory of <em>practical</em>
rationality. The aim is to characterise the attitudes of agents who
are practically rational, and various (static and sequential)
arguments are typically made to show that certain practical
catastrophes befall agents who do not satisfy standard
decision-theoretic constraints. Second, many of these constraints
concern the agents&rsquo; <em>beliefs</em>. In particular, normative
decision theory requires that agents&rsquo; degrees of beliefs satisfy
the probability axioms and that they respond to new information by
conditionalisation. Therefore, decision theory has great implications
for debates in epistemology and philosophy of science; that is, for
theories of <em>epistemic</em> rationality.</p>

<p>
Finally, decision theory should be of great interest to philosophers
of mind and psychology, and others who are interested in how people
can understand the behaviour and intentions of others; and, more
generally, how we can interpret what goes on in other people&rsquo;s
minds. Decision theorists typically assume that a person&rsquo;s
behaviour can be fully explained in terms of her beliefs and desires.
But perhaps more interestingly, some of the most important results of
decision theory&mdash;the various representation theorems, some of
which have discussed here&mdash;suggest that if a person satisfies
certain rationality requirements, then we can read her beliefs and
desires, and how strong these beliefs and desires are, from her choice
dispositions (or preferences). How much these theorems really tell us
is a matter of debate, as discussed above. But on an optimistic
reading of these results, they assure us that we can meaningfully talk
about what goes on in other people&rsquo;s minds without much evidence
beyond information about their dispositions to choose.</p>
</div>

<div id="bibliography">

<h2><a id="Bib">Bibliography</a></h2>

<ul class="hanging">

<li>Al-Najjar, Nabil I. and Jonathan Weinstein, 2009, &ldquo;The
Ambiguity Aversion Literature: A Critical Assessment&rdquo;,
<em>Economics and Philosophy</em>, 25: 249&ndash;284.
 [<a href="http://www.kellogg.northwestern.edu/faculty/alnajjar/papers/The_Ambiguity_Aversion_Literature_A_Critical_Assessment.pdf" target="other">al-Najjar and Weinstein 2009 available online (pdf)</a>]
 </li>

<li>Allais, Maurice, 1953, &ldquo;Le Comportement de l&rsquo;Homme
Rationnel devant le Risque: Critique des Postulats et Axiomes de
l&rsquo;Ecole Am&eacute;ricaine&rdquo;, <em>Econometrica</em>, 21:
503&ndash;546.</li>

<li>Alt, Franz, 1936, &ldquo;&Uuml;ber die Me&szlig;barkeit des
Nutzens&rdquo;, <em>Zeitschrift f&uuml;r National&ouml;konomie</em>,
7: 161&ndash;169.</li>

<li>Ben-Haim, Yakov, 2001, <em>Information-Gap Theory: Decisions Under
Severe Uncertainty</em>, London: Academic Press.</li>

<li>Berm&uacute;dez, Jos&eacute; Luis, 2009, <em>Challenges to
Decision Theory</em>, Oxford: Oxford University Press.</li>

<li>Binmore, Ken, 2009, <em>Rational Decisions</em>, Princeton:
Princeton University Press.</li>

<li>Bolker, Ethan D., 1966, &ldquo;Functions Resembling Quotients of
Measures&rdquo;, <em>Transactions of the American Mathematical
Society</em>, 124: 292&ndash;312.</li>

<li>&ndash;&ndash;&ndash;, 1967, &ldquo;A Simultaneous Axiomatisation
of Utility and Subjective Probability&rdquo;, <em>Philosophy of
Science</em>, 34: 333&ndash;340.</li>

<li>Bradley, Richard, 1998, &ldquo;A Representation Theorem for a
Decision Theory with Conditionals&rdquo;, <em>Synthese</em>, 116:
187&ndash;222</li>

<li>&ndash;&ndash;&ndash;, 2004, &ldquo;Ramsey&rsquo;s Representation
Theorem&rdquo;, <em>Dialectica</em>, 4: 484&ndash;497.</li>

<li>&ndash;&ndash;&ndash;, 2007, &ldquo;A Unified Bayesian Decision
Theory&rdquo;, <em>Theory and Decision</em>, 63: 233&ndash;263.</li>

<li>&ndash;&ndash;&ndash;, 2017, <em> Decision Theory with a Human
Face</em>, Cambridge: Cambridge University Press. </li>

<li>Bradley, Richard and H. Orri Stef&aacute;nsson, 2017,
&ldquo;Counterfactual Desirability&rdquo;, <em>British Journal for the
Philosophy of Science</em>, 68: 485&ndash;533.</li>

<li>&ndash;&ndash;&ndash;, 2016, &ldquo;Desire, Expectation and
Invariance&rdquo;, <em>Mind</em>, 125: 691&ndash;725.</li>

<li>Bradley, Seamus and Katie Steele, 2016, &ldquo;Can Free Evidence
be Bad? Value of Information for the Imprecise Probabilist&rdquo;,
<em>Philosophy of Science</em>, 83: 1&ndash;28.</li>

<li>Broome, John, 1991a, <em>Weighing Goods: Equality, Uncertainty and
Time</em>, Oxford: Blackwell.</li>

<li>&ndash;&ndash;&ndash;, 1991b, &ldquo;The Structure of Good:
Decision Theory and Ethics&rdquo;, in <em>Foundations of Decision
Theory</em>, Michael Bacharach and Susan Hurley (eds.), Oxford:
Blackwell, pp. 123&ndash;146.</li>

<li>&ndash;&ndash;&ndash;, 1991c, &ldquo;Desire, Belief and
Expectation&rdquo;, <em>Mind</em>, 100: 265&ndash;267.</li>

<li>&ndash;&ndash;&ndash;, 1993, &ldquo;Can a Humean be
moderate?&rdquo;, in <em>Value, Welfare and Morality</em>, G.R. Frey
and Christopher W. Morris (eds.), Cambridge: Cambridge University
Press. pp. 51&ndash;73.</li>

<li>Brown, Campbell, 2011, &ldquo;Consequentialize This&rdquo;,
<em>Ethics</em>, 121: 749&ndash;771.</li>

<li>Buchak, Lara, 2010, &ldquo;Instrumental rationality, epistemic
rationality, and evidence-gathering&rdquo;, <em>Philosophical
Perspectives</em>, 24: 85&ndash;120.</li>

<li>&ndash;&ndash;&ndash;, 2013, <em>Risk and Rationality</em>,
Oxford: Oxford University Press.</li>

<li>&ndash;&ndash;&ndash;, 2016, &ldquo;Decision Theory&rdquo;, in
<em>Oxford Handbook of Probability and Philosophy</em>, Christopher
Hitchcock and Alan H&aacute;jek (eds.), Oxford: Oxford University
Press, pp. 789&ndash;814.</li>

<li>Byrne, Alex and Alan H&aacute;jek, 1997, &ldquo;David Hume, David
Lewis, and Decision Theory&rdquo;, <em>Mind</em>, 106:
411&ndash;728.</li>

<li>Chang, Ruth, 2002, &ldquo;The Possibility of Parity&rdquo;,
<em>Ethics</em>, 112: 659&ndash;688.</li>

<li>Colyvan, Mark, Damian Cox, and Katie Steele, 2010,
&ldquo;Modelling the Moral Dimension of Decisions&rdquo;,
<em>No&ucirc;s</em>, 44: 503&ndash;529.</li>

<li>Davidson, Donald, J. C. C. McKinsey and Patrick Suppes, 1955,
&ldquo;Outlines of a Formal Theory of Value, I&rdquo;, <em>Philosophy
of Science</em>, 22: 140&ndash;160.</li>

<li>Dietrich, Franz and Christian List, 2013, &ldquo;A Reason-Based
Theory of Rational Choice&rdquo;, <em>No&ucirc;s</em>, 47:
104&ndash;134.</li>

<li>&ndash;&ndash;&ndash;, 2016a, &ldquo;Reason-Based Choice and
Context Dependence: An Explanatory Framework&rdquo;, <em>Economics and
Philosophy</em>, 32: 175&ndash;229.</li>

<li>&ndash;&ndash;&ndash;, 2016b, &ldquo;Mentalism Versus Behaviourism
in Economics: a Philosophy-of-Science Perspective&rdquo;,
<em>Economics and Philosophy</em>, 32: 249&ndash;281.</li>

<li>&ndash;&ndash;&ndash;, 2017, &ldquo;What Matters and How it
Matters: A Choice-Theoretic Representation of Moral Theories&rdquo;,
<em>The Philosophical Review</em>, 126: 421&ndash;479.</li>

<li>Dreier, James, 1996, &ldquo;Rational Preference: Decision Theory
as a Theory of Practical Rationality&rdquo;, <em>Theory and
Decision</em>, 40: 249&ndash;276.</li>

<li>&ndash;&ndash;&ndash;, 1993, &ldquo;Structures of Normative
Theories&rdquo;, <em>The Monist</em>, 76: 22&ndash;40.</li>

<li>Elster, Jon and John E. Roemer (eds.), 1993, <em>Interpersonal
Comparisons of Well-Being</em>, Cambridge: Cambridge University
Press.</li>

<li>Eriksson, Lina and Alan H&aacute;jek, 2007, &ldquo;What are Degrees
of Belief&rdquo;, <em>Studia Logica</em>, 86: 183&ndash;213.</li>

<li>G&auml;rdenfors, Peter and Nils-Eric Sahlin, 1982,
&ldquo;Unreliability Probabilities, Risk Taking, and Decision
Making&rdquo;, reprinted in P. G&auml;rdenfors and N.-E. Sahlin
(eds.), 1988, <em>Decision, Probability and Utility</em>, Cambridge:
Cambridge University Press, pp. 313&ndash;334.</li>

<li>Gaifman, Haim and Yang Liu, 2018, &ldquo;A Simpler and more
Realistic Subjective Decision Theory&rdquo;, <em>Synthese</em>, 195:
4205&ndash;4241.</li>

<li>Gilboa, Itzhak and David Schmeidler, 1989, &ldquo;Maxmin Expected
Utility With Non-Unique Prior&rdquo;, <em>Journal of Mathematical
Economics</em>, 18: 141&ndash;153.</li>

<li>Good, I.J., 1967, &ldquo;On the Principle of Total
Evidence&rdquo;, <em>British Journal for the Philosophy of
Science</em>, 17: 319&ndash;321.</li>

<li>Grant, Simon and John Quiggin, 2013a, &ldquo;Bounded Awareness,
Heuristics and the Precautionary Principle&rdquo;, <em>Journal of
Economic Behavior &amp; Organization</em>, 93: 17&ndash;31.</li>

<li>&ndash;&ndash;&ndash;, 2013b, &ldquo;Inductive Reasoning about
Unawareness&rdquo;, <em>Economic Theory</em>, 54: 717&ndash;755.</li>

<li>Guala, Francesco, 2006, &ldquo;Has Game Theory Been
Refuted?&rdquo;, <em>Journal of Philosophy</em>, 103:
239&ndash;263.</li>

<li>Gustafsson, Johan E., 2010, &ldquo;A Money-Pump for Acyclic
Intransitive Preferences&rdquo;, <em>Dialectica</em>, 64:
251&ndash;257.</li>

<li>&ndash;&ndash;&ndash;, 2013, &ldquo;The Irrelevance of the
Diachronic Money-Pump Argument for Acyclicity&rdquo;, <em>The Journal
of Philosophy</em>, 110: 460&ndash;464.</li>

<li>H&aacute;jek, Alan and Philip Pettit, 2004, &ldquo;Desire Beyond
Belief&rdquo;, <em>Australasian Journal of Philosophy</em>, 82:
77&ndash;92.</li>

<li>Halpern, Joseph Y., 2003, <em>Reasoning About Uncertainty</em>,
Cambridge, MA: MIT Press.</li>

<li>Hammond, Peter J., 1976, &ldquo;Changing Tastes and Coherent
Dynamic Choice&rdquo;, <em>The Review of Economic Studies</em>, 43:
159&ndash;173.</li>

<li>&ndash;&ndash;&ndash;, 1977, &ldquo;Dynamic Restrictions on
Metastatic Choice&rdquo;, <em>Economica</em>, 44: 337&ndash;350.</li>

<li>&ndash;&ndash;&ndash;, 1988a, &ldquo;Orderly Decision Theory: A
Comment on Professor Seidenfeld&rdquo;, <em>Economics and
Philosophy</em>, 4: 292&ndash;297.</li>

<li>&ndash;&ndash;&ndash;, 1988b, &ldquo;Consequentialism and the
Independence Axiom&rdquo;, in <em>Risk, Decision and Rationality</em>,
B. R. Munier (ed.), Dordrecht: D. Reidel, pp. 503&ndash;516. </li>

<li>&ndash;&ndash;&ndash;, 1988c, &ldquo;Consequentialist Foundations
for Expected Utility Theory&rdquo;, <em>Theory and Decision</em>, 25:
25&ndash;78.</li>

<li>Hansson, Bengt, 1988, &ldquo;Risk Aversion as a Problem of
Conjoint Measurement&rdquo;, in <em>Decision, Probability and
Utility</em>, P. G&auml;rdenfors and N.-E. Sahlin (ed.), Cambridge:
Cambridge University Press, pp. 136&ndash;158. </li>

<li>Hausman, Daniel M., 2011a, &ldquo;Mistakes about Preferences in
the Social Sciences&rdquo;, <em>Philosophy of the Social
Sciences</em>, 41: 3&ndash;25.</li>

<li>&ndash;&ndash;&ndash;, 2011b, <em>Preference, Value, Choice, and
Welfare</em>, Cambridge: Cambridge University Press.</li>

<li>Heap, Shaun Hargreaves, Martin Hollis, Bruce Lyons, Robert Sugden,
and Albert Weale, 1992, <em>The Theory of Choice: A Critical
Introduction</em>, Oxford: Blackwell Publishers.</li>

<li>Hill, Brian, 2013, &ldquo;Confidence and Decision&rdquo;,
<em>Games and Economic Behaviour</em>, 82: 675&ndash;692.</li>

<li>Jackson, Frank and Michael Smith, 2006, &ldquo;Absolutist Moral
Theories and Uncertainty&rdquo;, <em>The Journal of Philosophy</em>,
103: 267&ndash;283.</li>

<li>Jeffrey, Richard C., 1965, <em>The Logic of Decision</em>, New
York: McGraw-Hill.</li>

<li>&ndash;&ndash;&ndash;, 1974, &ldquo;Preferences Among
Preferences&rdquo;, <em>The Journal of Philosophy</em>, 71:
377&ndash;391.</li>

<li>&ndash;&ndash;&ndash;, 1983, &ldquo;Bayesianism With a Human
Face&rdquo;, in <em>Testing Scientific Theories</em>, John Earman
(ed.), Minneapolis: University of Minnesota Press, pp.
133&ndash;156.</li>

<li>Joyce, James M., 1998, &ldquo;A Non-Pragmatic Vindication of
Probabilism&rdquo;, <em>Philosophy of Science</em>, 65:
575&ndash;603.</li>

<li>&ndash;&ndash;&ndash;, 1999, <em>The Foundations of Causal
Decision Theory</em>, New York: Cambridge University Press.</li>

<li>&ndash;&ndash;&ndash;, 2002, &ldquo;Levi on Causal Decision Theory
and the Possibility of Predicting one&rsquo;s Own Actions&rdquo;,
<em>Philosophical Studies</em>, 110: 69&ndash;102.</li>

<li>&ndash;&ndash;&ndash;, 2010, &ldquo;A Defense of Imprecise
Credences in Inference and Decision Making&rdquo;, <em>Philosophical
Perspectives</em>, 24: 281&ndash;323.</li>

<li>Kadane, Joseph B., Mark J. Schervish, and Teddy Seidenfeld, 2008,
&ldquo;Is Ignorance Bliss?&rdquo;, <em>The Journal of Philosophy</em>,
105: 5&ndash;36.</li>

<li>Karni, Edi and Marie-Louise Vier&oslash;, 2013,
&ldquo;&lsquo;Reverse Bayesianism&rsquo;: A Choice-Based Theory of
Growing Awareness&rdquo;, <em>American Economic Review</em>, 103:
2790&ndash;2810.</li>

<li>&ndash;&ndash;&ndash;, 2015, &ldquo;Probabilistic Sophistication
and Reverse Bayesianism&rdquo;, <em>Journal of Risk and
Uncertainty</em>, 50: 189&ndash;208.</li>

<li>&ndash;&ndash;&ndash;, 2017, &ldquo;Awareness of Unawareness: A
Theory of Decision Making in the Face of Ignorance&rdquo;, <em>Journal
of Economic Theory</em>, 168: 301&ndash;325.</li>

<li>Keeney, Ralph L. and Howard Raiffa, 1993, <em>Decisions with
Multiple Objectives: Preferences and Value Tradeoffs</em>, Cambridge:
Cambridge University Press.</li>

<li>Klibanoff, Peter, Massimo Marinacci, and Sujoy Mukerji, 2005,
&ldquo;A Smooth Model of Decision Making Under Ambiguity&rdquo;,
<em>Econometrica</em>, 73: 1849&ndash;1892.</li>

<li>Knight, Frank, 1921, <em>Risk, Uncertainty, and Profit</em>,
Boston: Houghton Mifflin Company.</li>

<li>Koopmans, Tjalling C., 1960, &ldquo;Stationary Ordinal Utility and
Impatience&rdquo;, <em>Econometrica</em>, 28: 287&ndash;309.</li>

<li>Kreps, David M., 1988, <em>Notes on the Theory of Choice</em>,
Boulder: Westview Press.</li>

<li>Lazar, Seth, 2017, &ldquo;Deontological Decision Theory and
Agent-Centred Options&rdquo;, <em>Ethics</em>, 127:
579&ndash;609.</li>

<li>Levi, Isaac, 1986, <em>Hard Choices: Decision Making Under
Unresolved Conflict</em>, Cambridge: Cambridge University Press.</li>

<li>&ndash;&ndash;&ndash;, 1991, &ldquo;Consequentialism and
Sequential Choice&rdquo;, in <em>Foundations of Decision Theory</em>,
M. Bacharach and S. Hurley (eds.), Oxford: Basil Blackwell, pp.
70&ndash;101.</li>

<li>Lewis, David, 1988, &ldquo;Desire as Belief&rdquo;, <em>Mind</em>,
97: 323&ndash;332.</li>

<li>&ndash;&ndash;&ndash;, 1996, &ldquo;Desire as Belief II&rdquo;,
<em>Mind</em>, 105: 303&ndash;313.</li>

<li>Loomes, Graham and Robert Sugden, 1982, &ldquo;Regret Theory: An
Alternative Theory of Rational Choice Under Uncertainty&rdquo;,
<em>The Economic Journal</em>, 92: 805&ndash;824.</li>

<li>Louise, Jennie, 2004, &ldquo;Relativity of Value and the
Consequentialist Umbrella&rdquo;, <em>Philosophical Quarterly</em>, 4:
518&ndash;536.</li>

<li>Machina, Mark J., 1989, &ldquo;Dynamic Consistency and
Non-Expected Utility Models of Choice Under Uncertainty&rdquo;,
<em>Journal of Economic Literature</em>, 27: 1622&ndash;1668.</li>

<li>Maher, Patrick, 1992, &ldquo;Diachronic Rationality&rdquo;,
<em>Philosophy of Science</em>, 59: 120&ndash;141.</li>

<li>Mahtani, Anna, forthcoming, &ldquo;Awareness Growth and
Dispositional Attitudes&rdquo;, <em>Synthese</em>.</li>

<li>Mandler, Michael, 2001, &ldquo;A Difficult Choice in Preference
Theory: Rationality Implies Completeness or Transitivity but Not
Both&rdquo;, in <em>Varieties of Practical Reasoning</em>, Elijah
Millgram (ed.), Cambridge, MA: MIT Press, pp. 373&ndash;402.</li>

<li>McClennen, Edward F., 1988, &ldquo;Ordering and Independence: A
Comment on Professor Seidenfeld&rdquo;, <em>Economics and
Philosophy</em>, 4: 298&ndash;308.</li>

<li>&ndash;&ndash;&ndash;, 1990, <em>Rationality and Dynamic Choice:
Foundational Explorations</em>. Cambridge: Cambridge University
Press.</li>

<li>Meacham, Patrick, Christopher J. G. and Jonathan Weisberg, 2011,
&ldquo;Representation Theorems and the Foundations of Decision
Theory&rdquo;, <em>Australasian Journal of Philosophy</em>, 89:
641&ndash;663.</li>

<li>Peterson, Martin, 2009, <em>An Introduction to Decision
Theory</em>, Cambridge: Cambridge University Press.</li>

<li>Pettit, Philip, 1993, &ldquo;Decision Theory and Folk
Psychology&rdquo;, in <em>Foundations of Decision Theory: Issues and
Advances</em>, Michael Bacharach and Susan Hurley (eds.), Oxford:
Blackwell, pp. 147&ndash;175.</li>

<li>Piermont, Evan, 2017, &ldquo;Introspective Unawareness and
Observable Choice&rdquo;, <em>Games and Economic Behavior</em>, 106:
134&ndash;152.</li>

<li>Portmore, Douglas W., 2007, &ldquo;Consequentializing Moral
Theories&rdquo;, <em>Pacific Philosophical Quarterly</em>, 88:
39&ndash;73.</li>

<li>Rabin, Matthew, 2000, &ldquo;Risk Aversion and Expected-Utility
Theory: A Calibration Theorem&rdquo;, <em>Econometrica</em>, 68:
1281&ndash;1292.</li>

<li>Rabinowicz, Wlodek, 1995, &ldquo;To Have one&rsquo;s Cake and Eat
it, Too: Sequential Choice and Expected-Utility Violations&rdquo;,
<em>Journal of Philosophy</em>, 92: 586&ndash;620.</li>

<li>&ndash;&ndash;&ndash;, 2000, &ldquo;Preference Stability and
Substitution of Indifferents: A rejoinder to Seidenfeld&rdquo;,
<em>Theory and Decision</em>, 48: 311&ndash;318.</li>

<li>&ndash;&ndash;&ndash;, 2002, &ldquo;Does Practical Deliberation
Crowd out Self-Prediction?&rdquo;, <em>Erkenntnis</em>, 57:
91&ndash;122.</li>

<li>Ramsey, Frank P., 1926 [1931], &ldquo;Truth and Probability&rdquo;,
in <em>The Foundations of Mathematics and other Logical Essays</em>,
R.B. Braithwaite (ed.), London: Kegan, Paul, Trench, Trubner &amp;
Co., pp. 156&ndash;198.</li>

<li>&ndash;&ndash;&ndash;, 1928, &ldquo;A Mathematical Theory of
Saving&rdquo;, <em>The Economic Journal</em>, 38: 543&ndash;559.</li>

<li>&ndash;&ndash;&ndash;, 1990, &ldquo;Weight of the Value of
Knowledge&rdquo;, <em>British Journal for the Philosophy of
Science</em>, 41: 1&ndash;4.</li>

<li>Resnik, Michael D., 1987, <em>Choices: An Introduction to Decision
Theory</em>, Minneapolis: University of Minnesota Press.</li>

<li>Rinard, Susanna, 2017, &ldquo;No Exception for Belief&rdquo;,
<em>Philosophy and Phenomenological Research</em>, 94:
121&ndash;143.</li>

<li>Roussos, Joe, 2020, <em>Policymaking Under Scientific
Uncertainty</em>, Ph.D. thesis, London School of Economics and
Political Science.</li>

<li>Savage, Leonard J., 1954, <em>The Foundations of Statistics</em>,
New York: John Wiley and Sons.</li>

<li>Schervish, Mark J., Teddy Seidenfeld, Joseph B. Kadane, and Isaac
Levi, 2003, &ldquo;Extensions of Expected Utility Theory and Some
Limitations of Pairwise Comparisons&rdquo;, <em>Proceedings of the
Third ISIPTA (JM)</em>: 496&ndash;510.</li>

<li>Seidenfeld, Teddy, 1988a, &ldquo;Decision Theory Without
&lsquo;Independence&rsquo; or Without &lsquo;Ordering&rsquo;&rdquo;,
<em>Economics and Philosophy</em>, 4: 309&ndash;315.</li>

<li>&ndash;&ndash;&ndash;, 1988b, &ldquo;Rejoinder [to Hammond and
McClennen]&rdquo;, <em>Economics and Philosophy</em>, 4:
309&ndash;315.</li>

<li>&ndash;&ndash;&ndash;, 1994, &ldquo;When Normal and Extensive Form
Decisions Differ&rdquo;, <em>Logic, Methodology and Philosophy of
Science</em>, IX: 451&ndash;463.</li>

<li>&ndash;&ndash;&ndash;, 2000a, &ldquo;Substitution of Indifferent
Options at Choice Nodes and Admissibility: A Reply to
Rabinowicz&rdquo;, <em>Theory and Decision</em>, 48:
305&ndash;310.</li>

<li>&ndash;&ndash;&ndash;, 2000b, &ldquo;The Independence Postulate,
Hypothetical and Called-off Acts: A Further Reply to
Rabinowicz&rdquo;, <em>Theory and Decision</em>, 48:
319&ndash;322.</li>

<li>Sen, Amartya, 1973, &ldquo;Behaviour and the Concept of
Preference&rdquo;, <em>Economica</em>, 40: 241&ndash;259.</li>

<li>&ndash;&ndash;&ndash;, 1977, &ldquo;Rational Fools: A Critique of
the Behavioural Foundations of Economic Theory&rdquo;, <em>Philosophy
and Public Affairs</em>, 6: 317&ndash;344.</li>

<li>&ndash;&ndash;&ndash;, 1982, &ldquo;Rights and Agency&rdquo;,
<em>Philosophy and Public Affairs</em>, 11: 3&ndash;39.</li>

<li>Skyrms, Brian, 1993, &ldquo;A Mistake in Dynamic Coherence
Arguments?&rdquo;, <em>Philosophy of Science</em>, 60:
320&ndash;328.</li>

<li>Stalnaker, Robert C., 1987, <em>Inquiry</em>, Cambridge, MA: MIT
Press.</li>

<li>Steele, Katie S., 2010, &ldquo;What are the Minimal Requirements
of Rational Choice?: Arguments from the Sequential-Decision
Setting&rdquo;, <em>Theory and Decision</em>, 68: 463&ndash;487.</li>

<li>Steele, Katie S. and H. Orri Stef&aacute;nsson, forthcoming-a,
&ldquo;Belief Revision for Growing Awareness&rdquo;,
<em>Mind</em>.</li>

<li>&ndash;&ndash;&ndash;, forthcoming-b, <em>Beyond Uncertainty:
Reasoning with Unknown Possibilities</em>, Martin Peterson (ed.),
Cambridge University Press.</li>

<li>Stef&aacute;nsson, H. Orri, 2014, &ldquo;Desires, Beliefs and
Conditional Desirability&rdquo;, <em>Synthese</em>, 191:
4019&ndash;4035.</li>

<li>Stef&aacute;nsson, H. Orri and Richard Bradley, 2019, &ldquo;What
is Risk Aversion?&rdquo;, <em>British Journal for the Philosophy of
Science</em>, 70: 77&ndash;102.</li>

<li>Suppes, Patrick, 2002, <em>Representation and Invariance of
Scientific Structures</em>, Stanford: CSLI Publications.</li>

<li>Temkin, Larry, 2012, <em>Rethinking the Good: Moral Ideals and the
Nature of Practical Reasoning</em>, Oxford: Oxford University
Press.</li>

<li>Thoma, Johanna, 2020a, &ldquo;Instrumental Rationality
Without Separability&rdquo;, <em>Erkenntnis</em>, 85: 1219&ndash;1240.
doi:10.1007/s10670-018-0074-9</li>

<li>&ndash;&ndash;&ndash;, 2020b, &ldquo;In Defense of Revealed
Preference Theory&rdquo;, <em>Economics and Philosophy</em>, 
1-25. doi:10.1017/S0266267120000073</li>

<li>Tversky, Amos, 1975, &ldquo;A Critique of Expected Utility Theory:
Descriptive and Normative Considerations&rdquo;, <em>Erkenntnis</em>,
9: 163&ndash;173.</li>

<li>Villegas, C., 1964, &ldquo;On Qualitative Probability
\(\sigma\)-Algebras&rdquo;, <em>Annals of Mathematical
Statistics</em>, 35: 1787&ndash;1796.</li>

<li>Vallentyne, Peter, 1988, &ldquo;Gimmicky Representations of Moral
Theories&rdquo;, <em>Metaphilosophy</em>, 19: 253&ndash;263.</li>

<li>Vredenburgh, Kate, 2020, &ldquo;A Unificationist Defence of
Revealed Preferences&rdquo;, <em>Economics and Philosophy</em>, 
36(1): 149&ndash;169. doi:10.1017/S0266267118000524</li>

<li>von Neumann, John and Oskar Morgenstern, 1944, <em>Theory of Games
and Economic Behavior</em>, Princeton: Princeton University
Press.</li>

<li>Walley, Peter, 1991, <em>Statistical Reasoning with Imprecise
Probabilities</em>, New York: Chapman and Hall.</li>

<li>Walker, Oliver and Simon Dietz, 2011, &ldquo;A Representation
Result for Choice Under Conscious Unawareness&rdquo;, Grantham
Research Institute on Climate Change and the Environment, Working
Paper No. 59.</li>

<li>Zynda, Lyle, 2000, &ldquo;Representation Theorems and Realism
about Degrees of Belief&rdquo;, <em>Philosophy of Science</em>, 67:
45&ndash;69.</li>
</ul>
</div> 
<div id="academic-tools">

<h2 id="Aca">Academic Tools</h2>

<blockquote>
<table class="vert-top">
<tr>
<td><img src="../../symbols/sepman-icon.jpg" alt="sep man icon" /></td>
<td><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=decision-theory" target="other">How to cite this entry</a>.</td>
</tr>

<tr>
<td><img src="../../symbols/sepman-icon.jpg" alt="sep man icon" /></td>
<td><a href="https://leibniz.stanford.edu/friends/preview/decision-theory/" target="other">Preview the PDF version of this entry</a> at the
 <a href="https://leibniz.stanford.edu/friends/" target="other">Friends of the SEP Society</a>.</td>
</tr>

<tr>
<td><img src="../../symbols/inpho.png" alt="inpho icon" /></td>
<td><a href="https://www.inphoproject.org/entity?sep=decision-theory&amp;redirect=True" target="other">Look up topics and thinkers related to this entry</a>
 at the Internet Philosophy Ontology Project (InPhO).</td>
</tr>

<tr>
<td><img src="../../symbols/pp.gif" alt="phil papers icon" /></td>
<td><a href="https://philpapers.org/sep/decision-theory/" target="other">Enhanced bibliography for this entry</a>
at <a href="https://philpapers.org/" target="other">PhilPapers</a>, with links to its database.</td>
</tr>

</table>
</blockquote>
</div>

<div id="other-internet-resources">

<h2><a id="Oth">Other Internet Resources</a></h2>

<ul>

<li>Bradley, Richard, 2014,
 <em><a href="http://personal.lse.ac.uk/bradleyr/pdf/Handbook - Decision theory (revised).pdf" target="other">Decision Theory: A Formal Philosophical Introduction</a></em>.</li>
 
<li>Hansson, Sven Ove, 1994,
 <em><a href="http://people.kth.se/~soh/decisiontheory.pdf" target="other">Decision Theory: A Brief Introduction</a></em>.</li>
 </ul>
</div>

<div id="related-entries">

<h2><a id="Rel">Related Entries</a></h2>

<p>

 <a href="../decision-causal/index.html">decision theory: causal</a> |
 <a href="../epistemic-utility/index.html">epistemic utility arguments for probabilism</a> |
 <a href="../possible-worlds/index.html">possible worlds</a> |
 <a href="../imprecise-probabilities/index.html">probabilities, imprecise</a> |
 <a href="../probability-interpret/index.html">probability, interpretations of</a> |
 <a href="../rationality-normative-utility/index.html">rational choice, normative: expected utility</a> |
 <a href="../social-choice/index.html">social choice theory</a> |
 <a href="../statistics/index.html">statistics, philosophy of</a>

</p>

</div>

<script type="text/javascript" src="local.js"></script>
<script type="text/javascript" src="../../MathJax/MathJaxb198.js?config=TeX-MML-AM_CHTML"></script>

</div><!-- #aueditable --><!--DO NOT MODIFY THIS LINE AND BELOW-->

<!-- END ARTICLE HTML -->

</div> <!-- End article-content -->

  <div id="article-copyright">
    <p>
 <a href="../../info.html#c">Copyright &copy; 2020</a> by

<br />
<a href="http://philosophy.cass.anu.edu.au/people/katie-steele" target="other">Katie Steele</a>
&lt;<a href="m&#97;ilto:katie&#37;2esteele&#37;40anu&#37;2eedu&#37;2eau"><em>katie<abbr title=" dot ">&#46;</abbr>steele<abbr title=" at ">&#64;</abbr>anu<abbr title=" dot ">&#46;</abbr>edu<abbr title=" dot ">&#46;</abbr>au</em></a>&gt;<br />
<a href="http://orristefansson.is/" target="other">H. Orri Stef&aacute;nsson</a>
&lt;<a href="m&#97;ilto:orri&#37;2estefansson&#37;40philosophy&#37;2esu&#37;2ese"><em>orri<abbr title=" dot ">&#46;</abbr>stefansson<abbr title=" at ">&#64;</abbr>philosophy<abbr title=" dot ">&#46;</abbr>su<abbr title=" dot ">&#46;</abbr>se</em></a>&gt;
    </p>
  </div>

</div> <!-- End article -->

<!-- NOTE: article banner is outside of the id="article" div. -->
<div id="article-banner" class="scroll-block">
  <div id="article-banner-content">
    <a href="../../fundraising/index.html">
    Open access to the SEP is made possible by a world-wide funding initiative.<br />
    The Encyclopedia Now Needs Your Support<br />
    Please Read How You Can Help Keep the Encyclopedia Free</a>
  </div>
</div> <!-- End article-banner -->

    </div> <!-- End content -->

    <div id="footer">

      <div id="footer-menu">
        <div class="menu-block">
          <h4><i class="icon-book"></i> Browse</h4>
          <ul role="menu">
            <li><a href="../../contents.html">Table of Contents</a></li>
            <li><a href="../../new.html">What's New</a></li>
            <li><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/random">Random Entry</a></li>
            <li><a href="../../published.html">Chronological</a></li>
            <li><a href="../../archives/index.html">Archives</a></li>
          </ul>
        </div>
        <div class="menu-block">
          <h4><i class="icon-info-sign"></i> About</h4>
          <ul role="menu">
            <li><a href="../../info.html">Editorial Information</a></li>
            <li><a href="../../about.html">About the SEP</a></li>
            <li><a href="../../board.html">Editorial Board</a></li>
            <li><a href="../../cite.html">How to Cite the SEP</a></li>
            <li><a href="../../special-characters.html">Special Characters</a></li>
            <li><a href="../../tools/index.html">Advanced Tools</a></li>
            <li><a href="../../contact.html">Contact</a></li>
          </ul>
        </div>
        <div class="menu-block">
          <h4><i class="icon-leaf"></i> Support SEP</h4>
          <ul role="menu">
            <li><a href="../../support/index.html">Support the SEP</a></li>
            <li><a href="../../support/friends.html">PDFs for SEP Friends</a></li>
            <li><a href="../../support/donate.html">Make a Donation</a></li>
            <li><a href="../../support/sepia.html">SEPIA for Libraries</a></li>
          </ul>
        </div>
      </div> <!-- End footer menu -->

      <div id="mirrors">
        <div id="mirror-info">
          <h4><i class="icon-globe"></i> Mirror Sites</h4>
          <p>View this site from another server:</p>
        </div>
        <div class="btn-group open">
          <a class="btn dropdown-toggle" data-toggle="dropdown" href="https://plato.stanford.edu/">
            <span class="flag flag-usa"></span> USA (Main Site) <span class="caret"></span>
            <span class="mirror-source">Philosophy, Stanford University</span>
          </a>
          <ul class="dropdown-menu">
            <li><a href="../../mirrors.html">Info about mirror sites</a></li>
          </ul>
        </div>
      </div> <!-- End mirrors -->
      
      <div id="site-credits">
        <p>The Stanford Encyclopedia of Philosophy is <a href="../../info.html#c">copyright &copy; 2021</a> by <a href="http://mally.stanford.edu/">The Metaphysics Research Lab</a>, Department of Philosophy, Stanford University</p>
        <p>Library of Congress Catalog Data: ISSN 1095-5054</p>
      </div> <!-- End site credits -->

    </div> <!-- End footer -->

  </div> <!-- End container -->

   <!-- NOTE: Script required for drop-down button to work (mirrors). -->
  <script>
    $('.dropdown-toggle').dropdown();
  </script>

</body>

<!-- Mirrored from seop.illc.uva.nl/entries/decision-theory/ by HTTrack Website Copier/3.x [XR&CO'2014], Wed, 22 Jun 2022 19:44:09 GMT -->
</html>
