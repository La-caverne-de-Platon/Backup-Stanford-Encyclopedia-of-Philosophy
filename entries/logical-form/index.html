<!DOCTYPE html>
<!--[if lt IE 7]> <html class="ie6 ie"> <![endif]-->
<!--[if IE 7]>    <html class="ie7 ie"> <![endif]-->
<!--[if IE 8]>    <html class="ie8 ie"> <![endif]-->
<!--[if IE 9]>    <html class="ie9 ie"> <![endif]-->
<!--[if !IE]> --> <html> <!-- <![endif]-->

<!-- Mirrored from seop.illc.uva.nl/entries/logical-form/ by HTTrack Website Copier/3.x [XR&CO'2014], Wed, 22 Jun 2022 19:52:18 GMT -->
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>
Logical Form (Stanford Encyclopedia of Philosophy)
</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="robots" content="noarchive, noodp" />
<meta property="citation_title" content="Logical Form" />
<meta property="citation_author" content="Pietroski, Paul" />
<meta property="citation_publication_date" content="1999/10/19" />
<meta name="DC.title" content="Logical Form" />
<meta name="DC.creator" content="Pietroski, Paul" />
<meta name="DCTERMS.issued" content="1999-10-19" />
<meta name="DCTERMS.modified" content="2021-09-01" />

<!-- NOTE: Import webfonts using this link: -->
<link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,300,600,200&amp;subset=latin,latin-ext" rel="stylesheet" type="text/css" />

<link rel="stylesheet" type="text/css" media="screen,handheld" href="../../css/bootstrap.min.css" />
<link rel="stylesheet" type="text/css" media="screen,handheld" href="../../css/bootstrap-responsive.min.css" />
<link rel="stylesheet" type="text/css" href="../../css/font-awesome.min.css" />
<!--[if IE 7]> <link rel="stylesheet" type="text/css" href="../../css/font-awesome-ie7.min.css"> <![endif]-->
<link rel="stylesheet" type="text/css" media="screen,handheld" href="../../css/style.css" />
<link rel="stylesheet" type="text/css" media="print" href="../../css/print.css" />
<link rel="stylesheet" type="text/css" href="../../css/entry.css" />
<!--[if IE]> <link rel="stylesheet" type="text/css" href="../../css/ie.css" /> <![endif]-->
<script type="text/javascript" src="../../js/jquery-1.9.1.min.js"></script>
<script type="text/javascript" src="../../js/bootstrap.min.js"></script>

<!-- NOTE: Javascript for sticky behavior needed on article and ToC pages -->
<script type="text/javascript" src="../../js/jquery-scrolltofixed-min.js"></script>
<script type="text/javascript" src="../../js/entry.js"></script>

<!-- SEP custom script -->
<script type="text/javascript" src="../../js/sep.js"></script>
</head>

<!-- NOTE: The nojs class is removed from the page if javascript is enabled. Otherwise, it drives the display when there is no javascript. -->
<body class="nojs article" id="pagetopright">
<div id="container">
<div id="header-wrapper">
  <div id="header">
    <div id="branding">
      <div id="site-logo"><a href="../../index.html"><img src="../../symbols/sep-man-red.png" alt="SEP logo" /></a></div>
      <div id="site-title"><a href="../../index.html">Stanford Encyclopedia of Philosophy</a></div>
    </div>
    <div id="navigation">
      <div class="navbar">
        <div class="navbar-inner">
          <div class="container">
            <button class="btn btn-navbar collapsed" data-target=".collapse-main-menu" data-toggle="collapse" type="button"> <i class="icon-reorder"></i> Menu </button>
            <div class="nav-collapse collapse-main-menu in collapse">
              <ul class="nav">
                <li class="dropdown open"><a id="drop1" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-book"></i> Browse</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop1">
                    <li><a href="../../contents.html">Table of Contents</a></li>
                    <li><a href="../../new.html">What's New</a></li>
                    <li><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/random">Random Entry</a></li>
                    <li><a href="../../published.html">Chronological</a></li>
                    <li><a href="../../archives/index.html">Archives</a></li>
                  </ul>
                </li>
                <li class="dropdown open"><a id="drop2" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-info-sign"></i> About</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop2">
                    <li><a href="../../info.html">Editorial Information</a></li>
                    <li><a href="../../about.html">About the SEP</a></li>
                    <li><a href="../../board.html">Editorial Board</a></li>
                    <li><a href="../../cite.html">How to Cite the SEP</a></li>
                    <li><a href="../../special-characters.html">Special Characters</a></li>
                    <li><a href="../../tools/index.html">Advanced Tools</a></li>
                    <li><a href="../../contact.html">Contact</a></li>
                  </ul>
                </li>
                <li class="dropdown open"><a id="drop3" href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"><i class="icon-leaf"></i> Support SEP</a>
                  <ul class="dropdown-menu" role="menu" aria-labelledby="drop3">
                    <li><a href="../../support/index.html">Support the SEP</a></li>
                    <li><a href="../../support/friends.html">PDFs for SEP Friends</a></li>
                    <li><a href="../../support/donate.html">Make a Donation</a></li>
                    <li><a href="../../support/sepia.html">SEPIA for Libraries</a></li>
                  </ul>
                </li>
              </ul>
            </div>
          </div>
        </div>
      </div>
    </div>
    <!-- End navigation -->
    
    <div id="search">
      <form id="search-form" method="get" action="https://seop.illc.uva.nl/search/searcher.py">
        <input type="search" name="query" placeholder="Search SEP" />
        <div class="search-btn-wrapper"><button class="btn search-btn" type="submit"><i class="icon-search"></i></button></div>
      </form>
    </div>
    <!-- End search --> 
    
  </div>
  <!-- End header --> 
</div>
<!-- End header wrapper -->

<div id="content">

<!-- Begin article sidebar -->
<div id="article-sidebar" class="sticky">
  <div class="navbar">
    <div class="navbar-inner">
      <div class="container">
        <button class="btn btn-navbar" data-target=".collapse-sidebar" data-toggle="collapse" type="button"> <i class="icon-reorder"></i> Entry Navigation </button>
        <div id="article-nav" class="nav-collapse collapse-sidebar in collapse">
          <ul class="nav">
            <li><a href="#toc">Entry Contents</a></li>
            <li><a href="#Bib">Bibliography</a></li>
            <li><a href="#Aca">Academic Tools</a></li>
            <li><a href="https://leibniz.stanford.edu/friends/preview/logical-form/">Friends PDF Preview <i class="icon-external-link"></i></a></li>
            <li><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=logical-form">Author and Citation Info <i class="icon-external-link"></i></a> </li>
            <li><a href="#pagetopright" class="back-to-top">Back to Top <i class="icon-angle-up icon2x"></i></a></li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</div>
<!-- End article sidebar --> 

<!-- NOTE: Article content must have two wrapper divs: id="article" and id="article-content" -->
<div id="article">
<div id="article-content">

<!-- BEGIN ARTICLE HTML -->


<div id="aueditable"><!--DO NOT MODIFY THIS LINE AND ABOVE-->

<div id="preamble">

<h1>Logical Form</h1><div id="pubinfo"><em>First published Tue Oct 19, 1999; substantive revision Wed Sep 1, 2021</em></div>

<p>
Some inferences are impeccable. Examples like (1&ndash;3) illustrate
reasoning that cannot lead from true premises to false
conclusions.</p>

<dl class="sentag tag3em">
<dt>(1)</dt>
<dd>John danced if Mary sang, and Mary sang; so John
danced.</dd>

<dt>(2)</dt>
<dd>Every politician is deceitful, and every senator is
a politician; so every senator is deceitful.</dd>

<dt>(3)</dt>
<dd>The detective is in the garden; so someone is in
the garden.</dd>
</dl>

<p>
In such cases, a thinker takes no epistemic risk by endorsing the
<em>conditional</em> claim that the conclusion is true <em>if</em> the
premises are true. The conclusion follows from the premises, without
any further assumptions that might turn out to be false. Any risk of
error lies with the premises, as opposed to the reasoning. By
contrast, examples like (4&ndash;6) illustrate reasoning that involves
at least some risk of going wrong&mdash;from correct premises to a
mistaken conclusion.</p>

<dl class="sentag tag3em">
<dt>(4)</dt>
<dd>John danced if Mary sang, and John danced; so Mary
sang.</dd>

<dt>(5)</dt>
<dd>Every feathered biped is a bird, and Tweety is a
feathered biped; so Tweety can fly.</dd>

<dt>(6)</dt>
<dd>Every human born before 1879 died; so every human
will die.</dd>
</dl>


<p>
Inference (4) is not secure. John might dance whenever Mary sings, but
also sometimes when Mary doesn&rsquo;t sing. Similarly, with regard to
(5), Tweety might be a bird that cannot fly. Even (6) falls short of
the demonstrative character exhibited by (1&ndash;3). While laws of
nature may preclude immortality, the conclusion of (6) goes beyond its
premise, even if it is foolish to resist the inference.</p>

<p>
Appeals to logical form arose in the context of attempts to say more
about this intuitive distinction between impeccable inferences, which
invite metaphors of security, and inferences that involve some risk of
slipping from truth to falsity. The idea is that some inferences, like
(1&ndash;3), are <em>structured</em> in a way that confines any risk
of error to the premises. The motivations for developing this idea
were both practical and theoretical. Experience teaches us that an
inference can initially seem more secure than it is; and if we knew
which <em>forms</em> of inference are risk-free, that might help us
avoid errors. As we&rsquo;ll see, claims about inference are also
intimately connected with claims about the nature of thought and its
relation to language.</p>

<p>
Many philosophers have been especially interested in the possibility
that grammar <em>masks</em> the underlying structure of thought,
perhaps in ways that invite mistaken views about how ordinary language
is related to cognition and the world we talk about. For example,
similarities across sentences like &lsquo;Homer talked&rsquo;,
&lsquo;Nobody talked&rsquo;, and &lsquo;The nymph talked&rsquo;
initially suggest that the corresponding thoughts exhibit a common
subject-predicate form. But even if &lsquo;Homer&rsquo; indicates an
entity that can be the subject of a thought that is true if and only
if the entity in question talked, &lsquo;Nobody&rsquo; does not; and
as we&rsquo;ll see, &lsquo;The&rsquo; is complicated. Philosophers and
linguists have also asked general questions about how logic is related
to grammar. Do thoughts and sentences exhibit different <em>kinds</em>
of structure? Do sentences exhibit <em>grammatical</em> structures
that are not obvious? And if the logical structure of a thought can
diverge from the grammatical structure of a sentence that is used to
express the thought, how should we construe proposals about the
logical forms of inferences like (1)&ndash;(6)? Are such proposals
normative claims about how we ought to think/talk, or empirical
hypotheses about aspects of psychological/linguistic reality?</p>

<p>
Proposed answers to these questions are usually interwoven with claims
about why various inferences seem compelling. So it would be nice to
know which inferences really are secure, and in virtue of what these
inferences are special. The most common suggestion has been that
certain inferences are secure by virtue of their logical form. Though
unsurprisingly, conceptions of form have evolved along with
conceptions of logic and language.</p>
</div>

<div id="toc"><!--Entry Contents-->
<ul>
	<li><a href="#pat">1. Patterns of Reason</a></li>
	<li><a href="#prop">2. Propositions and Traditional Grammar</a></li>
	<li><a href="#mot">3. Motivations for Revision</a></li>
	<li><a href="#freg">4. Frege and Formal Language</a></li>
	<li><a href="#des">5. Descriptions and Analysis</a></li>
	<li><a href="#reg">6. Regimentation and Communicative Slack </a></li>
	<li><a href="#not">7. Notation and Restricted Quantification</a></li>
	<li><a href="#tran">8. Transformational Grammar</a></li>
	<li><a href="#sem">9. Semantic Structure and Events</a></li>
	<li><a href="#fq">10. Further Questions</a></li>
	<li><a href="#Bib">Bibliography</a></li>
	<li><a href="#Aca">Academic Tools</a></li>
	<li><a href="#Oth">Other Internet Resources</a></li>
	<li><a href="#Rel">Related Entries</a></li>
</ul>
<!--Entry Contents-->

<hr />

</div>

<div id="main-text">

<h2><a name="pat">1. Patterns of Reason</a></h2>

<p>
One ancient idea is that impeccable inferences exhibit patterns that
can be characterized schematically by abstracting away from the
specific contents of particular premises and conclusions, thereby
revealing a general form common to many other impeccable inferences.
Such forms, along with the inferences that exemplify them, are said to
be valid.</p>

<p>
Given a valid inference, there is a sense in which the premises
contain the conclusion, which is correspondingly extractable from the
premises. With regard to (1) and (7), it seems especially clear that
the conclusion is part of the first premise, and that the second
premise is another part of the first.</p>

<dl class="sentag tag3em">
<dt>(1)</dt>
<dd>John danced if Mary sang, and Mary sang; so John
danced.</dd>

<dt>(7)</dt>
<dd>Chris swam if Pat was asleep, and Pat was asleep;
so Chris swam.</dd>
</dl>

<p>
We can express this point by saying that these inferences are
instances of the following form: <strong>B</strong> if
<strong>A</strong>, and <strong>A</strong>; so <strong>B</strong>. The
 <a href="../stoicism/index.html">Stoics</a>
 discussed several patterns of this kind, using ordinal numbers
(instead of letters) to capture abstract forms like the ones shown
below.</p>

<div class="indent">

<p>
If <strong>the first</strong> then <strong>the second</strong>, and
<strong>the first</strong>; so <strong>the second</strong>.</p>

<p>
If <strong>the first</strong> then <strong>the second</strong>, but
not <strong>the second</strong>; so not <strong>the
first</strong>.</p>

<p>
Either <strong>the first</strong> or <strong>the second</strong>, but
not <strong>the second</strong>; so <strong>the first</strong>.</p>

<p>
Not both <strong>the first</strong> and <strong>the second</strong>,
but <strong>the first</strong>; so not <strong>the
second</strong>.</p>
</div>

<p>
These schematic formulations employ variables, indicated in bold.
Following a long tradition, let&rsquo;s use the word
&lsquo;proposition&rsquo; as a term of art for whatever these
variables range over.
 <a href="../propositions/index.html">Propositions</a>
 are potential premises/conclusions, which can be endorsed or
rejected. So they are, presumably, things that can be evaluated for
truth or falsity. This leaves room for various proposals about what
propositions are: sentences, statements, states of affairs, etc. But
let&rsquo;s assume that declarative sentences can be used to express
propositions; see, e.g., Cartwright (1962) and the essay on
 <a href="../propositions-structured/index.html">structured propositions</a>.</p>

<p>
A significant complication is that in ordinary conversation, the
context matters with regard to which proposition is expressed with a
given sentence. For example, &lsquo;Pat is asleep&rsquo; can be used
at one time to express a true premise, and at another time to express
a false premise. A certain speaker might use &lsquo;I am tired&rsquo;
to express a false proposition, while another speaker uses the same
sentence at the same time to express a true proposition. What counts
as being tired can also vary across conversations. Context
sensitivity, of various kinds, is ubiquitous in typical discourse.
Moreover, even given a context, a sentence like &lsquo;He is
bald&rsquo; may not express a unique proposition. (There may be no
referent for the pronoun; and even if there is, the
 <a href="../vagueness/index.html">vagueness</a>
 of &lsquo;bald&rsquo; may yield a range of candidate propositions,
with no fact of the matter as to which one is <em>the</em> proposition
expressed.) Still, we can and often do use sentences like &lsquo;Every
circle is an ellipse&rsquo; and &lsquo;Thirteen is a prime
number&rsquo; to express premises of valid arguments. To be sure,
mathematical examples are special cases. But the distinction between
impeccable and risky inferences is not limited to atypical contexts in
which we try to think especially clearly about especially abstract
matters. So when focusing on the phenomenon of valid inference, we can
try to simplify the initial discussion by abstracting away from the
context sensitivity of language use.</p>

<p>
Another complication is that in speaking of an inference, one might be
talking about (i) a process in which a thinker draws a conclusion from
some premises, or (ii) some propositions, one of which is designated
as an alleged consequence of the others; see, e.g., Harman (1973). But
we can describe a risky thought process as one in which a thinker who
accepts certain propositions&mdash;perhaps tentatively or
hypothetically&mdash;comes to accept, on that basis, a proposition
that does not follow from the initial premises. And it will be simpler
to focus on premises/conclusions, as opposed to episodes of
reasoning.</p>

<p>
With regard to (1), the inference seems secure in part
<em>because</em> its first premise has the form
&lsquo;<strong>B</strong> if <strong>A</strong>&rsquo;.</p>

<dl class="sentag tag3em">
<dt>(1)</dt>
<dd>John danced if Mary sang, and Mary sang; so John
danced.</dd>
</dl>

<p>
If the first premise didn&rsquo;t have this form, the inference
wouldn&rsquo;t be an instance of &lsquo;<strong>B</strong> if
<strong>A</strong>, and <strong>A</strong>; so
<strong>B</strong>&rsquo;. It isn&rsquo;t obvious that <em>all</em>
impeccable inferences are instances of a more general valid form, much
less inferences whose impeccability is due to the forms of the
relevant propositions. But this thought has served as an ideal for the
study of valid inference, at least since Aristotle&rsquo;s treatment
of examples like (2).</p>

<dl class="sentag tag3em">
<dt>(2)</dt>
<dd>Every senator is a politician, and every politician
is deceitful; so every senator is deceitful.</dd>
</dl>

<p>
Again, the first premise seems to have several parts, each of which is
a part of the second premise or the conclusion. (In English, the
indefinite article in &lsquo;Every senator is a politician&rsquo;
cannot be omitted; likewise for &lsquo;Every politician is a
liar&rsquo;. But at least for now, let&rsquo;s assume that in examples
like these, &lsquo;a&rsquo; does not itself indicate a propositional
constituent.)
 <a href="../aristotle/index.html">Aristotle</a>,
 predating the Stoics, noted that conditional claims like the
following are sure to be true: if (the property of) being a politician
belongs to every senator, and being deceitful belongs to every
politician, then being deceitful belongs to every senator.
Correspondingly, the inference pattern below is valid.</p>

<p class="indent">
Every <em>S</em> is <em>P</em>, and every <em>P</em> is <em>D</em>; so
every <em>S</em> is <em>D</em>.
</p>

<p>
And inference (2) seems to be valid because its parts exhibit this
pattern. Aristotle discussed many such forms of inference, called
syllogisms, involving propositions that can be expressed with
quantificational words like &lsquo;every&rsquo; and
&lsquo;some&rsquo;. For example, the syllogistic patterns below are
also valid.</p>

<div class="indent">

<p>
Every <em>S</em> is <em>P</em>, and some <em>S</em> is <em>D</em>; so
some <em>P</em> is <em>D</em>.</p>

<p>
Some <em>S</em> is <em>P</em>, and every <em>P</em> is <em>D</em>; so
some<em> S</em> is <em>D</em>.</p>

<p>
Some <em>S</em> is not <em>P</em>, every <em>D</em> is <em>P</em>; so
some <em>S</em> is not <em>D</em>.</p>
</div>

<p>
We can rewrite the last two, so that each of the valid syllogisms
above is represented as having a first premise of the form
&lsquo;Every <em>S</em> is <em>P</em>&rsquo;.</p>

<div class="indent">

<p>
Every <em>S</em> is <em>P</em>, and some <em>D</em> is <em>S</em>; so
some <em>D</em> is <em>P</em>.</p>

<p>
Every <em>S</em> is <em>P</em>, and some <em>D</em> is not <em>P</em>;
so some <em>D</em> is not <em>S</em>.</p>
</div>

<p>
But however the inferences are represented, the important point is
that the variables&mdash;represented here in italics&mdash;range over
certain <em>parts</em> of propositions. Intuitively, common nouns like
&lsquo;politician&rsquo; and adjectives like &lsquo;deceitful&rsquo;
are general terms, since they can apply to more than one individual.
And many propositions apparently contain correspondingly general
elements. For example, the proposition that every senator is wealthy
contains two such elements, both relevant to the validity of
inferences involving this proposition.</p>

<p>
Propositions thus seem to have structure that bears on the validity of
inferences, even ignoring premises/conclusions with propositional
parts. In this sense, even atomic propositions have logical form. And
as Aristotle noted, pairs of such propositions can be related in
interesting ways. If every <em>S</em> is <em>P</em>, then some
<em>S</em> is <em>P</em>. (For these purposes, assume there is at
least one <em>S</em>.) If no <em>S</em> is <em>P</em>, then some
<em>S</em> is not <em>P</em>. It is certain that either every
<em>S</em> is <em>P</em> or some <em>S</em> is not <em>P</em>; and
whichever of these propositions is true, the other is false.
Similarly, the following propositions cannot both be true: every
<em>S</em> is <em>P</em>; and no <em>S</em> is <em>P</em>. But it
isn&rsquo;t certain that either every <em>S</em> is <em>P</em>, or no
<em>S</em> is <em>P</em>. Perhaps some <em>S</em> is <em>P</em>, and
some <em>S</em> is not <em>P</em>. This network of logical relations
strongly suggests that the propositions in question contain a
quantificational element and two general elements&mdash;and in some
cases, an element of negation; see
 <a href="../logic-classical/index.html">logic: classical</a>.
 This raises the question of whether other propositions have a similar
structure.</p>

<h2><a name="prop"> 2. Propositions and Traditional Grammar</a></h2>

<p>
Consider the proposition that Vega is a star, which can figure in
inferences like (8).</p>

<dl class="sentag tag3em">
<dt>(8)</dt>
<dd>Every star is purple, and Vega is a star; so Vega
is purple.</dd>
</dl>

<p>
Aristotle&rsquo;s logic focused on quantificational propositions; and
as we shall see, this was prescient. But on his view, propositions
like the conclusion of (8) still exemplify a subject-predicate
structure that is shared by at least many of the sentences we used to
express propositions. And one can easily formulate the schema
&lsquo;every <em>S</em> is <em>P</em>, and <em>n</em> is <em>S</em>;
so <em>n</em> is <em>P</em>&rsquo;, where the new lower-case variable
is intended to range over proposition-parts of the sort indicated by
names. (On some views, discussed below, a name like &lsquo;Vega&rsquo;
is a complex quantificational expression; though unsurprisingly, such
views are tendentious.)</p>

<p>
Typically, a declarative sentence can be divided into a subject and a
predicate: &lsquo;Every star / is purple&rsquo;, &lsquo;Vega / is a
star&rsquo;, &lsquo;Some politician / lied&rsquo;, &lsquo;The
brightest planet / is visible tonight&rsquo;, etc. Until quite
recently, it was widely held that this grammatical division reflects a
corresponding kind of logical structure: the subject of a proposition
(i.e., what the proposition is about) is a target for predication. On
this view, both &lsquo;Every star&rsquo; and &lsquo;Vega&rsquo;
indicate subjects of propositions in (8), while &lsquo;is&rsquo;
introduces predicates. Aristotle would have said that in the premises
of (8), being purple is predicated of every star, and being a star is
predicated of Vega. Later theorists emphasized the contrast between
general terms like &lsquo;star&rsquo; and singular terms like
&lsquo;Vega&rsquo;, while also distinguishing terms from
syncategorematic expressions (e.g., &lsquo;every&rsquo; and
&lsquo;is&rsquo;) that can combine with terms to form complex subjects
and predicates, including &lsquo;will lie&rsquo;, &lsquo;can
lie&rsquo;, and &lsquo;may have lied&rsquo;. But despite the
complications, it seemed clear that many propositions have the
following canonical form: Subject-copula-Predicate; where a copula
links a subject, which may consist of a quantifier and a general term,
to a general term. Sentences like &lsquo;Every star twinkles&rsquo;
can be paraphrased with sentences like &lsquo;Every star is a
twinkling thing&rsquo;. This invites the suggestion that
&lsquo;twinkles&rsquo; is somehow an abbreviation for &lsquo;is a
twinkling thing&rsquo;.</p>

<p>
The proposition that not only Vega twinkles, which seems to contain
the proposition that Vega twinkles, presumably includes elements that
are indicated with &lsquo;only&rsquo; and &lsquo;not&rsquo;. Such
examples invite the hypothesis that all propositions are composed of
terms along with a relatively small number of syncategorematic
elements, and that complex propositions can be reduced to canonical
propositions that are governed by Aristotelian logic. This is not to
say that all propositions were, or could be, successfully analyzed in
this manner. But via this strategy, medieval logicians were able to
describe many impeccable infereces as instances of valid forms. And
this informed their discussions of how logic is related to
grammar.</p>

<p>
Many viewed their project as an attempt to uncover principles of a
mental language common to all thinkers. Aristotle had said, similarly,
that spoken sounds symbolize &ldquo;affections of the soul.&rdquo;
From this perspective, one expects to find some differences between
propositions and overt sentences. If &lsquo;Every star twinkles&rsquo;
expresses a proposition that contains a copula, then spoken languages
mask certain aspects of logical structure.
 <a href="../ockham/index.html">William of Ockham</a>
 held that a mental language would have no need for Latin&rsquo;s
declensions, and that logicians could ignore such aspects of spoken
language. The ancient Greeks were aware of sophisms like the
following: that dog is a father, and that dog is yours; so that dog is
your father. This bad inference cannot share its form with the
superficially parallel but impeccable variant: that dog is a mutt, and
that mutt is yours; so that dog is your mutt. (See Plato, Euthydemus
298 d-e.) So the superficial features of sentences are not infallible
guides to the logical forms of propositions. Still, the divergence was
held to be relatively minor. Spoken sentences have structure; they are
composed, in systematic ways, of words. And the assumption was that
spoken sentences reflect the major aspects of propositional form,
including a subject-predicate division. So while there is a
distinction between the study of valid inference and the study of
sentences used in spoken language, the connection between logic and
grammar was thought to run deep. This suggested that the logical form
of a proposition just is the grammatical form of some (perhaps mental)
sentence.</p>

<h2><a name="mot">3. Motivations for Revision</a></h2>

<p>
Towards the end of the eighteenth century, Kant could say (without
much exaggeration) that logic had followed a single path since its
inception, and that &ldquo;since Aristotle it has not had to retrace a
single step.&rdquo; He also said that syllogistic logic was &ldquo;to
all appearance complete and perfect.&rdquo; But this was exuberance.
The successes also highlighted problems that had been recognized.</p>

<p>
Some valid schemata are reducible to others, in that any inference of
the reducible form can be revealed as valid (with a little work) given
other schemata. Consider (9).</p>

<dl class="sentag tag3em">
<dt>(9)</dt>
<dd>If Al ran then either Al did not run or Bob did not
swim, and Al ran; so Bob did not swim.</dd>
</dl>

<p>
Assume that &lsquo;Al did not run&rsquo; negates &lsquo;Al ran&rsquo;,
while &lsquo;Bob did not swim&rsquo; negates &lsquo;Bob swam&rsquo;.
Then (9) is an instance of the following valid form: if
<strong>A</strong> then either not-<strong>A</strong> or
not-<strong>B</strong>, and <strong>A</strong>; so
not-<strong>B</strong>. But we can treat this as a derived form, by
showing that any instance of this form is valid given two (intuitively
more basic) Stoic inference forms: if <strong>the first </strong>then
<strong>the second</strong>, and<strong> the first</strong>, so
<strong>the second</strong>; either not<strong> the first </strong>or
not <strong>the second</strong>, and <strong>the first</strong>; so
not <strong>the second</strong>. For suppose we are given the
following premises: <strong>A</strong>; and if <strong>A</strong>,
then either not-<strong>A</strong> or not-<strong>B</strong>. We can
safely infer that either not-<strong>A</strong> or
not-<strong>B</strong>; and since we were given <strong>A</strong>, we
can safely infer not-<strong>B</strong>. Similarly, the syllogistic
schema (10) can be treated as a derived form.</p>

<dl class="sentag tag3em">
<dt>(10)</dt>
<dd>Some <em>S</em> is not <em>P</em>, and every
<em>D</em> is <em>P</em>; so not every <em>S</em> is <em>D</em>.</dd>
</dl>

<p>
If some <em>S</em> is not <em>P</em>, and every <em>D</em> is
<em>P</em>, then it isn&rsquo;t true that every <em>S</em> is
<em>D</em>. For if every <em>S</em> is <em>D</em>, and every
<em>D</em> is <em>P</em>, then every<em> S</em> is <em>P</em>. But
<em>if </em>some <em>S</em> is not <em>P</em>, then as we saw above,
not every <em>S</em> is <em>P</em>. So given the premises of (10),
adding &lsquo;every<em> S</em> is <em>D</em>&rsquo; would lead to
contradiction: every<em> S</em> is <em>P</em>, and not every<em>
S</em> is <em>P</em>. So the premises imply the <em>negation</em> of
&lsquo;every<em> S</em> is <em>D</em>&rsquo;. This reasoning shows how
(10) can be reduced to inferential patterns that seem more
basic&mdash;raising the question of how much reduction is possible.
Euclid&rsquo;s geometry had provided a model for how to present a body
of knowledge as a network of propositions that follow from a few basic
axioms. Aristotle himself indicated how to reduce all the valid
syllogistic schemata to four basic patterns, given a few principles
that govern how the basic patterns can be used to derive others; see
Parsons (2014) for discussion. And further reduction is possible given
insights from the medieval period.</p>

<p>
Consider the following pair of valid inferences: Fido is a brown dog,
so Fido is a dog; Fido is not a dog, so Fido is not a brown dog. As
illustrated with the first example, replacing a predicate (or general
term) like &lsquo;brown dog&rsquo; with a <em>less</em> restrictive
predicate like &lsquo;dog&rsquo; is often valid. But
sometimes&mdash;paradigmatically, in cases involving
negation&mdash;replacing a predicate like &lsquo;dog&rsquo; with a
<em>more</em> restrictive predicate like &lsquo;brown dog&rsquo; is
valid. Plausibly, the first pattern reflects the default direction of
valid replacement: removing a restriction preserves truth, except in
special cases like those involving negation. Suppose we take it as
given that poodles are dogs of a particular sort, and hence that every
poodle is a dog. Then replacing&lsquo;poodle&rsquo; with
&lsquo;dog&rsquo; in &lsquo;Fido is <em>P</em>&rsquo; is valid,
regardless of what &lsquo;Fido&rsquo; names. This can be viewed as a
special case of &lsquo;<em>n</em> is <em>P</em>, and every <em>P</em>
is <em>D</em>; so <em>n</em> is <em>D</em>&rsquo;. But the validity of
this inference form can also be viewed as symptom of a basic principle
that came be called <em>dictum de omni</em>: whatever is true of every
<em>P</em> is true of any <em>P</em>. Or as Aristotle might have put
it, if the property of being a dog belongs to every poodle, then it
belongs to any poodle. In which case, Fido is a dog if Fido is a
poodle. And since the property of being a dog surely belongs to every
brown dog, any brown dog is a dog. The flip side of this point is that
negation inverts the default direction of inference. Anything that
isn&rsquo;t a dog isn&rsquo;t a brown dog; and similarly, if Fido
isn&rsquo;t a dog, then Fido isn&rsquo;t a poodle. So in special
cases, adding a restriction to a general term like &lsquo;dog&rsquo;
can preserve truth.</p>

<p>
From this perspective, the Aristotelian quantifier &lsquo;Some&rsquo;
is a default-style quantifier that validates <em>removing</em>
restrictions. If some brown dog is a clever mutt, it follows that some
dog is a clever mutt, and hence that some dog is a mutt. By contrast,
&lsquo;No&rsquo; is an inverted-style quantifier that validates
<em>adding </em>restrictions. If no dog is a mutt, it follows that no
dog is a clever mutt, and hence that no brown dog is a clever mutt.
The corresponding principle, <em>dictum de nullo</em>, encodes this
pattern: whatever is true of no <em>P</em> is not true of any
<em>P</em>; so if the property of being a mutt belongs to no dog, it
belongs to no poodle. (And as Aristotle noted, instances of &lsquo;No
<em>S</em> is <em>P</em>&rsquo; can be analyzed as the propositional
negations of corresponding instances of &lsquo;Some <em>S</em>
isn&rsquo;t <em>P</em>&rsquo;.)</p>

<p>
Interestingly, &lsquo;Every&rsquo; is like &lsquo;No&rsquo; in one
respect, and like &lsquo;Some&rsquo; in another respect. If every dog
is clever, it follows that every brown dog is clever; but if every dog
is a clever mutt, it follows that every dog is a mutt. So when the
universal quantifier combines with a general term <em>S</em> to form a
subject, <em>S</em> is governed by the <em>inverted</em> rule of
replacement. But when a universally quantified subject combines with a
second general term to form a proposition, this second term is
governed by the <em>default </em>rule of replacement. Given that
&lsquo;Every&rsquo; has this mixed logical character, the valid
syllogisms can be derived from two basic patterns (noted above), both
of which reflect <em>dictum de omni</em>: whatever is true of every
<em>P</em> is true of any <em>P</em>.</p>

<div class="indent">

<p>
Every <em>S</em> is <em>P</em>, and every <em>P</em> is <em>D</em>; so
every <em>S</em> is <em>D</em>.</p>

<p>
Every <em>S</em> is <em>P</em>, and some <em>D</em> is <em>S</em>; so
some <em>D</em> is <em>P</em>.</p>
</div>

<p>
The first principle reflects the sense in which universal
quantification is transitive. The second principle captures the idea
that the universal premise can license replacement of
&lsquo;<em>S</em>&rsquo; with &lsquo;<em>P</em>&rsquo; in a
proposition about some individual. In this sense, classical logic
exhibits a striking unity and simplicity, at least with regard to
inferences involving the Aristotelian quantifiers and predication. For
further discussion, see Sommers (1984), van Bentham (1986), Sanchez
(1991, 1994), and Ludlow (2005).</p>

<p>
Alas, matters become more complicated once we consider relations.</p>

<p>
Sentences like &lsquo;Juliet kissed Romeo&rsquo; do not seem to have
Subject-copula-Predicate form. One might suggest &lsquo;Juliet was a
kisser of Romeo&rsquo; as a paraphrase. But &lsquo;kisser of
Romeo&rsquo; differs, in ways that matter to inference, from general
terms like &lsquo;politician&rsquo;. If Juliet (or anyone) was a
kisser of Romeo, it follows that someone was kissed; whereas if Juliet
was a politician, there is no corresponding logical consequence to the
effect that someone was __-ed. Put another way, the proposition that
Juliet kissed someone exhibits interesting logical structure, even if
we can express this proposition via the sentence &lsquo;Juliet was a
kisser of someone&rsquo;. A quantifier can be part of a complex
predicate. But classical logic did not capture the validity of
inferences involving predicates that have quantificational
constituents. Consider (11).</p>

<dl class="sentag tag3em">
<dt>(11)</dt>
<dd>Some patient respects every doctor, and some doctor
is a liar; so some patient respects some liar.</dd>
</dl>

<p>
If &lsquo;respects every doctor&rsquo; and &lsquo;respects some
liar&rsquo; indicate nonrelational proposition-parts, much like
&lsquo;is sick&rsquo; or &lsquo;is happy&rsquo;, then inference (11)
has the following form &lsquo;Some <em>P</em> is <em>S</em>, and some
<em>D</em> is <em>L</em>; so some <em>P</em> is <em>H</em>&rsquo;. But
this schema, which fails to reflect the quantificational structure
within the predicates is not valid. Its instances include bad
inferences like the following: some patient is sick, and some doctor
is a liar; so some patient is happy. This dramatizes the point that
&lsquo;respects every doctor&rsquo; and &lsquo;respects some
liar&rsquo; are&mdash;unlike &lsquo;is sick&rsquo; and &lsquo;is
tall&rsquo;&mdash;logically related in a way that matters given the
second premise of (11).</p>

<p>
One can adopt the view that many propositions have relational parts,
introducing a variable &lsquo;<u>R</u>&rsquo; intended to range over
relations; see the entries on
 <a href="../relations-medieval/index.html">medieval relations</a>,
 and
 <a href="../medieval-terms/index.html">medieval terms</a>.
 One can also formulate the following schema: some <em>P</em> <u>R</u>
every <em>D</em>, and some <em>D</em> is <em>L</em>; so some
<em>P</em> <u>R</u> some <em>L</em>. But the problem remains.
Quantifiers can appear in complex predicates that figure in valid
inferences like (12).</p>

<dl class="sentag tag3em">
<dt>(12)</dt>
<dd>Every patient who respects every doctor is sick,
and
<br />
some patient who saw every lawyer respects every doctor; so
<br />
some patient who saw every lawyer is sick.</dd>
</dl>

<p>
But if &lsquo;patient who respects every doctor&rsquo; and
&lsquo;patient who saw every lawyer&rsquo; are nonrelational, much
like &lsquo;old patient&rsquo; or &lsquo;young patient&rsquo;, then
(12) has the following form: every <em>O</em> is <em>S</em>, and some
<em>Y</em> <u>R</u> every <em>D</em>; so some <em>Y</em> is
<em>S</em>. And many inferences of this form are invalid. For example:
every otter is sick, and some yak respects every doctor; so some yak
is sick. Again, one can abstract a valid schema that covers (12),
letting parentheses indicate a relative clause that restricts the
adjacent predicate.</p>

<p class="indent">
Every <em>P</em>(<u>R1</u> every <em>D</em>) is <em>S</em>, and some
<em>P</em>(<u>R2</u> every <em>L</em>) <u>R1</u> every <em>D</em>; so
some <em>P</em>(<u>R2</u> every <em>L</em>) is <em>S</em>.
</p>

<p>
But no matter how complex the schema, the relevant predicates can
exhibit further quantificational structure. (Consider the proposition
that every patient<em> who met some doctor who saw no lawyer</em>
respects some lawyer<em> who saw no patient who met every
doctor</em>.) Moreover, schemata like the one above are poor
candidates for basic inference patterns.</p>

<p>
As medieval logicians knew, propositions expressed with relative
clauses also pose other difficulties; see the entry on
 <a href="../medieval-syllogism/index.html">medieval syllogism</a>.
 If every doctor is healthy, it follows that every young doctor is
healthy. By itself, this is expected, since a universally quantified
subject licenses replacement of &lsquo;doctor&rsquo; with the more
restrictive predicate &lsquo;young doctor&rsquo;. But consider (13)
and (14).</p>

<dl class="sentag tag3em">
<dt>(13)</dt>
<dd>No patient who saw every young doctor is
healthy.</dd>

<dt>(14)</dt>
<dd>No patient who saw every doctor is healthy.</dd>
</dl>

<p>
Here, the direction of valid inference is from &lsquo;young
doctor&rsquo; to &lsquo;doctor&rsquo;, as if the inference is governed
by the (default) inference rule that licenses replacement of
&lsquo;young doctor&rsquo; with the less restrictive predicate
&lsquo;doctor&rsquo;. One can say that the default direction of
implication, from more restrictive to less restrictive predicates, has
been inverted twice&mdash;once by &lsquo;No&rsquo;, and once by
&lsquo;every&rsquo;. But one wants a systematic account of
propositional structure that explains the net effect; see Ludlow
(2002) for further discussion. Sommers (1982) offers a strategy for
recoding and extending classical logic, in part by exploiting an idea
suggested by
 <a href="../leibniz/index.html">Leibniz</a>
 (and arguably P&#257;&#7751;ini): a relational sentence like
&lsquo;Juliet loved Romeo&rsquo; somehow combines an active-voice
sentence with a passive-voice sentence, perhaps along the lines of
&lsquo;Juliet loved, <em>and thereby</em> Romeo was loved&rsquo;; cp.
 <a href="#sem">section nine</a>.
 But one way or another, quantifiers need to be characterized in a way
that captures their general logical role&mdash;and not just their role
as potential subjects of Aristotelian propositions&mdash;if
impeccability is to be revealed as a matter of form. Quantifiers are
not simply devices for creating schemata like &lsquo;Every <em>S</em>
is <em>P</em>&rsquo;, into which general terms like
&lsquo;politician&rsquo; and &lsquo;deceitful&rsquo; can be inserted.
Instances of &lsquo;<em>S</em>&rsquo; and &lsquo;<em>P</em>&rsquo; can
themselves have quantificational structure and relational
constituents.</p>

<h2><a name="freg">4. Frege and Formal Language</a></h2>

<p>

 <a href="../frege/index.html">Gottlob Frege</a>
 showed how to resolve these difficulties for classical logic in one
fell swoop. His system of logic, published in 1879 and still in use
(with notational modifications), was arguably the single greatest
contribution to the subject. So it is significant that on
Frege&rsquo;s view, propositions do not have subject-predicate form.
Indeed, his leading idea was that propositions have
&ldquo;function-argument&rdquo; structure. Frege thereby drew a
substantial distinction between logical form and grammatical form as
traditionally conceived. This had a major impact on subsequent
discussions of thought and its relation to language. Though before
turning to details, it is worth taking a slight detour to note that
Frege did not think of functions as abstract <em>objects</em> like
numbers.</p>

<p>
Every function maps each entity in some domain onto exactly one entity
in some range. But while every function thus determines a set of
ordered pairs, Frege (1891) did not identify functions with such sets.
He said that a function &ldquo;by itself must be called incomplete, in
need of supplementation, or unsaturated. And in this respect functions
differ fundamentally from numbers (p. 133).&rdquo; For example, we can
represent the successor function as follows, with the natural numbers
as the relevant domain for the variable &lsquo;\(x\)&rsquo;: \(S(x) = x + 1\).
This function maps zero onto one, one onto two, and so on. So we can
specify the set \(\{\langle x, y \rangle : y = x + 1\}\) as the
&ldquo;value-range&rdquo; of the successor function. But according to
Frege, any particular argument (e.g., the number one) &ldquo;goes
together with the function to make up a complete whole&rdquo; (e.g.,
the number two); and a number does not go together with a set to form
a <em>unit</em> in this fashion. Frege granted that the word
&lsquo;function&rsquo; is often used to talk about the sets he would
call value-ranges. But he maintained that the notion of an
&ldquo;unsaturated&rdquo; function, which may be applied to endlessly
many arguments, is logically prior to any notion of a set with
endlessly many elements that are specified functionally; see p.135,
note E. While the second positive integer is the successor of the
first, the number two is still a single thing, distinct from any
combination of a number with a set. Frege was influenced by
 <a href="../kant-judgment/index.html">Kant&rsquo;s discussion of judgment</a>,
 the kind of unity that a
 <a href="../propositions-structured/index.html">(structured) proposition</a>
 exhibits, and the ancient observation that merely combining two
things (e.g., Socrates and the property of being mortal) does not make
the combination true or false. If it helps, think about
&lsquo;\(S(x)\)&rsquo;&mdash;or better, &lsquo;\(S(\ )\)&rsquo;&mdash;as the
unsaturated result of abstracting away from the numerical argument in
a complex denoting expression like &lsquo;\(S(1)\)&rsquo; or
&lsquo;\(S(62)\)&rsquo;; and think about saturating &lsquo;\(S(\ )\)&rsquo;
with a numerical argument, like &lsquo;1&rsquo; or &lsquo;62&rsquo;,
as a process of &ldquo;de-abstraction.&rdquo; So in saying that
propositions have &ldquo;function-argument&rdquo; structure, Frege was
not only rejecting the traditional idea that logical from reflects the
subject-predicate structure of ordinary sentences, he was suggesting
that propositions (and any of their complex constituents) exhibit a
kind of unity that is like the unity of &lsquo;\(S(1)\)&rsquo;, which can
appear in invented arithmetic sentences like &lsquo;\(S(1) = 2\)&rsquo;.
Church (1941) echoed Frege by distinguishing functions-in-intension,
which Church identified with computational procedures, from their
extensions. Perhaps Frege would have said that even procedures, as
abstractions of a special kind, are too object-like to be functions in
his special sense. But distinct procedures can determine the same
extension. (Compare adding one to a natural number <em>n</em> with the
following procedure: take the positive square root of the result of
adding one to <em>n</em> squared plus <em>n</em> doubled.) So at least
in this sense, functions-in-intension can be distinguished from the
extensions they determine; cp. Chomsky&rsquo;s (1986) contrast between
I-languages and E-languages.</p>

<p>
For purposes of capturing valid arguments concerning relations, the
more important point is that functions need not be unary. For example,
arithmetic division can be represented as a function from ordered
pairs of numbers onto quotients: \(Q(x, y) = \frac{x}{y}\). Mappings can also be
conditional. Consider the function that maps every even integer onto
itself, and every odd integer onto its successor: \(C(x) = x\) if \(x\) is
even, and \(x + 1\) otherwise; \(C(1) = 2\), \(C(2) = 2\), \(C(3) = 4\), etc. Frege
held that propositions have parts that correspond to functions, and in
particular, conditional functions that map arguments onto special
values that reflect the truth or falsity of propositions/sentences.
(As discussed below, Frege [1892] also distinguished these
&ldquo;truth values&rdquo; from what he called Thoughts [Gedanken] or
the &ldquo;senses&rdquo; [Sinnen] of propositions; where each of these
sentential senses &ldquo;presents&rdquo; a truth value in certain
way&mdash;i.e., as the value of a certain indicated function given a
certain indicated argument.)</p>

<p>
Variable letters, such as &lsquo;\(x\)&rsquo; and &lsquo;\(y\)&rsquo; in
&lsquo;\(Q(x, y) = \frac{x}{y}\)&rsquo;, are typographically convenient for
representing functions that take more than one argument. But we could
also index argument places, as shown below.</p>

\[
Q[(\ )_i, (\ )_j] = \frac{(\ )_i}{(\ )_j}
\]

<p>
Or we could replace the subscripts above with lines that connect each
pair of round brackets on the left of &lsquo;\(=\)&rsquo; to a
corresponding pair of brackets on the right. But the idea, however we
encode it, is that a proposition has at least one constituent that is
saturated by the requisite number of arguments.</p>

<p>
On Frege&rsquo;s view, the proposition that Mary sang has a functional
component corresponding to &lsquo;sang&rsquo; and an argument
corresponding to &lsquo;Mary&rsquo;, even if the English sentence
&lsquo;Mary sang&rsquo; has &lsquo;Mary&rsquo; as its subject and
&lsquo;sang&rsquo; as its predicate. The proposition can be
represented as follows: \(\textrm{Sang}(\textrm{Mary})\). Frege thought of the relevant
function as a conditional mapping from individuals to truth values:
\(\textrm{Sang}(x) = \textbf{T}\) if \(x\) sang, and \(\textbf{F}\)
otherwise; where &lsquo;\(\textbf{T}\)&rsquo; and
&lsquo;\(\textbf{F}\)&rsquo; stand for special entities such that
for each individual \(x\), \(\textrm{Sang}(x) = \textbf{T}\) if and only if \(x\)
sang, and \(\textrm{Sang}(x) = \textbf{F}\) if and only if \(x\) did not sing.
According to Frege, the proposition that John admires Mary combines an
ordered pair of arguments with a functional component that corresponds
to the transitive verb: \(\textrm{Admires}(\textrm{John}, \textrm{Mary})\); where for any individual
\(x\), and any individual \(y\), \(\textrm{Admires}(x, y) = \textbf{T}\) if \(x\)
admires \(y\), and \(\textbf{F}\) otherwise. From this perspective,
the structure and constituents are the same in the proposition that
Mary is admired by John, even though &lsquo;Mary&rsquo; is the
grammatical subject of the passive sentence. Likewise, Frege did not
distinguish the proposition that three precedes four from the
proposition that four is preceded by three. More importantly,
Frege&rsquo;s treatment of quantified propositions departs radically
from the traditional idea that the grammatical structure of sentence
reflects the logical structure of the indicated proposition.</p>

<p>
If \(S\) is the function corresponding to &lsquo;sang&rsquo;, then Mary
sang iff&mdash;i.e., if and only if&mdash;\(S(\textrm{Mary}) =
\textbf{T}\). Likewise, someone sang iff: \(S\) maps some individual
onto \(\textbf{T}\); that is, for some individual \(x\), \(S(x) =
\textbf{T}\). Or using a modern variant of Frege&rsquo;s
original notation, someone sang iff \(\exists x [S(x)]\). The quantifier
&lsquo;\(\exists x\)&rsquo; is said to bind the variable &lsquo;\(x\)&rsquo;,
which ranges over individual things in a domain of discourse. (For
now, assume that the domain contains only people.) If every individual
in the domain sang, then \(S\) maps every individual onto the truth value
\(\textbf{T}\); or using formal notation, \(\forall x [S(x)]\). A
quantifier binds each occurrence of its variable, as in
<span class="nw">&lsquo;\(\exists x [P(x) \land D(x)]\)&rsquo;</span>,
which reflects the logical form of &lsquo;Someone is both a politician
and deceitful&rsquo;. In this last example, the quantifier combines
with a complex functional component that is formed by conjoining two
simpler ones.</p>

<p>
With regard to the proposition that some politician is deceitful,
traditional grammar suggests the division &lsquo;Some politician / is
deceitful&rsquo;, with the noun &lsquo;politician&rsquo; combining
with the quantificational word to form a complex subject. But on a
Fregean view, grammar masks the logical division between the
existential quantifier and the rest: \(\exists x [P(x) \land D(x)]\). With
regard to the proposition that every politician is deceitful, Frege
also stresses the logical division between the quantifier and its
scope: \(\forall x [P(x) \rightarrow D(x)]\); every individual is deceitful if a
politician. Here too, the quantifier combines with a complex
functional component, albeit one that is conditional rather than
conjunctive. (The formal sentence &lsquo;\(\forall x [P(x) \land D(x)]\)&rsquo;
implies, unconditionally, that every individual is a
politician.) As Frege (1879) defined his analogs of the modern symbols
used here, &lsquo;\(P(x) \rightarrow D(x)\)&rsquo; is equivalent to
<span class="nw">&lsquo;\(\lnot P(x) \lor D(x)\)&rsquo;</span>, and
&lsquo;\(\forall x\)&rsquo; is equivalent to &lsquo;\(\lnot \exists
\lnot\)&rsquo;. So &lsquo;\(\forall x [P(x) \rightarrow D(x)]\)&rsquo;
is equivalent to <span class="nw">&lsquo;\(\lnot \exists x \lnot
[\lnot P(x) \lor D(x)]\)&rsquo;;</span> and given de Morgan&rsquo;s
Laws (concerning the relations between negation, disjunction, and
conjunction), \(\lnot \exists x \lnot [\lnot P(x) \lor D(x)]\) iff
\(\lnot \exists x [P(x) \land \lnot D(x)]\). Hence, \(\forall x [P(x)
\rightarrow D(x)]\) iff \(\lnot \exists x [P(x) \land \lnot
D(x)]\). This captures the idea that every politician is deceitful iff
no individual is both a politician and not deceitful.</p>

<p>
If this conception of logical form is correct, then grammar is
misleading in several respects. First, grammar leads us to think that
&lsquo;some politician&rsquo; indicates a constituent of the
proposition that some politician is deceitful. Second, grammar masks a
difference between existential and universally quantified
propositions; predicates are related conjunctively in the former, and
conditionally in the latter. (Though as discussed in
 <a href="#not">section seven</a>,
 one can&mdash;and Frege [1884] did&mdash;adopt a different view that
allows for relational/restricted quantifiers as in
&lsquo;\(\forall x{:}P(x) [D(x)]\)&rsquo;.)</p>

<p>
More importantly, Frege&rsquo;s account was designed to apply equally
well to propositions involving relations and multiple quantifiers. And
with regard to these propositions, there seems to be a big difference
between logical structure and grammatical structure.</p>

<p>
On Frege&rsquo;s view, a single quantifier can bind an unsaturated
position that is associated with a function that takes a single
argument. But it is equally true that two quantifiers can bind two
unsaturated positions associated with a function that takes a pair of
arguments. For example, the proposition that everyone likes everyone
can be represented with the formal sentence
&lsquo;\(\forall x \forall y [L(x, y)]\)&rsquo;. Assuming that
&lsquo;Romeo&rsquo; and &lsquo;Juliet&rsquo; indicate arguments, it
follows that Romeo likes everyone, and that everyone likes
Juliet&mdash;\(\forall y [L(r, y)]\) and \(\forall x [L(x, j)]\). And it follows
from all three propositions that Romeo likes Juliet: \(L(r, j)\). The
rules of inference for Frege&rsquo;s logic capture this general
feature of the universal quantifier. A variable bound by a universal
quantifier can be replaced with a name for some individual in the
domain. Correlatively, a name can be replaced with a variable bound by
an existential quantifier. Given that Romeo likes Juliet, it follows
that someone likes Juliet, and Romeo likes someone. Frege&rsquo;s
formalism can capture this as well: \(L(r, j)\); so \(\exists x [L(x, j)] \land \exists x [L(r, x)]\).
And given either conjunct in the conclusion,
it follows that someone likes someone: \(\exists x \exists y [L(x, y)]\). A
single quantifier can also bind multiple argument positions, as in
&lsquo;\(\exists x [L(x, x)]\)&rsquo;, which is true iff someone likes
herself. Putting these points schematically:
\(\forall x (\dots x \dots)\), so \(\dots n \dots\); and
\(\dots n \dots\), so \(\exists x (\dots x \dots)\).</p>

<p>
Mixed quantification introduces an interesting wrinkle. The
propositions expressed with &lsquo;\(\exists x \forall y [L(x, y)]\)&rsquo;
and &lsquo;\(\forall y \exists x [L(x, y)]\)&rsquo; differ. We can paraphrase
the first as &lsquo;there is someone who likes everyone&rsquo; and the
second as &lsquo;everyone is liked by someone or other&rsquo;. The
second follows from the first, but not vice versa. This suggests that
&lsquo;someone likes everyone&rsquo; is ambiguous, in that this string
of English words can be used to express two different propositions.
This in turn raises difficult questions about what natural language
expressions are, and how they can be used to express propositions; see
 <a href="#tran">section eight</a>.
 But for Frege, the important point concerned the distinction between
the propositions (Gedanken). Similar remarks apply to
&lsquo;\(\forall x \exists y [L(x, y)]\)&rsquo; and
&lsquo;\(\exists y \forall x [L(x, y)]\)&rsquo;.</p>

<p>
A related phenomenon is exhibited by &lsquo;John danced if Mary sang
and Chris slept&rsquo;. Is the intended proposition of the form
&lsquo;(<strong>A</strong> if <strong>B</strong>) and
<strong>C</strong>&rsquo; or &lsquo;<strong>A</strong> if
(<strong>B</strong> and <strong>C</strong>)&rsquo;? Indeed, it seems
that the relation between word-strings and propositions expressed is
often one-to-many. Is someone who says &lsquo;The artist drew a
club&rsquo; talking about a sketch or a card game? One can use
&lsquo;is&rsquo; to express identity, as in &lsquo;Hesperus is the
planet Venus&rsquo;; but in &lsquo;Hesperus is bright&rsquo;,
&lsquo;is&rsquo; indicates predication. In &lsquo;Hesperus is a
planet&rsquo;, &lsquo;a&rsquo; seems to be logically inert; yet in
&lsquo;John saw a planet&rsquo;, &lsquo;a&rsquo; seems to indicate
existential quantification: \(\exists x [P(x) \land S(j, x)]\). (One can
render &lsquo;Hesperus is a planet&rsquo; as &lsquo;\(\exists x [P(x) \land h = x]\)&rsquo;.
But this treats &lsquo;is a planet&rsquo; as
importantly different than &lsquo;is bright&rsquo;; and this leads to
other difficulties.) According to Frege, such ambiguities provide
further evidence that natural language is not suited to the task of
representing propositions and inferential relations perspicuously.
(Leibniz and others had envisioned a &ldquo;Characteristica
Universalis&rdquo;, but without detailed proposals for how to proceed
beyond syllogistic logic in creating one.) This is not to deny that
natural language is well suited for other purposes, perhaps including
efficient human communication. And Frege held that we often do use
natural language to express propositions. But he suggested that
natural language is like the eye, whereas a good formal language is
like a microscope that reveals structure not otherwise observable. On
this view, the logical form of a proposition is made manifest by the
structure of a sentence in an ideal formal language&mdash;what Frege
called a Begriffsschrift (concept-script); where the sentences of such
a language exhibit function-argument structures that differ in kind
from the grammatical structures exhibited by the sentences we use in
ordinary communication.</p>

<p>
The real power of Frege&rsquo;s strategy for representing
propositional structure is most evident in his discussions of proofs
by induction, the Dedekind-Peano axioms for arithmetic, and how the
proposition that every number has a successor is logically related to
more basic truths of arithmetic; see the entry on
 <a href="../frege-theorem/index.html">Frege&rsquo;s theorem and foundations for arithmetic</a>.
 But without getting into these details, one can get a sense of
Frege&rsquo;s improvement on previous logic by considering
(15&ndash;16) and Fregean analyses of the corresponding
propositions.</p>

<dl class="sentag tag3em">
<dt>(15)</dt>
<dd>Every patient respects some doctor
<br />
\(\forall x \{P(x) \rightarrow \exists y [D(y) \land R(x,y)]\}\)</dd>

<dt>(16)</dt>
<dd>Every old patient respects some doctor
<br />
\(\forall x \{[O(x) \land P(x)] \rightarrow \exists y [D(y) \land R(x,y)]\}\)
</dd>
</dl>

<p>
Suppose that every individual has the following conditional property:
if he\(_x\) is a patient, then some individual is such
that she\(_y\) is both a doctor and respected by
him\(_x\). Then it follows&mdash;intuitively and given
the rules of Frege&rsquo;s logic&mdash;that every
individual\(_x\) has the following conditional property:
if he\(_x\) is both old and a patient, then some
individual\(_y\) is such that she\(_y\) is
both a doctor and respected by him\(_x\). So the
proposition expressed with (16) follows from the one expressed with
(15). More interestingly, we can also account for why the proposition
expressed with (14) follows from the one expressed with (13).</p>

<dl class="sentag tag3em">
<dt>(13)</dt>
<dd>No patient who saw every young doctor is healthy
<br />
\(\neg \exists x \{P(x) \land \forall y \{[Y(y) \land D(y)] \rightarrow S(x,y)\} \land H(x)\}\)
</dd>

<dt>(14)</dt>
<dd>No patient who saw every doctor is healthy
<br />
\(\neg \exists x \{P(x) \land \forall y [D(y) \rightarrow S(x,y)] \land H(x)\}\)</dd>
</dl>

<p>
For suppose it is false that some individual has the following
conjunctive property: he<sub>\(x\)</sub> is a patient; and
he<sub>\(x\)</sub> saw every young doctor (i.e., every
individual<sub>\(y\)</sub> is such that if she<sub>\(y\)</sub>
is a young doctor, then he<sub>\(x\)</sub> saw
her<sub>\(y\)</sub>); and he<sub>\(x\)</sub> is healthy. Then
intuitively, and also given the rules of Frege&rsquo;s logic, it is
false that some individual has the following conjunctive property:
he<sub>\(x\)</sub> is a patient; and he<sub>\(x\)</sub> saw
every doctor; and he<sub>\(x\)</sub> is healthy. This captures the
fact that the direction of valid inference is from &lsquo;every young
doctor&rsquo; in (13) to &lsquo;every doctor&rsquo; in (14), despite
the fact that in simpler cases, replacing &lsquo;every doctor&rsquo;
with &lsquo;every young doctor&rsquo; is valid. More generally,
Frege&rsquo;s logic handles a wide range of inferences that had
puzzled medieval logicians. But the Fregean logical forms seem to
differ dramatically from the grammatical forms of sentences like
(13&ndash;16). Frege concluded that we need a Begriffsschrift,
distinct from the languages we naturally speak, to depict (and help us
discern) the structures of the propositions we can somehow express by
using ordinary sentences in contexts.</p>

<p>
Frege also made a different kind of contribution, which would prove
important, to the study of propositions. In early work, he spoke as
though propositional constituents were the relevant functions and
(ordered n-tuples of) entities that such functions map to
truth-values. But he later refined this view in light of his
distinction between Sinn and Bedeutung; see the entry on
 <a href="../frege/index.html">Frege</a>.
 The Sinn of an expression was said to be a &ldquo;way of
presenting&rdquo; the corresponding Bedeutung, which might be an
entity (with&nbsp;truth-values as&nbsp;special cases of
entities)&nbsp;or a function from (ordered n-tuples of) entities to
truth-values. The basic idea is that two names, like
&lsquo;Hesperus&rsquo; and &lsquo;Phosphorus&rsquo;, can present the
same Bedeutung in different ways; in which case, the Sinn of the first
name differs from the Sinn of the second. Given this distinction, we
can think of &lsquo;Hesperus&rsquo; as an expression that presents
Venus <em>as</em> the evening star, while &lsquo;Phosphorus&rsquo;
presents Venus <em>as</em> the morning star. Likewise, we can think of
&lsquo;is bright&rsquo; as an expression that presents a certain
function in a certain way, and &lsquo;Hesperus is bright&rsquo; as a
sentence that presents its truth-value in a certain way&mdash;i.e., as
the value of the function in question given the argument in question.
From this perspective, propositions are sentential ways of presenting
truth-values, and proposition-parts are subsentential ways of
presenting functions and arguments. Frege could thus distinguish the
proposition that Hesperus is bright from the proposition that
Phosphorus is bright, even though the two propositions are alike with
regard to the relevant function and argument. Likewise, he could
distinguish the trivial proposition Hesperus is Hesperus from the
(apparently nontrivial) proposition Hesperus is Phosphorus. This is an
attractive view. For intuitively, the inference &lsquo;Hesperus is
Hesperus, so Hesperus is Phosphorus&rsquo; is not an instance of the
following obviously valid schema: <strong>A</strong>, so
<strong>A</strong>. But this raised questions about what the Sinn of
an expression really is, what &ldquo;presentation&rdquo; could amount
to, and what to say about a name with no Bedeutung.</p>

<h2><a name="des">5. Descriptions and Analysis</a></h2>

<p>
Frege did not distinguish (or at least did not emphasize any
distinction between) names like &lsquo;John&rsquo; and descriptions
like &lsquo;the boy&rsquo; or &lsquo;the tall boy from Canada&rsquo;.
Initially, both kinds of expression seem to indicate arguments, as
opposed to functions. So one might think that the logical form of
&lsquo;The boy sang&rsquo; is simply &lsquo;\(S(b)\)&rsquo;, where
&lsquo;\(b\)&rsquo; is an unstructured symbol that stands for the boy in
question (and presents him in a certain way). But this makes the
elements of a description logically irrelevant. And this seems wrong.
If the tall boy from Canada sang, then some boy from Canada sang.
Moreover, &lsquo;the&rsquo; implies <em>uniqueness</em> in a way that
&lsquo;some&rsquo; does not. Of course, one can say &lsquo;The boy
sang&rsquo; without denying that universe contains more than one boy.
But likewise, in ordinary conversation, one can say &lsquo;Everything
is in the trunk&rsquo; without denying that the universe contains some
things not in the trunk. And intuitively, a speaker who uses
&lsquo;the&rsquo; does imply that the adjacent predicate is satisfied
by exactly one contextually relevant thing.</p>

<p>

 <a href="../russell/index.html">Bertrand Russell</a>
 held that these implications reflect the logical form of a
proposition expressed (in a given context) with a definite
description. On his view, &lsquo;The boy sang&rsquo; has the following
logical form:</p>

\[\exists x \{\textrm{Boy}(x) \land \forall y [\textrm{Boy}(y) \rightarrow y = x] \land S(x)\}
\]

<p>
some individual<sub>\(x\)</sub> is such that
he<sub>\(x\)</sub> is a boy, and every (relevant)
individual<sub>\(y\)</sub> is such that if he<sub>\(y\)</sub> is
a boy, then he<sub>\(y\)</sub> is identical with
him<sub>\(x\)</sub>, and he<sub>\(x\)</sub> sang. The awkward
middle conjunct was Russell&rsquo;s way of expressing uniqueness with
Fregean tools; cf.
 <a href="#not">section seven</a>.
 But rewriting the middle conjunct would not affect Russell&rsquo;s
technical point, which is that &lsquo;the boy&rsquo; does not
correspond to any constituent of the formalism. This in turn reflects
Russell&rsquo;s central claim&mdash;viz., that while a speaker may
refer to a certain boy in saying &lsquo;The boy sang&rsquo;, the boy
in question is not a constituent of the proposition indicated.
According to Russell, the proposition has the form of an existential
quantification with a bound variable. It does <em>not</em> have the
form of a function saturated by (an argument that is) the boy referred
to. The proposition is general rather than singular. In this respect,
&lsquo;the boy&rsquo; is like &lsquo;some boy&rsquo; and &lsquo;every
boy&rsquo;; though on Russell&rsquo;s view, not even &lsquo;the&rsquo;
indicates a constituent of the proposition expressed.</p>

<p>
This extended Frege&rsquo;s idea that natural language misleads us
about the structure of the propositions we assert. Russell went on to
apply this hypothesis to what became a famous puzzle. Even though
France is currently kingless, &lsquo;The present king of France is
bald&rsquo; can be used to express a proposition. The sentence is not
meaningless; it has implications. So if the proposition consists of a
function indicated with &lsquo;\(\textrm{Bald}(\ )\)&rsquo; and an argument
indicated with &lsquo;The present king of France&rsquo;, there must
<em>be</em> an argument that is indicated. But appeal to nonexistent
kings is, to say the least, dubious. Russell concluded that &lsquo;The
present king of France is bald&rsquo; expresses a quantificational
proposition:</p>

\[\exists x \{K(x) \land \forall y [K(y) \rightarrow y = x] \land B(x)\};
\]

<p>
where \(K(x) = \textbf{T}\) iff \(x\) is a present king of
France, and \(B(x) = \textbf{T}\) iff \(x\) is bald. (For present
purposes, set aside worries about the vagueness of
&lsquo;bald&rsquo;.) And as Russell noted, the following contrary
reasoning is spurious: every proposition is true or false; so the
present king of France is bald or not; so there is a king of France,
and he is either bald or not. For let <strong>P</strong> be the
proposition that the king of France is bald. Russell held that
<strong>P</strong> is indeed true or false. On his view, it is false.
Given that \(\neg \exists x [K(x)]\), it follows that</p>

\[
\neg \exists x \{K(x) \land \forall y [K(y) \rightarrow y = x] \land B(x)\}.
\]

<p>
But it does not follow
that there is a present king of France who is either bald or not.
Given that \(\neg \exists x [K(x)]\), it hardly follows that</p>

\[\exists x \{K(x) \land [B(x) \lor \neg B(x)]\}.\]

<p>
So we must not confuse the negation of
<strong>P</strong> with the following false proposition:</p>

\[\exists x \{K(x) \land \forall y [K(y) \rightarrow y = x] \land \neg B(x)\}.
\]

<p>
The ambiguity of natural language may foster such confusion, given
examples like &lsquo;The present king of France is bald or
not&rsquo;. But according to Russell, puzzles about
&ldquo;nonexistence&rdquo; can be resolved without special
metaphysical theses, given the right views about logical form and
natural language.</p>

<p>
This invited the thought that other philosophical puzzles might
<em>dissolve</em> if we properly understood the logical forms of our
claims.
 <a href="../wittgenstein/index.html">Ludwig Wittgenstein</a>
 argued, in his influential <em>Tractatus Logico-Philosophicus</em>,
that: (i) the very possibility of meaningful sentences, which can be
true or false depending on how the world is, requires propositions
with structures of the sort that Frege and Russell were getting at;
(ii) all propositions are logical compounds of&mdash;and thus
analyzable into&mdash;atomic propositions that are inferentially
independent of one another; though (iii) even simple natural language
sentences may correspond to very complex propositions; and (iv) the
right analyses would, given a little reflection, reveal all
philosophical puzzles as confusions about how language is related to
the world. Wittgenstein later noted that examples like &lsquo;This is
red&rsquo; and &lsquo;This is yellow&rsquo; present difficulties for
his earlier view. (If the expressed propositions are unanalyzable, and
thus logically independent, each should be compatible with the other;
but at least so far, no one has provided a plausible analysis that
accounts for the apparent impeccability of &lsquo;This is red, so this
is not yellow&rsquo;. This raises questions about whether <em>all</em>
inferential security is due to logical form.) And in any case, Russell
did not endorse (iv). But he did say, for reasons related to certain
epistemological puzzles, that (a) we are <em>directly acquainted</em>
with the constituents of those propositions into which every
proposition (that we can grasp) can be analyzed; (b) at least
typically, we are not directly acquainted with the mind-independent
bearers of proper names; and so (c) the things we typically refer to
with names are not constituents of basic propositions.</p>

<p>
This led Russell to say that natural language names are disguised
descriptions. On this view, &lsquo;Hesperus&rsquo; is semantically
associated with a complex predicate&mdash;say, for illustration, a
predicate of the form &lsquo;\(E(x) \land S(x)\)&rsquo;, suggesting
&lsquo;evening star&rsquo;. In which case, &lsquo;Hesperus is
bright&rsquo; expresses a proposition of the form </p>

\[\lsquo\exists x \{[E(x) \land S(x)] \land
\forall y \{[E(y) \land S(y)] \rightarrow y = x\} \land
B(x)\}\rsquo.
\]

<p>
It also follows that Hesperus exists iff
\(\exists x [E(x) \land S(x)]\); and this would be challenged by
Kripke (1980) and others; see the entries on
 <a href="../rigid-designators/index.html">rigid-designators</a>
 and
 <a href="../names/index.html">names</a>.  But by analyzing names as
 descriptions&mdash;quantificational expressions, as opposed to logical
constants (like &lsquo;\(b\)&rsquo;) that indicate
individuals&mdash;Russell offered an attractive account of why the
proposition that Hesperus is bright differs from the proposition that
Phosphorus is bright. Instead of saying that propositional
constituents are Fregean senses, Russell could say that
&lsquo;Phosphorus is bright&rsquo; expresses a proposition of the
form</p>

\[\lsquo\exists x \{[M(x) \land S(x)] \land
\forall y \{[M(y) \land S(y)] \rightarrow y = x\} \land
B(x)\}\rsquo ;\]

<p>
where &lsquo;\(E(x)\)&rsquo; and
&lsquo;\(M(x)\)&rsquo; indicate different functions, specified
(respectively) in terms of evenings and mornings. This leaves room for
the discovery that the complex predicates &lsquo;\(E(x) \land
S(x)\)&rsquo; and &lsquo;\(M(x) \land S(x)\)&rsquo; both indicate
functions that map Venus and nothing else to the
truth-value <strong>T</strong>.  The hypothesis was that the
propositions expressed with &lsquo;Hesperus is bright&rsquo; and
&lsquo;Phosphorus is bright&rsquo; have different (fundamental)
constituents, even though Hesperus is Phosphorus, but not because
propositional constituents are &ldquo;ways of presenting&rdquo;
Bedeutungen. Similarly, the idea was that the propositions expressed
with &lsquo;Hesperus is Hesperus&rsquo; and &lsquo;Hesperus is
Phosphorus&rsquo; differ, because only the latter has
predicational/unsaturated constituents corresponding to
&lsquo;Phosphorus&rsquo;. Positing unexpected logical forms seemed to
have explanatory payoffs.</p>

<p>
Questions about names and descriptions are also related to
psychological reports, like &lsquo;Mary thinks Venus is bright&rsquo;,
which present puzzles of their own; see the entry on
 <a href="../prop-attitude-reports/index.html">propositional attitude reports</a>.
 Such reports seem to indicate propositions that are neither atomic
nor logical compounds of simpler propositions. For as Frege noted,
replacing one name with another name for the same object can
apparently affect the truth of a psychological report. If Mary fails
to know that Hesperus is Venus, she might think Venus is a planet
without thinking Hesperus is a planet; though cp. Soames (1987, 1995,
2002) and see the entry on
 <a href="../propositions-singular/index.html">singular propositions</a>.
 Any function that has the value <strong>T</strong> given Venus as
argument has the value <strong>T</strong> given Hesperus as argument.
So Frege, Russell, and Wittgenstein all held&mdash;in varying
ways&mdash;that psychological reports are also misleading with respect
to the logical forms of the indicated propositions.</p>

<h2><a name="reg">6. Regimentation and Communicative Slack</a></h2>

<p>
Within the analytic tradition inspired by these philosophers, it
became a commonplace that logical form and grammatical form typically
diverge, often in dramatic ways. This invited attempts to provide both
analyses of propositions and claims about natural language, with the
aim of saying how relatively simple sentences (with subject-predicate
structures) could be used to express propositions (with
function-argument structures).</p>

<p>
The logical positivists explored the idea that the meaning of a
sentence is a procedure for determining the truth or falsity of that
sentence. From this perspective, studies of linguistic meaning and
propositional structure still dovetail, even if natural language
employs &ldquo;conventions&rdquo; that make it possible to indicate
complex propositions with grammatically simple sentences; see the
entry on
 <a href="../analysis/index.html">analysis</a>.
 But to cut short a long and interesting story, there was little
success in formulating &ldquo;semantic rules&rdquo; that were
plausible both as (i) descriptions of how ordinary speakers understand
sentences of natural language, and (ii) analyses that revealed logical
structure of the sort envisioned. (And until Montague [1970],
discussed briefly in the next section, there was no real progress in
showing how to systematically associate quantificational constructions
of natural language with Fregean logical forms.)</p>

<p>

 <a href="../carnap/index.html">Rudolf Carnap</a>,
 one of the leading positivists, responded to difficulties facing his
earlier views by developing a sophisticated position according to
which philosophers could (and should) articulate alternative sets of
conventions for associating sentences of a language with propositions.
Within each such language, the conventions would determine what
follows from what. But one would have to decide, on broadly pragmatic
grounds, which interpreted language was best for certain purposes
(like conducting scientific inquiry). On this view, questions about
&ldquo;the&rdquo; logical form of an ordinary sentence are in part
questions about which conventions one should adopt. The idea was that
&ldquo;internal&rdquo; to any logically perspicuous linguistic scheme,
there would be an answer to the question of how two sentences are
inferentially related. But &ldquo;external&rdquo; questions, about
which conventions we should adopt, would not be settled by descriptive
facts about how we understand languages that we already use.</p>

<p>
This was, in many ways, an attractive development of Frege&rsquo;s
vision. But it also raised a skeptical worry. Perhaps the structural
mismatches between sentences of a natural language and sentences of a
Fregean Begriffsschrift are so severe that one cannot formulate
general rules for associating the sentences we ordinarily use with
propositions. Later theorists would combine this view with the idea
that propositions are sentences of a
 <a href="../language-thought/index.html">mental language</a>
 that is relevantly like Frege&rsquo;s invented language and
relevantly unlike the spoken languages humans use to communicate; see
Fodor (1975, 1978). But given the rise of
 <a href="../behaviorism/index.html">behaviorism</a>,
 both in philosophy and psychology, this variant on a medieval idea
was initially ignored or ridiculed. (And it does face difficulties;
see
 <a href="#tran">section eight</a>.)</p>

<p>

 <a href="../quine/index.html">Willard Van Orman Quine</a>
 combined behaviorist psychology with a normative conception of
logical form similar to Carnap&rsquo;s. The result was an influential
view according to which there is no fact of the matter about which
proposition a speaker/thinker expresses with a sentence of natural
language, because talk of propositions is (at best) a way of talking
about how we should regiment our verbal behavior for certain
purposes&mdash;and in particular, for purposes of scientific inquiry.
On this view, claims about logical form are evaluative, and such
claims are underdetermined by the totality of facts concerning
speakers&rsquo; dispositions to use language. From this perspective,
mismatches between logical and grammatical form are to be expected,
and we should not conclude that ordinary speakers have mental
representations that are isomorphic with sentences of a Fregean
Begriffsschrift.</p>

<p>
According to Quine, speakers&rsquo; behavioral dispositions constrain
what can be plausibly said about how to best regiment their language.
He also allowed for some general constraints on interpretability that
an idealized &ldquo;field linguist&rdquo; might impose in coming up
with a regimented interpretation scheme.
 (<a href="../davidson/index.html">Donald Davidson</a>
 developed a similar line of thought in a less behavioristic idiom,
speaking in terms of constraints on a &ldquo;Radical
Interpreter,&rdquo; who seeks &ldquo;charitable&rdquo; construals of
alien speech.) But unsurprisingly, this left ample room for
&ldquo;slack&rdquo; with respect to which logical forms should be
associated with a given sentential utterance.</p>

<p>
Quine also held that decisions about how to make such associations
should be made <em>holistically</em>. As he sometimes put it, the
&ldquo;unit of translation&rdquo; is an entire language, not a
particular sentence. On this view, one can translate a sentence
<em>S</em> of a natural language NL with a structurally mismatching
sentence &micro; of a formal language FL, even if it seems (locally)
implausible that <em>S</em> is used to express the proposition
associated with &micro;, so long as the following condition is met:
the association between <em>S</em> and &micro; is part of a general
account of NL and FL that figures in an overall theory&mdash;which
includes an account of language, logic, and the language-independent
world&mdash;that is among the best overall theories available. This
holistic conception of how to evaluate proposed regimentations of
natural language was part and parcel of Quine&rsquo;s criticism of the
early positivists&rsquo;
 <a href="../analytic-synthetic/index.html">analytic-synthetic distinction</a>,
 and his more radical suggestion that there is no such distinction</p>

<p>
The suggestion was that even apparently tautologous sentences, like
&lsquo;Bachelors are unmarried&rsquo; and &lsquo;Caesar died if Brutus
killed him&rsquo;, have empirical content. These may be among the last
sentences we would dissent from, faced with recalcitrant experience;
we may prefer to say that Caesar didn&rsquo;t really die, or that
Brutus didn&rsquo;t really kill him, if the next best alternative is
to deny the conditional claim. But for Quine, every meaningful claim
is a claim that could turn out to be false&mdash;and so a claim we
must be prepared, at least in principle, to reject. Correlatively, no
sentences are known to be true simply by knowing what they mean and
knowing <em>a priori</em> that sentences with such meanings must be
true.</p>

<p>
For present purposes, we can abstract away from the details of debates
about whether Quine&rsquo;s overall view was plausible. Here, the
important point is that claims about logical form were said to be (at
least partly) claims about the kind of regimented language we
<em>should</em> use, not claims about the propositions actually
expressed with sentences of natural language. And one aspect of
Quine&rsquo;s view, about the kind of regimented language we
<em>should</em> use, turned out to be especially important for
subsequent discussions of logical form. For even among those who
rejected the behavioristic assumptions that animated Quine&rsquo;s
conception of language, it was often held that logical forms are
expressions of a first-order predicate calculus.</p>

<p>
Frege&rsquo;s Begriffsschrift, recall, was designed to capture the
Dedekind-Peano axioms for arithmetic, including the axiom of
induction; see the entry on
 <a href="../frege-theorem/index.html">Frege&rsquo;s theorem and foundations for arithmetic</a>.
 This required quantification into positions occupiable by predicates,
as well as positions occupiable by names. Using modern notation, Frege
allowed for formulae like &lsquo;\((Fa \land Fb) \rightarrow \exists X (Xa \land Xb)\)&rsquo;
and &lsquo;\(\forall x \forall y [x = y \leftrightarrow \forall X (Xx \leftrightarrow Xy)]\)&rsquo;.
And he took second-order
quantification to be quantification over functions. This is to say,
for example, that &lsquo;\(\exists X (Xa \land Xb)\)&rsquo; is true iff:
there is a function, \(X\), that maps both the individual called
&lsquo;\(a\)&rsquo; and the individual called &lsquo;\(b\)&rsquo; onto the
truth-value <strong>T</strong>. Frege also took it to be a truth of
logic that for any predicate \(P\), there is a function such that
for each individual \(x\), that function maps \(x\) to <strong>T</strong> iff
\(x\) satisfies (or &ldquo;falls under&rdquo;) \(P\). In which case,
for each predicate, there is the set of all and only the things that
satisfy the predicate. The axioms for Frege&rsquo;s logic thus
generated
 <a href="../russell-paradox/index.html">Russell&rsquo;s paradox</a>, 

given predicates like &lsquo;is not a member of itself&rsquo;. This
invited attempts to <em>weaken</em> the axioms, while preserving
second-order quantification. But for various reasons, Quine and others
advocated a restriction to a first-order fragment of Frege&rsquo;s
logic, disallowing quantification into positions occupied by
predicates.  (<a href="../goedel/index.html">Kurt G&ouml;del</a> had proved the
completeness of first-order predicate calculus, thus providing a
purely formal criterion for what followed from what in that
language. Quine also held that second-order quantification illicitly
treated predicates as names for sets, thereby spoiling Frege&rsquo;s
conception of propositions as unified by virtue of having unsaturated
predicational constituents that are satisfied by things denoted by
names.) On Quine&rsquo;s view, we should
replace</p>

\[\lsquo (Fa \land Fb) \rightarrow \exists X
(Xa \land Xb)\rsquo\]

<p> with explicit first-order quantification
over sets, as in</p>

\[\lsquo (Fa \land Fb) \rightarrow
\exists s (a \in s \land b \in s)\rsquo ;\]

<p>
where &lsquo;\(\in\)&rsquo; stands for &lsquo;is an element of&rsquo;,
and this second conditional is not a logical truth, but rather a
hypothesis (to be evaluated holistically) concerning sets.</p>

<p>
The preference for first-order regimentations has come to seem
unwarranted, or at least highly tendentious; see Boolos (1998). But it
fueled the idea that logical form can diverge wildly from grammatical
form. For as students quickly learn, first-order regimentations of
natural sentences often turn out to be highly artificial. (And in some
cases, such regimentations seem to be unavailable.) This was, however,
taken to show that natural languages are far from ideal for purposes
of indicating logical structure.</p>

<p>
A different strand of thought in analytic philosophy&mdash;pressed by
Wittgenstein in <em>Philosophical Investigations</em> and developed by
others, including
 <a href="../strawson/index.html">Peter Strawson</a>
 and
 <a href="../austin-john/index.html">John Austin</a>&mdash;also
 suggested that a single sentence could be used (on different
occasions) to express different kinds of propositions. Strawson (1950)
argued that <em>pace</em> Russell, a speaker could use an instance of
&lsquo;The <em>F</em> is <em>G</em>&rsquo; to express a singular
proposition about a specific individual: namely, the <em>F</em> in the
context at hand. According to Strawson, sentences themselves do not
have truth conditions, since sentences (as opposed to speakers) do not
express propositions; and speakers can use &lsquo;The boy is
tall&rsquo; to express a proposition with the contextually relevant
boy as a constituent. Donnellan (1966) went on to argue that a speaker
could even use an instance of &lsquo;The <em>F</em> is
<em>G</em>&rsquo; to express a singular proposition about an
individual that isn&rsquo;t an <em>F</em>; see the entry on
 <a href="../reference/index.html">reference</a>.
 Such considerations, which have received a great deal of attention in
recent discussions of context dependence, suggested that relations
between natural language sentences and propositions are (at best) very
complex and mediated by speakers&rsquo; intentions. All of which made
it seem that such relations are far more tenuous than the pre-Fregean
tradition suggested. This bolstered the Quine/Carnap idea that
questions about the structure of premises and conclusions are really
questions about how we <em>should</em> talk (when trying to describe
the world), much as logic itself seems to be more concerned with how
we should infer than with how we do infer. From this perspective, the
connections between logic and grammar seemed rather shallow; see
Iacona (2018) for extended discussion.</p>

<h2><a name="not">7. Notation and Restricted Quantification</a></h2>

<p>
On the other hand, more recent work on quantifiers suggests that the
divergence had been exaggerated, in part because of how Frege&rsquo;s
idea of variable-binding was originally implemented. Consider again
the proposition that some boy sang, and the proposed logical division
into the quantifier and the rest: \(\exists x [\textrm{Boy}(x) \land \textrm{Sang}(x)]\);
something is both a boy and an individual that sang. This is one way
to regiment the English sentence. But one can also offer a logical
paraphrase that more closely parallels the grammatical division
between &lsquo;some boy&rsquo; and &lsquo;sang&rsquo;: for some
individual \(x\) such that \(x\) is a boy, \(x\) sang. One can formalize this
paraphrase with restricted quantifiers, which incorporate a
restriction on the domain over which the variable in question ranges.
For example, &lsquo;\(\exists x{:}B(x)\)&rsquo; can be an existential
quantifier that binds a variable ranging over the boys in the relevant
domain, with &lsquo;\(\exists x{:}B(x) [S(x)]\)&rsquo; being true iff some boy
sang. Since &lsquo;\(\exists x{:}B(x) [S(x)]\)&rsquo; and &lsquo;\(\exists x [B(x) \land S(x)]\)&rsquo;
are logically equivalent, logic provides no reason
for preferring the latter regimentation of the English sentence. And
choosing the latter does not show that the proposition expressed with
&lsquo;Some boy sang&rsquo; has a structure that differs from
grammatical structure of the sentence.</p>

<p>
Universal quantifiers can also be restricted, as in
&lsquo;\(\forall x{:}B(x) [S(x)]\)&rsquo;, interpreted as follows: for every
individual \(x\) such that \(x\) is a boy, \(x\) sang. Restrictors can also be
logically complex, as in &lsquo;Some boy from Canada sang&rsquo; or
&lsquo;Some boy who respects Mary sang&rsquo;, rendered as
<span class="nw">&lsquo;\(\exists x{:}B(x) \land F(x, c)[S(x)]\)&rsquo;</span> and
<span class="nw">&lsquo;\(\exists x{:}B(x) \land R(x, m)[S(x)]\)&rsquo;</span>. Given these representations, the inferential
difference between &lsquo;some boy sang&rsquo; and &lsquo;every boy
sang&rsquo; lies with the propositional contributions of
&lsquo;some&rsquo; and &lsquo;every&rsquo; after all, and not partly
with the contribution of connectives like &lsquo;\(\land\)&rsquo; and
&lsquo;\(\rightarrow\)&rsquo;.</p>

<p>
Words like &lsquo;someone&rsquo;, and the grammatical requirement that
&lsquo;every&rsquo; must be followed by a noun (or noun phrase),
suggest that natural language employs restricted quantifiers. Phrases
like &lsquo;every boy&rsquo; are composed of a determiner and a noun.
Correspondingly, one can think of determiners as expressions that can
combine with an ordered pair of predicates to form a sentence, much as
one can think of transitive verbs as expressions that can combine with
an ordered pair of names to form a sentence. And this grammatical
analogy, between determiners and transitive verbs, invites a semantic
correlate.</p>

<p>
Since &lsquo;\(x\)&rsquo; and &lsquo;\(y\)&rsquo; are variables ranging over
individuals, one can say that the function indicated by the transitive
verb &lsquo;likes&rsquo; yields the value <strong>T</strong> given the
ordered pair \(\langle x,y \rangle\) as argument if and only if \(x\) likes \(y\). In
this notational scheme, &lsquo;\(y\)&rsquo; corresponds to the direct
object (or internal argument), which combines with the verb to form a
phrase; &lsquo;\(x\)&rsquo; corresponds to the grammatical subject (or
external argument) of the verb. If we think about &lsquo;every boy
sang&rsquo; analogously, &lsquo;boy&rsquo; is the internal argument of
&lsquo;every&rsquo;, since &lsquo;every boy&rsquo; is a phrase. By
contrast, &lsquo;boy&rsquo; and &lsquo;sang&rsquo; do not form a
phrase in &lsquo;every boy sang&rsquo;. So let us introduce
&lsquo;\(X\)&rsquo; and &lsquo;\(Y\)&rsquo; as second-order variables ranging
over functions, from individuals to truth values, stipulating that the
extension of such a function is the set of things that the function
maps onto the truth value <strong>T</strong>. Then one can say that
the function indicated by &lsquo;every&rsquo; yields the value
<strong>T</strong> given the ordered pair \(\langle X,Y \rangle\) as argument
iff the extension of \(X\) includes the extension of \(Y\). Similarly, one can
say that the function indicated by &lsquo;some&rsquo; maps the ordered
pair \(\langle X, Y \rangle\) onto <strong>T</strong> iff the extension of \(X\)
intersects with the extension of \(Y\).</p>

<p>
Just as we can describe &lsquo;likes&rsquo; as a predicate satisfied
by ordered pairs \(\langle x, y \rangle\) such that \(x\) likes \(y\), so we can think
about &lsquo;every&rsquo; as a predicate satisfied by ordered pairs
\(\langle X, Y \rangle\) such that the extension of \(X\) includes the extension
of \(Y\). (This is compatible with thinking about &lsquo;every boy&rsquo;
as a restricted quantifier that combines with a predicate to form a
sentence that is true iff every boy satisfies that predicate.) One
virtue of this notational scheme is that it lets us represent
relations between predicates that cannot be captured with
&lsquo;\(\forall\)&rsquo;, &lsquo;\(\exists\)&rsquo;, and the sentential
connectives; see Rescher (1962), Wiggins (1980). For example, most
boys sang iff the boys who sang outnumber the boys who did not sing.
So we can say that &lsquo;most&rsquo; indicates a function that maps
\(\langle X, Y \rangle\) to <strong>T</strong> iff the number of things that
both \(Y\) and \(X\) map to <strong>T</strong> exceeds the number of things
that \(Y\) but not \(X\) maps to <strong>T</strong>.</p>

<p>
Using restricted quantifiers, and thinking about determiners as
devices for indicating relations between functions, also suggests an
alternative to Russell&rsquo;s treatment of &lsquo;the&rsquo;. The
formula</p>

\[\lsquo \exists x \{B(x) \land \forall y
[B(y) \rightarrow x = y] \land S(x)\}\rsquo\]

<p> can be rewritten
as <span class="nw">&lsquo;\(\exists x{:}B(x)[S(x)] \land |B| =
1\)&rsquo;</span>, interpreted as follows: for some individual \(x\)
such that \(x\) is a boy, \(x\) sang; and the number of (relevant)
boys is exactly one. On this view, &lsquo;the boy&rsquo; still does
not correspond to a constituent of the formalism; nor does
&lsquo;the&rsquo;. But one can depart farther from Russell&rsquo;s
notation, while emphasizing his idea that &lsquo;the&rsquo; is
relevantly like &lsquo;some&rsquo; and &lsquo;every&rsquo;. For one
can analyze &lsquo;the boy sang&rsquo; as
&lsquo;\(!x:\textrm{Boy}(x)[\textrm{Sang}(x)]\)&rsquo;, specifying the
propositional contribution of &lsquo;\(!\)&rsquo;&mdash;on a par with
as &lsquo;\(\exists\)&rsquo; and &lsquo;\(\forall\)&rsquo;&mdash;as
follows:</p>

\[!x:Y(x)[X(x)] = \textbf{T} \text{ iff the extensions of } X 
\text{ and } Y \text{ intersect &amp; } |Y| = 1.\]

<p>
This way of encoding Russell&rsquo;s theory preserves his central
claim. While there may be a certain boy that a speaker refers to in
saying &lsquo;The boy sang&rsquo;, that boy is not a constituent of
the quantificational proposition expressed with
&lsquo;\(!x:\textrm{Boy}(x)[\textrm{Sang}(x)]\)&rsquo;; see Neale (1990) for discussion. But
far from showing that the logical form of &lsquo;The boy sang&rsquo;
<em>diverges</em> dramatically from its grammatical form, the
restricted quantifier notation suggests that the logical form closely
<em>parallels </em>the grammatical form. For &lsquo;the boy&rsquo; and
&lsquo;the&rsquo; do correspond to constituents of
&lsquo;\(!x:B(x)[S(x)]\)&rsquo;, at least if we allow for logical forms
that represent quantificational propositions in terms of second-order
relations; see Montague (1970), and for discussion of relevant
constraints on how such relations can be expressed with
quantificational determiners, see Barwise and Cooper (1981),
Higginbotham and May (1981), Keenan (1996), and the article on
 <a href="../generalized-quantifiers/index.html">generalized quantifiers</a>.</p>

<p>
It is worth noting, briefly, a potential implication for inferences
like &lsquo;The boy sang, so some boy sang&rsquo;. If the logical form
of &lsquo;The boy sang&rsquo; is</p>

\[\lsquo\exists x{:}B(x) [S(x)] \land |B| = 1\rsquo ,\]

<p>
then the inference is an
instance of the schema &lsquo;\(\textbf{A} \land \textbf{B}\), so
\(\textbf{A}\)&rsquo;. But if the logical form of &lsquo;The boy
sang&rsquo; is simply &lsquo;\(!(x){:}B(x)[S(x)]\)&rsquo;, the premise
and conclusion have the same form, differing only by substitution of
&lsquo;\(!\)&rsquo; for &lsquo;\(\exists\)&rsquo;. In which case, the
impeccability of the inference depends on the specific contributions
of &lsquo;the/\(!\)&rsquo; and &lsquo;some/\(\exists\)&rsquo;. Only
when these contributions are &ldquo;spelled out,&rdquo; perhaps in
terms of set-intersection, would the validity of the inference be
manifest; see, e.g., King (2002). So even if grammar and logic do not
diverge in this case, one might say that grammatical structure does
not
<em>reveal</em> the logical structure. From this perspective, further
analysis of &lsquo;the&rsquo; is required. Those who are skeptical of
an analytic/synthetic distinction can say that it remains more a
decision than a discovery to say that &lsquo;Some boy sang&rsquo;
follows from &lsquo;The boy sang&rsquo;. In general, and especially
with regard to aspects of propositional form indicated with individual
words, issues about logical form are connected with issues about the
 <a href="../analytic-synthetic/index.html">analytic-synthetic distinction</a>.</p>

<h2><a name="tran">8. Transformational Grammar</a></h2>

<p>
Even given restricted quantifiers (and acceptance of second-order
logical forms), the subject/predicate structure of &lsquo;Juliet /
likes every doctor&rsquo; diverges from the corresponding formula
below.</p>

\[\forall y{:}\textrm{Doctor}(y) [\textrm{Likes}(\textrm{Juliet}, y)]
\]

<p>
We can rewrite &lsquo;\(\textrm{Likes}(\textrm{Juliet}, y)\)&rsquo; as
&lsquo;\([\textrm{Likes}(y)](\textrm{Juliet})\)&rsquo;, to reflect the
fact that &lsquo;likes&rsquo; combines with a direct object to form a
phrase, which in turn combines with a subject. But this does not
affect the main point: &lsquo;every&rsquo; seems to be a grammatical
constituent of the verb phrase &lsquo;likes every doctor&rsquo;; yet
it also seems to indicate the main quantifier of the expressed
proposition. In natural language, &lsquo;likes&rsquo; and &lsquo;every
doctor&rsquo; form a phrase. But with respect to logical form, it is
as if &lsquo;likes&rsquo; combines with &lsquo;Juliet&rsquo; and a
variable to form a complex predicate that is in turn an external
argument of the higher-order predicate &lsquo;every&rsquo;. Similar
remarks apply to &lsquo;Some boy likes every doctor&rsquo; and</p>

\[\lsquo[\exists x{:}\textrm{Boy}(x)][\forall y{:}\textrm{Doctor}(y)]\{\textrm{Likes}(x,y)\}\rsquo.\]

<p>
So it
seems that mismatches remain in the very places that troubled medieval
logicians&mdash;viz., quantificational direct objects and other
examples of complex predicates with quantificational constituents.</p>

<p>
Montague (1970, 1974) showed that these mismatches do not preclude
systematic connections of natural language sentences with the
corresponding propositional structures. Abstracting from the technical
details, one can specify an algorithm that pairs each natural language
sentence that contains one or more quantificational expressions like
&lsquo;every doctor&rsquo; with one or more Fregean logical forms.
This was a significant advance. Together with subsequent developments,
Montague&rsquo;s work showed that Frege&rsquo;s logic was compatible
with the idea that quantificational constructions in natural language
have a systematic semantics. Indeed, one can use Frege&rsquo;s formal
apparatus to study such constructions. Montague maintained that the
syntax of natural language was, nonetheless, misleading for purposes
of (what he took to be) real semantics. On this view, the study of
valid inference still suggests that grammar disguises the structure of
propositional thought. But in thinking about the relation of logic to
grammar, one should not assume a naive conception of the latter.</p>

<p>
For example, the grammatical form of a sentence need not be determined
by the linear order of its words. Using brackets to disambiguate, we
can distinguish the sentence &lsquo;Mary [saw [the [boy [with
binoculars]]]]&rsquo;&mdash;whose direct object is &lsquo;the boy with
binoculars&rsquo;&mdash;from the homophonous sentence &lsquo;Mary
[[saw [the boy]] [with binoculars]]&rsquo;, in which &lsquo;saw the
boy&rsquo; is modified by an adverbial phrase. The first implies that
the boy had binoculars, while the second implies that Mary used
binoculars to see the boy. Even if this distinction is not audibly
marked, there is a significant difference between modifying a noun
(like &lsquo;boy&rsquo;) with a prepositional phrase and modifying a
verb phrase (&lsquo;saw the boy&rsquo;). More generally, grammatical
structure need not be obvious. Just as it may take work to discover
the kind(s) of structure that propositions exhibit, so it may take
work to discover the kind(s) of structure that sentences exhibit. And
many studies of natural language suggest a rich conception of
grammatical form that diverges from traditional views; see especially
Chomsky (1957, 1964, 1965, 1981, 1986, 1995). So we need to ask how
logical forms are related to actual grammatical forms, which linguists
try to discover, since these may differ importantly from any
hypothesized grammatical forms that may be suggested by casual
reflection on spoken language. Appearances may be misleading with
respect to both grammatical and logical form, leaving room for the
possibility that these notions of structure are not so different after
all.</p>

<p>
A leading idea of modern linguistics is that at least some grammatical
structures are transformations of others. Put another way, linguistic
expressions often appear to be displaced from positions canonically
associated with certain grammatical relations that the expressions
exhibit. For example, the word &lsquo;who&rsquo; in (17) is apparently
associated with the internal (direct object) argument position of the
verb &lsquo;saw&rsquo;.</p>

<dl class="sentag tag3em">
<dt>(17)</dt>
<dd>Mary wondered who John saw</dd>
</dl>

<p>
Correspondingly, (17) can be glossed as &lsquo;Mary wondered which
person is such that John saw that person&rsquo;. This invites the
hypothesis that (17) reflects a transformation of the &ldquo;Deep
Structure&rdquo; (17D) into the &ldquo;Surface Structure&rdquo; (17S);
where the subscripts indicate that &lsquo;who&rsquo; bears a certain
grammatical relation, often called &ldquo;movement,&rdquo; to the
coindexed position.</p>

<dl class="sentag tag3em">
<dt>(17D)</dt>
<dd>{Mary [wondered {John [saw who]}]}</dd>

<dt>(17S)</dt>
<dd>{Mary [wondered [who<sub><i>i</i></sub> {John [saw
( &hellip; )<sub><i>i</i></sub> ]}]]}</dd>
</dl>

<p>
The idea is that the embedded clause in (17D) has the same form as
&lsquo;John saw Bill&rsquo;, but in (17S), &lsquo;who&rsquo; has been
displaced from its original argument position. Similar remarks apply
to the question &lsquo;Who did John see&rsquo; and other
question-words like &lsquo;why&rsquo;, &lsquo;what&rsquo;,
&lsquo;when&rsquo;, and &lsquo;how&rsquo;.</p>

<p>
One might also try to explain the synonymy of (18) and (19) by
positing a common deep structure, (18D).</p>

<dl class="sentag tag3em">
<dt>(18)</dt>
<dd>John seems to like Mary</dd>

<dt>(19)</dt>
<dd>It seems John likes Mary</dd>

<dt>(18D)</dt>
<dd>[Seems{John [likes Mary]}]</dd>

<dt>(18S)</dt>
<dd>{John<sub><i>i</i></sub> [seems { ( _ )<sub><i>i</i></sub> [to like Mary]}]}</dd>
</dl>


<p>
If every English sentence needs a subject of some kind, (18D) must be
modified: either by displacing &lsquo;John&rsquo;, as in (18S); or by
inserting a pleonastic subject, as in (19). Note that in (19),
&lsquo;It&rsquo; does not indicate an argument; compare
&lsquo;There&rsquo; in &lsquo;There is something in the garden&rsquo;.
Appeal to displacement also lets one distinguish the superficially
parallel sentences (20) and (21).</p>

<dl class="sentag tag3em">
<dt>(20)</dt>
<dd>John is easy to please</dd>

<dt>(21)</dt>
<dd>John is eager to please</dd>
</dl>

<p>
If (20) is true, John is easily pleased. In which case, it is easy
(for someone) to please John; and here, &lsquo;it&rsquo; is
pleonastic. But if (21) is true, John is eager that he please someone
or other. This asymmetry is effaced by representations like
&lsquo;Easy-to-please(John)&rsquo; and
&lsquo;Eager-to-please(John)&rsquo;. The contrast is made manifest,
however, with (20S) and (21S); where &lsquo;e&rsquo; indicates an
unpronounced argument position.</p>

<dl class="sentag tag3em">
 <dt>(20S)</dt>
 <dd>{John<sub><i>i</i></sub> [is easy { e [to please (
_ )<sub><i>i</i></sub> ]}]}</dd>

  <dt>(21S)</dt>
  <dd>{John<sub><i>i</i></sub> [is eager { ( _
)<sub><i>i</i></sub> [to please e ]}]}</dd>
</dl>

<p>
It may be that in (21S), which does not mean that it is eager for John
to please someone, &lsquo;John&rsquo; is grammatically linked to the
coindexed position without being displaced from that position. But
whatever the details, the &ldquo;surface subject&rdquo; of a sentence
can be the object of a verb embedded within the main predicate, as in
(20S). Of course, such hypotheses about grammatical structure require
defense. But Chomsky and others have long argued that such hypotheses
are needed to account for various facts concerning human linguistic
capacities; see, e.g., Berwick et.al. (2011). As an illustration of
the kind of data that is relevant, note that while (22&ndash;24) are
perfectly fine as expressions of English, (25) is not.</p>

<dl class="sentag tag3em">
 <dt>(22)</dt>
 <dd>The boy who sang was happy</dd>

 <dt>(23)</dt>
 <dd>Was the boy who sang happy</dd>

 <dt>(24)</dt>
 <dd>The boy who was happy sang</dd>

 <dt>(25)</dt>
 <dd>*Was the boy who happy sang</dd>
</dl>

<p>
This suggests that the auxiliary verb &lsquo;was&rsquo; can be
displaced from some positions but not others. That is, while (23S) is
a permissible transformation of (22D), (25S) is not a permissible
transformation of (24D).</p>

<dl class="sentag tag3em">
  <dt>(22D)</dt>
  <dd>{[The [boy [who sang]]] [was happy]}</dd>

  <dt>(23S)</dt>
  <dd>Was<sub><em>i</em></sub> {[the [boy [who sang]]] [
( _ )<sub><em>i</em></sub> happy]}</dd>

  <dt>(24D)</dt>
  <dd>{[The [boy [who [was happy]]]] sang}</dd>

  <dt>(25S)</dt>
  <dd>*Was<sub><em>i</em></sub> {[the [boy [who [ ( _
)<sub><em>i</em></sub> happy]]]] sang}</dd>
</dl>


<p>
In (25), the asterisk indicates intuitive deviance; in (25S), it
indicates the hypothesized source of this deviance&mdash;viz., that
the auxiliary verb cannot be displaced from the embedded relative
clause. The ill-formedness of (25S) is striking, since one can
sensibly ask whether or not the boy who was happy sang. One can also
ask whether or not (26) is true. But (27) is not the yes/no question
corresponding to (26).</p>

<dl class="sentag tag3em">
  <dt>(26)</dt>
  <dd>The boy who was lost kept crying</dd>

  <dt>(27)</dt>
  <dd>Was the boy who lost kept crying</dd>
</dl>

<p>
Rather, (27) is the yes/no question corresponding to &lsquo;The boy
who lost was kept crying&rsquo;, which has an unexpected meaning. So
we want some account of why (27) cannot have the interpretation
corresponding to (26). But this &ldquo;negative fact&rdquo; concerning
(27) is precisely what one would expect if &lsquo;was&rsquo; cannot be
displaced from its position in (26), as in the following logically
possible but grammatically illicit structure: *Was<sub><i>i</i></sub>
{[the [boy [who [( _ )<sub><i>i</i></sub> lost]]]] [kept crying]}.</p>

<p>
By contrast, if we merely specify an algorithm that associates (27)
with its actual meaning&mdash;or if we merely hypothesize that (27) is
the English translation of a certain mental sentence&mdash;we have not
yet explained why (27) cannot also be used to ask whether or not (26)
is true. Explanations of such facts appeal to nonobvious grammatical
structure, and constraints on natural language transformations. (For
example, an auxiliary verb in a relative clause cannot be
&ldquo;fronted;&rdquo; though of course, theorists try to find deeper
explanations for such constraints.)</p>

<p>
The idea was that a sentence has both a deep structure (DS), which
reflects semantically relevant relations between verbs and their
arguments, and a surface structure (SS) that may include displaced (or
pleonastic) elements. In some cases, pronunciation might depend on
further transformations of SS, resulting in a distinct
&ldquo;phonological form&rdquo; (PF). Linguists posited various
constraints on these levels of grammatical structure, and the
transformations that relate them. But as the theory was elaborated and
refined under empirical pressure, various facts that apparently called
for explanation in these terms still went unexplained. This suggested
another level of grammatical structure, obtained by a different kind
of transformation on SS. The hypothesized level was called
&lsquo;LF&rsquo;, intimating &lsquo;Logical Form&rsquo;; and the
hypothesized transformation&mdash;called &lsquo;Quantifier
Raising&rsquo; because it targeted the kinds of expressions that
indicate (restricted) quantifiers&mdash;mapped structures like (28S)
onto structures like (28L).</p>

<dl class="sentag tag3em">
  <dt>(28S)</dt>
  <dd>{Juliet [likes [every doctor]]}</dd>

  <dt>(28L)</dt>
  <dd>{[every doctor]<sub><em>i</em></sub> {Juliet [
likes ( _ )<sub><em>i</em></sub> ]}}</dd>
</dl>

<p>
Clearly, (28L) does not reflect the pronounced word order in English.
But the idea was that PF determines pronunciation, while LF was said
to be the level at which the scope of a natural language quantifier is
determined; see May (1985). If we think about &lsquo;every&rsquo; as a
kind of second-order transitive predicate, which can combine with two
predicates like &lsquo;doctor&rsquo; and &lsquo;Juliet <span class="nw">likes ( _
)<sub><em>i</em></sub>&rsquo;</span> to form a complete sentence, we should
expect that at some level of analysis, the sentence &lsquo;Juliet
likes every doctor&rsquo; has the structure indicated in (28L). And
mapping (28L) to the Fregean logical
form</p>

\[\lsquo [\forall x{:}\textrm{Doctor}(x)]\{\textrm{Likes}(\textrm{Juliet},
x)\}\rsquo\]

<p>
is trivial.  Similarly, consider the following:</p>

<dl class="sentag tag3em">
  <dt>(29S)</dt>
  <dd>{[some boy] [likes [every doctor]]}</dd>

  <dt>(29L)</dt>
  <dd>{[some boy]<sub><em>i</em></sub> {[every
doctor]j<sub><em>j</em></sub> {( _ )<sub><em>i</em></sub> [likes ( _
)<sub><em>j</em></sub> ]}}</dd>

  <dt>(29L&prime;)</dt>
  <dd>{[every doctor]<sub><em>j</em></sub> {[some
boy]<sub><em>i</em></sub> { ( _ )<sub><em>i </em></sub>[likes ( _
)<sub><em>j</em></sub> ]}}}</dd>
</dl>


<p>If the surface structure
(29S) can be mapped onto either (29L) or (29L&prime;), then (29S) can
be easily mapped onto the Fregean logical
forms</p>

\[\lsquo[\exists x{:}\textrm{Boy}(x)][\forall
y{:}\textrm{Doctor}(y)]\{\textrm{Likes}(x,y)\}\rsquo\]

<p>and</p>

\[\lsquo [\forall y{:}\textrm{Doctor}(y)][\exists x{:} \textrm{Boy}(x)]\{\textrm{Likes}(x,y)\}\rsquo .
\]


<p>
This assimilates quantifier scope ambiguity to the structural
ambiguity of examples like &lsquo;Juliet saw the boy with
binoculars&rsquo;. More generally, many apparent examples of
grammar/logic mismatches were rediagnosed as mismatches between
different aspects of grammatical structure&mdash;between those aspects
that determine pronunciation, and those that determine interpretation.
In one sense, this is fully in keeping with the idea that in natural
language, &ldquo;surface appearances&rdquo; are often misleading with
regard to propositional structure. But it also makes room for the idea
that grammatical structure and logical structure converge, in ways
that can be discovered through investigation, once we move beyond
traditional subject-predicate conceptions of structure with regard to
both logic and grammar.</p>

<p>
There is independent evidence for &ldquo;covert&rdquo;
transformations&mdash;displacement of expressions from their audible
positions, as in (28L); see Huang (1995), Hornstein (1995). Consider
&lsquo;Jean a vu qui&rsquo;, which is the French translation of
&lsquo;Who did John see&rsquo;. If we assume that &lsquo;qui&rsquo;
(&lsquo;who&rsquo;) is displaced at LF, then we can explain why the
question-word is understood in both French and English like a
quantifier binding a variable: which person \(x\) is such that John saw \(x\)?
Similarly, example (30) from Chinese is transliterated as in (31).</p>

<dl class="sentag tag3em">
  <dt>(30)</dt>
  <dd>Zhangsan zhidao Lisi mai-te sheme</dd>

  <dt>(31)</dt>
  <dd>Zhangsan know Lisi bought what</dd>
</dl>

<p>
But (30) is ambiguous, between the interrogative (31a) and the complex
declarative (31b).</p>

<dl class="sentag tag3em">
  <dt>(31a)</dt>
  <dd>Which thing is such that Zhangsan knows Lisi bought
it</dd>

  <dt>(31b)</dt>
  <dd>Zhangsan knows which thing (is such that) Lisi
bought (it)</dd>
</dl>

<p>
This suggests covert displacement of the quantificational
question-word in Chinese; see Huang (1982, 1995). Chomsky (1981) also
argued that the constraints on such displacement can help explain
contrasts like the one illustrated with (32) and (33).</p>

<dl class="sentag tag3em">
  <dt>(32)</dt>
  <dd>Who said he has the best smile</dd>

  <dt>(33)</dt>
  <dd>Who did he say has the best smile</dd>
</dl>


<p>
In (32), the pronoun &lsquo;he&rsquo; can have a bound-variable
reading: which person \(x\) is such that \(x\) said that \(x\) has the best smile.
This suggests that the following grammatical structure is possible:
Who<sub><i>i</i></sub> {[( )<sub><i>i</i></sub> said
[he<sub><i>i</i></sub> has the best smile]]}. But (33) cannot be used
to ask this question, suggesting that some linguistic constraint rules
out the following logically possible structure:
*Who<sub><i>i</i></sub> [did {[he<sub><i>i</i></sub> say [(
)<sub><i>i</i></sub> has the best smile]]]. And there cannot be
constraints on transformations without transformations. So if English
overtly displaces question-words that are covertly displaced in other
languages, we should not be too surprised if English covertly
displaces other quantificational expressions like &lsquo;every
doctor&rsquo;. Likewise, (34) has the reading indicated in (34a) but
not the reading indicated in (34b).</p>

<dl class="sentag tag3em">
<dt>(34)</dt>
<dd>It is false that Juliet likes every doctor</dd>

<dt>(34a)</dt>
<dd>\(\neg \forall x{:}\textrm{Doctor}(x) [\textrm{Likes}(\textrm{Juliet}, x)]\)</dd>

<dt>(34b)</dt>
<dd>\(\forall x{:}\textrm{Doctor}(x) \neg [\textrm{Likes}(\textrm{Juliet}, x)]\)</dd>
</dl>

<p>
This suggests that &lsquo;every doctor&rsquo; gets displaced, but only
so far. Similarly, (13) cannot mean that every doctor is such that no
patient who saw that doctor is healthy.</p>


<dl class="sentag tag3em">
 <dt>(13)</dt>
 <dd>No patient who saw every doctor is healthy</dd>
</dl>

<p>
As we have already seen, English seems to abhor fronting certain
elements from within an embedded relative clause. This invites the
hypothesis that Quantifier Raising is subject to a similar constraint,
and hence, that many quantificational expressions get displaced in
English. This hypothesis is not uncontroversial; see, e.g., Jacobson
(1999). But many linguists (following Chomsky [1995, 2000]) would now
posit only two levels of grammatical structure, corresponding to PF
and LF&mdash;the thought being that constraints on DS and SS can be
eschewed in favor of a simpler theory that only posits constraints on
how expressions can be combined in the course of constructing complex
expressions that can be pronounced and interpreted. If this
development of earlier theories proves correct, then the only
semantically relevant level of grammatical structure often reflects
covert displacement of audible expressions; see, e.g., Hornstein
(1995). In any case, there is a large body of work suggesting that
many logical properties of quantifiers, names, and pronouns are
reflected in properties of LF.</p>

<p>
For example, if (35) is true, it follows that some doctor treated some
doctor; whereas (36) does not have this consequence:</p>

<dl class="sentag tag3em">
  <dt>(35)</dt>
  <dd>Every boy saw the doctor who treated himself</dd>

  <dt>(36)</dt>
  <dd>Every boy saw the doctor who treated him</dd>
</dl>

<p>
The meanings of (35) and (36) seem to be roughly as indicated in (35a)
and (36a); where &lsquo;\(!\)&rsquo; indicates the contribution of
&lsquo;the&rsquo;.</p>

<dl class="sentag tag3em">
  <dt>(35a)</dt>
  <dd>\([\forall x{:}\textrm{Boy}(x)][!y{:}\textrm{Doctor}(y) \land \textrm{Treated}(y,y)] \{\textrm{Saw}(x,y)\}\)</dd>

  <dt>(36a)</dt>
  <dd>\([\forall x{:}\textrm{Boy}(x)][!y{:}\textrm{Doctor}(y) \land \textrm{Treated}(y,x)] \{\textrm{Saw}(x,y)\}\)</dd>
</dl>

<p>
This suggests that &lsquo;himself&rsquo; is behaving like a variable
bound by &lsquo;the doctor&rsquo;, while &lsquo;every boy&rsquo; can
bind &lsquo;him&rsquo;. And there are independent grammatical reasons
for saying that &lsquo;himself&rsquo; must be linked to &lsquo;the
doctor&rsquo;, while &lsquo;him&rsquo; must not be so linked. Note
that in &lsquo;Pat thinks Chris treated himself/him&rsquo;, the
antecedent of &lsquo;himself&rsquo; must be the subject of
&lsquo;treated&rsquo;, while the antecedent of &lsquo;him&rsquo; must
not be; see Chomsky (1981).</p>

<p>
We still need to enforce the conceptual distinction between LF and the
traditional notion of logical form. There is no guarantee that
structural features of natural language sentences will mirror the
logical features of propositions; cp. Stanley (2000), King (2007). But
this leaves room for the empirical hypothesis that LF reflects at
least a great deal of propositional structure; see Harman (1972),
Higginbotham (1986), Segal (1989), Larson and Ludlow (1993), and the
essay on
 <a href="../propositions-structured/index.html">structured propositions</a>.
 Moreover, even if the LF of a sentence <em>S</em> underdetermines the logical
form of the proposition a speaker expresses with <em>S</em> (on a given
occasion of use), the LF may provide a &ldquo;scaffolding&rdquo; that
can be elaborated in particular contexts, with little or no mismatch
between grammatical and propositional architecture. If some such view
is correct, it might avoid certain (unpleasant) questions prompted by
earlier Fregean views: how can a sentence be used to express a
proposition with a radically different structure; and if grammar is
deeply misleading, why think that our intuitions concerning
impeccability provide reliable evidence about which propositions
follow from which? These are, however, issues that remain
unsettled.</p>

<h2><a name="sem">9. Semantic Structure and Events</a></h2>

<p>
If propositions are the &ldquo;things&rdquo; that really have logical
form, and sentences of English are not themselves propositions, then
sentences of English &ldquo;have&rdquo; logical forms only by
association with propositions. But if the meaning of a sentence is
some proposition&mdash;or perhaps a function from contexts to
propositions&mdash;then one might say that the logical form
&ldquo;of&rdquo; a sentence is its semantic structure (i.e., the
structure of that sentence&rsquo;s meaning). Alternatively, one might
suspect that in the end, talk of propositions is just convenient
shorthand for talking about the semantic properties of certain
sentences: perhaps sentences of a Begriffsschrift, or sentences of
mentalese, or sentences of natural languages (abstracting away from
their logically/semantically irrelevant properties). In any case, the
notion of logical form has played a significant role in recent work on
theories of meaning for natural languages. So an introductory
discussion of logical form would not be complete without some hint of
why such work is relevant, especially since attending to details of
natural languages (as opposed to languages invented to study the
foundations of arithmetic) led to renewed discussion of how to
represent propositions that involve relations.</p>

<p>
Prima facie, &lsquo;Every old patient respects some doctor&rsquo; and
&lsquo;Some young politician likes every liar&rsquo; exhibit common
modes of linguistic combination. So a natural hypothesis is that the
meaning of each sentence is fixed by these modes of combination, given
the relevant word meanings. It may be hard to see how this hypothesis
could be true if there are widespread mismatches between logical and
grammatical form. But it is also hard to see how the hypothesis could
be false. Children, who have finite cognitive resources, typically
acquire the capacity to understand the endlessly many expressions of
the languages spoken around them. A great deal of recent work has
focussed on these issues, concerning the connections between logical
form and the senses in which natural languages are semantically
 <a href="../compositionality/index.html">compositional</a>.</p>

<p>
It was implicit in Frege that each of the endlessly many sentences of
an ideal language would have a compositionally determined
truth-condition. Frege did not actually specify an algorithm that
would associate each sentence of his Begriffsschrift with its
truth-condition. But
 <a href="../tarski/index.html">Tarski</a> (1933) showed how to do this for the
 first-order predicate calculus, focussing on interesting cases of
 multiple quantification like the one shown below:</p>

\[\begin{align}
\forall x &amp;[\textrm{Number}(x) \:\rightarrow \\
 &amp; \exists y [\textrm{SuccessorOf}(y, x) 
 \land \forall z [\textrm{SuccessorOf}(z, x) \rightarrow z =  y]]]
\end{align}\]

<p>
This made it possible to capture, with precision, the idea that an
inference is valid in the predicate calculus iff: every interpretation
that makes the premises true also makes the conclusion true, holding
fixed the interpretations of logical elements like &lsquo;if&rsquo;
and &lsquo;every&rsquo;. Davidson (1967a) conjectured that one could
do for English what Tarski did for the predicate calculus; and
Montague, similarly inspired by Tarski, showed how one could start
dealing with predicates that have quantificational
constituents. Still, many apparent objections to the conjecture
remained. As noted at the end of
 <a href="#freg">section four</a>,
 sentences like &lsquo;Pat thinks that Hesperus is Phosphorus&rsquo;
present difficulties; though Davidson (1968) offered an influential
suggestion. Davidson&rsquo;s (1967b) proposal concerning examples like
(37&ndash;40) also proved enormously fruitful.</p>

<dl class="sentag tag3em">
  <dt>(37)</dt>
  <dd>Juliet kissed Romeo quickly at midnight.</dd>

  <dt>(38)</dt>
  <dd>Juliet kissed Romeo quickly.</dd>

  <dt>(39)</dt>
  <dd>Juliet kissed Romeo at midnight.</dd>

  <dt>(40)</dt>
  <dd>Juliet kissed Romeo.</dd>
</dl>

<p>
If (37) is true, so are (38&ndash;40); and if (38) or (39) is true, so
is (40). The inferences seem impeccable. But the function-argument
structures are not obvious. If we represent &lsquo;kissed quickly at
midnight&rsquo; as an unstructured predicate that takes two arguments,
like &lsquo;kissed&rsquo; or &lsquo;kicked&rsquo;, we will represent
the inference from (37) to (40) as having the form: \(K^*(x, y)\); so \(K(x, y)\).
But this form is exemplified by the bad inference &lsquo;Juliet
kicked Romeo; so Juliet kissed Romeo&rsquo;. Put another way, if
&lsquo;kissed quickly at midnight&rsquo; is a logically unstructured
binary predicate, then the following conditional is a nonlogical
assumption: if Juliet kissed Romeo in a certain manner at a certain
time, then Juliet kissed Romeo. But this conditional seems like a
tautology, not an assumption that introduces any epistemic risk.
Davidson concluded that the surface appearances of sentences like
(37&ndash;40) mask relevant semantic structure. In particular, he
proposed that such sentences are understood in terms of quantification
over events.</p>

<p>
According to Davidson, who echoed Ramsey (1927), the meaning of (40)
is reflected in the paraphrase &lsquo;There was a kissing of Romeo by
Juliet&rsquo;. One can formalize this proposal in various ways, with
different implications for how verbs like &lsquo;kiss&rsquo; are
related to propositional constituents: \(\exists e [\textrm{Past}(e)
\land \textrm{KissingOf}(e, \textrm{Romeo}) \land
\textrm{KissingBy}(e, \textrm{Juliet})]\); or \(\exists e
[\textrm{Past}(e) \land \textrm{KissingByOf}(e, \textrm{Juliet},
\textrm{Romeo})]\); or as in (40a), with Juliet and Romeo explicitly
represented as players of certain roles in an event.</p>

<dl class="sentag tag3em">
  <dt>(40a)</dt>
  <dd>\(\exists e [\textrm{Agent}(e, \textrm{Juliet}) \land \textrm{Kissing}(e) \land \textrm{Patient}(e, \textrm{Romeo})]\)</dd>
</dl>

<p>
But given any such representation, adverbs like &lsquo;quickly&rsquo;
and &lsquo;at midnight&rsquo; can be analyzed as additional predicates
of events, as shown in (37a&ndash;39a).</p>

<dl class="sentag tag3em">
<dt>(37a)</dt>
<dd>\(\exists e [\textrm{Agent}(e, \textrm{Juliet}) \land
  \textrm{Kissing}(e) \land \textrm{Patient}(e, \textrm{Romeo})\:\land\)
  \(\textrm{Quick}(e) \land \textrm{At-midnight}(e)]\)</dd>

<dt>(38a)</dt>
<dd>\(\exists e [\textrm{Agent}(e, \textrm{Juliet}) \land
  \textrm{Kissing}(e) \land \textrm{Patient}(e, \textrm{Romeo})\:\land\)
  \(\textrm{Quick}(e)]\)</dd>

<dt>(39a)</dt>
<dd>\(\exists e [\textrm{Agent}(e, \textrm{Juliet}) \land
  \textrm{Kissing}(e) \land \textrm{Patient}(e, \textrm{Romeo})\:\land\)
  \(\textrm{At-midnight}(e)]\)</dd>
</dl>

<p>
If this is correct, then the inference from (37) to (40) is an
instance of the following valid form: \(\exists e [\ldots e \ldots
\land Q(e) \land A(e)]\); hence, \(\exists e [\dots e \dots]\). The
other impeccable inferences involving (37&ndash;40) can likewise be
viewed as instances of conjunction reduction in the scope of an
existential quantifier; see Pietroski (2018) for discussion that
connects this point to medieval insights noted in
 <a href="#mot">section three</a>.
 If the grammatical form of (40) is simply &lsquo;{Juliet [kissed
Romeo]}&rsquo;, then the mapping from grammatical to logical form is
not transparent; and natural language is misleading, in that no word
corresponds to the event quantifier. But this does not posit a
significant structural mismatch between grammatical and logical form.
On the contrary, each word in (40) corresponds to a conjunct in (40a).
This suggests a strategy for thinking about how the meaning of a
sentence like (40) might be composed from the meanings of the
constituent words. A growing body of literature, in philosophy and
linguistics, suggests that Davidson&rsquo;s proposal captures an
important feature of natural language semantics, and that &ldquo;event
analyses&rdquo; provide a useful framework for discussions of logical
form; see, e.g., Schein (2017) for extended discussion and many
references.</p>

<p>
In one sense, it is an ancient idea that action reports like (40)
represent individuals as participating in events; see Gillon&rsquo;s
(2007) discussion of P&#257;&#7751;ini&rsquo;s grammar of Sanskrit.
But if (40) can be glossed as &lsquo;Juliet did some kissing, and
Romeo was thereby kissed&rsquo;, perhaps the ancient idea can be
deployed in developing Leibniz&rsquo; suggestion that relational
sentences like (40) somehow contain simpler active-voice and
passive-voice sentences; cp. Kratzer (1996). And perhaps appeals to
quantifier raising can help in defending the idea that &lsquo;Juliet
kissed <em>some/the/every</em> boy&rsquo; is, after all, a sentence
that exhibits Subject-copula-Predicate form:
&lsquo;[<em>some/the/every</em> boy]<sub><i>i</i></sub> is
<em>P</em>&rsquo;, with &lsquo;<em>P</em>&rsquo; as a complex
predicate akin to &lsquo;[some event]<sub><i>e</i></sub> was both a
kissing done by Juliet and one in which he<sub><i>i</i></sub> was
kissed&rsquo;.</p>

<p>
With this in mind, let&rsquo;s return to the idea that each complex
expression of natural language has semantic properties that are
determined by (i) the semantic properties of its constituents, and
(ii) the ways in which these constituents are grammatically arranged.
If this is correct, then following Davidson, one might say that the
logical forms of expressions (of some natural language) just are the
structures that determine the corresponding meanings given the
relevant word meanings; see Lepore and Ludwig (2002). In which case,
the phenomenon of valid inference may be largely a by-product of
semantic compositionality. If principles governing the meanings of
(37&ndash;40) have the consequence that (40) is true iff an
existential claim like (40a) is true, perhaps this is illustrative of
the general case. Given a sentence of some natural language NL, the
task of specifying its logical form may be inseparable from the task
of providing a compositional specification of what the sentences of NL
mean.</p>

<h2><a name="fq">10. Further Questions</a></h2>

<p>
At this point, many issues become relevant to further discussions of
logical form. Most obviously, there are questions concerning
particular examples. Given just about any sentence of natural
language, one can ask interesting questions (that remain unsettled)
about its logical form. There are also very abstract questions about
the relation of semantics to logic. Should we follow Davidson and
Montague, among others, in characterizing theories of meaning for
natural languages as theories of truth (that perhaps satisfy certain
conditions on learnability)? Is an algorithm that correctly associates
sentences with truth-conditions (relative to contexts) necessary
and/or sufficient for being an adequate theory of meaning? What should
we say about the paradoxes apparently engendered by sentences like
&lsquo;This sentence is false&rsquo;? If we allow for second-order
logical forms, how should we understand second-order quantification,
given Russell&rsquo;s Paradox? Are claims about the &ldquo;semantic
structure&rdquo; of a sentence fundamentally descriptive claims about
speakers (or their communities, or their languages)? Or is there an
important sense in which claims about semantic structure are normative
claims about how we should use language? Are facts about the
acquisition of language germane to hypotheses about logical form? And
of course, the history of the subject reveals that the answers to the
central questions are by no means obvious: what is logical structure,
what is grammatical structure, and how are they related? Or put
another way, what kinds of structures do propositions and sentences
exhibit, and how do thinkers/speakers relate them?</p>
</div>

<div id="bibliography">

<h2><a name="Bib">Bibliography</a></h2>

<h3>Cited Works</h3>

<ul class="hanging">

<li>Barwise, J. &amp; Cooper, R., 1981, &ldquo;Generalized Quantifiers
and Natural Language&rdquo;, <em>Linguistics and Philosophy</em>, 4:
159&ndash;219.</li>

<li>Beaney, M., ed., 1997, <em>The Frege Reader</em>, Oxford:
Blackwell.</li>

<li>Berwick, B. et al., 2011, &ldquo;Poverty of the Stimulus
Revisited&rdquo;, <em>Cognitive Science</em>, 35: 1207&ndash;42.</li>

<li>Boolos, G., 1998, <em>Logic, Logic, and Logic</em>, Cambridge, MA:
Harvard University Press.</li>

<li>Carnap, R., 1950, &ldquo;Empiricism, Semantics, and
Ontology&rdquo;, reprinted in R. Carnap, <em>Meaning and
Necessity</em>; second edition, Chicago: University of Chicago Press,
1956.</li>

<li>Cartwright, R., 1962, &ldquo;Propositions&rdquo;, in R. J. Butler,
<em>Analytical Philosophy</em>, 1st series, Oxford: Basil Blackwell
1962; reprinted with addenda in Richard Cartwright, <em>Philosophical
Essays</em>, Cambridge, MA: MIT Press 1987.</li>

<li>Chomsky, N., 1957, <em>Syntactic Structures</em>, The Hague:
Mouton.</li>

<li>&ndash;&ndash;&ndash;, 1964, <i>Current Issues in Linguistic
Theory</i>, The Hague: Mouton.</li>

<li>&ndash;&ndash;&ndash;, 1965, <em>Aspects of the Theory of
Syntax</em>, Cambridge, MA: MIT Press.</li>

<li>&ndash;&ndash;&ndash;, 1981, <em>Lectures on Government and
Binding</em>, Dordrecht: Foris.</li>

<li>&ndash;&ndash;&ndash;, 1986, <em>Knowledge of Language</em>, New
York: Praeger.</li>

<li>&ndash;&ndash;&ndash;, 1995, <em>The Minimalist Program</em>,
Cambridge, MA: MIT Press.</li>

<li>Davidson, D., 1967a, &ldquo;Truth and Meaning&rdquo;,
<em>Synthese</em>, 17: 304&ndash;23.</li>

<li>&ndash;&ndash;&ndash;, 1967b, &ldquo;The Logical Form of Action
Sentences&rdquo;, in N. Rescher (ed.), <em>The Logic of Decision and
Action</em>, Pittsburgh: University of Pittsburgh Press.</li>

<li>&ndash;&ndash;&ndash;, 1968, &ldquo;On Saying That&rdquo;,
<em>Synthese</em>, 19: 130&ndash;46.</li>

<li>&ndash;&ndash;&ndash;, 1980, <em>Essays on Actions and
Events</em>, Oxford: Oxford University Press.</li>

<li>&ndash;&ndash;&ndash;, 1984, <em>Inquiries into Truth and
Interpretation</em>, Oxford: Oxford University Press.</li>

<li>Donnellan, K., 1966, &ldquo;Reference and Definite
Descriptions&rdquo;, <em>Philosophical Review</em>, 75:
281&ndash;304.</li>

<li>Fodor, J., 1978, &ldquo;Propositional Attitudes&rdquo;, <em>The
Monist</em>, 61: 501&ndash;23.</li>

<li>Frege, G., 1879, <em>Begriffsschrift</em>, reprinted in Beaney
1997.</li>

<li>&ndash;&ndash;&ndash;, 1884, <em>Die Grundlagen der
Arithmetik</em>, Breslau: Wilhelm Koebner. English translation,
<em>The Foundations of Arithmetic</em>, J. L. Austin (trans). Oxford:
Basil Blackwell, 1974.</li>

<li>&ndash;&ndash;&ndash;, 1891, &ldquo;Function and Concept&rdquo;,
reprinted in Beaney 1997.</li>

<li>&ndash;&ndash;&ndash;, 1892, &ldquo;On Sinn and Bedeutung&rdquo;,
reprinted in Beaney 1997.</li>

<li>Gillon, B., 2007, &ldquo;P&#257;&#7751;ini&rsquo;s
A&#7779;&#7789;&#257;dhy&#257;y&#299; and Linguistic Theory&rdquo;,
<em>Journal of Indian Philosophy</em>, 35: 445&ndash;468.</li>

<li>Harman, G., 1972, &ldquo;Logical Form&rdquo;, <em>Foundations of
Language</em>, 9: 38&ndash;65.</li>

<li>&ndash;&ndash;&ndash;, 1973, <em>Thought</em>, Princeton: Princeton
University Press.</li>

<li>Higginbotham, J., 1986, &ldquo;Linguistic Theory and
Davidson&rsquo;s Program in Semantics&rdquo;, in E. Lepore (ed.),
<em>Truth and Interpretation</em>, pp. 29&ndash;48, Oxford:
Blackwell.</li>

<li>Higginbotham, J. &amp; May, R., 1981, &ldquo;Questions,
Quantifiers, and Crossing&rdquo;, <em>Linguistic Review</em>, 1:
47&ndash;79.</li>

<li>Hornstein, N., 1995, <em>Logical Form: From GB to Minimalism</em>,
Oxford: Blackwell.</li>

<li>Huang, J., 1995, &ldquo;Logical Form&rdquo;, in G. Webelhuth
(ed.), <em>Government and Binding Theory and the Minimalist Program:
Principles and Parameters in Syntactic Theory</em>, pp. 127&ndash;175,
Oxford: Blackwell.</li>

<li>Iacona, A., 2018, <em>Logical Form: Between Logic and Natural
Language</em>, Berlin: Springer.</li>

<li>Jacobson, P., 1999, &ldquo;Variable Free Semantics&rdquo;,
<em>Linguistics and Philosophy</em>, 22: 117&ndash;84.</li>

<li>King, J., 2002, &ldquo;Two Sorts of Claims about Logical Form
&rdquo; in Preyer and Peter 2002.</li>

<li>&ndash;&ndash;&ndash;, <em>The Nature and Structure of
Content</em>, Oxford: Oxford University Press.</li>

<li>Keenan, E., 1996, &ldquo;The Semantics of Determiners&rdquo;, in
S. Lappin (ed.), <em>The Handbook of Contemporary Semantic
Theory</em>, Oxford: Blackwell, pp. 41&ndash;63.</li>

<li>Kratzer, A., 1986, &ldquo;Severing the External Argument from its
Verb&rdquo;, in J. Rooryck and L. Zaring (eds.), <em>Phrase Structure
and the Lexicon</em>, Dordrecht: Kluwer, pp. 109&ndash;137.</li>

<li>Larson, R. and Ludlow, P., 1993, &ldquo;Interpreted Logical
Forms&rdquo;, <em>Synthese</em>, 95: 305&ndash;55.</li>

<li>Lepore, E. and Ludwig, K., 2002, &ldquo;What is Logical
Form?&rdquo;, in Preyer and Peter 2002, pp. 54&ndash;90.</li>

<li>Ludlow, P., 2002, &ldquo;LF and Natural Logic&rdquo;, in Preyer
and Peter 2002, pp. 132&ndash;168.</li>

<li>May, R., 1985, <em>Logical Form: Its Structure and
Derivation</em>, Cambridge, MA: MIT Press.</li>

<li>Montague, R., 1970, &ldquo;English as a Formal Language&rdquo;, in
R. Thomason (ed.), <em>Formal Philosophy</em>, New
Haven, CT: Yale University Press, 1974, pp. 7&ndash;27.</li>

<li>Parsons, T., 2014, <em>Articulating Medieval Logic</em>, Oxford:
Oxford University Press.</li>

<li>Pietroski, P., 2018, <em>Conjoining Meanings</em>, Oxford: Oxford
University Press.</li>

<li>Preyer, G. and Peter, G. (eds.), 2002, <em>Logical Form and
Language</em>, Oxford: Oxford University Press.</li>

<li>Quine, W.V.O., 1950, <em>Methods of Logic</em>, New York: Henry
Holt.</li>

<li>&ndash;&ndash;&ndash;, 1951, &ldquo;Two Dogmas of
Empiricism&rdquo;, <em>Philosophical Review</em>, 60:
20&ndash;43.</li>

<li>&ndash;&ndash;&ndash;, 1953, &ldquo;On What There Is&rdquo;, in
<i>From a Logical Point of View</i>, Cambridge, MA:
Harvard University Press, pp. 1&ndash;19.</li>

<li>&ndash;&ndash;&ndash;, 1960, <em>Word and Object</em>, Cambridge
MA: MIT Press.</li>

<li>&ndash;&ndash;&ndash;, 1970, <em>Philosophy of Logic</em>,
Englewood Cliffs, NJ: Prentice Hall.</li>

<li>Ramsey, F., 1927, &ldquo;Facts and Propositions&rdquo;,
<em>Proceedings of the Aristotelian Society</em> (Supplementary
Volume), 7: 153&ndash;170.</li>

<li>S&agrave;nchez, V., 1991, <em>Studies on Natural Logic and
Categorial Grammar</em>, Ph.D. Thesis, University of Amsterdam.</li>

<li>&mdash;1994, &ldquo;Montonicity in Medieval Logic&rdquo;,
<i>Language and Cognition</i>, 4: 161&ndash;74.</li>

<li>Schein, B., 1993, <i>Events and Plurals</i>, Cambridge, MA: MIT
Press.</li>

<li>&ndash;&ndash;&ndash;, 2017, <em>And: Conjunction Reduction
Redux</em>, Cambridge, MA: MIT Press.</li>

<li>Segal, G., 1989, &ldquo;A Preference for Sense and
Reference&rdquo;, <em>The Journal of Philosophy</em>, 86:
73&ndash;89.</li>

<li>Soames, S., 1987, &ldquo;Direct Reference, Propositional
Attitudes, and Semantic Content&rdquo;, <em>Philosophical Topics</em>,
15: 47&ndash;87.</li>

<li>&ndash;&ndash;&ndash;, 1995, &ldquo;Beyond Singular
Propositions&rdquo;, <em>Canadian Journal of Philosophy</em>, 25:
515&ndash;50.</li>

<li>&ndash;&ndash;&ndash;, 2002, <em>Beyond Rigidity</em>, Oxford:
Oxford University Press.</li>

<li>Sommers, F., 1984, <em>The Logic of Natural Language</em>, Oxford:
Oxford University Press.</li>

<li>Stanley, J., 2000, &ldquo;Context and Logical Form&rdquo;,
<em>Linguistics and Philosophy</em>, 23: 391&ndash;434.</li>

<li>Strawson, P., 1950, &ldquo;On Referring&rdquo;, <em>Mind</em>, 59:
320&ndash;44.</li>

<li>Tarski, A., 1933, &ldquo;The Concept of Truth in Formalized
Languages&rdquo;, reprinted in Tarski 1983.</li>

<li>&ndash;&ndash;&ndash;, 1944, &ldquo;The Semantic Conception of
Truth&rdquo;, <em>Philosophy and Phenomenological Research</em>, 4:
341&ndash;75.</li>

<li>&ndash;&ndash;&ndash;, 1983, <em>Logic, Semantics,
Metamathematics</em>, J. Corcoran (ed.), J.H. Woodger (trans.), 2nd
edition, Indianapolis: Hackett.</li>

<li>van Benthem, J., 1986, <i>Essays in Logical Semantics</i>,
Dordrecht: D. Reidel.</li>

<li>Wiggins, D., 1980, &ldquo;&lsquo;Most&rsquo; and
&lsquo;all&rsquo;: some comments on a familiar programme, and on th
clogical form of quantified sentences&rdquo;, in M. Platts (ed.)
<i>Reference, truth and reality: Essays on the philosophy of
language</i>, London: Routledge &amp; Kegan
Paul, pp. 318&ndash;346.</li>

<li>Wittgenstein, L., 1921, <i>Tractatus Logico-Philosophicus</i>, D.
Pears and B. McGuinness (trans.), London: Routledge &amp; Kegan
Paul.</li>

<li>&ndash;&ndash;&ndash;, 1953. <i>Philosophical Investigations</i>,
New York: Macmillan.</li>
</ul>

<h3>Some Other Useful Works</h3>

<p>
A few helpful overviews of the history and basic subject matter of
logic:</p>

<ul class="hanging">

<li>Kneale, W. &amp; Kneale, M., 1962, <em>The Development of
Logic</em>, Oxford: Oxford University Press; reprinted 1984.</li>

<li>Sainsbury, M., 1991, <em>Logical Forms</em>, Oxford:
Blackwell.</li>

<li>Broadie, A., 1987, <em>Introduction to Medieval Logic</em>,
Oxford: Oxford University Press.</li>

<li>For these purposes, Russell&rsquo;s most important books are:
<em>Introduction to Mathematical Philosophy</em>, London: George Allen
and Unwin, 1919; <em>Our Knowledge of the External World</em>, New
York: Norton, 1929; and <em>The Philosophy of Logical Atomism</em>, La
Salle, Ill: Open Court, 1985. Stephen Neale&rsquo;s
book <em>Descriptions</em> (Cambridge, MA: MIT Press, 1990) is a
recent development of Russell&rsquo;s theory.</li>
</ul>

<p>
For introductions to Transformational Grammar and Chomsky&rsquo;s
conception of natural language:</p>

<ul class="hanging">

<li>Radford, A., 1988, <em>Transformational Grammar</em>, Cambridge:
Cambridge University Press.</li>

<li>Haegeman, L., 1994, <em>Introduction to Government &amp; Binding
Theory</em>, Oxford: Blackwell.</li>

<li>Lasnik, H. (with M. Depiante and A. Stepanov), 2000, <em>Syntactic
Structures Revisited</em>, Cambridge, MA: MIT Press.</li>
</ul>

<p>
For discussions of work in linguistics bearing directly on issues of
logical form:</p>

<ul class="hanging">

<li>Higginbotham, J., 1985, &ldquo;On Semantics&rdquo;, <em>Linguistic
Inquiry</em>, 16: 547&ndash;93.</li>

<li>Hornstein, N., 1995, <em>Logical Form: From GB to Minimalism</em>,
Oxford: Blackwell.</li>

<li>Larson, R. and Segal, G., 1995, <em>Knowledge of Meaning</em>,
Cambridge, MA: MIT Press.</li>

<li>May, R., 1985, <em>Logical Form: Its Structure and
Derivation</em>, Cambridge, MA: MIT Press.</li>

<li>Neale, S., 1993, <em>Grammatical Form, Logical Form, and
Incomplete Symbols</em>, in A. Irvine &amp; G. Wedeking (eds.),
<em>Russell and Analytic Philosophy</em>, Toronto:
University of Toronto, pp. 97&ndash;139.</li>
</ul>

<p>
For discussions of the Davidsonian program (briefly described in
 <a href="#sem">section nine</a>)
 and appeal to events:</p>

<ul class="hanging">

<li>Davidson, D., 1984, <em>Essays on Truth and Interpretation</em>,
Oxford: OUP.</li>

<li>&ndash;&ndash;&ndash;, 1985, &ldquo;Adverbs of Action&rdquo;, in
B. Vermazen and M. Hintikka (eds.), <em>Essays on Davidson: Actions
and Events</em>, Oxford: Clarendon Press, pp. 230&ndash;241.</li>

<li>Evans, G. &amp; McDowell, J. (eds.), 1976, <em>Truth and
Meaning</em>, Oxford: Oxford University Press.</li>

<li>Higginbotham, J., Pianesi, F. and Varzi, A. (eds.), 2000,
<em>Speaking of Events</em>, Oxford: Oxford University Press.</li>

<li>Ludwig, K. (ed.), 2003, <em>Contemporary Philosophers in Focus:
Donald Davidson</em>, Cambridge: Cambridge University Pres</li>

<li>Lycan, W., 1984, <em>Logical Form in Natural Language</em>,
Cambridge, MA: MIT Press.</li>

<li>Parsons, T., 1990, <em>Events in the Semantics of English</em>
Cambridge, MA: MIT Press.</li>

<li>Pietroski, P., 2005, <em>Events and Semantic Architecture</em>,
Oxford: Oxford University Press.</li>

<li>Taylor, B., 1985, <em>Modes of Occurrence</em>, Oxford:
Blackwell.</li>
</ul>
</div>

<div id="academic-tools">

<h2 id="Aca">Academic Tools</h2>

<blockquote>
<table class="vert-top">
<tr>
<td><img src="../../symbols/sepman-icon.jpg" alt="sep man icon" /></td>
<td><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=logical-form" target="other">How to cite this entry</a>.</td>
</tr>

<tr>
<td><img src="../../symbols/sepman-icon.jpg" alt="sep man icon" /></td>
<td><a href="https://leibniz.stanford.edu/friends/preview/logical-form/" target="other">Preview the PDF version of this entry</a> at the
 <a href="https://leibniz.stanford.edu/friends/" target="other">Friends of the SEP Society</a>.</td>
</tr>

<tr>
<td><img src="../../symbols/inpho.png" alt="inpho icon" /></td>
<td><a href="https://www.inphoproject.org/entity?sep=logical-form&amp;redirect=True" target="other">Look up topics and thinkers related to this entry</a>
 at the Internet Philosophy Ontology Project (InPhO).</td>
</tr>

<tr>
<td><img src="../../symbols/pp.gif" alt="phil papers icon" /></td>
<td><a href="https://philpapers.org/sep/logical-form/" target="other">Enhanced bibliography for this entry</a>
at <a href="https://philpapers.org/" target="other">PhilPapers</a>, with links to its database.</td>
</tr>

</table>
</blockquote>
</div>

<div id="other-internet-resources">

<h2><a name="Oth">Other Internet Resources</a></h2>

<ul>

<li><a href="https://en.wikipedia.org/wiki/Logical_form_(linguistics)">Logical Form (linguistics)</a>,
 entry on Wikipedia</li>

</ul>


</div>

<div id="related-entries">

<h2><a name="Rel">Related Entries</a></h2>

<p>

 <a href="../analysis/index.html">analysis</a> |
 <a href="../analytic-synthetic/index.html">analytic/synthetic distinction</a> |
 <a href="../aristotle-logic/index.html">Aristotle, General Topics: logic</a> |
 <a href="../behaviorism/index.html">behaviorism</a> |
 <a href="../carnap/index.html">Carnap, Rudolf</a> |
 <a href="../davidson/index.html">Davidson, Donald</a> |
 <a href="../descriptions/index.html">descriptions</a> |
 <a href="../frege/index.html">Frege, Gottlob</a> |
 <a href="../frege-theorem/index.html">Frege, Gottlob: theorem and foundations for arithmetic</a> |
 <a href="../generalized-quantifiers/index.html">generalized quantifiers</a> |
 <a href="../logic-classical/index.html">logic: classical</a> |
 <a href="../logic-modal/index.html">logic: modal</a> |
 <a href="../logical-consequence/index.html">logical consequence</a> |
 <a href="../model-theory/index.html">model theory</a> |
 <a href="../names/index.html">names</a> |
 <a href="../prop-attitude-reports/index.html">propositional attitude reports</a> |
 <a href="../propositions/index.html">propositions</a> |
 <a href="../propositions-singular/index.html">propositions: singular</a> |
 <a href="../propositions-structured/index.html">propositions: structured</a> |
 <a href="../quine/index.html">Quine, Willard Van Orman</a> |
 <a href="../reference/index.html">reference</a> |
 <a href="../relations-medieval/index.html">relations: medieval theories of</a> |
 <a href="../rigid-designators/index.html">rigid designators</a> |
 <a href="../russell/index.html">Russell, Bertrand</a> |
 <a href="../russell-paradox/index.html">Russell&rsquo;s paradox</a> |
 <a href="../medieval-syllogism/index.html">syllogism: medieval theories of</a> |
 <a href="../medieval-terms/index.html">terms, properties of: medieval theories of</a> |
 <a href="../vagueness/index.html">vagueness</a>

</p>

</div>

<div id="acknowledgments">

<h3>Acknowledgments</h3>

<p>
The author would like to thank: Christopher Menzel for spotting an
error in an earlier characterization of the generalized quantifier
&lsquo;every&rsquo;, prompting revision of the surrounding discussion;
Karen Carter, Max Heiber, Claus Schlaberg, and David Korfmacher for
catching various typos in previous versions; and for comments on the
intial versions, Susan Dwyer, James Lesher, the editors and
referees.</p>

</div>

<script type="text/javascript" src="local.js"></script>
<script type="text/javascript" src="../../MathJax/MathJaxb198.js?config=TeX-MML-AM_CHTML"></script>

</div><!-- #aueditable --><!--DO NOT MODIFY THIS LINE AND BELOW-->

<!-- END ARTICLE HTML -->

</div> <!-- End article-content -->

  <div id="article-copyright">
    <p>
 <a href="../../info.html#c">Copyright &copy; 2021</a> by

<br />
<a href="http://www.wam.umd.edu/~pietro/" target="other">Paul Pietroski</a>
&lt;<a href="m&#97;ilto:pietro&#37;40umd&#37;2eedu"><em>pietro<abbr title=" at ">&#64;</abbr>umd<abbr title=" dot ">&#46;</abbr>edu</em></a>&gt;
    </p>
  </div>

</div> <!-- End article -->

<!-- NOTE: article banner is outside of the id="article" div. -->
<div id="article-banner" class="scroll-block">
  <div id="article-banner-content">
    <a href="../../fundraising/index.html">
    Open access to the SEP is made possible by a world-wide funding initiative.<br />
    The Encyclopedia Now Needs Your Support<br />
    Please Read How You Can Help Keep the Encyclopedia Free</a>
  </div>
</div> <!-- End article-banner -->

    </div> <!-- End content -->

    <div id="footer">

      <div id="footer-menu">
        <div class="menu-block">
          <h4><i class="icon-book"></i> Browse</h4>
          <ul role="menu">
            <li><a href="../../contents.html">Table of Contents</a></li>
            <li><a href="../../new.html">What's New</a></li>
            <li><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/random">Random Entry</a></li>
            <li><a href="../../published.html">Chronological</a></li>
            <li><a href="../../archives/index.html">Archives</a></li>
          </ul>
        </div>
        <div class="menu-block">
          <h4><i class="icon-info-sign"></i> About</h4>
          <ul role="menu">
            <li><a href="../../info.html">Editorial Information</a></li>
            <li><a href="../../about.html">About the SEP</a></li>
            <li><a href="../../board.html">Editorial Board</a></li>
            <li><a href="../../cite.html">How to Cite the SEP</a></li>
            <li><a href="../../special-characters.html">Special Characters</a></li>
            <li><a href="../../tools/index.html">Advanced Tools</a></li>
            <li><a href="../../contact.html">Contact</a></li>
          </ul>
        </div>
        <div class="menu-block">
          <h4><i class="icon-leaf"></i> Support SEP</h4>
          <ul role="menu">
            <li><a href="../../support/index.html">Support the SEP</a></li>
            <li><a href="../../support/friends.html">PDFs for SEP Friends</a></li>
            <li><a href="../../support/donate.html">Make a Donation</a></li>
            <li><a href="../../support/sepia.html">SEPIA for Libraries</a></li>
          </ul>
        </div>
      </div> <!-- End footer menu -->

      <div id="mirrors">
        <div id="mirror-info">
          <h4><i class="icon-globe"></i> Mirror Sites</h4>
          <p>View this site from another server:</p>
        </div>
        <div class="btn-group open">
          <a class="btn dropdown-toggle" data-toggle="dropdown" href="https://plato.stanford.edu/">
            <span class="flag flag-usa"></span> USA (Main Site) <span class="caret"></span>
            <span class="mirror-source">Philosophy, Stanford University</span>
          </a>
          <ul class="dropdown-menu">
            <li><a href="../../mirrors.html">Info about mirror sites</a></li>
          </ul>
        </div>
      </div> <!-- End mirrors -->
      
      <div id="site-credits">
        <p>The Stanford Encyclopedia of Philosophy is <a href="../../info.html#c">copyright &copy; 2021</a> by <a href="http://mally.stanford.edu/">The Metaphysics Research Lab</a>, Department of Philosophy, Stanford University</p>
        <p>Library of Congress Catalog Data: ISSN 1095-5054</p>
      </div> <!-- End site credits -->

    </div> <!-- End footer -->

  </div> <!-- End container -->

   <!-- NOTE: Script required for drop-down button to work (mirrors). -->
  <script>
    $('.dropdown-toggle').dropdown();
  </script>

</body>

<!-- Mirrored from seop.illc.uva.nl/entries/logical-form/ by HTTrack Website Copier/3.x [XR&CO'2014], Wed, 22 Jun 2022 19:52:18 GMT -->
</html>
